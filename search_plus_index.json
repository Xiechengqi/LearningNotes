{"./":{"url":"./","title":"Introduction","keywords":"","body":"XCQ DAILY LEARNING NOTES Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"网络学习资源整理/":{"url":"网络学习资源整理/","title":"网络学习资源整理","keywords":"","body":"网上学习时总会遇到一些高质量的文章或资料，以前往往就是浏览器收藏或 github star 一下 比如这样： 但浏览器收藏越来越多，github 里的 star 直奔上千，但都是些收藏不看系列... 所以，希望换一种方式“收藏”自己平时学习时遇到的好文和好料！ 中文独立博客 BlogHub - 个人独立博客推荐 全世界4K云旅游 芝加哥大学50000幅油画 同网页实时聊天-开源 全国工资税后计算器 新趣集-发现有趣最新的IT产品 DevOps 和 SRE 邮件技术提问的正道 Wangdoc - 阮一峰搭建的静态文档生成器 Markdown 文档生成工具 github 上整理的 IT 学习资源 能用 js 实现的，最后一定都会用 js 实现 TIOBE 编程语言排行榜 技术人员的发展之路 感恩中国 一个在北京街头乞讨的小姑娘之死：杨丹的故事（转载） 上海有哪些值得加入的互联网公司？ http://wttr.in/ ip.sb 数据库引擎排行榜 上海程序员 落户攻略 一个模拟生成 App 商店展示图的在线工具 掘金高级搜索 Xiechengqi            最新修订时间： 2020-10-09 10:09:48 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"网络学习资源整理/技术学习.html":{"url":"网络学习资源整理/技术学习.html","title":"技术学习","keywords":"","body":"网络学习资源 目录 Linux Shell Python Go Git Gitbook Ansible Prometheus Docker Node Vim Tmux 微服务 Spring Boot Hexo 私有云 HTTPS etcd FrontEnd IOS Linux 鸟哥的 Linux 私房菜 - 基础篇 鸟哥的 Linux 私房菜 - 服务器架设篇 《Linux工具快速教程》 Shell 《Linux命令行与shell脚本编程大全.第3版》) 《Linux Shell脚本攻略（第二版）》 《Shell 编程范例》 《sed and awk 101 hacks》 《高级shell脚本编程指南》 Bash Pitfalls 简洁的 Bash Programming 技巧 The Unix School One-Liners Explained Python Awsome Python Python frameworks, libraries, software and resources - 7w stars python模拟登陆一些大型网站 - github 1w stars 《python爬虫教程，带你从零到一》- 快速入门 《爬虫教程》- 详细 在线编辑python Django 优秀资源大全 Requests urllib BeautifulSoup4 scrapy Go 《The way to go中文版》 《build-web-application-with-golang》 参考百度文库，使用Beego（Golang）开发的开源文库系统 Awsome Go Git 《Pro Git》 《Pro Git》 中文优排 猴子都能懂的GIT入门 廖学峰GIT教程 Git 工作流 使用 GitHub 操作自动化工作流程 《git community book中文版》 《Git Magic》 在线 git 可视化编程学习 Gitbook Gitbook中文文档 Ansible Ansible 专题文章总揽 Ansible github Ansible中文权威指南 《ansible-first-book中文》 Ansible博客系列教程 Prometheus 《Prometheus 中文文档》 Docker 《Docker學習筆記》 docker中文 10张图带你深入理解Docker容器和镜像 - 原文 Marathon - A container orchestration platform for Mesos and DC/OS kubernetes - 生产级别的容器编排系统，自动化的容器部署、扩展和管理 微服务 《微服务gitbook》 Spring Boot Spring Boot 系列文章 Node cnpm - Private npm registry and web for Company 《Node.js区块链开发》 Tmux Tmux 快捷键 & 速查表 & 简明教程 A Tmux crash course: tips and tweaks Tmux - Linux从业者必备利器 tmux shortcuts & cheatsheet 文本三巨头：zsh、tmux 和 vim .tmux 经典配置 https://github.com/gpakosz/.tmux VIM 专注于Vim配置、插件、Vim命令和Vim教程的网站 Vim中的自定义快捷键 插件网站 Vimrc 经典配置 https://spacevim.org/ https://github.com/rafi/vim-config Hexo Hexo Hexo Admin Plugin Hexo Theme Hexo 系列博客 Next 主题 【持续更新】最全Hexo博客搭建+主题优化+插件配置+常用操作+错误分析 主题 https://github.com/JoeyBling/hexo-theme-yilia-plus Vuejs https://zhousiwei.gitee.io/ibooks - [源码] 私有云 《主流的网盘（文档管理）软件镜像部署和使用、运维实战指南》 HTTPS 图解 HTTPS etcd Etcd 使用入门 FrontEnd 前端工程化概述 究竟什么是前端脚手架？ 前端小峰哥的学习笔记 工具 webpack Postman 前端 UI 组件库 Ant Design - antd 是基于 Ant Design 设计体系的 React UI 组件库，主要用于研发企业级中后台产品 Element - 一套为开发者、设计师和产品经理准备的基于 Vue 2.0 的桌面端组件库 Bootstrap - Bootstrap is an open source toolkit for developing with HTML, CSS, and JS. Quickly prototype your ideas or build your entire app with our Sass variables and mixins, responsive grid system, extensive prebuilt components, and powerful plugins built on jQuery 前端工具库 React - A JavaScript library for building user interfaces - 用于构建用户界面的 JavaScript 库 Vue -The Progressive JavaScript Framework - 渐进式 JavaScript 框架 Angulars - One framework.Mobile & desktop IOS ios 学习笔记 Xiechengqi            最新修订时间： 2020-10-09 10:09:48 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"网络学习资源整理/运维博客.html":{"url":"网络学习资源整理/运维博客.html","title":"运维博客","keywords":"","body":"运维博客 团子的小窝 - [源码] - wordpress 运维生存时间 dockone 山月行 - [源码] 胡伟煌 https://www.huweihuang.com/linux-notes/ - gitbook 技术文档 https://www.huweihuang.com - Hexo 博客 运维之窗 博客园 jingsam 代码日志 Sail 小z博客 ARLOOR 果冻想 运维咖啡吧 纯洁的微笑 运维派 Linux 运维部落 jeremy的技术点滴 Xiechengqi            最新修订时间： 2020-10-09 10:09:48 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"网络学习资源整理/工具.html":{"url":"网络学习资源整理/工具.html","title":"工具","keywords":"","body":"工具 科学上网 统计coding时间插件 猪八戒网-IT Md2All Markdown Nice - https://mdnice.github.io/ 在线正则表达式测试 课程图谱-爬虫 海底电缆分布 Jupyter Notebook 上传网站 Linux 常用软件国内镜像 - https://leops.cn/topics/28 百度 AI 开放平台 腾讯 AI 开放平台 萌豚技术组织 | 播放器、音视频、弹幕相关开源开发 ʘᴗʘ Xiechengqi            最新修订时间： 2020-10-09 10:09:48 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"DevOps/":{"url":"DevOps/","title":"DevOps","keywords":"","body":"DevOps TAPD（Tencent Agile Product Development）腾讯的敏捷研发协作平台的 DevOps 架构 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"DevOps/Ops.html":{"url":"DevOps/Ops.html","title":"运维职位知识图谱","keywords":"","body":"运维技能图谱 **[原文链接](https://zhuanlan.zhihu.com/p/66525026） 运维是一个融合多学科(网络、系统、开发、安全、应用架构、存储等)的综合性技术岗位，从最初的网络管理（网管）发展到现在的系统运维工程师、网络运维工程师、安全运维工程师、运维开发工程师等，可以看出，运维的分工一直在细化，并且对综合技能要求越来越高，可以看出，未来运维的发展趋势是高、精、尖，高表示高度，精表示精通，尖表示尖端，也就是运维职场一定要站在一定的技术高度，在多个技术领域中，要精通某项技能，同时对尖端前沿技术一定要能掌控趋势。 一、运维职位的发展和趋势 根据不同的运维领域和技术面以及分工流程三个方面来了解下2019年运维职位的发展趋势。 1、按领域来划分 1）、基础设施运维：IDC/网络运维、服务器/存储设备运维 2）、系统运维：系统中间件运维、云计算平台运维 3）、数据运维：数据库运维、大数据技术平台运维 4）、应用运维：应用软件系统 5）、云平台运维：公有云平台运维 6）、容器运维：基于容器服务的运维 2、按技术切面来分 1）、安全运维 2）、性能运维 3）、数据运维 4）、集成运维 3、按流程来划分 1）、构建/持续集成、发布 2）、安装部署、升级、迁移、合并、扩展 3）、配置、初始化、配置变更 4）、备份、传输、恢复 5）、日志、监控、预警 6）、诊断排查、优化 二、系统运维技能图谱 系统运维是运维的基础，新的一年中，对基础运维技能要求也在提高，打好系统运维基础，才能深入学习后面的各种运维技能。 下图列出了系统运维要掌握的必备技能： 三、web运维技能图谱 web运维是运维岗位中岗位最多的一个，薪资也相对较高，但需要掌握的知识点也比较多，新的技能要掌握，老的运维技能也不能丢，下图列出了web运维要掌握的各种必备技能 四、大数据运维技能图谱 大数据从2017年开始逐渐走到生活的各个角落，2018年在逐渐落地，而在2019年，大数据依然火热，加上国家对大数据产业的扶持，大数据产业在新的一年岗位需求一定会更加大，因此掌握大数据运维技能，就走在了运维的前沿，下图列出了大数据运维要掌握的各种必备技能 五、容器运维技能图谱 容器的产生，是一次IT行业的革命，2015 年到 2016 年，是业界普遍认为的容器技术爆发的一年，短短一年多时间里，容器技术在中国大陆完成了从零星概念到烽火燎原的壮举 时至今日，容器技术在国内大多数企业中落地已成为一种共识，而国内的生态系统，也呈现出了企业产品、开源社区和公有云齐头并进的良好局面。因此，2019年也是容器继续快速落地的一年，下图列出了大数据运维要掌握的各种必备技能 六、数据为王的时代 万丈高楼平地起，高楼稳不稳取决于地基是否扎实。运维数据便是运维管理这座高楼的地基。运维数据大致分为CMDB、日志、生产DB、知识库四个方面。 CMDB中文是配置管理数据库，存储与管理企业IT架构中设备的各种配置信息，主要是IT资产管理信息。 日志数据保护了企业服务器上运行的各种系统产生的应用日志，系统日志、设备日志、数据库日志等数据，这部分数据是企业数据的核心。 DB数据主要是所有IT系统的数据库信息，包括运维管理系统本身的数据库，数据库包含生产数据库、测试数据库、开发数据库三种类型。 知识库主要存储日常开发、测试、运维管理中发生的事件、问题以及一些经典问题的解决和常用的解决方案，主要起到运维管理辅助的功能。 对数据的维护和管理只管重要，特别是日志数据，对运维来说，通过日志可以比较准确全面地知道系统或是设备的运行情况，可以返查问题产生的原因，还原问题发生的整个过程。通过日志也可以提前预测系统可能要发生的问题或是故障，如系统安全日志，如果网络攻 击会在系统安全日志中有一定的体现。 下面简单介绍下，运维重点收集的日志数据有哪些部分以及用途。 1、系统日志 系统日志主要指的是操作系统的日志，主要在/var/log下的各种日志信息。包含系统操作日志、系统安全日志、定时任务日志等。系统日志是运维管理安全模块中审计的重要依据。一般默认的操作系统日志不能满足要求，需要对系统的参数进行修改，如为history命令加上时间戳、IP，并且长久保留历史等功能。并且对日志文件进行处理，不允许用户进行清空命令，只能追加。 2、应用日志 应用日志主要记录应用服务的健康运行情况以及业务操作的具体日志两部分。应用监控运行情况反应应用服务的健康状态，如果应用占用CPU或是内存过高或是忽高忽低不定，都可以通过分析应用日志结合业务操作日志得出结论。业务操作日志可以为业务审计提供主要依据。有一些系统喜欢把业务操作日志写到数据库中，这个也是需要注意的。不过不管在哪个地方，要求是不可缺少的，它为以后业务审计和问题返查提供依据。 3、数据库日志 数据库日志主要反馈数据库的运行情况。通过监控和管理数据库的日志，及时了解数据库的运行情况，遇到问题及时解决等。可以通过数据库日志结合数据库系统自带的数据库如Oracle的系统视图v$开头，MySQL的performance_schema等。虽然数据库的一些信息不是存在日志中而是在数据库里面，但是也可以作为数据库日志的一部分进行管理和监控，已便我们及时知道数据库的监控状况，从而预防可能出现的问题。 4、设备日志 设备日志一般是一个比较容易忽略的地方，但设备日志往往可以反映设备的运行情况。交换机故障，防火墙故障等设备故障都可能引起大面积的系统和服务故障。所以设备日志一定要收集，分析和监控预警。常用的设备日志有交换机日志、防火墙日志、网络安全设备日志等。 这么多的日志，运维要通过各种手段完成日志的收集、过滤分析、可视化展示，那么如何实现这些功能呢，方法很多，例如ELK集成套件（Elasticsearch , Logstash, Kibana）就可以轻松实现日志数据的实时收集、分析传输以及图形化展示。 Elasticsearch是个开源分布式搜索引擎，提供搜集、分析、存储数据三大功能。它的特点有：分布式，零配置，自动发现，索引自动分片，索引副本机制，restful风格接口，多数据源，自动搜索负载等。 Logstash主要是用来日志的搜集、分析、过滤日志的工具，支持大量的数据获取方式。一般工作方式为c/s架构，client端安装在需要收集日志的主机上，server端负责将收到的各节点日志进行过滤、修改等操作在一并发往elasticsearch上去。 Kibana 也是一个开源和免费的工具，Kibana可以为 Logstash 和 ElasticSearch 提供的日志分析友好的 Web 界面，可以帮助汇总、分析和搜索重要数据日志。 另外，还有Filebeat可以替换Logstash作为日志收集工具，Filebeat隶属于Beats。目前Beats包含四种工具： Packetbeat（搜集网络流量数据） Topbeat（搜集系统、进程和文件系统级别的 CPU 和内存使用情况等数据） Filebeat（搜集文件数据） Winlogbeat（搜集Windows事件日志数据） 可以看到，Beats涵盖了所有收集日志数据的各个方面。 那么要如何使用ELK呢，根据日志量的不同，对应的ELK架构也不尽相同，看下面几个常见架构： 此架构主要是将Logstash部署在各个节点上搜集相关日志、数据，并经过分析、过滤后发送给远端服务器上的Elasticsearch进行存储。Elasticsearch再将数据以分片的形式压缩存储，并提供多种API供用户查询、操作。用户可以通过Kibana Web直观的对日志进行查询，并根据需求生成数据报表。 此架构的优点是搭建简单，易于上手。缺点是Logstash消耗系统资源比较大，运行时占用CPU和内存资源较高。另外，由于没有消息队列缓存，可能存在数据丢失的风险。此架构建议供初学者或数据量小的环境使用。 由此衍生出来了第二种架构： 此架构主要特点是引入了消息队列机制，位于各个节点上的Logstash Agent（一级Logstash，主要用来传输数据）先将数据传递给消息队列（常见的有Kafka、Redis等），接着，Logstash server（二级Logstash，主要用来拉取消息队列数据，过滤并分析数据）将格式化的数据传递给Elasticsearch进行存储。最后，由Kibana将日志和数据呈现给用户。由于引入了Kafka（或者Redis）缓存机制，即使远端Logstash server因故障停止运行，数据也不会丢失，因为数据已经被存储下来了。 这种架构适合于较大集群、数据量一般的应用环境，但由于二级Logstash要分析处理大量数据，同时Elasticsearch也要存储和索引大量数据，因此它们的负荷会比较重，解决的方法是将它们配置为集群模式，以分担负载。 此架构的优点在于引入了消息队列机制，均衡了网络传输，从而降低了网络闭塞尤其是丢失数据的可能性，但依然存在Logstash占用系统资源过多的问题，在海量数据应用场景下，可能会出现性能瓶颈。 最后，还有第三种架构： 这个架构是在上面第二个架构基础上改进而来的，主要是将前端收集数据的Logstash Agent换成了filebeat，消息队列使用了kafka集群，然后将Logstash和Elasticsearch都通过集群模式进行构建，此架构适合大型集群、海量数据的业务场景，它通过将前端Logstash Agent替换成filebeat，有效降低了收集日志对业务系统资源的消耗。同时，消息队列使用kafka集群架构，有效保障了收集数据的安全性和稳定性，而后端Logstash和Elasticsearch均采用集群模式搭建，从整体上提高了ELK系统的高效性、扩展性和吞吐量。 七、用大数据思维做运维监控 大数据分析最早就来源于运维人的日志分析，到逐渐发展对各种业务的分析，人们发现这些数据蕴涵着非常大的价值，通过实时监测、跟踪研究对象在互联网上产生的海量行为数据，进行挖掘分析，揭示出规律性的东西，提出研究结论和对策。这就是大数据的用途。 同样，通过大数据分析，我们可以得到各种指标，例如： 1、在业务层面，如团购业务每秒访问数，团购券每秒验券数，每分钟支付、创建订单等。 2、在应用层面，每个应用的错误数，调用过程，访问的平均耗时，最大耗时，95线等 3、在系统资源层面：如cpu、内存、swap、磁盘、load、主进程存活等 4、在网络层面： 如丢包、ping存活、流量、tcp连接数等 而这些指标，刚好是运维特别需要的东西。通过大数据分析出的这些指标，可以解决如下方面的问题： 系统健康状况监控 查找故障根源 系统瓶颈诊断和调优 追踪安全相关问题 那么如何用大数据思维做运维呢，大数据架构上的一个思维就是：提供一个平台让运维方便解决这些问题， 而不是，让大数据平台去解决出现的问题 基本的一个大数据运维架构是这样的： 对于运维的监控，利用大数据思维，需要分三步走： 获取需要的数据 过滤出异常数据并设置告警阀值 通过第三方监控平台进行告警 所有系统最可靠的就是日志输出，系统是不是正常，发生了什么情况，我们以前是出了问题去查日志，或者自己写个脚本定时去分析。现在这些事情都可以整合到一个已有的平台上，我们唯一要做的就是定义分析日志的的逻辑 DevOps常用工具集清单 Operating Systems Linux (RHEL, CentOS, Ubuntu,CoreOS) Unix (Solaris, AIX, HP/UX, etc.) Windows Mac OS X Infrastructure as a Service Amazon Web Services Azure OpenStack Aliyun Virtualization Platforms VMware VirtualBox Vagrant Containerization Tools Docker Rocket Kubernetes Linux OS Installation Kickstart Cobbler Stacki Foreman Configuration Management Ansible Puppet Chef Salstack Compile and Build Systems Gradle Maven Ant Integration System Jenkins Hudson Bamboo Application Servers JBoss Tomcat Jetty Glassfish Weblogic Web Servers Nginx Apache Queues, Caches ActiveMQ RabbitMQ Memcache Databases Percona Server MySQL PostgreSQL MongoDB Cassandra Redis Oracle MS SQL Monitoring, Alerting, and Trending Nagios Graphite Ganglia Cacti PagerDuty Logging PaperTrail Logstash Loggly ELK Splunk Process Supervisors Monit Runit Supervisor God Security Snorby Threat Stack Tripwire Snort Miscellaneous Tools Multihost SSH Wrapper Code Climate Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"网站搭建/":{"url":"网站搭建/","title":"网站搭建","keywords":"","body":"记录搭建网站过程的学习 此在线笔记搭建 笔记模板：gitbook 部署环境：Aliyun OSS 代码托管平台：Github、Gitee CI 和 CD：Github Action 本地编辑：Typora Xiechengqi            最新修订时间： 2020-10-09 10:09:48 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"网站搭建/静态网站生成器.html":{"url":"网站搭建/静态网站生成器.html","title":"静态网站生成器","keywords":"","body":"静态网站生成器 静态网站生成器排行榜 - https://www.staticgen.com/ **Hexo NexT 主题优化 Vuepress - Vue 驱动的静态网站生成器 Gitbook ReadTheDocs Hugo Github HugoThemes 大全 - 官网 Hexo Jekyll Vuepress Jekyll Hugo Hexo Gitbook ReadTheDocs 实例 https://brew.sh - 源码 - Jeklly https://study.bestzuo.cn/#/ - [源码] - Jeklly https://deanattali.com/beautiful-jekyll/ - [源码] - Jeklly 大佬修改 - https://www.liwen.id.au/ https://gaohaoyang.github.io/ - [源码] - Jekyll https://xin-tan.com - [源码] - Vuepress https://shanyue.tech/ - [源码] - Vuepress https://www.xiangyunhuang.com.cn/ - [源码] - Hugo https://xianmin.github.io/hugo-theme-jane/ - [源码] - Hugo https://blog.joway.io - [源码] - Hugo 大佬修改 - https://github.com/LKI/lki.github.io http://www.huweihuang.com/ - [源码] - Hexo https://notes.iissnan.com/ - [源码] - [官网] - Hexo 魔改1 - [源码] https://blinkfox.github.io/ - [源码] - Hexo https://www.kuajie.me/ - [源码] https://github.com/rayleighl/rayleighl.github.io - Hexo https://bestzuo.cn/ - [源码] - Hexo Xiechengqi            最新修订时间： 2020-10-09 10:09:48 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"网站搭建/静态网站部署.html":{"url":"网站搭建/静态网站部署.html","title":"静态网站部署","keywords":"","body":"静态网站的部署 参考 青云静态网站托管方案 部署方法 1、云平台的对象存储服务 2、静态网站托管服务平台 3、 web 服务器 　云平台的对象存储服务 腾讯云对象存储 COS (Cloud Object Storage) - https://cloud.tencent.com/product/cos 阿里云对象存储 OSS (Object Storage Service) - https://cn.aliyun.com/product/oss 华为云对象存储 OBS (Object Storage Service) - https://www.huaweicloud.com/product/obs.html 七牛云对象存储系统（KODO) - https://www.qiniu.com/products/kodo AWS云对象存储 S3 (Simple Storage Service) - https://aws.amazon.com/cn/what-is-cloud-object-storage/ 青云云对象存储 QingStor® - https://www.qingcloud.com/products/qingstor/ 静态网站托管服务平台 Github Pages - https://pages.github.com/ Netlify - https://www.netlify.com/ Gitlab Pages - https://about.gitlab.com/stages-devops-lifecycle/pages/ Gitee 开源中国旗下的码云 - https://gitee.com Coding 腾讯云开发者平台 - https://dev.tencent.com/production Now - https://zeit.co/now 国内，Gitee 速度最快，但绑定域名需要 99 一年 Github Pages Github Pages 官方文档 GitHub Pages 站点在使用上有如下限制： 仓库大小不得超过 1 GB，每月限100 GB 流量，每小时限构建 10 次 每个仓库都可以开启 github pages( 使用 gh-pages 分支) 所有 GitHub Pages 网站（包括使用自定义域正确配置的网站）已经都支持 HTTPS 和 HTTPS 强制实施 不支持服务端代码，比如 PHP、Ruby 或 Python 　Netlify 可以使用 CLI 上传代码 支持自定义域名且自定义域名支持一键开启 https（证书来自 Let's Encrype） 支持强制让用户通过 https 访问网站（开启后此功能后，http 的访问一律会 301 跳转到 https 支持自动构建 支持重定向（Redirects）和重写（Rewrites）功能 数据通过 HTTP2 协议传输 提供 webhooks 与 API Gitlab Pages 可以使用任何静态网站生成器，如 Jekyll、Middleman、Hexo、Hugo、Pelican等 可以配置自定义域名 HTTPS，需要的是上传证书 Gitee Coding 可以免费绑定多个自定义域名 自定义域名可以享有免费 SSL 证书，全站支持 HTTPS 协议 更新代码库就可以自动部署。服务器稳定，香港服务器国外支持也友好 Now 可以使用 CLI 上传代码，或者链接一个 Git 仓库 不仅提供静态网站托管，同时也支持托管 Node.js 服务 支持自定义域名且自定义域名支持一键开启 https（证书来自 Let's Encrype） 数据通过 HTTP2 协议传输 提供 API Xiechengqi            最新修订时间： 2020-10-09 10:09:48 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"网站搭建/静态网站的CI和CD.html":{"url":"网站搭建/静态网站的CI和CD.html","title":"静态网站的CI和CD","keywords":"","body":"静态网站的持续集成和持续部署 本地工作区 - 远程源代码仓库 - 触发编译 - 部署到服务器或oss或其他仓库 一、本地仓库内修改 -> 本地 git repo push 到 github repo ->触发 github action 或 travis 或 jenkins 等 -> 编译并 push 到 aliyun oss、aliyun ecs、gitee repo 等 -> 成功更新网站 使用 github action 终于实现了 gh-pages 和 aliyun oss 的自动部署，但仍然有不满意的地方，比如：每次集成部署时间太长了（10分钟左右），还有就是静态网站无法实现 web 端在线编辑，在 web 端实时编辑功能一直都想有，这样就不局限在哪一台电脑了！！！ Xiechengqi            最新修订时间： 2020-10-09 10:09:48 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"网站搭建/Hugo学习.html":{"url":"网站搭建/Hugo学习.html","title":"Hugo学习","keywords":"","body":"Hugo 学习 安装 https://github.com/gohugoio/hugo/releases 快速开始 hugo new site - 创建一个 Hugo 主题项目 项目目录结构 ├── archetypes │ └── default.md ├── config.toml ├── content ├── data ├── layouts ├── static // 一般存放 css、js、img 等静态资源 └── themes // 存放主题目录 6 directories, 2 files hugo new about.md - 会在 content/ 目录新建 about.md 文件，文件内有自动生成的头 hugo new post/first.md - `` - `` - `` - Xiechengqi            最新修订时间： 2020-10-09 10:09:48 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"网站搭建/CDN.html":{"url":"网站搭建/CDN.html","title":"CDN","keywords":"","body":"CDN 介绍 CDN 全称是 Content Delivery Network，即内容分发网络。CDN 是构建在网络之上的内容分发网络，依靠部署在各地的边缘服务器，通过中心平台的负载均衡、内容分发、调度等功能模块，使用户就近获取所需内容，降低网络拥塞，提高用户访问响应速度和命中率。CDN 的关键技术主要有内容存储和分发技术 jsDeliver + Github https://www.jsdelivr.com/ Xiechengqi            最新修订时间： 2020-10-09 10:09:48 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"网站搭建/图床.html":{"url":"网站搭建/图床.html","title":"图床","keywords":"","body":"图床 chevereto 搭建个人图床 http://img.xiechengqi.top Xiechengqi            最新修订时间： 2020-10-09 10:09:48 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"网站搭建/网盘.html":{"url":"网站搭建/网盘.html","title":"网盘","keywords":"","body":"网盘 使用 cloudreve 搭建个人网盘 http://pan.xiechengqi.top Xiechengqi            最新修订时间： 2020-10-09 10:09:48 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"心灵鸡汤/":{"url":"心灵鸡汤/","title":"心灵鸡汤","keywords":"","body":"干了这碗鸡汤！！！ Xiechengqi            最新修订时间： 2020-10-09 10:09:48 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"心灵鸡汤/心灵鸡汤.html":{"url":"心灵鸡汤/心灵鸡汤.html","title":"语录","keywords":"","body":"    每一件与众不同的绝世好东西，其实都是以无比寂寞的勤奋为前提的，要么是血，要么是汗，要么是大把大把的曼妙青春好时光。     人生不如意十八九 可与语人无二三     没有上进心不是过错 但是会让你错过 - 蔡康永     种一棵树最好的时机是 10 年前 其次是现在     愿得一人心 白首不相离     很多时候，你觉得自己对某个东西感兴趣，是因为不了解     在运气来临之前，越努力，越幸运     与人善言，暖于布帛:伤人以言，深于矛戟 Xiechengqi            最新修订时间： 2020-10-09 10:09:48 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Linux/":{"url":"Linux/","title":"Linux","keywords":"","body":"Linux Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Linux/Linux常用命令.html":{"url":"Linux/Linux常用命令.html","title":"Linux常用命令","keywords":"","body":"记录平时常用易忘的 Linux 命令 【参考】 搞定Linux Shell文本处理工具，看完这篇集锦就够了 - 腾讯云 目录 系统信息 硬件信息 日志管理 搜索命令 find locate whereis which grep ag fd fzf screen wget gcc paping nmap tldr du 系统信息 [Top] 系统信息&&硬件信息查看 uname -a # 查看 Linux 内核版本信息 cat /proc/version # 查看内核版本 cat /etc/os-release # 查看Linux系统版本 cat /etc/issue # 查看系统版本 lsb_release -a # 查看系统版本，可以带各种参数, -a ALL locale -a # 列出所有语系 locale # 当前环境变量中所有编码 hwclock # 查看时间 who # 显示已登录用户 w # 显示已登录用户并显示它们正在执行任务 whoami # 查看当前用户名 logname # 查看初始登录用户名 uptime # 查看服务器启动时间 sar -n DEV 1 10 # 查看网卡网速流量 dmesg # 显示开机信息 lsmod # 查看内核模块 硬件信息 [Top] lscpu# 查看 CPU 信息 more /proc/cpuinfo# 查看 CPU 信息 cat /proc/cpuinfo | grep name | cut -f2 -d: | uniq -c # 查看 CPU 型号和逻辑核心数 getconf LONG_BIT # CPU 运行的位数 cat /proc/cpuinfo | grep 'physical id' | sort | uniq -c # 物理 CPU 个数 cat /proc/cpuinfo | grep flags | grep 'lm' | wc -l # 结果大于 0 则支持 64 位 more /proc/meminfo # 查看内存信息 dmidecode # 查看全面硬件信息 dmidecode | grep \"Product Name\" # 查看服务器型号 dmidecode | grep -P -A5 \"Memory\\s+Device\" | grep Size | grep -v Range # 查看内存插槽 cat /proc/mdstat # 查看软 raid 信息 cat /proc/scsi/scsi # 查看 Dell 硬 raid 信息 ( IBM、HP 需要官方检测工具 ) lspci # 查看硬件信息 lspci | grep RAID # 查看是否支持 RAID lspci -vvv | grep Ethernet # 查看网卡型号 lspci -vvv | grep Kernel | grep driver # 查看驱动模块 modinfo tg2 # 查看驱动版本 ( 驱动模块 ) ethtool -i # 查看网卡驱动版本，先用 ip -a 查看网卡名 日志管理 [Top] 搜索命令 [Top] 1、find 实时查找工具，通过遍历指定路径而完成对文件的查找，精确实时查找，但速度慢，且只能搜索用户具备读取和执行权限的目录 find [选项]|[表达式] ... - 指定搜索范围路径，默认为当前目录 - 指定对符合条件的文件的操作，默认输出至屏幕 [选项] -name - 搜索文件（夹）名 -iname：name的忽略大小写版本 -lname pattern：查找符号连接文件名为pattern的文件 -ilname：lname的忽略大小写版本 -type filetype - 以指定文件类型 filetype 查找文件，filetype 可以是： b：块设备 c：字符设备 d：目录 p：命名管道 f：普通文件 l：符号连接 s：socket -regex \"PATTERN\" - 以 PATTERN 匹配整个文件路径字符串，而不仅仅是文件名称 -iregex - regex 的忽略大小写版本 -inum - 根据文件的 inode 编号查找 -size [+-]n[cwbkMG] - 指定文件长度查找文件。单位可以是： c：字节单位 b：默认以块为单位，块大小为 512 字节 w：以 words 为单位，words 表示两个字节 k：以 1024 字节为单位 M：以 1048576 字节为单位 G：以 1073741824 字节为单位 +或-：文件大小大于或小于 n 单位 [表达式] expr1 expr2 expr1 -a expr2 或 expr1 -and expr2 - 效果一样，若 expr1 是 false 则不执行 expr2 ，反之则执行 expr2 find / -size +10M -a -size -50M -type f - 根目录下搜索大于 10M 且 小于 50M 的普通文件 expr1 -o expr2 或 expr1 -or expr2 - 效果一样，类似上面 实战 # 正则方式查找 .txt 和 pdf $ find . -regex \".*\\(\\.txt|\\.pdf\\)$\" # 查找 txt 和 pdf 文件 $ find . \\( -name \"*.txt\" -o -name \"*.pdf\" \\) -print # 查找所有非 txt 文本 $ find . ! -name \"*.txt\" -print # 最近 7 天被访问过的所有文件 $ find . -atime 7 -type f -print # 寻找大于 2k 的文件 $ find . -type f -size +2k # 找具有可执行权限的所有文件 $ find . -type f -perm 644 -print # 找用户weber所拥有的文件 $ find . -type f -user weber -print # 删除当前目录下所有的swp文件 $ find . -type f -name \"*.swp\" -delete # 将当前目录下的所有权变更为weber $ find . -type f -user root -exec chown weber {} \\ 2、locate 原理 Linux 系统会在 /etc/crontab 设定每天执行一次 updatedb ，而 updatedatedb 这个命令会建立硬盘中的所有档案和目录资料的索引数据库 更新 lib/mlocate/mlocage.db ，执行 locate 命令会在这个索引数据库中查找，所以相比于 find 命令查找 locate 更快 $ cat /etc/crontab 25 6 * * * root test -x /usr/sbin/anacron || ( cd / && run-parts --report /etc/cron.daily ) . . . $ ls /etc/cron.daily mlocate . . . $ cat /etc/cron.daily/mlocate # 可以看到定时执行 updatedb 具体过程 locate 不能查找到上次(一般一天更新一次) updatedb 或变动的文件，所以，需要查找当天变动的文件，可以前执行一边 updatedb ，更新索引数据库，再执行 locate locate [选项] 目标名 [选项] -r - 使用正规运算式 做寻找的条件 # 搜索 /etc/ 目录下名为 passwd 的文件路径 $ locate /etc/passwd /etc/passwd /etc/passwd- /snap/core/7917/etc/passwd /snap/core/8039/etc/passwd # 搜索主目录下以 a 开头的所有文件，且不区分大小写 $ locate -i ~/a 3、whereis whereis [选项] commandName 用于定位命令的二进制可执行文件、源码文件和手册文件 [选项] -b - binaries -m - manuals -s - sources $ whereis docker docker: /usr/bin/docker /etc/docker /usr/libexec/docker /usr/share/man/man1/docker.1.gz # 选项一定要放在 whereis 和 commandName 之间 $ whereis -b docker docker: /usr/bin/docker /etc/docker /usr/libexec/docker 4、which 在当前环境变量 $PATH 路径中，搜快速查找命令可执行文件路径 which [-a] commandName [-a] - 输出所有匹配的结果 $ which docker /usr/bin/docker # -a 必须在 which 和 commandName 之间 $ which -a java /usr/lib/jvm/jdk-12.0.1/bin/java /usr/bin/java 5、grep 6、af 5、grep 8、fzf 命令行交互式模糊匹配 https://github.com/junegunn/fzf screen [Top] yum install screen apt install screen screen - 新建一个会话 screen -S [name] - 新建一个 name 会话 Ctrl+a+d - 暂离当前会话 screen -r -当只有一个会话时，直接重新进入会话 screen -r [name]|[id] - 重新进入 name 会话 screen -ls - 列出已创建的会话 exit - 在需要退出的会话执行 exit ，即删除当前会话 wget [Top] wget - World Wide Web Get wget 支持 http、https 和 ftp 协议，支持 ftp 和 http 下载方式，支持通过 http 代理（ 但不支持通过 socks 代理 ） wget [options]... [URL]... 常用命令 支持断点续传 wget -c URL 获取https地址时不检查证书 wget --no-check-certificate URL 后台下载文件 wget -b URL # 查看下载进度命令：tail -f wget-log 测试下载链接 wget --spider URL 设定下载带宽上线，实现限速下载 wget --limit-rate 数字k(千字节)/m(兆字节) URL 访问需认证的页面 wget --user username -password password URL # 指定–user 和–password参数 wget --user username --ask-password pass URL # 不指定密码，而由网页提示并手动的输入密码 从保存多个链接的文件读取 URL 并下载（又称递归下载） cat > filelist.txt url1 url2 url3 url4 wget -i filelist.txt 限制总下载文件大小 wget -Q 5m -i filelist.txt 想要下载的文件超过5M而退出下载，-Q 参数对单个文件下载不起作用，只能递归下载时才有效 爬取整站 wget --random-wait -r -p -e robots=off -U mozilla http://www.baidu.com wget -c -r -npH -k -nv http://www.baidu.com 参数说明 -c：断点续传 -r：递归下载 -np：递归下载时不搜索上层目录 -nv：显示简要信息 -nd：递归下载时不创建一层一层的目录,把所有文件下载当前文件夹中 -p：下载网页所需要的所有文件(图片,样式,js文件等) -H：当递归时是转到外部主机下载图片或链接 -k：将绝对链接转换为相对链接,这样就可以在本地脱机浏览网页了 -L: 只扩展相对连接，该参数对于抓取指定站点很有用，可以避免向宿主主机 启用地址伪装 -user-agent=\"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.104 Safari/537.36 Core/1.53.4482.400 QQBrowser/9.7.13001.400\" GCC [Top] gcc 编译 c 源文件过程详解 GCC - GNU project C and C++ compiler gcc 命令使用 GNU 推出的基于 C/C++ 的编译器，是开放源代码领域应用最广泛的编译器，具有功能强大，编译代码支持性能优化等特点 经过了这么多年的发展，GCC 已经不仅仅能支持 C 语言；它现在还支持 Ada 语言、C++ 语言、Java 语言、Objective C 语言、Pascal 语言、COBOL 语言，以及支持函数式编程和逻辑编程的 Mercury 语言，等等 gcc [选项] [参数] [选项] -o：指定生成的输出文件 -E：仅执行编译预处理 -S：将C代码转换为汇编代码 -wall：显示警告信息 -c：仅执行编译操作，不进行连接操作 // 无选项编译链接 - 将 test.c 预处理、汇编、编译并链接形成可执行文件，这里未指定输出文件，默认输出为 a.out gcc test.c // 将 test.c 预处理、汇编、编译并链接形成可执行文件 test，-o 选项用来指定输出文件的文件名 gcc test.c -o test // 将 test.c 预处理输出 test.i 文件 gcc -E test.c -o test.i gcc -E test.c //直接在终端输出显示 test.i 文件内容 // 将预处理输出文件 test.i 汇编成 test.s 文件 gcc -S test.c //会生成 test.s 文件 gcc -S test.i gcc -S test.i -o test.s // 将汇编输出文件 test.s 编译输出二进制 test.o 文件 gcc -c test.c //会生成 test.o 文件 gcc -c test.o gcc -c test.s -o test.o // 将编译输出文件 test.o 链接成最终可执行文件 test gcc test.o -o test // 多个文件一起编译 gcc test1.c test2.c -o test //或 gcc -c test1.c -o test1.o gcc -c test2.c -o test2.o gcc test1.o test2.o -o test paping [Top] 安装：https://code.google.com/archive/p/paping/downloads 用于测试主机 tcp 端口连通和延迟 -p, --port N 指定被测试服务的 TCP 端口（必须） --nocolor 屏蔽彩色输出 -t, --timeout 指定超时时长，单位为毫秒，默认值为 1000 -c, --count N 指定测试次数 nmap [Top] https://github.com/nmap/nmap 安装： windows - https://nmap.org/dist/nmap-7.70-setup.exe linux - yum/apt install nmap tldr [Top] Too Long; Didn't Read - https://github.com/tldr-pages/tldr tldr [command] 简化输出 command 的 man 手册 $ tldr grep grep Matches patterns in input text. Supports simple patterns and regular expressions. - Search for an exact string: grep search_string path/to/file - Search in case-insensitive mode: grep -i search_string path/to/file - Search recursively (ignoring non-text files) in current directory for an exact string: grep -RI search_string . - Use extended regular expressions (supporting ?, +, {}, () and |): grep -E ^regex$ path/to/file - Print 3 lines of [C]ontext around, [B]efore, or [A]fter each match: grep -C|B|A 3 search_string path/to/file - Print file name with the corresponding line number for each match: grep -Hn search_string path/to/file - Use the standard input instead of a file: cat path/to/file | grep search_string - Invert match for excluding specific strings: grep -v search_string du du -sh * du -d 0 -h du -d 1 -h htop crontab Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Linux/Linux小知识.html":{"url":"Linux/Linux小知识.html","title":"平时 linux 遇到的问题解决办法和扩展小知识","keywords":"","body":"平时 linux 遇到的问题解决办法和扩展小知识 目录 Linux 密码破解 &&就类似一个bash yum group install \"Development Tools\" adduser 和 useradd 区别 sudo su 和 su 区别 Linux终端颜色设置 Linux系统时钟和硬件时钟 Linux用户见shell实时同步 ssh反向代理实现内网穿透 Linux修改时区 yum 快速找到软件包名 应用权限最小化执行 创建一个无家目录无登录权限的应用用户 CentOS net-tools 软件包详解 CentOS 7.6图形化界面中文显示乱码的问题 解决远程链接的Gtk-WARNING **: cannot open display或Cannot connect to display问题 pushd、popd 切换目录 /etc/motd ssh 登陆后欢迎界面 端口、进程名、进程号互查 Linux adduser 与 useradd 区别 使用 wget 提示无法建立SSL连接 通过编译安装软件时：[Error]运行时找不到.so文件 更换 Ubuntu 18.04 LTS 登录界面背景 执行 make 命令时提示“makefile:2: * 遗漏分隔符 停止” Linux 下 gcc 编译 c 源文件过程详解 创建启动器（.Desktop文件) 浅谈 /etc/skel 文件夹 apt、wget、curl 设置代理端口 shell、终端、终端模拟器 Ubuntu 彻底关闭 dash sudo apt update显示：鉴于仓库 'xxx' 不支持 'i386' 体系结构，跳过配置文件 'xx' 的获取 Linux 中使用 crontab 命令启用自定义定时任务 Linux 添加环境变量 $PATH Linux 手动添加字体文件 #!/usr/bin/env 与 #!/usr/bin区别 永久修改 DNS Linux程序存放目录 更换镜像源 诊断某文件无法修改 Linux terminal 快捷键 通过 PID 查看进程完整信息 文件权限 777 /tmp 目录自动清理 修改时区 Linux 密码破解 启动后一直按 e 键进入可编辑的页面 在可编辑页面，找到 linux16 开头那一行的 LANG=en_US.UTF-8 后面加上 init=/bin/sh，注意最后不要有空格 mount -o remount,rw / passwd root touch /.authorelabel - 更新系统信息 exec /sbin/init 直接进入系统或 exec /sbin/reboot 重启进入即可生效 yum group install \"Development Tools\" adduser 和 useradd 区别 对于 CentOS 来说是没有区别的，adduser 通过符号链接指向 useradd，即 CentOS 只有 useradd 创建一个用户背后的实际操作 在 /etc/passwd 和 /etc/shadow 中创建对应用户名 - useradd newuser 设置用户密码 - passwd newuser 创建家目录 - mkdir /home/newuser 复制 /etc/skel 目录下所有文件到用户家目录 - cp -r /etc/skel/* /home/newuser 更改家目录属主 - chown -R newuser:newuser /home/newuser 指定 shell - usermod -s /bin/bash newuser adduser - 交互式创建用户 adduser 是一个 perl 脚本，通过交互式菜单设定一些用户参数。在输入 adduser 用户名后，会自动创建用户主目录（并复制 `/etc/skel`` 目录下的文件）、指定系统 shell，提示输入用户密码，很简单的就添加了一个标准的普通用户 Adding user `p3terx' ... Adding new group `p3terx' (1002) ... Adding new user `p3terx' (1001) with group `p3terx' ... Creating home directory `/home/p3terx' ... Copying files from `/etc/skel' ... New password: Retype new password: passwd: password updated successfully Changing the user information for p3terx Enter the new value, or press ENTER for the default Full Name []: Room Number []: Work Phone []: Home Phone []: Other []: Is the information correct? [Y/n] useradd - 带参数创建用户 `useradd` 是一个指令，如果不使用任何选项，创建的用户将无密码、无主目录、没有指定 shell。如果你需要正常使用这个账户，就还需要设置密码、创建家目录等额外操作 1、指定用户家目录和 shell useradd -m -s /bin/bash newuser -m - 自动创建用户的家目录，并将 /etc/skel 中的文件复制到家目录中 -s - 指定用户登入后所使用的 shell 2、设置用户密码 passwd newnser 删除用户 1、结束用户所有进程 - pkill -u newuser 2、删除用户及用户家目录 - userdel -r newuser sudo su 和 su 区别 sudo su - 切换输入的是当前用户的密码，因为当前用户拥有 root 权限，所以可以使用 sudo su 使用 root 权限的命令 su - 输入的是 root 的密码 Linux终端颜色设置 命令提示符 - 阮一峰 如果需要设置永久，将一下两行写入 ~/.bashrc，之后 source ~/.bashrc 即可 ls 文件颜色 - alias ls='ls --color=auto' 命令提示符颜色 - **PS1='\\[\\e]0;\\u@\\h: \\w\\a\\]${debian_chroot:+($debian_chroot)}\\[\\033[0;36m\\]\\u@\\h\\[\\033[00m\\]:\\[\\033[01;34m\\]\\w\\[\\033[00m\\]\\$' Linux系统时钟和硬件时钟 Linux系统时间同步的两种方法 国内外常用公共NTP网络时间服务器 之前装 Grafana+Prometheus 时候，恢复快照后 Grafana 就无法展示内容，折腾了一两天，发现是恢复快照后软硬件时间不同步导致的，ntpdate ntp.aliyun.com | hwclock -w 后就可以了。最近，jenkins 触发编译查看日志发现时间又有偏差，看来确实需要整理一下 Linux 时钟问题。 Linux 时钟分为：系统时钟（System Clock）和 硬件时钟（Real Time Clock，简称 RTC） 默认情况下，系统时间和硬件时间并不会自动同步。系统运行过程中，系统时间和硬件时间异步计时，互不干扰 系统时钟是当前 Linux Kernel 的时钟，而硬件时钟是主板上由电池供电的时钟，硬件时钟可在 BIOS 中设置。当 Linux 启动时，硬件时钟会去读取系统时钟的设置，并独立于硬件时间进行计时 Linux 中的所有命令（包括函数）均采用系统时钟 Linux 中，时钟相关的命令主要有 date 和 hwclock 相关命令 date tzselect ntpdate hwclock # 将系统时间写入硬件时间 hwclock --systohc # 将硬件时间写入系统时间 hwclock --hctosys # 将当前时间写入BIOS 避免重启后失效 hwclock -w Linux用户见shell实时同步 1、yum install - y tcl expect 2、查看当前在线用户 w # 或 who 3、使用kibitz命令发起同步（连接） # kibitz -tty pts/[数字] [用户] asking bailong to type: kibitz -1534 另一端可以看到： Message from root@LingYun on pts/4 at 10:09 ... Can we talk? Run: kibitz -1534 EOF 另一端如果想要接受邀请同步，按下回车后输入 [bailong@LingYun ~]$ kibitz -1534 Escape sequence is ^] 此时，终端实现了实时共享，（双方都以root用户执行命令且过程同步输出到两个终端）无论哪方希望退出， 只需要输入 exit即可退出共享的shell终端 ssh反向代理实现内网穿透 内网主机 A，可以连接公网但没有公网 ip 有公网 ip 的主机 B 实现任意主机上登陆主机 A 1、修改服务器 B 的 /etc/sshd_config 配置文件 GatewayPorts yes 2、重启 ssh 服务 3、登录服务器 A 执行如下命令，实现连接到服务器 B 开启反向端口代理，其中 22 为 A 的本地端口，2222 为 B 的监听端口（执行后会要求输入服务器 B 的密码） ssh -CqTfnN -R :2222:localhost:22 root@60.95.190.137 4、登陆 B 可以看到 2222 端口的 sshd 监听进程 netstat -anp | grep :2222 5、使用 2222 端口登陆 B 主机即会提示输入 A 主机密码，输入后即可登陆 A ssh -p 2222 root@[hostA] Linux修改时区 sudo ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime yum 快速找到软件包名 # yum provides vim Loaded plugins: fastestmirror Loading mirror speeds from cached hostfile * base: mirrors.bfsu.edu.cn * extras: mirrors.huaweicloud.com * updates: mirrors.huaweicloud.com https://yum.dockerproject.org/repo/main/centos/7/repodata/repomd.xml: [Errno 14] curl#6 - \"Could not resolve host: yum.dockerproject.org; Unknown error\" Trying other mirror. 2:vim-enhanced-7.4.629-6.el7.x86_64 : A version of the VIM editor which includes recent enhancements Repo : base Matched from: Provides : vim = 7.4.629-6.el7 2:vim-enhanced-7.4.629-6.el7.x86_64 : A version of the VIM editor which includes recent enhancements Repo : installed Matched from: Provides : vim = 7.4.629-6.el7 应用权限最小化执行 比如执行 Prometheus 1、创建用于执行 prometheus 的普通用户 sudo useradd --no-create-home --shell /usr/sbin/nologin prometheus 2、创建用于存储 Prometheus 可执行文件和相关配置的目录 sudo mkdir /etc/prometheus sudo mkdir /var/lib/prometheus 3、将以上目录属主和属组设置为 prometheus 用户，确保 prometheus 用户有访问目录权限 sudo chown prometheus:prometheus /etc/prometheus sudo chown prometheus:prometheus /var/lib/prometheus 创建一个无家目录无登录权限的应用用户 Linux 安装运行用户往往会新创建一个对应的用户，这也是处于安全考虑，常用的创建用户命令就是： sudo useradd --no-create-home --shell /usr/sbin/nologin prometheus CentOS net-tools 软件包详解 net-tools 包里有 ifconfig、netstat、whois 等命令 CentOS 7 默认没有安装该软件包，yum intall -y net-tools 安装 centos 7.6图形化界面中文显示乱码的问题 https://blog.csdn.net/linxue110/article/details/85293022 解决远程链接的Gtk-WARNING **: cannot open display;或Cannot connect to display;问题 [Top] pushd、popd 切换目录 [Top] 使用 cd 切换目录经常想回到之前的目录，但 cd - 只能回到上一个目录，使用 pushd、popd 可以以目录堆栈的方式(FILO，先进后出)前进后退切换目录，结合 dirs 查看堆栈内容（最左边的是栈顶），十分方便！$ pushd ~/桌面/WORK ~/桌面/WORK ~/桌面/codeLearn/Shell/kjyw/redis xcq@xcq:~/桌面/WORK$ pushd ~/桌面/codeLearn/git/github/ ~/桌面/codeLearn/git/github ~/桌面/WORK ~/桌面/codeLearn/Shell/kjyw/redis xcq@xcq:~/桌面/codeLearn/git/github$ dirs ~/桌面/codeLearn/git/github ~/桌面/WORK ~/桌面/codeLearn/Shell/kjyw/redis xcq@xcq:~/桌面/codeLearn/git/github$ popd ~/桌面/WORK ~/桌面/codeLearn/Shell/kjyw/redis xcq@xcq:~/桌面/WORK$ popd ~/桌面/codeLearn/Shell/kjyw/redis xcq@xcq:~/桌面/codeLearn/Shell/kjyw/redis$ dirs ~/桌面/codeLearn/Shell/kjyw/redis /etc/motd ssh 登陆后欢迎界面 [Top] 通过修改 /etc/motd 文件可以自定义 ssh 登录欢迎界面 常用终端 ASCII 码图 在线图片转 ASCII 码网站 aliyun 登录后界面 ``` shell $ ssh root@aliyun Welcome to Ubuntu 18.04.4 LTS (GNU/Linux 4.15.0-48-generic x86_64) Documentation: https://help.ubuntu.com Management: https://landscape.canonical.com Support: https://ubuntu.com/advantage \"If you've been waiting for the perfect Kubernetes dev solution for macOS, the wait is over. Learn how to install Microk8s on macOS.\" https://www.techrepublic.com/article/how-to-install-microk8s-on-macos/ Canonical Livepatch is available for installation. Reduce system reboots and improve kernel security. Activate at: https://ubuntu.com/livepatch Welcome to Alibaba Cloud Elastic Compute Service ! Last login: Fri Jul 3 23:03:28 2020 from 218.82.189.64 root@xcq:~# ## Port、PName、PID互查 [[Top]](#目录) **Port** -> **PID** ``` shell netstat -nlp | grep [Port] PID -> Port nestat -nltp | grep [PID] PName -> PID ps aux | grep [PName] PID -> PName -> Linux adduser 与 useradd 区别 [Top] 一、Debian 或 Ubuntu 主要的区别在使用方式上 adduser adduser 是一个 perl 脚本，通过交互式菜单设定一些用户参数。在输入adduser 用户名 后，会自动创建用户主目录（并复制 /etc/skel 目录下的文件）、指定系统 shell，提示输入用户密码，很简单的就添加了一个标准的普通用户 # 添加用户，会在目录（/home/）增加对应用户家目录 $ adduser au adduser：只有 root 才能将用户或组添加到系统。 $ sudo adduser au [sudo] xcq 的密码： 正在添加用户\"au\"... 正在添加新组\"au\" (1001)... 正在添加新用户\"au\" (1001) 到组\"au\"... 创建主目录\"/home/au\"... 正在从\"/etc/skel\"复制文件... 输入新的 UNIX 密码： 重新输入新的 UNIX 密码： passwd：已成功更新密码 正在改变 au 的用户信息 请输入新值，或直接敲回车键以使用默认值 全名 []: 房间号码 []: 工作电话 []: 家庭电话 []: 其它 []: 这些信息是否正确？ [Y/n] y useradd useradd是一个指令，如果不使用任何选项，创建的用户将无密码、无主目录、没有指定 shell。如果你需要正常使用这个账户，就还需要设置密码、创建家目录等额外操作 对于 useradd 添加标准的普通用户有使用选项和不使用选项两种方式 使用选项 # 添加用户 ua，输入命令添加用户、添加用户目录、指定 bash 为 shell $ useradd -m -s /bin/bash ua # -m 自动创建用户的家目录，并将/etc/skel中的文件复制到家目录中 # -s 指定用户登入后所使用的 shell # 然后对该用户设置密码 $ passwd ua 不使用选项 在不使用选项的情况下，添加一个标准普的通用户的过程相总共有 6 个步骤，略显麻烦，也没必要这样操作。但可以从中了解添加一个用户具体做了哪些事情，对解决一些问题有参考价值。 1、以添加用户名为ua 的用户为例子，输入命令添加用户 $ useradd ua 2、设置密码 $ passwd ua 3、创建家目录 $ mkdir /home/ua 4、将/etc/skel目录下的文件复制到该用户目录 $ cp -r /etc/skel/. /home/ua 5、更改家目录归属 $ chown -R ua:ua /home/ua 6、指定 Shell 为/bin/bash $ usermod -s /bin/bash ua 二、Cen­tOS 两者没有区别 adduser通过符号链接指向useradd，即 Cen­tOS 只有useradd 三、删除用户 如果因为错误的方式添加了用户，而不知道如何解决，可以删除这个用户 以删除 au 这个用户为例子，首先终结该用户所有进程 $ pkill -u au 然后输入删除命令 $ userdel -r au -r 表示删除用户的同时，将其宿主目录和系统内与其相关的内容删除 使用 wget 提示无法建立SSL连接 [Top] [root@localhost ~]# wget https://www.kernel.org/pub/software/scm/git/git-2.0.5.tar.gz --2018-03-22 01:43:37-- https://www.kernel.org/pub/software/scm/git/git-2.0.5.tar.gz Resolving www.kernel.org... 147.75.42.139, 2604:1380:40a0:500::1 Connecting to www.kernel.org|147.75.42.139|:443... connected. ERROR: certificate common name “kernel.org” doesn’t match requested host name “www.kernel.org”. To connect to www.kernel.org insecurely, use ‘--no-check-certificate’. 这是因为 wget 在使用 HTTPS 协议时，默认会去验证网站的证书，而这个证书验证经常会失败，加上 \"--no-check-certificate\" 选项，就能排除掉这个错误 通过编译安装软件时：[Error]运行时找不到.so文件 [Top] 在 linux 下，.so 文件相当与 windows 上的 dll 文件，即动态链接库 在 Linux 下面，共享库(*.so) 的寻找和加载是由 /lib/ld.so 实现的 ld.so 会在标准路经 /lib，/usr/lib 中寻找应用程序用到的共享库 ld.so 也会在存有非标准路径的文件夹 /etc/ld.so.conf.ld 寻找应用程序用到的共享库 动态链接库是为了减少发布程序的大小，可以将具有相同功能的代码模块放在动态链接库中，随应用程序一起发布；而对于应用程序来说，只需要知道其接口就可以，在运行时动态的加载代码到内存中 ./SystemArchitect: error while loading shared libraries: libqt.so.3: cannot open shared object file: No such file or directory 原因：链接器 ld 提示找不到库文件 /etc/ld.so.conf 文件和 /etc/ld.so.conf.d/ 文件夹 Linux 中 ld 的默认目录为 /lib 和 /usr/lib，扩展库路径目录都存储在 /etc/ld.so.conf 文件里，而 /etc/ld.so.conf 的文件内容是include /etc/ld.so.conf.d/*.conf，所以在 /etc/ld.so.conf.d 目录下，加入任何以 .conf 为后缀的文件，都能被 ld 链接器识别 /etc/ld.so.conf 文件 /etc/ld.so.conf.d/文件夹 查看某个库是否安装 # 查看 libqt.so 是否安装 ldconfig -p | grep qt ldconfig -p | grep qt # ldconfig -p: 打印当前缓存所保存的所有库的名字 # grep qt/libqt: 用管道符解析 libqt.so 是否已加入缓存中 # qt 会打印所有 *qt.so.* 库文件信息，可以联想搜索；libqt 只会搜索 libqt.so.* 是否安装，若不存在不会返回显示 ldconfig 是一个动态链接库管理命令，其目的为了让动态链接库为系统所共享 ldconfig 默认搜寻/lib 和 /usr/lib 以及动态库配置文件 /etc/ld.so.conf 内所列的目录下的库文件 ldconfig 会搜索出所有库，进而创建动态装入程序(ld.so)所需的连接和产生缓存文件 /etc/ld.so.cache（该文件保存已排好序的动态链接库名字列表） ldconfig 通常在系统启动时运行，而当用户安装了一个新的动态链接库时，就需要手工运行这个命令 新增库文件（.so文件）方法 若库文件已经在 /lib 和 /usr/lib 里面，是不用修改 /etc/ld.so.conf 文件的，但是添加完后需要调用下 ldconfig，不然添加的 library 会找不到 .so 文件不在 /lib 和 /usr/lib 里，新增库路径方法 直接在 /etc/ld.so.conf 文件中后续添加 将库文件路径写入 /etc/ld.so.conf.d/ 文件夹中的 .conf 文件中 在 /etc/ld.so.conf.d/ 文件夹中添加新的 .conf 文件 如果添加的库不在 /lib 或 /usr/lib 下，但是却没有权限操作写 /etc/ld.so.conf 文件的话，这时就需要往 export 里写一个全局变量LD_LIBRARY_PATH就可以了 ld.so.cache 的更新是递增式的，就像 PATH 系统环境变量一样，不是从头重新建立，而是向上累加，只有重新开机，系统才从零开始建立 ld.so.cache 文件。所以每次修改 /etc/ld.so.conf 文件或 /etc/ld.so.conf.d/ 文件夹都要执行一次命令：ldconfig 更换 Ubuntu 18.04 LTS 登录界面背景 [Top] Ubuntu 18.04 LTS 默认登录界面 修改 /usr/share/gnome-shell/theme/ubuntu.css 或 /usr/share/gnome-shell/theme/gdm3.css 文件 Ubuntu 18.04 用的 Gnome 的桌面，和以前 Unity 桌面配置方式不同，所以 16.04 及以前版本修改方法与此不同 ubuntu.css 和 gdm3.css 内容相同，只需修改其一即可 修改该文件第 1814 行左右（#lockDialogGroup)： 修改前： #lockDialogGroup { background: #2c001e url(resource:///org/gnome/shell/theme/noise-texture.png); background-repeat: repeat; } 修改后： #lockDialogGroup { background: #2c001e url(file:///usr/share/gnome-shell/theme/denglubeijing.jpg); background-repeat: no-repeat; background-size: cover; background-position: center; } 这种方法在执行系统更新 -sudo apt upgrade 后可能以上修改的文件也被更新，再次登录时会发现又变回原来黑界面，所以还需要手动按照以上步骤修改才行 执行 make 命令时提示 “makefile:2: * 遗漏分隔符 停止\" [Top] 分析原因：gcc、rm、cp 前面是 tab 分割符，不能用空格，make 中规定每一 Shell 命令之前的开头必须使用字符 # makefile 文件部分示例 all: gcc -o helloworld helloworld.c fresh: rm -rf Makefile clean: rm -rf helloworld helloworld.o install: cp helloworld /usr/bin uninstall: rm -rf /usr/bin/helloworld Linux 下 gcc 编译 c 源文件过程详解 [Top] gcc 编译过程图 gcc 编译过程文件变化图 Linux 下与 C 语言有关的文件类型 .c - 源代码文件 .h - C语言头文件 .i - 经过预处理之后的源代码文件 .s - 汇编代码文件 .o - 目标代码文件（二进制机器指令文件） .a - 静态对象库文件 .so - 共享（动态）对象库文件 test.c 源文件 预编译（预处理 - Preprocessing） - gcc -E test.c -o test.i test.i 源文件预处理生成的文件 编译（Compilation） - gcc -S test.i -o test.s test.s 经编译生成的汇编文件 此阶段会检查代码逻辑，若出现错误会中断编译提示 test.s 编译出错中断提示 汇编(Assembly) - gcc -c test.s -o test.o test.o 由汇编文件生成的二进制文件 链接(Linking) - gcc test.o test test 链接后生成的可执行文件 多个 c 源文件生成一个可执行文件 方法一、 gcc test1.c test2.c -o test 方法二、 gcc -c test1.c -o test1.o gcc -c test2.c -o test2.o gcc test1.o test2.o -o test 第一种方法编译时需要所有文件重新编译，而第二种方法可以只重新编译修改的文件，未修改的文件不用重新编译 [补充参考] gcc 编译过程详解 创建启动器（.Desktop文件) [Top] 在 Linux 中，一个 .desktop 文件就是一个用来运行程序的快捷方式，没有此文件，你的应用就不会在应用菜单中显示。例如从源代码中编译的程序或者自己下载的压缩格式的应用，每次都需要打开终端来执行它的二进制文件 desktop 文件路径： 仅对当前用户可见：~/.local/share/applications 所有用户可见：/usr/share/applications/ desktop 文件创建 $ touch test.desktop test.desktop 文件内容 [Desktop Entry] Encoding=UTF-8 Name=IntelliJ IDEA GenericName=IntelliJ IDEA Comment=The Java IDE for Professional Developers by JetBrains Exec=/opt/SoftWare/idea-IU-172.4343.14/bin/idea.sh %f Icon=/opt/SoftWare/idea-IU-172.4343.14/bin/idea.png Terminal=false Type=Application Categories=Application;Programme; 语法解释： 关键词 意义 [Desktop Entry] 文件头 Encoding 编码 Name 应用名称 Name[xx] 不同语言的应用名称 GenericName 描述 Comment 注释 Exec 执行的命令 Icon 图标路径 Terminal 是否使用终端 Type 启动器类型 Categories 应用的类型（内容相关） 说明： 其中 Exec 常用的参数有：%f %F %u %U %f：单个文件名，即使选择了多个文件。如果已选择的文件不在本地文件系统中（比如说在HTTP或者FTP上），这个文件将被作为一个临时文件复制到本地，％f将指向本地临时文件； %F：文件列表。用于程序可以同时打开多个本地文件。每个文件以分割段的方式传递给执行程序。 %u：单个URL。本地文件以文件URL或文件路径的方式传递。 %U：URL列表。每个URL以分割段的方式传递给执行程序。本地文件以文件URL或文件路径的方式传递 修改权限: $ chmod 755 test.desktop 浅谈 /etc/skel 文件夹 [Top] skel 是 skeleton 的缩写，每当你新建一个用户的时候 (通过 useradd 命令)，/etc/skel 目录下的文件，都会原封不动的复制到新建用户的家目录下（~/） skel 目录 如果你是一个多用户系统的管理员，你可以在 skel 目录下写个 ReadMe.txt 之类的文件，写一些使用说明，这样每个新建的用户都会在自己的目录下看到这个说明文件了 再比如，你希望新建用户可以直接 startx 就启动到 gnome 桌面环境，你可以在 skel 目录下建立一个 .xinitrc 文件，内容如下： export LC_ALL=\"zh_CN.UTF-8\" export XMODIFIERS=@im=SCIM export GTK_IM_MODULE=\"scim\" eval `dbus-launch --exit-with-session --sh-syntax` exec gnome-session .xinitrc 是 X 启动需要读取的用户配置文件，这样每个用户 startx 之后就直接装载 gnome 了 你甚至可以在 sekl 目录下再建立目录，总之 /etc/skel 下的所有文件都会拷贝的用户的家目录去 你也许会想到，在 skel 目录下的 .bashrc 文件中加入一些方便的环境变量或者命令别名，这样每个新建用户都可以使用这些功能。不过，更好的选择是把这些设置放到全局的 /etc/profile 中，skel 目录下的文件是拷贝过去的，如果你修改或者增加了新的文件，只有新建的用户才能受益 Linux shell 中执行命令的查找顺序 apt、wget、curl 设置代理端口 [Top] apt 代理设置 １. 作用于当前终端（临时有效，关闭当前终端，再打开终端则无效） bash 里命令行执行export http_proxy=http://yourproxyaddress:proxyport（https、ftp等其他代理类型类似） 此时 wget、curl等应用程序都是使用http_proxy ２. 专门设置 apt 的代理 如果您希望 apt（而不是其他应用程序）一直使用某个代理，可以编辑 /etc/apt/apt.conf 配置文件（如果 /etc/apt/ 目录下没有 apt.conf 文件，那么需要手动创建） 按照下面的格式，将网络代理配置信息加入到 apt.conf 文件里Acquire::http::proxy “http://user:passwd@proxyserver:port”; Acquire::http::Proxy \"http://yourproxyaddress:proxyport\"; Acquire::http::Proxy “http://192.168.0.1：80“； Acquire::ftp::proxy \"ftp://127.0.0.1:8000/\"; 保存退出当前配置文件，关闭当前终端，然后打开另一个终端 运行 sudo apt-get update 命令，来检测 ubuntu 系统是否能够正常更新 统一设置所有应用程序的代理，对所有用户有效 统一设置所有应用程序的代理，对当前用户和所有有效，会覆盖　/etc/environment 里的相同代理设置 如果您希望 apt和其他应用程序如 wget 等都使用代理，您可以使用这种方式，编辑 ~/.bashrc文件，在您的.bashrc文件末尾添加如下内容：export http_proxy=http://yourproxyaddress:proxyport # 根据你的实际情况替换yourproxyaddress和proxyport 保存退出当前配置文件，关闭当前终端，然后打开另一个终端 运行 sudo apt-get update 命令，来检测 ubuntu 系统是否能够正常更新 wget 代理设置 １. 临时有效 bash 里命令行执行export http_proxy=http://yourproxyaddress:proxyport（https、ftp等其他代理类型类似） 此时 wget、curl、apt 等应用程序都是使用http_proxy 直接将代理作为 wget 命令的参数：wget ... -e use_proxy=yes -e http_proxy=http://yourproxyaddress:proxyport ... shell、终端、终端模拟器 [Top] shell 其实是 /bin 目录下的可执行文件 Linux 将允许使用的 shell 不同版本名存储在 /etc/shells，可以使用cat /etc/shells查看 /bin 目录下的不同的 shell 版本 终端 - terminal terminal 只是一个命令的输入窗口，例如 Windows 有 CMD 谈到 shell 以前以为就是这个，但这只是 terminal 终端模拟器 - terminal emulator 例如：Windows 下的 Putty、Xshell；Linux 下的 Guake Terminal Ubuntu 彻底关闭 dash [Top] Ubuntu 安装了 dockey 代替系统设置里的默认 dash，但系统设置不能选择关闭 dash（只能选择隐藏，但时常误触就会弹出，很烦人） 解决方法：在目录 /usr/share/gnome-shell/extensions/删除文件夹ubuntu-dock@ubuntu.com 一定要先备份ubuntu-dock@ubuntu.com，注意权限问题 sudo apt update 提示异常信息 [Top] N: 鉴于仓库 'http://dl.google.com/linux/earth/deb stable InRelease' 不支持 'i386' 体系结构，跳过配置文件 'main/binary-i386/Packages' 的获取。 分析：这是因为执行sudo apt update时根据/etc/apt/sources.list镜像站读取下载所有软件源到`/var/lib/apt/lists/'目录，但可能会下载了自己电脑架构不兼容的软件源，这样就会提示上面信息 解决方法 移除架构不兼容的软件源 执行命令：dpkg --remove-architecture i386 上面命令可能出现错误：dpkg: 错误: 无法移除体系结构 i386 ，当前它仍被数据库使用 先查看 安装了哪些外部架构： dpkg --print-foreign-architectures 可能会显示： i386 删除所有已下载的 i386 软件包：apt-get purge \".*:i386\" purge 关键字（而不是 remove ）将删除与要卸载的软件包关联的所有配置文件 现在您可以删除 i386 架构：dpkg --remove-architecture i386 Linux 中使用 crontab 命令启用自定义定时任务 [Top] crontab - 定时任务 简介 Linux 下的任务调度分为两类，系统任务调度和用户任务调度 系统任务调度：系统需要定期执行的任务，比如重启、日志清理等，其配置文件是：/etc/crontab 用户任务调度：某个用户需要定期执行的任务，用户可以使用crontab命令来配置自己的定时任务。所有用户配置的定时任务都存放在 /var/spool/cron/crontabs/ 目录下，其文件名与用户名一致。如：root用户的所有定时任务就保存在 /var/spool/cron/root 文件中 /var/spool/cron/crontabs目录需要切换到 root 权限才能打开 crontab 文件详解 /etc/crontab文件源代码 # /etc/crontab: system-wide crontab # Unlike any other crontab you don't have to run the `crontab' # command to install the new version when you edit this file # and files in /etc/cron.d. These files also have username fields, # that none of the other crontabs do. SHELL=/bin/sh PATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin # m h dom mon dow user command 17 * * * * root cd / && run-parts --report /etc/cron.hourly 25 6 * * * root test -x /usr/sbin/anacron || ( cd / && run-parts --report /etc/cron.daily ) 47 6 * * 7 root test -x /usr/sbin/anacron || ( cd / && run-parts --report /etc/cron.weekly ) 52 6 1 * * root test -x /usr/sbin/anacron || ( cd / && run-parts --report /etc/cron.monthly ) # /var/spool/cron/crontab/用户名文件源代码 # DO NOT EDIT THIS FILE - edit the master and reinstall. # (/tmp/crontab.LtbPsE/crontab installed on Fri Dec 14 21:01:59 2018) # (Cron version -- $Id: crontab.c,v 2.13 1994/01/17 03:20:37 vixie Exp $) # Edit this file to introduce tasks to be run by cron. # # Each task to run has to be defined through a single line # indicating with different fields when the task will be run # and what command to run for the task # # To define the time you can provide concrete values for # minute (m), hour (h), day of month (dom), month (mon), # and day of week (dow) or use '*' in these fields (for 'any').# # Notice that tasks will be started based on the cron's system # daemon's notion of time and timezones. # # Output of the crontab jobs (including errors) is sent through # email to the user the crontab file belongs to (unless redirected). # # For example, you can run a backup of all your user accounts # at 5 a.m every week with: # 0 5 * * 1 tar -zcf /var/backups/home.tgz /home/ # # For more information see the manual pages of crontab(5) and cron(8) # # m h dom mon dow command */10 * * * * /usr/local/bin/himawaripy */10 * * * * /usr/local/bin/himawaripy 详解 crontab 文件中添加配置格式 它的格式一共分为六个字段，前五段是时间设置段，第六段是要执行的命令段，格式如下： minute hour day month week command minute： 表示分钟，可以是从 0 到 59 之间的任何整数 hour：表示小时，可以是从 0 到 23 之间的任何整数 day：表示日期，可以是从 1 到 31 之间的任何整数 month：表示月份，可以是从 1 到 12 之间的任何整数 week：表示星期，可以是从 0 到 7 之间的任何整数，这里的 0 或 7 都代表星期日 command：表示需要执行的命令，可以是系统命令，也可以是自己编写的脚本文件 在以上各个字段中，还可以使用以下特殊字符： ``` 代表所有可能的值，例如：如果 month 字段是星号，则表示在满足其它字段的约束条件后每月都执行该命令 , 用逗号隔开的值表示一个范围列表，例如：如果 minute 字段的值是 “1,3,15”，则表示每小时的第 1 分钟、第 3 分钟和第 15 分钟都执行该命令 – 可以用整数之间的 – 表示一个整数范围，例如：如果 day 字段的值是 “2-6”，则表示每月的第2天到底6天都执行该命令 / 可以用斜线表示命令的执行频率，例如：如果 minute 字段的值是 “*/10”，则表示每十分钟执行一次命令 ``` Linux 添加环境变量 $PATH [Top] 有时手动编译安装软件包时，可执行目录 - bin 目录并不在环境变量 $PATH 里，所以不可以直接在终端执行，这时需要手动添加新的 bin 路径到 $PATH 环境变量中 $PATH：决定了 shell 将到哪些目录中寻找命令或程序，PATH 的值是一系列目录，当您运行一个程序时，Linux 在这些目录下进行搜寻编译链接 其格式为： PATH=$PATH::::------: 你可以自己加上指定的路径，中间用冒号隔开 环境变量更改后，在用户下次登陆时生效，如果想立刻生效而免去重新启动，则可执行下面的语句：$source /etc/profile 添加方法 临时添加，退出终端即没有效果了 sudo export PATH=/usr/local/vim/bin:$PATH /etc/profile 文件中修改，全局永久有效 sudo vim /etc/profile # 在文档最后，添加 export PATH=\"/usr/local/vim/bin:$PATH\" # 保存，退出，然后运行，即可立即生效 source /etc/profile Linux 手动添加字体文件 [Top] Linux 的字体都在 /usr/share/fonts 这个目录里，一种字体就是这个目录下面的一个子目录 将字体文件（.ttf 文件）放入这个目录下，还需要用root用户身份依次执行如下三条命令，这个字体才能用sudo mkfontscale sudo mkfontdir sudo fc-cache -fv #!/usr/bin/env 与 #!/usr/bin区别 [Top] 在 Linux、Unix、Mac 的一些脚本中，经常在开头出现#!/usr/bin/env 与 #!/usr/bin 例如： #!/usr/bin/env python #!/usr/bin python #!/usr/bin/env perl #!/usr/bin perl 区别 #!/usr/bin python: 表示脚本执行的一定是/usr/bin/python解释器，但有时 python 解释器并不是安装在/usr/bin目录下，这时脚本就无法执行。 #!/usr/bin/env python: 脚本执行时会通过命令/usr/bin/env运行 python，env 会从环境变量中寻找 python 解释器并执行。所以，即使 python 并未安装在 /usr/bin 目录下也是可以的 推荐使用#!/usr/bin/env python 形式 永久修改 DNS [Top] https://blog.csdn.net/MrBaymax/article/details/79430744 https://www.zhujibiji.com/2017/12/linux-permanently-modify-dns/ Linux程序存放目录 [Top] 更换镜像源 [Top] 阿里镜像源：https://opsx.alibaba.com/mirror?lang=zh-CN 对应镜像源后【帮助】，有对应修改详细介绍 诊断某文件无法修改 [Top] 使用 file filename 查看文件格式，若不是文本文件，是无法编辑的 最可能是权限问题，ls -l filename 查看文件权限，若是，使用 chmod 或 chown 修改之 1 、2 都不是的话，使用 lsattr filename 查看文件隐藏属性，若是，使用 chattr 修改之 Linux terminal 快捷键 [Top] 终端快捷键 功能 Ctrl + a 光标移动到行首 Ctrl + e 光标移动到行尾 Ctrl + c 终止当前程序 Ctrl + d 如果光标前有字符则删除，没有则退出当前中断 Ctrl + l 清屏 Ctrl + u 剪切光标以前的字符 Ctrl + k 剪切光标以后的字符 Ctrl + y 复制 Ctrl u / k 的内容 Ctrl + r 查找最近用过的命令 Ctrl+shift+c 复制 Ctrl+shift+v 粘贴 通过 PID 查看进程完整信息 [Top] 通常已知 Port ，可以通过 lsof -i:\\ 得到 PID，然后使用 ps aux | grep PID 或 ps -ef | grep PID，查看进程信息，但有时需要进程的更多的信息，这时就可以直接找到进程的文件（Linux 中一切皆是文件） 每个进程，都会在 /proc 文件夹里面生成一个进程目录，里面存放了进程的各种信息 sudo ls -l /proc/\\ $ ps -ef | grep v2ray | grep -v grep root 9541 1 0 Nov21 ? 00:00:02 /usr/bin/v2ray/v2ray -config /etc/v2ray/config.json $ sudo ls -l /proc/9541 总用量 0 dr-xr-xr-x 2 root root 0 Nov 21 19:23 attr -rw-r--r-- 1 root root 0 Nov 22 19:41 autogroup -r-------- 1 root root 0 Nov 22 19:41 auxv -r--r--r-- 1 root root 0 Nov 21 19:23 cgroup --w------- 1 root root 0 Nov 22 19:41 clear_refs -r--r--r-- 1 root root 0 Nov 21 19:23 cmdline -rw-r--r-- 1 root root 0 Nov 21 19:23 comm -rw-r--r-- 1 root root 0 Nov 22 19:41 coredump_filter -r--r--r-- 1 root root 0 Nov 22 19:41 cpuset lrwxrwxrwx 1 root root 0 Nov 22 19:41 cwd -> / -r-------- 1 root root 0 Nov 22 19:41 environ lrwxrwxrwx 1 root root 0 Nov 22 19:41 exe -> /usr/bin/v2ray/v2ray dr-x------ 2 root root 0 Nov 21 19:23 fd dr-x------ 2 root root 0 Nov 22 19:41 fdinfo -rw-r--r-- 1 root root 0 Nov 22 19:41 gid_map -r-------- 1 root root 0 Nov 22 19:41 io -r--r--r-- 1 root root 0 Nov 22 19:41 limits -rw-r--r-- 1 root root 0 Nov 21 19:23 loginuid dr-x------ 2 root root 0 Nov 22 19:41 map_files -r--r--r-- 1 root root 0 Nov 22 19:41 maps -rw------- 1 root root 0 Nov 22 19:41 mem -r--r--r-- 1 root root 0 Nov 22 19:41 mountinfo -r--r--r-- 1 root root 0 Nov 22 19:41 mounts -r-------- 1 root root 0 Nov 22 19:41 mountstats dr-xr-xr-x 6 root root 0 Nov 22 19:41 net dr-x--x--x 2 root root 0 Nov 22 19:41 ns -r--r--r-- 1 root root 0 Nov 22 19:41 numa_maps -rw-r--r-- 1 root root 0 Nov 22 19:41 oom_adj -r--r--r-- 1 root root 0 Nov 22 19:41 oom_score -rw-r--r-- 1 root root 0 Nov 22 19:41 oom_score_adj -r-------- 1 root root 0 Nov 22 19:41 pagemap -r-------- 1 root root 0 Nov 22 19:41 patch_state -r-------- 1 root root 0 Nov 22 19:41 personality -rw-r--r-- 1 root root 0 Nov 22 19:41 projid_map lrwxrwxrwx 1 root root 0 Nov 22 19:41 root -> / -rw-r--r-- 1 root root 0 Nov 22 19:41 sched -r--r--r-- 1 root root 0 Nov 22 19:41 schedstat -r--r--r-- 1 root root 0 Nov 21 19:23 sessionid -rw-r--r-- 1 root root 0 Nov 22 19:41 setgroups -r--r--r-- 1 root root 0 Nov 22 19:41 smaps -r--r--r-- 1 root root 0 Nov 22 19:41 smaps_rollup -r-------- 1 root root 0 Nov 22 19:41 stack -r--r--r-- 1 root root 0 Nov 21 19:23 stat -r--r--r-- 1 root root 0 Nov 22 19:41 statm -r--r--r-- 1 root root 0 Nov 21 19:23 status -r-------- 1 root root 0 Nov 22 19:41 syscall dr-xr-xr-x 19 root root 0 Nov 22 19:41 task -r--r--r-- 1 root root 0 Nov 22 19:41 timers -rw-rw-rw- 1 root root 0 Nov 22 19:41 timerslack_ns -rw-r--r-- 1 root root 0 Nov 22 19:41 uid_map -r--r--r-- 1 root root 0 Nov 22 19:41 wchan cwd - 符号链接的是进程运行目录 exe - 符号连接就是执行程序的绝对路径 cmdline - 就是程序运行时输入的命令行命令 environ - 记录了进程运行时的环境变量 fd - 目录下是进程打开或使用的文件的符号连接 文件权限 777 [Top] 文件权限 777、644 等等，其实是八进制的表示方法 /tmp 目录自动清理 [Top] 在线安装软件时，常常将安装包先下载到 /tmp/ 下面，这是因为 /tmp/ 目录会定时自动清理 在 RHEL6 中，系统自动清理 /tmp 文件夹的默认时限是 30 天 在 Ubuntu 中，系统自动清理 /tmp 文件夹的时限默认每次启动 修改时区 [Top] 设置修改Linux系统时间与时区的6种方法- 2018 Linux时间和timezone概念解释 CST - 中国标准时间 (China Standard Time) UTC - 通用协调时(Universal Time Coordinated) /etc/localtime 是用来描述本机时间，而 /etc/timezone 是用来描述本 机所属的时区 zdump -v /etc/localtime 读取 /etc/localtime 内容 修改 /etc/localtime 使本地时间正确(对应 linux 的 date 指令正确),另外还需要修改 /etc/timezone 使得时区正确 修改配置文件 $ sudo echo 'Asia/Shanghai' > /etc/timezone # 例如：Dockerfile 时区设置 RUN ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime RUN echo 'Asia/Shanghai' >/etc/timezon timedatectl 命令设定 $ timedatectl set-timezone Asia/Shanghai #其他时区以此类推 直接手动创建软链接 $ ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime tzselect 命令引导设定 $ tzselect Please identify a location so that time zone rules can be set correctly. Please select a continent, ocean, \"coord\", or \"TZ\". 1) Africa 2) Americas 3) Antarctica 4) Asia 5) Atlantic Ocean 6) Australia 7) Europe 8) Indian Ocean 9) Pacific Ocean 10) coord - I want to use geographical coordinates. 11) TZ - I want to specify the time zone using the Posix TZ format. #? vim 高亮 echo export EDITOR=vim >> /etc/profile.d/env.sh source /etc/profile.d/env.sh 一段脚本片段 [Top] #!/bin/bash # Don't generate .pyc files export PYTHONDONTWRITEBYTECODE=1 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Linux/Linux性能相关常用命令.html":{"url":"Linux/Linux性能相关常用命令.html","title":"Linux性能相关常用命令","keywords":"","body":"Linux 性能相关常用命令 - Linux Performance 主要以Ubuntu 18.04 LTS 为例，命令在 Linux 不同操作系统可能略有差别 《BPF Performance Tools》 linux 指标监控小记 Linux 性能分析工具 Linux 性能观测工具 Linux 性能测评工具 Linux Linux Linux 目录 top - CPU DRAM netstat - Sockets TCP\\UDP IP Ethernet ip - Ethernet nload - iostat - Block Device Interface I/O Controller iotop iopp lsof ps free - Virtual Memory pidstat - CPU vmstat - System Call InterFace Scheduler Virtual Memory dstat - CPU Virtual Memory Disk Port brctl - 网桥管理工具 mpstat - CPU perf - CPU tcpdump - Ethernet nicstat - Ethernet dtrace - Ethernet ping - Port dastat - Port dtrace - Port dastat - Disk dtrace - Disk perl ipconfig slabtop nicstat nmcli conn show -a nmcli conn show '连接名称' vmstat [Top] Virtual Meomory Statistics, Report virtual memory statistics 对操作系统的虚拟内存、进程、CPU活动进行监控，低开销的系统性能观察方式，不足之处是无法对某个进程进行深入分析 使用技巧 vmstat 本身就是低开销工具，在非常高负荷的服务器上，你需要查看并监控系统的健康情况，在控制窗口还是能够使用 vmstat 输出结果 pidstat [Top] Report statistics for Linux tasks 监控全部或指定进程的 cpu、内存、线程、设备 IO 等系统资源的占用情况 pidstat [选项] [时间] [次数] [选项] -u - 默认的参数，显示各个进程的 CPU 使用统计 -r - 显示各个进程的内存使用统计 -d - 显示各个进程的 IO 使用情况 -p - 指定进程号 -w - 显示每个进程的上下文切换情况 -t - 显示选择任务的线程的统计信息外的额外信息 常用命令 pidstat # 显示所有进程的 CPU 使用率 pidstat -r # 输出进程内存使用情况统计 pidstat -d -p 1 1 5 # 每隔一秒，一共输出 5 次进程 ID 为 1 的 IO 统计信息 pidstat -t -p 1 # 显示选择任务 ( pid =1 )的线程的统计信息外的额外信息 使用技巧 pidstat 首次运行时显示自系统启动开始的各项统计信息，之后运行 pidstat 将显示自上次运行该命令以后的统计信息。用户可以通过指定统计的次数和时间来获得所需的统计信息 pidstat 是 sysstat 软件套件的一部分，sysstat 包含很多监控 linux 系统状态的工具，它能够从大多数 linux 发行版的软件源中获得 安装：sudo apt install sysstat 或 yum install sysstat 命令输出详解 pidstat Linux 4.15.0-66-generic (xcq) Friday, November 08, 2019 _x86_64_ (8 CPU) 08:41:58 CST UID PID %usr %system %guest %wait %CPU CPU Command 08:41:58 CST 0 1 0.05 0.17 0.00 0.03 0.22 7 systemd 08:41:58 CST 0 7 0.00 0.00 0.00 0.00 0.00 0 ksoftirqd/0 08:41:58 CST 0 8 0.03 0.29 0.00 0.06 0.32 3 rcu_sched 08:41:58 CST 0 16 0.00 0.00 0.00 0.00 0.00 1 ksoftirqd/1 08:41:58 CST 0 22 0.00 0.00 0.00 0.00 0.00 2 ksoftirqd/2 08:41:58 CST 0 28 0.00 0.00 0.00 0.01 0.00 3 ksoftirqd/3 08:41:58 CST 0 34 0.00 0.00 0.00 0.00 0.00 4 ksoftirqd/4 UID - 用户 ID PID - 进程 ID %usr - 进程在用户空间占用 CPU 的百分比 %system - 进程在内核空间占用 CPU 的百分比 %guest - 任务花费在虚拟机上的 CPU 使用率（ 运行在虚拟处理器 ） %CPU - 任务总的 CPU 使用率 CPU - 正在运行这个任务的处理器编号 Command - 这个任务的命令名称 pidstat -r Linux 4.15.0-66-generic (xcq) Friday, November 08, 2019 _x86_64_ (8 CPU) 08:55:44 CST UID PID minflt/s majflt/s VSZ RSS %MEM Command 08:55:44 CST 0 1 8.72 0.04 225880 9476 0.12 systemd 08:55:44 CST 0 299 5.12 0.17 174836 46424 0.58 systemd-journal minflt/s - 从内存中加载数据时每秒出现的次要错误的数目，这些不要求从磁盘载入内存页面 majflt/s - 从内存中加载数据时每秒出现的主要错误的数目，这些要求从磁盘载入内存页面 VSZ - 虚拟地址大小，虚拟内存的使用 KB RSS - 长期内存使用，任务的不可交换物理内存的使用量 KB %MEM - 进程使用的物理内存百分比，top命令也会输出该字段 Command - task 命令名 pidstat -d Linux 4.15.0-66-generic (xcq) Friday, November 08, 2019 _x86_64_ (8 CPU) 09:01:44 CST UID PID kB_rd/s kB_wr/s kB_ccwr/s iodelay Command 09:01:44 CST 0 1 -1.00 -1.00 -1.00 713 systemd 09:01:44 CST 0 61 -1.00 -1.00 -1.00 8 kworker/2:1 09:01:44 CST 0 219 -1.00 -1.00 -1.00 228 kworker/u16:3 kB_rd/s - 进程每秒从磁盘读取的数据量( kB ) kB_wr/s - 进程每秒向磁盘写入的数据量(kB ) kB_ccwr/s - 任务写入磁盘被取消的速率（ KB ）( 当任务截断脏的 pagecache 的时候会发生 ) pidstat -t Linux 4.15.0-66-generic (xcq) Friday, November 08, 2019 _x86_64_ (8 CPU) 09:13:48 CST UID TGID TID %usr %system %guest %wait %CPU CPU Command 09:13:48 CST 0 1 - 0.03 0.12 0.00 0.04 0.15 4 systemd 09:13:48 CST 0 - 1 0.03 0.12 0.00 0.04 0.15 4 |__systemd 09:13:48 CST 0 2 - 0.00 0.00 0.00 0.00 0.00 7 kthreadd TGID - 主线程的标识 TID - 线程 ID pidstat -w Linux 4.15.0-66-generic (xcq) Friday, November 08, 2019 _x86_64_ (8 CPU) 09:17:57 CST UID PID cswch/s nvcswch/s Command 09:17:57 CST 0 1 29.38 0.13 systemd 09:17:57 CST 0 2 0.09 0.00 kthreadd Cswch/s - 每秒主动任务上下文切换数量 Nvcswch/s - 每秒被动任务上下文切换数量 iostat [Top] Report Central Processing Unit (CPU) statistics and input/output statistics for devices and partitions 主要用于监控磁盘 iostat [选项] [时间间隔（秒）] [输出次数] [选项] -c - 显示 CPU 使用情况 -d - 显示磁盘使用情况 -k - 以 KB 为单位显示 -m - 以 M 为单位显示 -N - 显示磁盘阵列 ( LVM ) 信息 -n - 显示 NFS 使用情况 -p - 显示磁盘和分区的情况 -t - 显示终端和 CPU 的信息 -x - 显示详细信息 -V - 显示版本信息 常用命令 iostat -x # 打印磁盘使用详细状态 iostat -d 2 10 # 每隔 2 秒打印一次磁盘使用情况，一共打印 10 次 命令输出详解 iostat # CentOS 7 iostat Linux 3.10.0-514.26.2.el7.x86_64 (iZuf62pye4v8osus1bsqgjZ) Thursday, November 07, 2019 _x86_64_ (1 CPU) avg-cpu: %user %nice %system %iowait %steal %idle 0.49 0.00 0.29 0.13 0.00 99.09 Device: tps kB_read/s kB_wrtn/s kB_read kB_wrtn vda 4.18 0.82 72.32 1690217 148491664 avg-cpu - 和 top 输出第三行一样 %user - CPU 处在用户模式下的时间百分比 %nice - CPU 处在带 NICE 值的用户模式下的时间百分比 %system - CPU 处在系统模式下的时间百分比 %iowait - CPU 等待输入输出完成时间的百分比。如果该值较高，表示磁盘存在 I/O 瓶颈 %steal - 管理程序维护另一个虚拟处理器时，虚拟 CPU 的无意识等待时间百分比 %idle - CPU 空闲时间百分比 Device tps - 每秒 I/O 数（ 即 IOPS，磁盘连续读和连续写之和 ） kB_read/s - 每秒从磁盘读取数据大小，单位 KB/s kB_wrtn/s - 每秒写入磁盘的数据的大小，单位 KB/s kB_read - 从磁盘读出的数据总数，单位 KB kB_wrtn - 写入磁盘的的数据总数，单位 KB iostat -x # CentOS 7 iostat -x Linux 3.10.0-514.26.2.el7.x86_64 (iZuf62pye4v8osus1bsqgjZ) Thursday, November 07, 2019 _x86_64_ (1 CPU) avg-cpu: %user %nice %system %iowait %steal %idle 0.49 0.00 0.29 0.13 0.00 99.09 Device: rrqm/s wrqm/s r/s w/s rkB/s wkB/s avgrq-sz avgqu-sz await r_await w_await svctm %util vda 0.00 0.54 0.04 4.14 0.82 72.32 34.97 0.01 2.06 4.43 2.03 0.35 0.15 Device - 设备名称 rrqm/s - 每秒合并到设备的读取请求数 wrqm/s - 每秒合并到设备的写请求数 r/s - 每秒向磁盘发起的读操作数 w/s - 每秒向磁盘发起的写操作数 rkB/s - 每秒读 K 字节数 wkB/s - 每秒写 K 字节数 avgrq-sz - 平均每次设备 I/O 操作的数据大小 avgqu-sz - 平均 I/O 队列长度 await - 平均每次设备 I/O 操作的等待时间 ( 毫秒 )。一般地，系统 I/O 响应时间应该低于 5ms，如果大于 10ms 就比较大了 r_await - 每个读操作平均所需的时间；不仅包括硬盘设备读操作的时间，还包括了在 kernel 队列中等待的时间 w_await - 每个写操作平均所需的时间；不仅包括硬盘设备写操作的时间，还包括了在 kernel 队列中等待的时间 svctm - 平均每次设备 I/O 操作的服务时间 ( 毫秒 )（ 这个数据不可信！） %util - 一秒中有百分之多少的时间用于 I/O 操作，即被 IO 消耗的 CPU 百分比。一般地，如果该参数是 100% 表示设备已经接近满负荷运行了 使用技巧 除了关注指标外，我们更需要结合部署的业务进行分析。对于磁盘随机读写频繁的业务，比如图片存取、数据库、邮件服务器等，此类业务吗，tps 才是关键点。对于顺序读写频繁的业务，需要传输大块数据的，如视频点播、文件同步，关注的是磁盘的吞吐量 如果 %util 接近 100%，说明产生的 I/O 请求太多，I/O 系统已经满负荷，该磁盘可能存在瓶颈 如果 svctm 比较接近 await，说明 I/O 几乎没有等待时间 如果 await 远大于 svctm，说明 I/O 队列太长，I/O 响应太慢，则需要进行必要优化 如果 avgqu-sz 比较大，也表示有大量 I/O 在等待 iotop [Top] `` iopp [Top] iopp 的实现原理非常简单，无非是遍历 /proc/pid/io 文件，读取出结果后，再通过进一步计算得出 安装 # 编译工具 $ yum install cmake $ apt-get install cmake # 编译安装 iopp，最好切换到 root 下执行 $ git clone https://github.com/markwkm/iopp.git $ cd iopp $ cmake CMakeLists.txt $ make && make install 说明 $ iopp --help usage: iopp -h|--help usage: iopp [-ci] [-k|-m] [delay [count]] -c, --command display full command line #显示完整命令行 -h, --help display help #显示帮助信息 -i, --idle hides idle processes #隐藏空闲进程 -k, --kilobytes display data in kilobytes #以KB为单位显示数据 -m, --megabytes display data in megabytes #以MB为单位显示数据 -u, --human-readable display data in kilo-, mega-, or giga-bytes #以方便读的方式显示数据 命令输出详解 $ iopp -i -k -c 1 pid rchar wchar syscr syscw rkb wkb cwkb command pid rchar wchar syscr syscw rkb wkb cwkb command 15103 63 0 0 0 0 0 0 iopp pid rchar wchar syscr syscw rkb wkb cwkb command 15103 63 0 0 0 0 0 0 iopp pid rchar wchar syscr syscw rkb wkb cwkb command 4483 0 1372 0 0 0 1384 0 /opt/google/chrome/chrome 15103 63 0 0 0 0 0 0 iopp pid rchar wchar syscr syscw rkb wkb cwkb command 4147 0 1 0 0 0 0 0 /usr/bin/python3 4483 0 0 0 0 0 4 0 /opt/google/chrome/chrome pid 进程ID rchar 将要从磁盘读取的字节数 wchar 已经写入或应该要写入磁盘的字节 syscr 读I/O次数 syscw 写I/O次数 rbytes 真正从磁盘读取的字节数 wbytes 真正写入到磁盘的字节数 cwbytes 因为清空页面缓存而导致没有发生操作的字节数 command 执行的命令 ps [Top] report a snapshot of the current processes ps [选项] [选项] ps命令支持三种使用的语法格式 UNIX 风格，选项可以组合在一起，并且选项前必须有“-”连字符 BSD 风格，选项可以组合在一起，但是选项前不能有“-”连字符 GNU 风格的长选项，选项前有两个“-”连字符 常用命令 ps aux ps -ef ps axjf ps axms ps axZ ps -U root -u root u lsof [Top] list open files lsof 可以查看打开的文件有：普通文件、目录、网络文件系统的文件、字符或设备文件、(函数)共享库、管道、命名管道、符号链接、网络文件（NFS file、网络 socket、unix 域名 socket ）、还有其它类型的文件，等等 lsof [选项] [选项] -a - 使用 AND 逻辑，合并选项输出内容 -c - 列出名称以指定名称开头的进程打开的文件 -d - 列出打开指定文件描述的进程 +d - 列出目录下被打开的文件 +D - 递归列出目录下被打开的文件 -n - 列出使用 NFS 的文件 -u - 列出指定用户打开的文件 -p - 列出指定进程号所打开的文件 -i - 列出打开的套接字 常用命令 lsof -i # 列出所有的网络连接 lsof -i :80 # 列出 80 端口目前打开的文件列表 lsof -i tcp # 列出所有的 TCP 网络连接信息 lsof -i udp # 列出所有的 UDP 网络连接信息 lsof -i tcp:80 # 列出 80 端口 TCP 协议的所有连接信息 lsof -i udp:25 # 列出 25 端口 UDP 协议的所有连接信息 lsof -c ngin # 列出以 ngin 开头的进程打开的文件列表 lsof -p 20711 # 列出指定进程打开的文件列表 lsof -u xcq # 列出指定用户打开的文件列表 lsof -u xcq -i tcp # 将所有的 TCP 网络连接信息和指定用户打开的文件列表信息一起输出 lsof -a -u uasp -i tcp # 将指定用户打开的文件列表信息，同时是 TCP 网络连接信息的一起输出；注意和上一条命令进行对比 lsof +d /usr/local/ # 列出目录下被进程打开的文件列表 lsof +D /usr/local/ # 递归搜索目录下被进程打开的文件列表 lsof -i @peida.linux:20,21,22,80 -r 3 # 列出目前连接到主机 peida.linux 上端口为 20，21，22，80相关的所有文件信息，且每隔 3 秒不断的执行 lsof 指令 命令输出详解 lsof sudo lsof COMMAND PID TID USER FD TYPE DEVICE SIZE/OFF NODE NAME systemd 1 root cwd DIR 8,2 4096 2 / systemd 1 root rtd DIR 8,2 4096 2 / systemd 1 root txt REG 8,2 1595792 46137607 /lib/systemd/systemd systemd 1 root mem REG 8,2 1700792 46137433 /lib/x86_64-linux-gnu/libm-2.27.so systemd 1 root mem REG 8,2 121016 46137523 /lib/x86_64-linux-gnu/libudev.so.1.6.9 systemd 1 root mem REG 8,2 84032 46139105 /lib/x86_64-linux-gnu/libgpg-error.so.0.22.0 systemd 1 root mem REG 8,2 43304 46139138 /lib/x86_64-linux-gnu/libjson-c.so.3.0.1 systemd 1 root mem REG 8,2 34872 21766670 /usr/lib/x86_64-linux-gnu/libargon2.so.0 systemd 1 root mem REG 8,2 432640 46137584 /lib/x86_64-linux-gnu/libdevmapper.so.1.02.1 . . . COMMAND - 进程的名称 PID - 进程标识符 TID - 线程标识符 USER - 进程所有者 FD - 文件描述符，应用程序通过文件描述符识别该文件，一般有以下取值 cwd - 表示 current work dirctory，即：应用程序的当前工作目录，这是该应用程序启动的目录 txt - 该类型的文件是程序代码，如应用程序二进制文件本身或共享库 lnn - library references ( AIX ) er - FD information error ( see NAME column ) jld - jail directory ( FreeBSD ) ltx - shared library text ( code and data ) mxx - hex memory-mapped type number xx m86 - DOS Merge mapped file mem - memory-mapped file mmap - memory-mapped device pd - parent directory rtd - root directory tr - kernel trace file ( OpenBSD ) v86 - VP/ix mapped file 0 - 表示标准输出 1 - 表示标准输入 2 - 表示标准错误 TYPE - 文件类型，常见的文件类型有以下几种 DIR - 表示目录 CHR - 表示字符类型 BLK - 块设备类型 UNIX - UNIX 域套接字 FIFO - 先进先出 ( FIFO ) 队列 IPv4 - 网际协议 ( IP ) 套接字 DEVICE - 指定磁盘的名称 SIZE/OFF - 文件的大小 NODE - 索引节点（ 文件在磁盘上的标识 ） NAME - 打开文件的确切名称 netstat [Top] Print network connections, routing tables, interface statistics, masquerade connections, and multicast memberships 显示与 IP、TCP、UDP 和 ICMP 协议相关的统计数据，同时还可用于检验本机各端口的网络连接情况 netstat [选项] [选项] -a - 显示所有选项，默认不显示 LISTEN 相关 -t - 仅显示 tcp 相关选项 -u - 仅显示 udp 相关选项 -n - 拒绝显示别名，能显示数字的全部转化成数字 -l - 仅显示正在 Listen（ 监听 ）的服务状态 -p - 显示建立相关连接的程序名 -r - 显示路由信息，路由表 -e - 显示扩展信息，例如 uid 等 -s - 按各个协议进行统计 -c - 每隔一个固定时间，执行该 netstat 命令 -i - 显示网卡接口信息 常用命令 netstat -antp # 以数字的形式显示所有的 TCP 连接，并显示对应程序所监听的端口号 netstat -anup # 以数字的形式显示所有的 UDP 连接，并显示对应程序所监听的端口号 netstat -st # 统计 TCP 协议相关的网络统计数据 netstat -rn # 打印内核路由信息 netstat -ie # 显示网络接口信息 # 统计中当前 TCP 每个状态的数量，通过这个数量，我们就可以大致知道服务器 TCP 连接当前的健康状态 netstat -n | awk '/^tcp/{++state[$NF]}; END{for(key in state) print key, \"\\t\", state[key]}' # 统计连接某服务端口最多的 IP 地址 netstat -nat | grep \":80\" | awk '{print $5}' | awk -F: '{print $1}' | sort | uniq -c | sort -nr | head -20 命令输出详解 netstat -a netstat -a Active Internet connections (servers and established) Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 0.0.0.0:http 0.0.0.0:* LISTEN tcp 0 0 0.0.0.0:https 0.0.0.0:* LISTEN tcp 0 0 jellythink:https 39.154.11.104:8543 ESTABLISHED tcp 0 0 jellythink:50398 100.100.30.25:http ESTABLISHED . . . . Active UNIX domain sockets (servers and established) Proto RefCnt Flags Type State I-Node Path unix 9 [ ] DGRAM 6897 /dev/log unix 2 [ ] DGRAM 9721 /run/systemd/shutdownd unix 3 [ ] STREAM CONNECTED 11477 unix 3 [ ] STREAM CONNECTED 11478 /run/systemd/journal/stdout unix 3 [ ] STREAM CONNECTED 11234 /run/systemd/journal/stdout . . . . Active Internet connections (servers and established) - 称为有源 TCP 连接，包括 TCP 和 UDP 等的详细状态 Active UNIX domain sockets (servers and established) - 称为有源 Unix 域套接口（ 和网络套接字一样，但是只能用于本机通信，性能可以提高一倍 ） 有源 TCP 连接字段详解： Proto - 当前连接的协议；如 TCP、UDP Recv-Q - 网络接收队列 Send-Q - 网络发送队列；接收队列和发送队列一般都应该是 0，如果不是则表示数据包正在队列中堆积，但是这种情况比较少见 Local Address - 本机的 ip:port（ 注意此处 127.0.0.1 默认显示主机名，0.0.0.0 默认显示 *，端口可能显示别名。若强制显示数字，加 -n 参数 ） Foreign Address - 对端 ip:port；与 Local Address 规则相同 State - 当前套接字的网络状态，有以下几种状态： LISTEN - 监听来自其它 TCP 端口的连接请求 SYN-SENT - 再发送连接请求后等待匹配的连接请求（如果有大量这样的状态包，检查是否中招了） SYN-RECEIVED - 再收到和发送一个连接请求后等待对方对连接请求的确认（如有大量此状态，估计被flood攻击了） ESTABLISHED - 代表一个打开的连接 FIN-WAIT-1 - 等待远程TCP连接中断请求，或先前的连接中断请求的确认 FIN-WAIT-2 - 从远程TCP等待连接中断请求 CLOSE-WAIT - 等待从本地用户发来的连接中断请求 CLOSING - 等待远程TCP对连接中断的确认 LAST-ACK - 等待原来的发向远程TCP的连接中断请求的确认（不是什么好东西，此项出现，检查是否被攻击） TIME-WAIT - 等待足够的时间以确保远程TCP接收到连接中断请求的确认 CLOSED - 没有任何连接状态 netstat -rn netstat -rn 内核 IP 路由表 Destination Gateway Genmask Flags MSS Window irtt Iface 0.0.0.0 192.168.152.1 0.0.0.0 UG 0 0 0 wlo1 169.254.0.0 0.0.0.0 255.255.0.0 U 0 0 0 wlo1 172.17.0.0 0.0.0.0 255.255.0.0 U 0 0 0 docker0 192.168.152.0 0.0.0.0 255.255.248.0 U 0 0 0 wlo1 Destination - 目标网络或目标主机 Gateway - 网关地址，如果没有就显示星号 Genmask - 网络掩码，0.0.0.0 表示默认路由 Flags - 标志位，有以下常用取值： U - 表示该路由是启动的 H - 目标是一部主机（ IP ）而非网域 G - 需要透过外部的主机（ gateway ）来转递封包 Iface - 网络接口名 free [Top] Display amount of free and used memory in the system 显示系统中已用和未用的物理内存、交换内存、共享内存和内核使用的缓冲区的总和 free [选项] [选项] -k - 以 KB 为单位显示内存使用情况 -m - 以 MB 为单位显示内存使用情况 -g - 以 GB 为单位显示内存使用情况 -h - 以人类友好的方式显示内存使用情况 命令输出详解 free -h total used free shared buff/cache available Mem: 7.7G 5.5G 637M 735M 1.5G 1.3G Swap: 7.9G 495M 7.4G total - 内存总数，物理内存总数 Mem - 物理内存 used - 已经使用的内存数 free - 空闲的内存数 shared - 多个进程共享的内存总额 buffers - 缓冲内存数 cached - 缓存内存数 Swap - 交换分区，虚拟内存 total = used + free + buff + cache buffer 是用于存放要输出到 disk（ 块设备 ）的数据的，而 cache 是存放从 disk 上读出的数据 A buffer is something that has yet to be \"written\" to disk A cache is something that has been \"read\" from the disk and stored for later use top [Top] Display Linux processes 显示当前系统正在执行的进程的相关信息，包括进程 ID、内存占用率、CPU 占用率等 top [选项] ([参数]) [选项] ( [参数] ) -b - 批处理 -c - 显示进程的命令行参数 ( 默认只有进程名 ) -I - 忽略失效过程 -s - 保密模式 -S - 累积模式 -d - 设置更新间隔时间 -u - 指定用户名 -p - 指定进程 -n - 循环显示的次数 常用命令 top #显示系统进程信息 top -b #以批处理模式显示程序信息 top -S #以累积模式显示程序信息 top -n 2 #设置信息更新次数,表示更新 2 次后终止更新显示 top -d -3 #设置信息更新时间,表示更新周期为 3 秒 top -p 1138 #显示进程号为1138 的进程信息，CPU、内存占用率等 使用技巧 进程字段排序 默认进入 top 时，各进程是按照 CPU 的占用量来排序的。但是，我们可以改变这种排序： M 键 - 根据驻留内存大小进行排序 P 键 - 根据 CPU 使用百分比大小进行排序 T 键 - 根据时间 / 累计时间进行排序 多核 CPU 监控 在 top 基本视图中，第三行表示 CPU 状态信息；这里显示数据是所有 CPU 的平均值（ avg-cpu ），多核 CPU 可以通过按 1 键来展开显示每个 CPU 状态 命令输出详解 top $ top top - 11:32:24 up 6:37, 0 users, load average: 0.50, 0.55, 0.52 Tasks: 2 total, 1 running, 1 sleeping, 0 stopped, 0 zombie %Cpu(s): 4.3 us, 1.4 sy, 0.2 ni, 93.3 id, 0.7 wa, 0.0 hi, 0.0 si, 0.0 st KiB Mem : 8055256 total, 444928 free, 4203968 used, 3406360 buff/cache KiB Swap: 8275964 total, 8273784 free, 2180 used. 3538032 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 1 root 20 0 18508 3188 2776 S 0.0 0.0 0:00.21 bash 10 root 20 0 36484 2940 2540 R 0.0 0.0 0:00.01 top 第一行：与 uptime 输出的信息一样 11:32:24 - 当前系统时间 up 6:37 - 系统已运行时间 0 users - 当前连接系统的终端数 系统负载 load average: 0.50, 0.55, 0.52 - 后面的三个数分别是 1 分钟、5 分钟、15 分钟的负载情况；如果平均负载值大于 0.7 * CPU 内核数，就需要引起关注 第二行：表示进程数信息 2 total - 总进程数 1 running - 正在运行的进程数 1 sleeping - 正在睡眠的进程数 0 stopped - 停止的进程数 0 zombie - 僵尸进程数 第三行：表示 CPU 状态信息 这里显示数据是所有 CPU 的平均值。多核 CPU 可以通过按 1 键来展开显示每个 CPU 状态 4.3 us - 用户空间占用 CPU 百分比 1.4 sy - 内核空间占用 CPU 百分比 0.2 ni - 用户进程空间内改变过优先级的进程占用 CPU 百分比 93.3 id - CPU 空闲率 0.7 wa - 等待 IO 的 CPU 时间百分比 0.0 hi - 硬中断（ Hardware IRQ ）占用 CPU 的百分比 0.0 si - 软中断（ Software Interrupts ）占用 CPU 的百分比 0.0 st - 这个虚拟机被 hypervisor 偷去的 CPU 时间（ 译注：如果当前处于一个 hypervisor 下的 vm，实际上 hypervisor 也是要消耗一部分 CPU 处理时间的 ） 第四行：物理内存使用信息 8055256 total - 物理内存总量 444928 free - 使用的物理内存总量 4203968 used- 空闲内存总量 3406360 buff/cache - 用作内核缓冲 / 缓存的内存量 第五行：交换空间使用信息 我们要时刻监控交换分区的 used，如果这个数值在不断的变化，说明内核在不断进行内存和 swap 的数据交换，这是真正的内存不够用了 8275964 total - 交换区总量 8273784 free - 交换区空闲量 2180 used - 交换区使用量 3538032 avail Mem - 可用于进程下一次分配的物理内存数量 第六行：空行 第七行：各个进程的状态信息 PID - 进程 id USER - 进程所有者 PR - 进程优先级 NI - nice 值；越小优先级越高，最小 -20，最大 20（ 用户设置最大 19 ） VIRT - 进程使用的虚拟内存总量，单位 kb；VIRT=SWAP+RES RES - 进程使用的、未被换出的物理内存大小，单位 kb；RES=CODE+DATA SHR - 共享内存大小，单位 kb S - 进程状态；D = 不可中断的睡眠状态、R = 运行、S = 睡眠、T = 跟踪/停止、Z = 僵尸进程 %CPU - 上次更新到现在的 CPU 时间占用百分比 %MEM - 进程使用的物理内存百分比 TIME+ - 进程使用的 CPU 时间总计 COMMAND - 命令名/命令行 ip [Top] show / manipulate routing, network devices, interfaces and tunnels ip [选项] 对象 { 命令 | help } 常用对象 link - 网络设备 address - 设备上的协议（ IP 或 IPv6 ）地址 addrlabel - 协议地址选择的标签配置 route - 路由表条目 rule - 路由策略数据库中的规则 常用选项 -V，-Version - 显示指令版本信息 -s，-stats，statistics - 输出详细信息 -h，-human，-human-readable - 输出人类可读的统计信息和后缀 -o，-oneline - 将每条记录输出到一行，用 \\ 字符替换换行符 常用命令 ip address # 设定与 IP 有关的各项参数，包括 netmask， broadcast 等 ip addr show # 显示网卡及配置的地址信息，也可用 ip a s 或 ip a # ip address [add|del] [IP参数] [dev 设备名] [相关参数] # [add|del]：进行相关参数的增加(add)或删除(del)设定 # [IP 参数] ：主要就是网域的设定，例如 192.168.100.100/24 之类的设定 # [dev 设备名]：IP 参数所要设定的设备，例如eth0, eth1等 # [相关参数]： # broadcast：设定广播位址，如果设定值是 + 表示让系统自动计算 # label：该设备的别名，例如eth0:0 # scope：这个设备的领域，默认global，通常是以下几个大类 # global：允许来自所有来源的连线 # site：仅支持IPv6 ，仅允许本主机的连接 # link：仅允许本设备自我连接 # host：仅允许本主机内部的连接 ip addr add 192.168.0.50/255.255.255.0 dev eth0 # 为网卡分配 IP 地址以及其他网络信息 ip addr add broadcast 192.168.0.255 dev eth0 # 设置广播地址 ip addr add 192.168.0.20/24 dev eth0 label eth0:1 # 添加 eth0 网卡别名 ip addr del 192.168.0.10/24 dev eth0 # 删除网卡中配置的 IP 地址 ip link # 可以操作与设备( device )有关的相关设定，包括 MTU 以及该网络设备的 MAC 等，也可以启动 ( up ) 或关闭 ( down ) 某个网络设备 ip -s link # 显示所有网络接口的统计数据 ip link set eth0 up # 启用网卡名为 etho0 的网卡 ip link set eth0 down # 禁用网卡 ip link set eth0 mtu 1000 # 更改 MTU 为 1000 bytes ip link set ent0 name eth1 # 更改网卡名字 ip route # 路由配置,功能几乎与 route 这个命令一样，但是，它还可以进行额外的参数设置 ip route show # 查看路由信息，也可用 ip r s 或 ip r ip route get 119.75.216.20 # 通过 IP 地址查询路由包从哪条路由来 # ip route [add|del] [IP或网域] [via gateway] [dev 设备] # [add|del]：增加 ( add ) 或删除 ( del ) 路由 # [IP或网域]：可使用 192.168.50.0/24 之类的网域或者是单纯的 IP # [via gateway]：从哪个 gateway 出去，不一定需要 # [dev 设备名]：所要设定的设备，例如 eth0, eth1 等 ip route add default via 192.168.0.150/24 # 修改当前默认路由为 192.168.0.150 ip route add 172.16.32.32 via 192.168.0.150/24 dev eth0 # 添加特定网卡的路由，增加通往外部路由 ip route del 192.168.0.150/24 # 删除路由 ip route flush cache # 刷新路由表 # 检查所有的 ARP 记录 ip neigh 命令输出详解 ip address ip address 1: lo: mtu 65536 qdisc noqueue state UNKNOWN qlen 1 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever 2: eth0: mtu 1500 qdisc pfifo_fast state UP qlen 1000 link/ether 00:1e:4f:c8:43:fc brd ff:ff:ff:ff:ff:ff inet 192.168.0.24/24 brd 192.168.0.255 scope global eth0 valid_lft forever preferred_lft forever 3: wlo1: mtu 1500 qdisc mq state UP group default qlen 1000 link/ether a4:02:b9:54:3f:80 brd ff:ff:ff:ff:ff:ff inet 192.168.158.164/21 brd 192.168.159.255 scope global dynamic noprefixroute wlo1 valid_lft 3378sec preferred_lft 3378sec inet6 fe80::1b3d:9f06:efac:3878/64 scope link noprefixroute valid_lft forever preferred_lft forever 系统有三个接口：lo 、eth0 和 wlo1，lo 是环回接口，eth0 这个普通网络接口，wlo1 是 wifi 接口 BROADCAST - 表示该接口支持广播 MULTICAST - 表示该接口支持多播 UP - 表示该网络接口已启用 LOWER_UP - 表示网络电缆已插入，设备已连接至网络 mtu 1500 - 最大传输单位（ 数据包大小 ）为 1500 字节 qdisc pfifo_fast - 用于数据包排队 state UP - 网络接口已启用 qlen 1000 - 传输队列长度 link/ether 00:1e:4f:c8:43:fc - 接口的 MAC（ 硬件 ）地址 brd ff:ff:ff:ff:ff:ff - 广播地址 inet 192.168.0.24/24 - IPv4 地址 brd 192.168.0.255 - 广播地址 scope global - 全局有效 dynamic noprefixroute wlo1 - 地址是动态分配的 valid_lft forever - IPv4 地址的有效使用期限 preferred_lft 3378sec - IPv4 地址的首选生存期 inet6 fe80::1b3d:9f06:efac:3878/64 - IPv6 地址 scope link - 仅在此设备上有效 valid_lft forever - IPv6 地址的有效使用期限 preferred_lft forever - IPv6 地址的首选生存期 ip route ip route default via 192.168.152.1 dev wlo1 proto dhcp metric 600 169.254.0.0/16 dev wlo1 scope link metric 1000 172.17.0.0/16 dev docker0 proto kernel scope link src 172.17.0.1 linkdown 192.168.152.0/21 dev wlo1 proto kernel scope link src 192.168.158.164 metric 600 第一条是默认的路由，我们可以根据我们的需要改动它 metric 1002 - 跳跃计数，确定网关的优先级，默认 20，数值越小优先级越高 proto kernel - 该路由的协议，主要有 redirect，kernel，boot，static，ra 等，其中 kernel 指的是直接由核心判断自动设定 ip -s link 1: lo: mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 RX: bytes packets errors dropped overrun mcast 12421814 19572 0 0 0 0 TX: bytes packets errors dropped carrier collsns 12421814 19572 0 0 0 0 2: eno1: mtu 1500 qdisc fq_codel state DOWN mode DEFAULT group default qlen 1000 link/ether ec:8e:b5:44:4a:1c brd ff:ff:ff:ff:ff:ff RX: bytes packets errors dropped overrun mcast 0 0 0 0 0 0 TX: bytes packets errors dropped carrier collsns 0 0 0 0 0 0 3: wlo1: mtu 1500 qdisc mq state UP mode DORMANT group default qlen 1000 link/ether a4:02:b9:54:3f:80 brd ff:ff:ff:ff:ff:ff RX: bytes packets errors dropped overrun mcast 429373334 837924 0 0 0 0 TX: bytes packets errors dropped carrier collsns 23895841 143531 0 0 0 0 ip -s -s link eno1 2: eno1: mtu 1500 qdisc fq_codel state DOWN mode DEFAULT group default qlen 1000 link/ether ec:8e:b5:44:4a:1c brd ff:ff:ff:ff:ff:ff RX: bytes packets errors dropped overrun mcast 0 0 0 0 0 0 RX errors: length crc frame fifo missed 0 0 0 0 0 TX: bytes packets errors dropped carrier collsns 0 0 0 0 0 0 TX errors: aborted fifo window heartbeat transns 0 0 0 0 1 RX - 表示接收 TX - 表示发送 bytes - 接收/发送的字节数 packets - 接收/发送的包数 errors - 接收/发送的带有错误的包总数 dropped - 由于处理资源不足导致接收/发送的丢弃的包数 overrun - 因接收溢出（ 环形缓冲区 ）导致丢失的包；通常如果接口溢出，则表示内核中存在严重问题，或者说服务器上该网络设备的处理设备太慢 mcast - 接收到的多播包数 carrier - 因数据链路错误导致发送失败的包数 collsns - 因在网络上发送冲突而导致的失败数 brctl brctl 用来管理以太网桥，在内核中建立，维护，检查网桥配置 brctl [命令] 常用命令 $ brctl addbr [name] # 创建一个名为name的桥接网络接口 $ brctl delbr [name] # 删除一个名为name的桥接网络接口，桥接网络接口必须先down掉后才能删除 $ brctl show # 显示目前所有的桥接接口 $ brctl addif [brname] [ifname] # 把一个物理接口ifname加入桥接接口brname中，所有从ifname收到的帧都将被处理，就像网桥处理的一样。所有发往brname的帧，ifname就像输出接口一样。当物理以太网加入网桥后，据处于混杂模式了，所以不需要配置IP Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Linux/Linux各种安装下载慢解决方法.html":{"url":"Linux/Linux各种安装下载慢解决方法.html","title":"Linux各种安装下载慢解决方法","keywords":"","body":"Linux 各种安装下载慢解决方法 由于墙或服务器在境外的原因，导致基本所有命令行工具安装下载速度都极慢，一般解决办法有以下三种： 1、更换国内镜像源（部分工具有国内镜像源） 2、使用 VPN 代理 + 流量转发工具 3、离线包安装 终端代理 + 流量转发针对所有走 http、https 的工具都有效 依据这三种方式介绍 pip、git、npm、brower、gem、apt、yum 等（后续持续更新） [registry url] 指的就是镜像源网站, 比如 http://registry.npm.taobao.org/ 一、更换国内镜像源 最推荐使用这种方法 Pip [registry url] 阿里云 https://mirrors.aliyun.com/pypi/simple/ 豆瓣 http://pypi.douban.com/simple/ 清华大学 https://pypi.tuna.tsinghua.edu.cn/simple/ 中科大 https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple/ pypi https://pypi.python.org/simple/ 临时生效 $ pip install modules -i [registry url] $ pip3 install modules -i [registry url] 永久生效 (pip 和 pip3 都一样) # 先使用 updatedb 命令更新 locate 查找的数据 $ updatedb # 使用 locate 查找 pip.conf # 没有 pip.conf 则自行创建 ~/.pip/pip.conf $ locate pip.conf /home/xcq/.pip/pip.conf /home/xcq/.pip/pip.conf.bak # 在 pip.conf 添加以下内容 [global] index-url = https://pypi.tuna.tsinghua.edu.cn/simple 使用 pqi 管理镜像 - https://github.com/yhangf/PyQuickInstall # 安装 $ pip install pqi $ pqi Usage: pqi ls pqi use pqi show pqi add pqi remove pqi (-h | --help) pqi (-v | --version) Options: -h --help Show this screen. -v --version Show version. Git Git 主要是在克隆 Github 仓库时很慢，但并不能通过修改软件源增速 介绍三种方法： 修改 hosts 文件，网上很多教程 先使用 gitee clone ，再 clone gitee 仓库 使用代理 + 流量转发，这个最好用！ NPM [registry url] 淘宝npm镜像 搜索地址：http://npm.taobao.org/ registry地址：http://registry.npm.taobao.org/ cnpmjs镜像 搜索地址：http://cnpmjs.org/ registry地址：http://r.cnpmjs.org/ 临时生效 $ npm install --registry [registry url] 永久生效 # npm config 配置 $ npm config set registry [registry url] # 或修改 ~/.npmrc 文件，添加如下内容 registry=https://registry.npm.taobao.org # 验证是否成功 npm config get registry # 或 npm info express 使用 nrm 模块管理镜像 - https://github.com/Pana/nrm # 安装 $ npm install -g nrm $ nrm Usage: nrm [options] [command] Options: -V, --version output the version number -h, --help output usage information Commands: ls List all the registries . . . # 查看有哪些镜像 $ nrm ls # 对比各个镜像的访问速度 $ nrm test 镜像名 # 使用淘宝的镜像 $ nrm use taobao gem 使用以下命令替换 gems 默认源 # 添加 TUNA 源并移除默认源 gem sources --add https://mirrors.tuna.tsinghua.edu.cn/rubygems/ --remove https://rubygems.org/ # 列出已有源 gem sources -l # 应该只有 TUNA 一个 或者，编辑 ~/.gemrc，将 https://mirrors.tuna.tsinghua.edu.cn/rubygems/ 加到 sources 字段 bundler 使用以下命令替换 bundler 默认源 bash bundle config mirror.https://rubygems.org https://mirrors.tuna.tsinghua.edu.cn/rubygems 二、VPN 代理 + 流量转发工具 折腾终端开启代理实在是一波三折，反反复复尝试了数次，之前没一次成功，但每次遇到需要安装国外源的软件时就痛不欲生！跨度一两年的一个问题终于解决了，记录一下 终端代理究其原理和 chrome 扩展 Proxy SwitchyOmega 是一样的，都是为了将 socks 协议的数据转换成 http 协议, 因为终端很多下载安装命令 - wget、curl、git、brew 等等都是使用的 http 协议 VPN 代理一般有 shadowsocks 和 v2ray 流量转发工具，主要是为了实现 socks5 和 http 加密数据间的转换，常用的有 polipo 和 privoxy v2ray + polipo + http_proxy + curl ip.gs 1、v2ray 客户端和服务端安装配置很简单 - v2ray 官方安装教程 v2ray 客户端和服务端一定要在 /etc/v2ray/config.json 文件添加日志路径！！！ \"log\": { \"loglevel\": \"warning\", \"access\": \"/var/log/v2ray/access.log\", \"error\": \"/var/log/v2ray/error.log\" } 2、安装 polipo ## Ubuntu 下的安装 sudo apt-get install polipo ## CentOS 下的安装 sudo yum install polipo ## 编辑配置文件 /etc/polipo/config vim /etc/polipo/config # This file only needs to list configuration variables that deviate # from the default values. See /usr/share/doc/polipo/examples/config.sample # and \"polipo -v\" for variables you can tweak and further information. logSyslog = true logFile = /var/log/polipo/polipo.log proxyAddress = \"0.0.0.0\" socksParentProxy = \"127.0.0.1:1080\" socksProxyType = socks5 chunkHighMark = 50331648 objectHighMark = 16384 serverMaxSlots = 64 serverSlots = 16 serverSlots1 = 32 # This file only needs to list configuration variables that deviate # from the default values. See /usr/share/doc/polipo/examples/config.sample # and \"polipo -v\" for variables you can tweak and further information. logSyslog = true logFile = /var/log/polipo/polipo.log # socks 代理地址 socksParentProxy = \"127.0.0.1:1080\" # 类型 socksProxyType = socks5 # 转换为 HTTP 之后的端口 proxyPort = 8123 # 下面不清楚，但需要 chunkHighMark = 50331648 objectHighMark = 16384 serverMaxSlots = 64 serverSlots = 16 serverSlots1 = 32 3、确保服务器 v2ray、客户端 v2ray 和 polipo 服务都正常运行，且查看日志没有报错！ 4、在客户端本地 ~/.bashrc 文件中设置 export http_proxy=http://127.0.0.1:8123 export https_proxy=http://127.0.0.1:8123 别名 # 添加如下 alias hp=\"export http_proxy=http://127.0.0.1:8123\" alias hps=\"export https_proxy=http://127.0.0.1:8123\" 5、使用 curl ip.gs 查看是否成功实现代理，若不成功，检查如下 本地和服务器防火墙是否开启，都没开启则跳过这项；本地防火墙开启的话，检查 8123 和 1080 端口是否开启 tcp；服务器防火墙开启的话，检查 v2ray 配置的端口是否开启 tcp，以上端口没开启的话，都要开启 登录 VPS 控制台，检查安全组（称呼不一，阿里云叫防火墙）里的 v2ray 端口是否开启 tcp 可以在本地使用 paping -p port hostip 检查服务器和本地端口开启情况 一般修改安全组，需要重启服务器才有效 设置了安全组就可以不设置云服务器防火墙，因为安全组规则相对于云服务器防火墙是在更上一层的拦截！比如，安全组开启了 10001 端口的 tcp，如果开启防火墙的服务器没有开启 10001 端口的 tcp ，外面也是无法连接的。 6、重启服务，再次使用 curl ip.gs 检查是否代理成功，不成功，就 Google！ Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Linux/APT-剖析详解.html":{"url":"Linux/APT-剖析详解.html","title":"APT 原理剖析、详解","keywords":"","body":"APT 原理剖析、详解 APT - Advanced Packaging Tool 软件安装方法历程图 /etc/apt/sources.list 只会告知系统可以访问的镜像站点地址，这时每当系统执行一次 sudo apt install xxx 都要链接镜像站检索出对应的软件地址，这样是很浪费时间的，所以在本地 /var/lib/apt/lists/ 会缓存一份镜像站里的所有软件源信息，这样每次执行 sudo apt install xxx 直接在本地缓冲里检索，在连接网络下载文件。所以 sudo apt install 会先访问 /var/lib/apt/lists/；而且 sudo apt update 更新的是 /var/lib/apt/lists/ 里的软件源 每当执行命令进行软件的安装或着更新，或者软件源的更新时，apt 会访问 /etc/apt/sources.list 内的地址，并在该网站中找到对应系统的包信息例如我的操作系统是 ubuntu，网站是 deb http://mirrors.163.com/ubuntu/ precise main restricted universe multiverse 网易的，那么当我们执行安装的命令时，他就会对应的访问 http://mirrors.163.com/ubuntu/dists/lucid/main/binary-i386/ 的 packages.gz，这个文件是服务器上软件包及其依赖关系的清单，并且用 gzip 压缩过了。apt-get update使用这个清单来确定能够获得哪些补充的软件包且他的内容会被保存在 /var/lib/apt/lists 内，通过访问这个 lists 确定该软件是否已安装，是否是最新版本，依赖关系是否满足，从而确定要更新内容，并进行更新，其安装过程主要是由 dpkg 来完成 一、 背景知识 1. PPA 源 - Personal Package Archives - 个人软件包集 源和软件仓库实际上是一个意思，厂商将编译后的二进制文件和软件信息存放至服务器，用户需要安装软件时，包管理器自动分析本机和容器（repository）内的信息，下载需要的包并自动安装，安装后将新安装的软件信息存放至本地 添加、删除 PPA 软件源# 添加 PPA 软件源的命令 $ sudo add-apt-repository ppa:user/ppa-name # 删除 PPA 软件源的命令 $ sudo add-apt-repository --remove ppa:user/ppa-name 例如，我们想要添加一个 Wireshark 软件的 PPA 源，我们可以根据它官网上提供的命令来进行添加，如下图所示： 当我们添加完 PPA 源之后，系统就会在 /etc/apt/sources.list.d/ 文件夹里创建了两个文件，一个 .list 文件和一个带有 .save 后缀的备份文件： $ cd /etc/apt/sources.list.d $ ls | grep wireshark wireshark-dev-stable-trusty.list wireshark-dev-stable-trusty.list.save 我们再来打开一下 wireshark-dev-stable-trusty.list 文件看看里面的内容是什么： deb http://ppa.launchpad.net/wireshark-dev/stable/ubuntu trusty main # deb-src http://ppa.launchpad.net/wireshark-dev/stable/ubuntu trusty main 原来文件里就是添加了一个跟软件源一模一样的东西，他们的作用殊途同归啊。我想这其实是 Ubuntu 为了分辨官方的源和第三方的源才设计成在 sources.list 和 sources.list.d/ 这两个地方中存储软件源信息。因为第三方的源毕竟不太可信，如果随便更新的话可是会出事情的。 2. deb http://site.example.com/debian distribution component 格式详解 deb http://site.example.com/debian distribution component1 component2 component3 deb-src http://site.example.com/debian distribution component1 component2 component3 # 例如 deb http://mirrors.aliyun.com/ubuntu/ bionic main restricted deb-src http://mirrors.aliyun.com/ubuntu/ bionic restricted universe multiverse main 档案类型 - Archive type 条目的第一个词 deb 或是 deb-src 表明了所获取的软件包档案类型 deb - 档案类型为二进制预编译软件包，一般我们所用的档案类型 deb-src - 档案类型为用于编译二进制软件包的源代码 每行的第一个单词 deb 或 deb-src，描述了文件类型，目录中包含的是二进制软件包（ deb ），即我们通常使用的已编译好的软件包；或包含的是源码包（ deb-src ），源码包包含源程序编码、Debian 管理文件（ .dsc ）和 “Debian 化” 该程序所做更改的记录文件 diff.gz 仓库地址 - Repository URL 条目的第二个词则是软件包所在仓库的地址，我们可以更换仓库地址为其他地理位置更靠近自己的镜像来提高下载速度 Ubuntu 软件源的源列表：国内开源镜像站点汇总 仓库地址可以是多种类型：http、ftp、file（ 本地文件，例如：一个加载了 ISO9600 文件系统的目录 ） 或 ssh 发行版 - Distribution 跟在仓库地址后的是发行版。发行版有两种分类方法 一类是发行版的具体代号，如 xenial,trusty, precise 等 另一类则是发行版的发行类型，如 oldstable, stable, testing 和 unstable 另外，在发行版后还可能有进一步的指定，如 xenial-updates, trusty-security, stable-backports 等 可以通过命令 lsb_release -cs,查看当前操作系统代号, 例如 Ubuntu 16.04 LTS 代号为 xenial, Ubuntu 18.04 LTS 代号为 bionic $ lsb_release -ca No LSB modules are available. Distributor ID: Ubuntu Description: Ubuntu 18.04.3 LTS Release: 18.04 Codename: bionic 软件包分类 - Component 跟在发行版之后的就是软件包的具体分类了，可以有一个或多个。不同的 Linux 发行版对软件有着不同的分类 Debian main 包含符合 DFSG 指导原则的自由软件包，而且这些软件包不依赖不符合该指导原则的软件包。这些软件包被视为 Debian 发型版的一部分 contrib 包含符合 DFSG 指导原则的自由软件包，不过这些软件包依赖不在 main 分类中的软件包 non-free 包含不符合 DFSG 指导原则的非自由软件包 Ubuntu main 官方支持的自由软件 restricted 官方支持的非完全自由的软件 universe 社区维护的自由软件 multiverse 非自由软件 Ubuntu 自由软件 非自由软件 官方支持 Main Restricted 非官方支持 Universe Multiverse 二、 apt 基本命令 apt [选项] 命令 [选项] list - 根据名称列出软件包 search - 搜索软件包描述 show - 显示软件包细节 install - 安装软件包 remove - 移除软件包 autoremove - 卸载所有自动安装且不再使用的软件 update - 根据 /etc/apt/sources.list 更新 /var/lib/apt/lists 软件包列表 upgrade - 根据 /var/lib/apt/lists 安装/升级 软件来更新系统 full-upgrade - 通过 卸载/安装/升级 来更新系统 edit-sources - 编辑软件源信息文件 添加 PPA 软件源并安装 $ sudo add-apt-repository # 此命令将 PPA 仓库添加到列表中 $ sudo apt-get update # 此命令更新可以在当前系统上安装的软件包列表 $ sudo apt-get install # 此命令安装软件包 # 例如 $ sudo add-apt-repository ppa:dr-akulavich/lighttable $ sudo apt-get update $ sudo apt-get install lighttable-installer 强制重装已安装的软件 $ sudo apt-get --reinstall install # 会先删除软件，再安装 sudo apt install \\ 新增文件位置 主要分散到以下四个目录 /usr/bin - 二进制文件 /usr/lib - 动态函数库文件 /usr/share/doc - 使用手册 /usr/share/man - man page 所以在多用户情况下使用 sudo apt install 安装软件，会造成软件存放散乱，寻找软件配置文件麻烦；但好处是 apt 安装软件系统会自动注册环境变量，且是全局的 当自己使用源码安装软件通常把源码包放在 /usr/local sudo apt update 具体执行动作 执行 sudo apt update 链接 /etc/apt/sources.list 里的软件源的镜像站，自动检索对比镜像站里的所有软件源与本地的 /var/lib/apt/lists/ 目录，若发现有更新，立即在 /var/lib/apt/lists/ 目录里跟新 更新完毕 强制更新 sudo rm -rf /var/lib/apt/lists/* sudo apt-get update 3. sudo apt autoremove autoclean 是另一种方法，用于清除下载的包文件的本地存储库，clean 和之间的区别在于autoclean后者仅删除无法再从其源下载的包文件，并且很可能无用 4. /etc/apt/ 目录详解 /etc/apt 目录详解图 /etc/apt/sources.list && /etc/apt/sources.list.d/ /etc/apt/sources.list内容组成 /etc/apt/sources.list 文件 当使用sudo apt install xxx安装软件时，系统会自动在配置的镜像软件源列表（ /var/lib/apt/lists/ )寻找，找到后自动添加进来 /etc/apt/sources.list.d/内容组成 /etc/apt/sources.list.d/ 文件夹 /etc/apt/sources.list.d/多是由第三方软件源文件组成，比如使用sudo dpkg -i xxx.deb安装或通过添加 PPA 软件第三方源sudo add-apt-repository ppa:user/ppa-name安装，而这些文件主要有这么三种： xxx.list xxx.list.distUpgrade xxx.list.save xxx.list - 记录第三方软件的软件源信息 ### THIS FILE IS AUTOMATICALLY CONFIGURED ### # You may comment out this entry, but any other modifications may be lost. # deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main # 已禁止升级到 bionic xxx.list.save - 是xxx.list.save的备份，内容相同 xxx.list.disUpgrade - 网上没找到，未知待续 ### THIS FILE IS AUTOMATICALLY CONFIGURED ### # You may comment out this entry, but any other modifications may be lost. deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main /etc/apt/apt.conf && /etc/apt/apt.conf.d/ /etc/apt/apt.conf:APT配置文件。 /etc/apt/apt.conf.d/:APT配置文件片段。 /etc/apt/preferences 版本首选项文件。您可以在此处指定“ 固定 ”，即从单独的源或不同版本的分发中获取某些包的首选项。 5. /var/cache/apt/ /var/cache/apt/archives/ 检索到的包文件的存储区域 $ sudo apt clean清空此目录 APT缓存文件，目录是在用 apt-get install 安装软件时，软件包的临时存放路径 /var/cache/apt/archives/partial/ 传输中的包文件的存储区域。 /var/lib/apt/lists/ sources.list中指定的每个包资源的状态信息的存储区域 /var/ lib/apt/lists/partial/ 传输中的状态信息的存储区域。 /var/lib/dpkg/available 文件的内容是软件包的描述信息，该软件包括当前系统所使用的安装源中的所有软件包，其中包括当前系统中已安装的和未安装的软件包 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Linux/Linux主机、虚拟机和docker网络配置.html":{"url":"Linux/Linux主机、虚拟机和docker网络配置.html","title":"Linux 主机、虚拟机和docker网络配置","keywords":"","body":"Linux 主机、虚拟机和docker网络配置 使用过 VMware 、VirtualBox、KVM，但一直不太喜欢，最主要的原因就是繁琐的网络配置，例如 NAT、桥接、Host-Only 都啥意思，一直不懂，一直都是按着网上安装教程傻瓜式操作，最近需要搭建多台虚拟机，单是一个里面 ping 外面、外面 ping 里面、虚拟机互相 ping，就弄得我晕头转向！关键还是网络配置的短板，特来记录一下几天来的学习！ 背景学习 1、IP、NetMask、GateWay、DNS 检查 DNS 是否正常：因为 QQ 不需要有 DNS ( QQ 只是一个客户端程序，用不到 DNS)，只有浏览网页 ( 需输入网址时 ) 才用到 DNS，所以如果出现 QQ 能用但浏览器连不上网，则很可能是 DNS 出现问题 Sub NetMask - 子网掩码 子网掩码 - 用来判断任意两台计算机的 IP 地址是否属于同一子网络 对于一台计算机来说，差不多有三种场合的通信 1）自己与自己通信 2）与本网段其它主机通信 3）与别的网段主机的通信 子网掩码就是为了分辨出以上三个场景而设计的 举个例子：10.10.10.1 255.255.255.0 其中 255.255.255.0 就是网络掩码，由于这个掩码全 1 的二进制位长为 24位，我们也经常写为 10.10.20.1/24 自己与自己通信 当 ping 10.10.10.1 时，计算机和自己的IP相比较，所以会发给自己，我们称之为精确匹配 与本网段其它主机通信 当 ping 10.10.10.2 时，计算机和自己的 IP 相比较，发现并不相等，则需要退而求其次，使用模糊匹配，用自己的掩码 255.255.255.0 与 10.10.10.2 做按位与，得到网段 10.10.10，这个和自己在一个网段（一个广播域），所以可以广播 ARP 得到对方的 MAC，完成通信。 与别的网段主机的通信 当 ping 8.8.8.8 时，计算机和自己的 IP 相比较，发现并不相等，则需要退而求其次，使用模糊匹配，用自己的掩码 255.255.255.0 与 8.8.8.8 做按位与，得到网段 8.8.8，和自己 10.10.10 不在一个网段，需要使用最模糊的匹配，一般会匹配 0.0.0.0/0，这个是最后的选择，一般指向网关，由于网关和自己在一个网段（一个广播域），所以可以广播 ARP 得到网关的MAC，然后把 ping 包发给网关，完成通信 GateWay - 网关 网关 - 是一个网络通向其他网络的 IP 地址 比如有网络 A 和网络 B，网络 A 的 IP 地址范围为 192.168.1.1~192. 168.1.254，子网掩码为 255.255.255.0；网络 B 的 IP 地址范围为 192.168.2.1~192.168.2.254，子网掩码为 255.255.255.0。在没有路由器的情况下，两个网络之间是不能进行 TCP/IP 通信的，即使是两个网络连接在同一台交换机（或集线器）上，TCP/IP 协议也会根据子网掩码（ 255.255.255.0 ）判定两个网络中的主机处在不同的网络里。而要实现这两个网络之间的通信，则必须通过网关 ( 比如路由器 ) 如果网络 A 中的主机发现数据包的目的主机不在本地网络中，就把数据包转发给它自己的网关，再由网关转发给网络 B 的网关，网络 B 的网关再转发给网络 B 的某个主机 DNS - Domain Name Server - 域名服务器 将 URL 解析成主机 IP 地址 2、常见网卡详解 ​ 服务器通常有多块网卡，有板载集成的，同时也有插在 PCIe 插槽的。Linux 系统的命名原来是 eth0,eth1 这样的形式，但是这个编号往往不一定准确对应网卡接口的物理顺序 网卡查看方法 ip a ifconfig 以上命令都没安装，还可直接读取文件 cat /proc/net/dev 判断网卡是虚拟还是物理网卡 # /sys/devices/virtual/net 目录下都是虚拟网卡 $ ls -l /sys/devices/virtual/net 总用量 0 drwxr-xr-x 7 root root 0 Nov 22 16:48 docker0 drwxr-xr-x 5 root root 0 Nov 22 16:48 lo drwxr-xr-x 6 root root 0 Nov 22 16:48 veth61d2c91 drwxr-xr-x 6 root root 0 Nov 22 16:48 vethbe484a2 物理网卡 eno1 - 代表由主板 bios 内置的网卡，如果从 BIOS 中能够取到可用的，板载网卡的索引号，则使用这个索引号命名，例如: eno1 ens1 - 代表有主板 bios 内置的 PCI-E 网卡，如果从BIOS中能够取到可以用的，网卡所在的PCI-E热插拔插槽(\\注：pci槽位号)**的索引号，则使用这个索引号命名，例如: ens1 enp2s0 - PCI-E 独立网卡，如果能拿到设备所连接的物理位置（PCI总线号+槽位号）信息，则使用这个信息命名，例如: enp2s0 eth0、eth1、eth2 ... - 如果以上都不使用，则回到默认的网卡名，统一的 kernel 命名方法，例如: eth0，这种命名方法的结果不可预知的，即可能第二块网卡对应 eth0，第一块网卡对应 eth1 虚拟网卡 虚拟网络接口并不真实地从外界接收和发送数据包，而是在系统内部接收和发送数据包，因此虚拟网络接口不需要驱动程序 虚拟网卡和物理网卡在使用上是一致的 lo - localhost - 本地环回接口，ip 是 127.0.0.1，实现系统内部发送和接收数据 docker0 - docker 在宿主机中的网卡 3. Linux 网络配置文件 I、CentOS 系列 /etc/sysconfig/network-scripts/ - 网卡的控制文件目录 $ ls /etc/sysconfig/network-scripts/ ifcfg-eth0 ifdown-ib ifdown-ppp ifdown-tunnel ifup-ib ifup-plusb ifup-Team network-functions ifcfg-lo ifdown-ippp ifdown-routes ifup ifup-ippp ifup-post ifup-TeamPort network-functions-ipv6 ifdown ifdown-ipv6 ifdown-sit ifup-aliases ifup-ipv6 ifup-ppp ifup-tunnel ifdown-bnep ifdown-isdn ifdown-Team ifup-bnep ifup-isdn ifup-routes ifup-wireless ifdown-eth ifdown-post ifdown-TeamPort ifup-eth ifup-plip ifup-sit init.ipv6-global /etc/sysconfig/network-scripts/ifcfg-eth0 - 网卡信息文件 DEVICE=eth0 #网卡设备名称 ONBOOT=yes #启动时是否激活 yes | no BOOTPROTO=static #协议类型 dhcp bootp none IPADDR=192.168.1.90 #网络IP地址 NETMASK=255.255.255.0 #网络子网地址 GATEWAY=192.168.1.1 #网关地址 BROADCAST=192.168.1.255 #广播地址 HWADDR=00:0C:29:FE:1A:09 #网卡MAC地址 TYPE=Ethernet #网卡类型为以太网 TYPE 网络类型（通常是 Ethemet） DEVICE 接口名（设备,网卡） USERCTL [yes|no]（非root用户是否可以控制该设备） BOOTPROTO IP 的配置方法 [none|static|bootp|dhcp]（引导时不使用协议|静态分配IP|BOOTP协议|DHCP协议） HWADDR MAC地址 ONBOOT 系统启动的时候网络接口是否有效（yes/no） NETMASK 网络掩码 IPADDR IP 地址 IPV6INIT IPV6 是否有效（yes/no） GATEWAY 默认网关IP地址 BROADCAST 广播地址 NETWORK 网络地址 DNS1 第一 DNS 服务器指向； DNS2 备用 DNS 服务器指向； 修改 /etc/sysconfig/network-scripts/ifcfg-eth0 文件后需要重启网卡 ( sudo systemctl restart network )或电脑 /etc/sysconfig/network /etc/resolv.conf - DNS 配置文件 /etc/hostname - 主机名 /etc/hosts II、Ubuntu 系列 /etc/network /etc/network/interfaces - ip、子网掩码、默认网关 /etc/NetworkManager/ /etc/hostname - 主机名 /etc/resolv.conf - DNS 配置文件 /etc/hosts Linux 主机常用网络配置 I. Ubuntu 设置静态 IP $ vim /etc/network/interface # 在 interface 添加 eth0 接口的 IP，网络号，掩码，广播地址和网关 auto eth0 iface eth0 inet static address 192.168.2.100 network 192.168.2.0 netmask 255.255.255.0 broadcast 192.168.0.255 gateway 192.168.0.1 重启网卡 $ sudo ifup eth0 $ sudo ifdown eth0 # 或 $ sudo ifconfig eth0 down $ sudo ifconfig eth0 up 重启网络 `sudo` `/etc/init``.d``/networking` `restart``sudo` `/etc/init``.d``/network-manager` `restart` `` `` `` 2. NAT Bridged Adapter Host-Only VM -> Host Host -> VM VM VM VM -> Other Host Other Host -> VM 桥接 - Bridged Adapter 虚拟机和主机是处于同等地位的机器，所以网络功能也无异于主机。并且和主机处于同一网段 原理 桥接模式，使用的是VMnet0虚拟网卡。 vmnet0实际上就是一个虚拟的网桥(2层交换机)，这个网桥有若干个接口，一个端口用于连接你的Host主机，其余端口可以用于连接虚拟机，他们的位置是对等的，谁也不是谁的网关。所以桥接模式下，虚拟机和Host主机是同等地位的主机 配置 /etc/sysconfig/network-scripts/ifcfg-enp0s3 NAT - Network address translation - 网络地址转换 Linux 网络配置命令 ifconfig - 网卡配置 【参考】 linux网卡命名规则 IP地址，子网掩码，默认网关，DNS服务器详解 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Linux/Linux文件系统学习.html":{"url":"Linux/Linux文件系统学习.html","title":"Linux文件系统学习","keywords":"","body":"Linux 文件系统学习 最近在做 OS 实现一个文件系统的课程设计，详细学习了一下 Linux 的文件系统，来总结记录一下 参考 阮一峰的网络日志 - 理解inode 背景知识 扇区 、簇 、 块 物理层面：一个磁盘按层次分为 磁盘组合 -> 单个磁盘 -> 某一盘面 -> 某一磁道 -> 某一扇区 扇区 - sector 扇区是磁盘中最小的物理存储单位，通常情况下每个扇区的大小是 512 字节（ 由于不断提高磁盘的大小，部分厂商设定每个扇区的大小是 4096 字节 ） 每个磁盘有多条同心圆似的磁道，磁道被分割成多个部分，每部分的弧长加上到圆心的两个半径，恰好形成一个扇形，所以叫做扇区 簇 - cluster 簇可以说是操作系统在实际分配、调度的逻辑存储单位 由于操作系统无法对数目众多的扇区进行寻址，所以操作系统就将相邻的扇区组合在一起，形成一个簇，然后再对簇进行管理 操作系统规定一个簇中只能放置一个文件的内容，因此文件所占用的空间，只能是簇的整数倍 Windows 的文件系统（ NTFS ）称呼为 “簇” 块 - block 块是 Linux 的文件系统（ EXT ）下逻辑存储单位，类似于簇，产生由来同簇 通过虚拟出来磁盘块的概念，在操作系统中认为块是最小的单位 MBR GPT / BIOS UEFI 待续 # Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Linux/Linux用户和用户组管理.html":{"url":"Linux/Linux用户和用户组管理.html","title":"Linux用户和用户组管理","keywords":"","body":"Linux 用户和用户组管理 相关配置文件： /etc/passwd 用户账户信息。 /etc/shadow 安全用户账户信息。 /etc/group 组账户信息。 /etc/gshadow 安全组账户信息 一台服务器至少应该设置两个用户，一个是 root,另外一个是拥有 root 权限的普通用户（通过配置 /etc/sudoers 可以实现），这样就能够保证一个密码出错后还可以通过另外一个用户登录服务器重置密码 chmod chown chgrp useradd userdel [username] - 删除 username 用户，但不删除该用户主目录 userdel -r [username] - 删除 username 用户，一并删除该用户主目录 groupadd groupdel passwd gpasswd -a [username] [groupname] - 将用户 username 添加到 groupname 组 gpasswd -d [username] [groupname] - 将用户 username 从 groupname 组中删除 cat -n /etc/group | grep [groupname] - 单独查看 groupname 组信息 cat -n /etc/passwd | grep [username] - 单独查看 username 用户信息 id [username] - 查看 username 用户信息和该用户的组信息 usermod suid/guid useradd userdel usermod groupadd groupdel groupmod chmod Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Linux/Linux用户增删改等学习.html":{"url":"Linux/Linux用户增删改等学习.html","title":"Linux用户增删改等学习.md","keywords":"","body":" Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Linux/Linux程序存放目录.html":{"url":"Linux/Linux程序存放目录.html","title":"Linux程序存放目录.md","keywords":"","body":" Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Linux/Linux编译安装软件包详解.html":{"url":"Linux/Linux编译安装软件包详解.html","title":"Linux C/C++ 软件包编译、安装原理详解","keywords":"","body":"Linux C/C++ 软件包编译、安装原理详解 Linux 下开源的　C/C++ 项目常常提供源码包，以下是转自阮一峰博客的一篇的安装方法./configure make make install(这些都是典型的使用GNU的AUTOCONF和AUTOMAKE产生的程序的安装步骤)的原理详解 ./configure - 配置　- 确定标准库和头文件的位置　- 确定依赖关系 make - 头文件的预编译(precompilation) - 预处理（Preprocessing）- 编译（Compilation）- 连接（Linking） sudo make install - 安装（Installation）- 操作系统连接 ./configure　通过检查用户的编译环境, 在根据用于指定的编译特性来生成Makefile文件，它是个shell脚本。 make是用来编译的，它从Makefile中读取指令，然后编译 make install是用来安装的，它也从Makefile中读取指令，安装到指定的位置 第一步 配置（configure） 编译器在开始工作之前，需要知道当前的系统环境，比如标准库在哪里、软件的安装位置在哪里、需要安装哪些组件等等。这是因为不同计算机的系统环境不一样，通过指定编译参数，编译器就可以灵活适应环境，编译出各种环境都能运行的机器码。这个确定编译参数的步骤，就叫做\"配置\"（configure） 这些配置信息保存在一个配置文件之中，约定俗成是一个叫做configure的脚本文件。通常它是由autoconf工具生成的。编译器通过运行这个脚本，获知编译参数 第二步 确定标准库和头文件的位置 源码肯定会用到标准库函数（standard library）和头文件（header）。它们可以存放在系统的任意目录中，编译器实际上没办法自动检测它们的位置，只有通过配置文件才能知道。 编译的第二步，就是从配置文件中知道标准库和头文件的位置。一般来说，配置文件会给出一个清单，列出几个具体的目录。等到编译时，编译器就按顺序到这几个目录中，寻找目标。 第三步 确定依赖关系 对于大型项目来说，源码文件之间往往存在依赖关系，编译器需要确定编译的先后顺序。 编译顺序保存在一个叫做makefile的文件中，里面列出哪个文件先编译，哪个文件后编译。而makefile文件由configure脚本运行生成，这就是为什么编译时configure必须首先运行的原因。 在确定依赖关系的同时，编译器也确定了，编译时会用到哪些头文件。 第四步 头文件的预编译（precompilation） 不同的源码文件，可能引用同一个头文件（比如stdio.h）。编译的时候，头文件也必须一起编译。为了节省时间，编译器会在编译源码之前，先编译头文件。这保证了头文件只需编译一次，不必每次用到的时候，都重新编译了。 不过，并不是头文件的所有内容，都会被预编译。用来声明宏的#define命令，就不会被预编译。 第五步 预处理（Preprocessing） 预编译完成后，编译器就开始替换掉源码中bash的头文件和宏。编译器在这一步还会移除注释。 这一步称为\"预处理\"（Preprocessing），因为完成之后，就要开始真正的处理了 第六步 编译（Compilation） 预处理之后，编译器就开始生成机器码。对于某些编译器来说，还存在一个中间步骤，会先把源码转为汇编码（assembly），然后再把汇编码转为机器码 第七步 连接（Linking） 对象文件还不能运行，必须进一步转成可执行文件 编译器的下一步工作，就是把外部函数的代码（通常是后缀名为.lib和.a的文件），添加到可执行文件中。这就叫做连接（linking）。这种通过拷贝，将外部函数库添加到可执行文件的方式，叫做静态连接（static linking），后文会提到还有动态连接（dynamic linking） 第八步 安装（Installation） 上一步的连接是在内存中进行的，即编译器在内存中生成了可执行文件。下一步，必须将可执行文件保存到用户事先指定的安装目录。 表面上，这一步很简单，就是将可执行文件（连带相关的数据文件）拷贝过去就行了。但是实际上，这一步还必须完成创建目录、保存文件、设置权限等步骤。这整个的保存过程就称为\"安装\"（Installation）。 第九步 操作系统连接 可执行文件安装后，必须以某种方式通知操作系统，让其知道可以使用这个程序了。比如，我们安装了一个文本阅读程序，往往希望双击txt文件，该程序就会自动运行。 这就要求在操作系统中，登记这个程序的元数据：文件名、文件描述、关联后缀名等等。Linux系统中，这些信息通常保存在/usr/share/applications目录下的.desktop文件中。另外，在Windows操作系统中，还需要在Start启动菜单中，建立一个快捷方式。 这些事情就叫做\"操作系统连接\"。make install命令，就用来完成\"安装\"和\"操作系统连接\"这两步。 第十步 生成安装包 写到这里，源码编译的整个过程就基本完成了。但是只有很少一部分用户，愿意耐着性子，从头到尾做一遍这个过程。事实上，如果你只有源码可以交给用户，他们会认定你是一个不友好的家伙。大部分用户要的是一个二进制的可执行程序，立刻就能运行。这就要求开发者，将上一步生成的可执行文件，做成可以分发的安装包。 所以，编译器还必须有生成安装包的功能。通常是将可执行文件（连带相关的数据文件），以某种目录结构，保存成压缩文件包，交给用户。 第十一步 动态连接（Dynamic linking） 正常情况下，到这一步，程序已经可以运行了。至于运行期间（runtime）发生的事情，与编译器一概无关。但是，开发者可以在编译阶段选择可执行文件连接外部函数库的方式，到底是静态连接（编译时连接），还是动态连接（运行时连接）。所以，最后还要提一下，什么叫做动态连接。 前面已经说过，静态连接就是把外部函数库，拷贝到可执行文件中。这样做的好处是，适用范围比较广，不用担心用户机器缺少某个库文件；缺点是安装包会比较大，而且多个应用程序之间，无法共享库文件。动态连接的做法正好相反，外部函数库不进入安装包，只在运行时动态引用。好处是安装包会比较小，多个应用程序可以共享库文件；缺点是用户必须事先安装好库文件，而且版本和安装位置都必须符合要求，否则就不能正常运行。 现实中，大部分软件采用动态连接，共享库文件。这种动态共享的库文件，Linux平台是后缀名为.so的文件，Windows平台是.dll文件，Mac平台是.dylib文件。 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Linux/SSH详解.html":{"url":"Linux/SSH详解.html","title":"SSH 详解","keywords":"","body":"SSH 详解 目录 SSH 介绍 应用篇 Linux SSH 相关命令 SSH 密码或无密码( 密钥 )登录 **OpenSSH升级到最新 openssh8 的坑 原理篇 密码学加密算法 SSH 登录原理 SSH 中间人攻击 SSH 介绍 Secure Shell（安全外壳协议，简称 SSH）是一种加密的网络传输协议，可在不安全的网络中为网络服务提供安全的传输环境 SSH 通过在网络中创建安全隧道来实现 SSH 客户端与服务器之间的连接 在设计上，SSH 是 Telnet 和非安全 shell 的替代品，Telnet 和 Berkeley rlogin、rsh、rexec 等协议采用明文传输，使用不可靠的密码，容易遭到监听、嗅探和中间人攻击 SSH使用客户端-服务器模型，标准端口为 22。服务器端需要开启SSH守护进程以便接受远端的连接，而用户需要使用 SSH 客户端与其创建连接 SSH 的经典用途是登录到远程电脑中执行命令。除此之外，SSH 也支持隧道协议、端口映射和 X11 连接。借助 SFTP 或 SCP 协议，SSH 还可以传输文件 应用篇 Linux SSH 相关命令 ssh -v @ - 打印运行情况和调试信息 ssh -vv @ - 打印更详细的运行情况和调试信息 ssh -vvv @ - 打印最详细的运行情况和调试信息 $ ssh root@aliyun -v OpenSSH_7.6p1 Ubuntu-4ubuntu0.3, OpenSSL 1.0.2n 7 Dec 2017 debug1: Reading configuration data /etc/ssh/ssh_config debug1: /etc/ssh/ssh_config line 19: Applying options for * debug1: Connecting to aliyun [106.15.72.140] port 22. debug1: Connection established. debug1: identity file /home/xcq/.ssh/id_rsa type 0 debug1: key_load_public: No such file or directory debug1: identity file /home/xcq/.ssh/id_rsa-cert type -1 debug1: key_load_public: No such file or directory debug1: identity file /home/xcq/.ssh/id_dsa type -1 debug1: key_load_public: No such file or directory debug1: identity file /home/xcq/.ssh/id_dsa-cert type -1 debug1: key_load_public: No such file or directory debug1: identity file /home/xcq/.ssh/id_ecdsa type -1 debug1: key_load_public: No such file or directory debug1: identity file /home/xcq/.ssh/id_ecdsa-cert type -1 debug1: key_load_public: No such file or directory debug1: identity file /home/xcq/.ssh/id_ed25519 type -1 debug1: key_load_public: No such file or directory debug1: identity file /home/xcq/.ssh/id_ed25519-cert type -1 debug1: Local version string SSH-2.0-OpenSSH_7.6p1 Ubuntu-4ubuntu0.3 debug1: Remote protocol version 2.0, remote software version OpenSSH_7.6p1 Ubuntu-4ubuntu0.3 debug1: match: OpenSSH_7.6p1 Ubuntu-4ubuntu0.3 pat OpenSSH* compat 0x04000000 debug1: Authenticating to aliyun:22 as 'root' debug1: SSH2_MSG_KEXINIT sent debug1: SSH2_MSG_KEXINIT received debug1: kex: algorithm: curve25519-sha256 debug1: kex: host key algorithm: ecdsa-sha2-nistp256 debug1: kex: server->client cipher: chacha20-poly1305@openssh.com MAC: compression: none debug1: kex: client->server cipher: chacha20-poly1305@openssh.com MAC: compression: none debug1: expecting SSH2_MSG_KEX_ECDH_REPLY debug1: Server host key: ecdsa-sha2-nistp256 SHA256:Shnbq2gjAuoqjUmvnn4fwTRFvByWlHFmxi6WXGAtOPs debug1: Host 'aliyun' is known and matches the ECDSA host key. debug1: Found key in /home/xcq/.ssh/known_hosts:51 debug1: rekey after 134217728 blocks debug1: SSH2_MSG_NEWKEYS sent debug1: expecting SSH2_MSG_NEWKEYS debug1: SSH2_MSG_NEWKEYS received debug1: rekey after 134217728 blocks debug1: SSH2_MSG_EXT_INFO received debug1: kex_input_ext_info: server-sig-algs= debug1: SSH2_MSG_SERVICE_ACCEPT received debug1: Authentications that can continue: publickey,password debug1: Next authentication method: publickey debug1: Offering public key: RSA SHA256:rdOjFLUoUcd66Ni/HuR353ht01sfhYpZh3y1y9lwuwM /home/xcq/.ssh/id_rsa debug1: Server accepts key: pkalg rsa-sha2-512 blen 279 debug1: Authentication succeeded (publickey). Authenticated to aliyun ([106.15.72.140]:22). debug1: channel 0: new [client-session] debug1: Requesting no-more-sessions@openssh.com debug1: Entering interactive session. debug1: pledge: network debug1: client_input_global_request: rtype hostkeys-00@openssh.com want_reply 0 debug1: Sending environment. debug1: Sending env LC_MEASUREMENT = en_HK.UTF-8 debug1: Sending env LC_PAPER = en_HK.UTF-8 debug1: Sending env LC_MONETARY = en_HK.UTF-8 debug1: Sending env LANG = zh_CN.UTF-8 debug1: Sending env LC_NAME = en_HK.UTF-8 debug1: Sending env LC_ADDRESS = en_HK.UTF-8 debug1: Sending env LC_NUMERIC = en_HK.UTF-8 debug1: Sending env LC_TELEPHONE = en_HK.UTF-8 debug1: Sending env LC_IDENTIFICATION = en_HK.UTF-8 debug1: Sending env LC_TIME = en_HK.UTF-8 Welcome to Ubuntu 18.04.4 LTS (GNU/Linux 4.15.0-48-generic x86_64) identity file type .../.ssh/id_* type 中的数字只是 sshkey_types 枚举 的整数值（基于零），-1表示错误 KEY_RSA, // id_rsa has type 0 KEY_DSA, // id_dsa has type 1, but as you have no id_dsa key file, -1 is used KEY_ECDSA, // id_ecdsa has type 2 debug [123]: 行前缀中的数字表示其后面的消息的调试级别。它对应于您在命令行上给出的 -v 的数量（3 是最大值）。即如果设置 -v，将打印 debug1 消息，使用 -vv，您将获得 debug1 和 debug2，最多是三级，即 -vvv ssh -T git@xxx.com - 测试 ssh 密钥连接是否成功# github $ ssh -T git@github.com # gitee $ ssh -T git@gitee.com # coding $ ssh -T git@e.coding.net ssh @ - 登录 host ssh @ \"[command]\" - 登录 host 并执行命令 ssh -J @: @ -p - 通过跳板机登录目标机 ssh 命令登录失败后，重试时总是卡住，一般在重试前先重启 sshd 服务就可以解决 ssh @ - 登录 host 直接执行命令 ssh @ 'tar cz file' | tar zxv - 本地~/file 文件通过 ssh 加密传输到 hostip 的~ 目录下 ssh @ 'tar cz file' | tar xzv - hostip 的~/file 文件通过 ssh 加密传输到本地的 ~ 目录下 scp @: - 通过 scp 命令上传本地文件到远程 scp -r @: - 通过 scp 命令上传本地文件夹到远程 scp @: - 通过 scp 命令传下载远程文件到本地 scp -r @: - 通过 scp 命令传下载远程文件夹到本地 **Linux 和　Windows 实现 scp 互传文件＊＊ 因为 Windows 系统本身不支持 ssh 协议，所以要想实现两者 scp 互传文件，必须在 Windows 客户端安装 ssh for windows 的客户端软件，比如 winsshd，使 Windows 系统支持 ssh 协议 scp /root/README.md administrator@192.168.7.12:/d:/test/ - 通过 scp 命令上传本地 (Linux) 文件到远程 (Windows) 上 scp administrator@192.168.7.12:/d:/test/README.md /root/ - 通过 scp 命令下载远程 (Windows) 文件到本地 (Linux) scp -o \"ProxyCommand=nc -X connect -x proxy_ip:proxy_port %h %p\" filename username@target_ip:/target_path scp -o \"ProxyCommand=nc -X connect -x 47.101.133.201:22 %h %p\" /home/xcq/test1 root@54.250.52.188:/root ssh-keygen - 默认在~/.ssh/ 下生成 RSA 公私密钥对 ssh-keygen -t dsa - 在~/.ssh/ 下生成 dsa 公私密钥对 ssh-keygen -t rsa -C '电子邮箱' ssh-keygen -f ~/.ssh/id_rsa -y > ~/.ssh/id_rsa.pub - 如果您有 OpenSSH 私钥（id_rsa 文件），则可以使用以下命令生成 OpenSSH 公钥文件 ssh-keygen -y [私钥] - 从私钥生成公钥，反之显而是不行的 ssh-keygen -R - 从 SSH 的 known_hosts 文件中删除特定的主机密钥 ssh-keygen -f \"/home/xcq/.ssh/known_hosts\" -R \"192.168.7.47\" - 删除指定 known_hosts 文件中的主机公钥 ssh-keyscan ssh-add ssh-keysign ssh-copy-id @ - 默认将本地主机公钥 ~/.ssh/id_rsa.pub 添加到远程服务器 /.ssh/authorized_keys 文件中，实现无密码登录 ssh-copy-id -i /id_rsa.pub @ - 将本地主机公钥 公钥路径 中的 id_rsa.pub 添加到远程服务器 /.ssh/authorized_keys 文件中，实现无密码登录 /etc/ssh/ssh.config - 客户端配置文件 /etc/ssh/sshd.config - 服务的配置文件 开启密钥认证登录 # 开启密钥验证 RSAAuthentication yes PubkeyAuthentication yes RSAAuthentication yes # 制定公钥文件路径 AuthorsizedKeysFile $h/.ssh/authorized_keys 关闭密码登录 PasswordAuthentication no ~/.ssh/known_hosts - 查看已知主机的公钥 关闭 hostkeychecking，初次登录时不用输入 yes StrictHostKeyChecking no ~/.ssh/authorized_keys - 存放需要密钥登录本机的 host 公钥 SSH 密码或无密码( 密钥 )登录 SSH 登录通常有密码登录和密钥登录 ( 或无密码直接登录 ) 密码登录 云服务器创建配后配置密码登录 无密码登录 1、生成本地 RSA 或 DSA 密钥对 $ ssh-keygen # 一路回车就可 # root 用户生成公私钥在：/root/.ssh/ # 非 root 用户：在自己主目录下的 .ssh/ 2、将本地公钥内容追加到远程服务器的/root/.ssh/authorized_keys 或 用户目录下的.ssh/authorized_keys # 也可以使用 ssh-copy-id $ ssh-copy-id root@目标节点IP # ssh-copy-id root@192.168.56.101 /usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: \"/root/.ssh/id_rsa.pub\" /usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed /usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys root@192.168.56.101's password: Number of key(s) added: 1 Now try logging into the machine, with: \"ssh 'root@192.168.56.101'\" and check to make sure that only the key(s) you wanted were added. 3、重启 ssh, 退出再次登陆即可实现无密码登录 OpenSSH升级到最新 openssh8 的坑 官网升级教程 - http://www.linuxfromscratch.org/blfs/view/9.0-systemd/postlfs/openssh.html entOS7升级OpenSSH 到8.3版本 - https://www.hncldz.com/?p=625 如果使用默认的源码，make install 安装到Ubuntu16.04或者Centos7，在默认使用systemd管理sshd时，你会发现，启动命令会卡起，稍后用systemctl 查看status发现卡在正在启动的阶段 - http://blog.chinaunix.net/uid-28813320-id-5786956.html 服务启动成功，用户密码也都对，就是无法建立连接，可能是UsePAM和SELinux的问题 - https://segmentfault.com/a/1190000018629266 原理篇 密码学加密算法 加密方法可以分为两大类，一类是单钥加密（ private key cryptography ），还有一类叫做双钥加密（ public key cryptography ）。前者的加密和解密过程都用同一套密码，后者的加密和解密过程用的是两套密码 【mì yuè】读音下的“密钥”的意思：紧密的锁闭。这里的用法用了“密钥”的动词性质。 【 mì yào】读音下的“密钥”的意思：密码学中的专有名词，指解密所需要的特殊代码。这里用了“密钥”的名词性 对称密钥加密 - Symmetric-key algorithm 又称为对称加密、私钥加密、共享密钥加密、单钥加密 这类算法在加密和解密时使用相同的密钥，或是使用两个可以简单地相互推算的密钥，所以这被称为 \"对称加密算法\" 1976 年以前，所有的加密算法都使用 \"对称加密算法\"，通用的单钥加密算法为 DES（ Data Encryption Standard ） 在对称密钥加密的情况下，密钥只有一把，所以密钥的保存变得很重要。一旦密钥泄漏，密码也就被破解 公开密钥加密 - Public-key cryptography 又称为非对称加密 - asymmetric cryptography 公开密钥加密需要两个密钥，一个是公开密钥（ 加密使用 ），另一个是私有密钥（ 解密使用 ） SSH 原理简述 ssh 密码登录原理 用户使用ssh user@host 命令对远程主机发起登陆 远程主机将自己的公钥返回给请求主机 请求主机使用公钥对用户输入的密码进行加密 请求主机将加密后的密码发送给远程主机 远程主机使用私钥对密码进行解密 最后，远程主机判断解密后的密码是否与用户密码一致，一致就同意登陆，否则反之 ssh 密钥登录原理 用户使用ssh user@host 命令对远程主机发起登陆 远程主机对用户返回一个随机串 用户所在主机使用私钥对这个随机串进行加密，并将加密的随机串返回至远程主机 远程主机使用分发过来的公钥对加密随机串进行解密 如果解密成功，就证明用户的登陆信息是正确的，则允许登陆；否则反之 SSH 中间人攻击 由于 SSH 不像 https 协议那样，SSH 协议的公钥是没有证书中心（CA）公证的，也就是说，都是自己签发的。这就导致如果有人截获了登陆请求，然后冒充远程主机，将伪造的公钥发给用户，那么用户很难辨别真伪，用户再通过伪造的公钥加密密码，再发送给冒充主机，此时冒充的主机就可以获取用户的登陆密码了，那么 SSH 的安全机制就荡然无存了，这也就是我们常说的中间人攻击 参考 SSH Kung Fu scp 跨机远程拷贝 如何透过 SSH 代理穿越跳板机 数字签名是什么？- 阮一峰 SSH原理与运用 - 阮一峰 SSH原理与运用（一）：远程登录 - 阮一峰 SSH原理与运用（二）：远程操作与端口转发 - 阮一峰 详解SSH原理 - 果冻想 Linux ssh命令详解 - 小a玖拾柒 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Linux/Tomcat和Ngnix和Apache.html":{"url":"Linux/Tomcat和Ngnix和Apache.html","title":"Tomcat和Ngnix和Apache.md","keywords":"","body":" Apache / Nginx 应该叫做「HTTP Server」；而 Tomcat 则是一个「Application Server」，或者更准确的来说，是一个「Servlet / JSP」应用的容器（Ruby / Python 等其他语言开发的应用也无法直接运行在 Tomcat 上）。 一个 HTTP Server 关心的是 HTTP 协议层面的传输和访问控制，所以在 Apache / Nginx 上你可以看到代理、负载均衡等功能。客户端通过 HTTP Server 访问服务器上存储的资源（HTML 文件、图片文件等等）。通过 CGI 技术，也可以将处理过的内容通过 HTTP Server 分发，但是一个 HTTP Server 始终只是把服务器上的文件如实的通过 HTTP 协议传输给客户端。而应用服务器，则是一个应用执行的容器。它首先需要支持开发语言的 Runtime（对于 Tomcat 来说，就是 Java），保证应用能够在应用服务器上正常运行。其次，需要支持应用相关的规范，例如类库、安全方面的特性。对于 Tomcat 来说，就是需要提供 JSP / Sevlet 运行需要的标准类库、Interface 等。为了方便，应用服务器往往也会集成 HTTP Server 的功能，但是不如专业的 HTTP Server 那么强大，所以应用服务器往往是运行在 HTTP Server 的背后，执行应用，将动态的内容转化为静态的内容之后，通过 HTTP Server 分发到客户端 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Linux/UbuntuSoftwareInstall.html":{"url":"Linux/UbuntuSoftwareInstall.html","title":"Ubuntu 软件包安装","keywords":"","body":"Ubuntu 软件包安装 deb 是 Debian、Ubuntu 软件安装的一种格式 rpm 是 Redhat、Fedora、SUSE 软件安装的一种格式 源码包（ Tarball 软件) 安装编译工具：$ sudo apt-get install build-essential 在 ubuntu 上编译程序，默认是有 gcc 的，但是没有 g++。如果自己来安装 g++ 也可以，不过它涉及到一些依赖库，有点麻烦，但 build-essential 包里有很多开发必备的软件包：dpkg-dev fakeroot g++ g++-4.6 libalgorithm-diff-perl libalgorithm-diff-xs-perl libalgorithm-merge-perl libdpkg-perl libstdc++6-4.6-dev libtimedate-perl 推荐将源码包放在/usr/local/src目录下 进入/usr/local/src目录，解压源码包，进入源码目录 编译、安装软件 一般情况下，里面有个 configure 文件，则运行命令:sudo ./configure --prefix=/usr/local/filename #存放路径，可更改 make #编译 sudo make install #安装 --prefix 选项是配置安装目录，如果不配置该选项，安装后可执行文件默认放在 /usr /local/bin，库文件默认放在/usr/local/lib，配置文件默认放在/usr/local/etc，其它的资源文件放在/usr /local/share，比较凌乱。如上安装后的所有资源文件都在/usr/local/filename文件夹里 如果只有Makefile文件，则运行命令：make #编译 sudo make install #安装 如果只是Imake文件，则运行命令：xmkmf #配置 make #编译 sudo make install # 安装 卸载软件：$ dpkg -r filename.deb 清除编译过程中产生的临时文件：$ make clean 清除配置过程中产生的文件：$ make distclean (谨用) 卸载软件时，进入源码文件目录：$ make uninstall 关于卸载 如果没有配置 --prefix 选项，源码包也没有提供 make uninstall，则可以通过以下方式可以完整卸载： 找一个临时目录重新安装一遍，如：./configure --prefix=/tmp/to_remove && make install 然后遍历/tmp/to_remove的文件，删除对应安装位置的文件即可（ 因为/tmp/to_remove里的目录结构就是没有配置 --prefix 选项时的目录结构 ） deb包 方法一、 使用 dpkg 软件管理系统双击直接安装 方法二、 命令行安装 sudo apt-get install dpkg #先安装dpkg dpkg -i filename.deb #安装软件 dpkg -r filename.deb #卸载 rpm包 方法一、 先用 alien 命令把 rpm 包转换为 deb 软件包，再安装即可 sudo apt install alien #安装alien alien -d filename.rpm #使用alien将rpm包转换为deb包 sudo dpkg -i filename.deb #安装 sudo dpkg -r filename.deb #卸载 方法二、 使用 rpm 命令直接安装 sudo apt install rpm #安装 rpm ./alien -i filename.rpm 　bin 包 sudo chmod a+x filename.bin #更改执行权限 ./filename.bin #安装 sh 包或 bash 包 sudo chmod a+x filename.sh filename.bash # 更改权限 ./filename.sh (或 $ ./filename.bash) #安装软件 二进制包 不用安装，将软件放于某目录下。 直接运行软件：$ ./filename py 包 sudo apt-get install python # 安装 python sudo python3 setup.py install # 安装 python3 的库 python filename.py # 安装软件 pl 包 sudo apt-get install perl # 安装 perl perl filename.pl # 安装软件 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Linux/YAML-配置文件语言.html":{"url":"Linux/YAML-配置文件语言.html","title":"YAML 配置文件语言","keywords":"","body":"YAML 配置文件语言 YAML 语言教程-阮一峰 基本语法 大小写敏感 使用缩进表示层级关系 缩进时不允许使用 Tab 键，只允许使用空格 缩进的空格数不重要，只要相同层级的元素左侧对齐即可 # 表示注释，从这个字符一直到行尾，都会被解析器忽略 字符串可以不用引号标注 数据结构 对象：键值对的集合，又称为映射（mapping）/ 哈希（hashes） / 字典（dictionary） 数组：一组按次序排列的值，又称为序列（sequence） / 列表（list） 纯量（scalars）：单个的、不可再分的值 例子 对象 - key: value person: student: xiaoming teacher: wang # 或 person: { student: xiaoming, teacher: wang } 数组 - - value（横杠和空格）开头 - - xiaoming - xiaohong - wang # 类似 python 中：[[xiaoming, xiaohong, wang]] 纯量 字符串、布尔值、整数、浮点数、Null、时间、日期 --- num: 12.23 iftrue: true # null 用 ~ 表示 isNull: ~ # 时间采用 ISO8601 格式 iso8601: 2001-12-14t21:59:43.10-05:00 # 使用两个感叹号，强制转换数据类型 e: !!str 123 f: !!str true 纯量 - 字符串 字符串默认不是有引号 字符串中包含空格或特殊字符，需要使用引号 只有单引号可以对特殊字符转义 字符串可以使用 | 保留换行符，也可以使用 > 折叠换行 引用 & 用来建立锚点（defaults）， 表示合并到当前数据，* 用来引用锚点 - &showell Steve - Clark - *showell # 等价于 python 中 # [ Steve, Clark, Steve ] &defaults defaults: adapter: postgres development: database: myapp_development Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Linux/bin目录详解.html":{"url":"Linux/bin目录详解.html","title":"bin目录详解.md","keywords":"","body":" /bin是系统的一些指令。bin为binary的简写主要放置一些系统的必备执行档例如:cat、cp、chmod df、dmesg、gzip、kill、ls、mkdir、more、mount、rm、su、tar等。 /sbin一般是指超级用户指令。主要放置一些系统管理的必备程式例如:cfdisk、dhcpcd、dump、e2fsck、fdisk、halt、ifconfig、ifup、 ifdown、init、insmod、lilo、lsmod、mke2fs、modprobe、quotacheck、reboot、rmmod、 runlevel、shutdown等。 /usr/bin　是你在后期安装的一些软件的运行脚本。主要放置一些应用软体工具的必备执行档例如c++、g++、gcc、chdrv、diff、dig、du、eject、elm、free、gnome、 gzip、htpasswd、kfm、ktop、last、less、locale、m4、make、man、mcopy、ncftp、 newaliases、nslookup passwd、quota、smb、wget等。 /usr/sbin 放置一些用户安装的系统管理的必备程式例如:dhcpd、httpd、imap、in.*d、inetd、lpd、named、netconfig、nmbd、samba、sendmail、squid、swap、tcpd、tcpdump等。 如果新装的系统，运行一些很正常的诸如：shutdown，fdisk的命令时，悍然提示：bash:command not found。那么 首先就要考虑root 的$PATH里是否已经包含了这些环境变量。 可以查看PATH，如果是：PATH=$PATH:$HOME/bin则需要添加成如下： PATH=$PATH:$HOME/bin:/sbin:/usr/bin:/usr/sbin Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Linux/ffmpeg详解.html":{"url":"Linux/ffmpeg详解.html","title":"ffmpeg学习","keywords":"","body":"FFmpeg - [github] FFmpeg 是处理多媒体内容（ 如音频，视频，字幕和相关元数据 ）的库和工具的集合 库 libavcodec 提供更广泛的编解码器的实现。 libavformat 实现流协议，容器格式和基本 I / O 访问。 libavutil 包括垫圈，解压缩器和其他实用功能。 libavfilter 提供通过过滤器链改变解码的音频和视频的方法。 libavdevice 提供访问捕获和回放设备的抽象。 libswresample 实现音频混合和重采样例程。 libswscale 实现颜色转换和缩放例程 工具 ffmpeg ffplay ffprobe ffmpeg ffmpeg 是一个非常强大的工具，它可以转换任何格式的媒体文件，并且还可以用自己的 AudioFilter 以及 VideoFilter 进行处理和编辑。有了它，我们就可以对媒体文件做很多我们想做的事情了 预备知识 codec - 编码解码器 A codec is a device or computer program for encoding or decoding a digital data stream or signal. Codec is a portmanteau of coder-decoder. A codec encodes a data stream or a signal for transmission and storage, possibly in encrypted form, and the decoder function reverses the encoding for playback or editing. Codecs are used in videoconferencing, streaming media, and video editing applications. 使用 FFmpeg 视频分割 # 这个例子是将 test.mp4 视频的前 3 秒，重新生成一个新视频 ffmpeg -ss 00:00:00 -t 00:00:03 -y -i test.mp4 -vcodec copy -acodec copy test1.mp4 [参数] -ss 开始时间，如： 00:00:00，表示从 0 秒开始，也可以写成 00:00:0 -t 时长，如： 00:00:03，表示截取 3 秒长的视频，也可以写成 00:00:3 -y 如果文件已存在强制替换 -i 输入，后面是空格，紧跟着就是输入视频文件 -vcodec [copy] 视频的编码格式，copy 表示保持视频编码格式不变 -acodec [copy] 音频的编码格式，copy 表示保持音频编码格式不变 使用 FFmpeg 从视频中制作 GIF 图 使用 FFmpeg 转换 flv 到 mp4 ffmpeg -i input.flv -vcodec copy -acodec copy output.mp4 使用 FFmpeg 给视频添加水印 # 给视频添加图片水印，水印居中显示 ffmpeg -i input.mp4 -i watermark.png -filter_complex overlay=\"(main_w/2)-(overlay_w/2):(main_h/2)-(overlay_h)/2\" output.mp4 # 给视频添加 GIF 动态图水印，水印居中显示 ffmpeg -i input.mp4 -i watermark.gif -filter_complex overlay=\"(main_w/2)-(overlay_w/2):(main_h/2)-(overlay_h)/2\" output.mp4 # 给视频添加文字水印，水印左上角显示 ffmpeg -i input.mp4 -vf \"drawtext=/usr/share/fonts/truetype/source-code-pro/SourceCodePro-BlackIt.ttf:text='视频添加文字水印':x=10:y=10:fontsize=24:fontcolor=yellow:shadowy=2\" output.mp4 [参数] overlay=\"(main_w/2)-(overlay_w/2):(main_h/2)-(overlay_h)/2\" 设置水印的位置，居中显示 参数 overlay 详解 overlay 设置位置格式：`overlay=\"x:y[:1]\" x:y 以左上的视频界面顶点为原点，向右为 x 轴正方向，向下为 y 轴正方向的直角坐标系中一点的横纵坐标 :1 表示支持透明水印 overlay 可选参数 | 说明 ------ | ------ main_w | 视频单帧图像宽度 main_h | 视频单帧图像高度 overlay_w | 水印图片的宽度 overlay_h | 水印图片的高度 (main_w/2)-(overlay_w/2):(main_h/2)-(overlay_h)/2 | 相对位置（居中显示） 10:10 | 绝对位置（距离上边和左边都是 10 像素）main_w-overlay_w-10:10 | 绝对位置（距离上边和右边都是 10 像素） 水印图片的尺寸不能大于视频单帧图像尺寸，否则会出错 使用 FFmpeg 提取视频中的音频文件( aac、mp3 等 ) # 一、提取的音频格式是 mp3 的情况 # 先查看自己的 ffmpeg 的库依赖有没有编码 mp3 的库（通常是 libmp3lame，而且一般安装 ffmpeg 时只有解码 mp3 的库） ffmpeg -codecs | grep mp # 提取视频中音，音频格式为 mp3 ffmpeg -i input.mp4 -f mp3 -vn output.mp3 # 或 ffmpeg -i input.mp4 -acodec libmp3lame -vn output.mp3 [参数] -vn 禁止视频输出 -f 输出编码格式 -acodec 音频编码器 # 二、提取的音频格式是 acc 的情况 # 一般 acc 编码器默认已经装上 ffmpeg -i input.mp4 -c copy output.acc 使用 FFmpeg 合并多个视频或多个音频 一、合并多个音频 ffmpeg -i input1.mp3 -i input2.mp4 output.mp3 二、合并多个视频 更多方法 FFmpeg concat 分离器（需要 FFmpeg 1.1 以上版本，最通用方法） 先创建一个文本文件(.txt)# 例如文件 inputfilelist.txt 内容 file 'input1.mp4' file 'input2.mp4' file 'input3.mp4' 文件新建在当前目录下，文件存放待合并的视频文件名，注意格式：file 'xxx' 然后执行命令ffmpeg -f concat -i inputfilelist.txt -c copy output.mp4 使用 FFmpeg 将字幕文件集成到视频文件 字幕文件格式间转换 # 将 .srt 文件转换为 .ass 文件 ffmpeg -i subtitle.srt subtitle.ass # 将 .ass 文件转换为 .srt 文件 ffmpeg -i subtitle.ass subtitle.srt 由于 mp4 容器，不像 mkv 等容器有自己的字幕流 mkv 这种容器的视频格式中，会带有一个字幕流，可以在播放中，控制字幕的显示与切换，也可以通过工具或命令，将字幕从视频中分离出来 mp4 格式的容器，是不带字幕流的，所以如果要将字幕添加进去，就需要将字幕文件烧进视频中去。烧进去的视频，不能再分离出来，也不能控制字幕的显示与否 # 比如将 input.srt 烧入 input.mp4 中，将合并的视频拷到 output.mp4 # input.srt、input.mp4、output.mp4都是相对当前目录下 ffmpeg -i input.mp4 -vf subtitles=input.srt output.srt [参数] -y :覆盖同名的输出文件 -i ：资源文件 -vf：一般用于设置视频的过滤器 ( set video filters ) subtitles= ：后面跟字幕文件，可以是 srt，ass ffplay ffplay 是以 FFmpeg 框架为基础，外加渲染音视频的库 libSDL 构建的媒体文件播放器 格式 - ffplay [选项] ['输入文件'] 主要选项 '-x width' 强制以 \"width\" 宽度显示 '-y height' 强制以 \"height\" 高度显示 '-an' 禁止音频 '-vn' 禁止视频 '-ss pos' 跳转到指定的位置(秒) '-t duration' 播放 \"duration\" 秒音/视频 '-bytes' 按字节跳转 '-nodisp' 禁止图像显示(只输出音频) '-f fmt' 强制使用 \"fmt\" 格式 '-window_title title' 设置窗口标题(默认为输入文件名) '-loop number' 循环播放 \"number\" 次(0将一直循环) '-showmode mode' 设置显示模式 可选的 mode '0, video' 显示视频 '1, waves' 显示音频波形 '2, rdft' 显示音频频带 默认值为 'video'，你可以在播放进行时，按 \"w\" 键在这几种模式间切换 '-i input_file' 指定输入文件 一些高级选项 '-sync type' 设置主时钟为音频、视频、或者外部。默认为音频。主时钟用来进行音视频同步 '-threads count' 设置线程个数 '-autoexit' 播放完成后自动退出 '-exitonkeydown' 任意键按下时退出 '-exitonmousedown' 任意鼠标按键按下时退出 '-acodec codec_name' 强制指定音频解码器为 \"codec_name\" '-vcodec codec_name' 强制指定视频解码器为 \"codec_name\" '-scodec codec_name' 强制指定字幕解码器为 \"codec_name\" 一些快捷键 'q, ESC' 退出 'f' 全屏 'p, SPC' 暂停 'w' 切换显示模式(视频/音频波形/音频频带) 's' 步进到下一帧 'left/right' 快退/快进 10 秒 'down/up' 快退/快进 1 分钟 'page down/page up' 跳转到前一章/下一章(如果没有章节，快退/快进 10 分钟) 'mouse click' 跳转到鼠标点击的位置(根据鼠标在显示窗口点击的位置计算百分比) ffprobe ffprobe 是 ffmpeg 命令行工具中是用来查看媒体文件格式的工具 xcq@xcq-HP-Pavilion-Notebook:~/桌面$ ffprobe test.mp4 ffprobe version 3.4.4-0ubuntu0.18.04.1 Copyright (c) 2007-2018 the FFmpeg developers built with gcc 7 (Ubuntu 7.3.0-16ubuntu3) configuration: --prefix=/usr --extra-version=0ubuntu0.18.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared libavutil 55. 78.100 / 55. 78.100 libavcodec 57.107.100 / 57.107.100 libavformat 57. 83.100 / 57. 83.100 libavdevice 57. 10.100 / 57. 10.100 libavfilter 6.107.100 / 6.107.100 libavresample 3. 7. 0 / 3. 7. 0 libswscale 4. 8.100 / 4. 8.100 libswresample 2. 9.100 / 2. 9.100 libpostproc 54. 7.100 / 54. 7.100 Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'test.mp4': Metadata: major_brand : isom minor_version : 1 compatible_brands: isomavc1 creation_time : 2018-07-16T15:13:16.000000Z Duration: 00:08:46.07, start: 0.000000, bitrate: 2577 kb/s # 该视频文件的时长是 8 分 46 秒 7 毫秒，开始播放时间是 0，整个文件的比特率是 2577 Kbit/s Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 1920x1080 [SAR 1:1 DAR 16:9], 2446 kb/s, 23.98 fps, 23.98 tbr, 24k tbn, 47.95 tbc (default) # 第一个流是视频流，编码格式是 h264 格式( 封装格式为 AVC1 )，每一帧的数据表示为 yuv420p，分辨率为 1920 × 1080，这路流的比特率为2466 Kbit/s，帧率为每秒钟 24 帧 Metadata: creation_time : 2018-07-16T15:13:16.000000Z Stream #0:1(und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 127 kb/s (default) # 第二个流是音频流，编码方式为 ACC（ 封装格式为 MP4A ），并且采用的 Profile（ 配置文件 ）是 LC 规格，采样率是 44.1 KHz，声道是立体声，这路流的比特率 92 Kbit/s Metadata: creation_time : 2018-07-16T14:53:06.000000Z 颜色编码：其中YUV420是视频中通常采用的颜色编码方式，Y表示亮度，而U，V则与颜色相关，而420则分别对应着存储相应分量所占用的比特数之比。其实采用这种编码方式就是为了早期彩色电视与黑白电视能更好的相容 tbn is the time base in AVStream that has come from the container, I think. It is used for all AVStream time stamps. tbc is the time base in AVCodecContext for the codec used for a particular stream. It is used for all AVCodecContext and related time stamps. tbr is guessed from the video stream and is the value users want to see when they look for the video frame rate, except sometimes it is twice what one would expect because of field rate versus frame rate. fps 自然的是 frame per second，就是帧率了。 所以tbn和tbc应该都是在相应层上的时间单元，比如tbn=2997就相当于在视频流层把1s的时间分成了2997个时间单元，如此精细可以更好的与其他流比如音频流同步，对应着fps=29.97就表示每100个时间单元中有一帧。 时间同步方式： 问题来了：fps=29.97这是一个小数啊，我如果直接利用公式 frame number = time * fps 得到了也不是一个整数啊，而帧号应该是一个整数才对。 首先，29.97f/s这个变态的数是如何得到的？这起源于早期的NTSC电视制式，而现代的数字编码只是为了兼容而沿用了它的标准。其实在标准制定 时，NTSC采用的是30f/s的帧率，只是后来為了消除由彩色信号及伴音信号所產生的圖像干擾，每秒幀幅由30幀稍微下調至29.97幀，同時線頻由 15750Hz稍微下降至15734.26Hz 然后，带小数点的帧率如何实现呢，显然每一秒不可能显示相同个数的帧。实际上存在着叫做SMPTE Non-Drop-Frame和SMPTE Drop-Frame的时间同步标准，也就是说在某些时候，会通过丢掉一些帧的方式来将时间同步上。 比如刚才提到的29.97帧率，我们可以计算：29.97 f/sec = 1798.2 f/min = 107892 f/hour; 对于30f/s的帧率我们可以计算： 30 f/s = 1800 f/s = 108000 f/hour; 这样，如果利用每秒30帧的速度来采集视频，而用29.97f/s的速率来播放视频，每个小时就少播放了108帧，这样播放时间会比真实时间变慢。为了解决这个问题，SMPTE 30 Drop-Frame就采取了丢掉这108帧的方式，具体策略是每1分钟丢两帧，如果是第10分钟则不丢，所以每小时丢掉的帧数是：2×60 – 2×6 = 108 帧。更具体的信息， 25 tbr代表帧率；1200k tbn代表文件层（st）的时间精度，即1S=1200k，和duration相关；50 tbc代表视频层（st->codec）的时间精度，即1S=50，和strem->duration和时间戳相关。 25 tbr代表帧率； 90k tbn代表文件层（st）的时间精度，即1S=1200k，和duration相关； 50 tbc代表视频层（st->codec）的时间精度，即1S=50，和strem->duration和时间戳相关。 https://www.jianshu.com/p/bfec3e6d3ec8 https://www.jianshu.com/p/5b78a91f1091 显示帧信息 ffprobe -show_frames test.mp4 查看包信息 ffprobe -show_packets test.mp4 参考 20 篇 ffmpeg 学习 系统学习 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Linux/trans命令.html":{"url":"Linux/trans命令.html","title":"trans命令","keywords":"","body":"trans 命令详解 常用命令 转换到特定语言，例如转换到中文和日文 $ trans :en+ja Hello Hello こんにちは (Kon'nichiwa) Hello的定义 [ English -> 日本語 ] 感叹词 もしもし！ Hello! 今日は! Hi!, Hello!, Good afternoon!, Good day! Hello こんにちは, もしもし 指定待转换的源语言的语言类型，例如确定“手紙”是中文或日文 $ trans ja: 手紙 手紙 (Tegami) 一封信 (Yī fēng xìn) 手紙 的翻译 [ 日本語 -> 简体中文 ] 手紙 一封信, 信 $ trans en: 手紙 手紙 手纸 (Shǒuzhǐ) 手紙 的翻译 [ English -> 简体中文 ] 手纸 手纸 转换一个句子，例如转换 “Hello world” 若不加引号，则是以单个词逐个翻译 $ trans en: 'Hello world' Hello world 你好，世界 (Nǐ hǎo, shìjiè) Hello world 的翻译 [ English -> 简体中文 ] Hello world 你好，世界, 你好世界 # 多行句子翻译 $ trans en: 'Hello world' 语言和相关的更多细节，参见wiki: Languages Language Code Language Code Language Code Afrikaans Afrikaans af Hebrew עִבְרִית he Portuguese Português pt Albanian Shqip sq Hill Mari Кырык мары mrj Punjabi ਪੰਜਾਬੀ pa Amharic አማርኛ am Hindi हिन्दी hi Querétaro Otomi Hñąñho otq Arabic العربية ar Hmong Hmoob hmn Romanian Română ro Armenian Հայերեն hy Hmong Daw Hmoob Daw mww Russian Русский ru Azerbaijani Azərbaycanca az Hungarian Magyar hu Samoan Gagana Sāmoa sm Bashkir башҡорт теле ba Icelandic Íslenska is Scots Gaelic Gàidhlig gd Basque Euskara eu Igbo Igbo ig Serbian (Cyrillic)) српски sr-Cyrl Belarusian беларуская be Indonesian Bahasa Indonesia id Serbian (Latin)) srpski sr-Latn Bengali বাংলা bn Irish Gaeilge ga Sesotho Sesotho st Bosnian Bosanski bs Italian Italiano it Shona chiShona sn Bulgarian български bg Japanese 日本語 ja Sindhi سنڌي sd Cantonese 粵語 yue Javanese Basa Jawa jv Sinhala සිංහල si Catalan Català ca Kannada ಕನ್ನಡ kn Slovak Slovenčina sk Cebuano Cebuano ceb Kazakh Қазақ тілі kk Slovenian Slovenščina sl Chichewa Nyanja ny Khmer ភាសាខ្មែរ km Somali Soomaali so Chinese Simplified 简体中文 zh-CN Klingon tlhIngan Hol tlh Spanish Español es Chinese Traditional 正體中文 zh-TW Klingon (pIqaD))   tlh-Qaak Sundanese Basa Sunda su Corsican Corsu co Korean 한국어 ko Swahili Kiswahili sw Croatian Hrvatski hr Kurdish Kurdî ku Swedish Svenska sv Czech Čeština cs Kyrgyz Кыргызча ky Tahitian Reo Tahiti ty Danish Dansk da Lao ລາວ lo Tajik Тоҷикӣ tg Dutch Nederlands nl Latin Latina la Tamil தமிழ் ta Eastern Mari Олык марий mhr Latvian Latviešu lv Tatar татарча tt Emoji Emoji emj Lithuanian Lietuvių lt Telugu తెలుగు te English English en Luxembourgish Lëtzebuergesch lb Thai ไทย th Esperanto Esperanto eo Macedonian Македонски mk Tongan Lea faka-Tonga to Estonian Eesti et Malagasy Malagasy mg Turkish Türkçe tr Fijian Vosa Vakaviti fj Malay Bahasa Melayu ms Udmurt удмурт udm Filipino Tagalog tl Malayalam മലയാളം ml Ukrainian Українська uk Finnish Suomi fi Maltese Malti mt Urdu اُردُو ur French Français fr Maori Māori mi Uzbek Oʻzbek tili uz Frisian Frysk fy Marathi मराठी mr Vietnamese Tiếng Việt vi Galician Galego gl Mongolian Монгол mn Welsh Cymraeg cy Georgian ქართული ka Myanmar မြန်မာစာ my Xhosa isiXhosa xh German Deutsch de Nepali नेपाली ne Yiddish ייִדיש yi Greek Ελληνικά el Norwegian Norsk no Yoruba Yorùbá yo Gujarati ગુજરાતી gu Papiamento Papiamentu pap Yucatec Maya Màaya T'àan yua Haitian Creole Kreyòl Ayisyen ht Pashto پښتو ps Zulu isiZulu zu Hausa Hausa ha Persian فارسی fa Hawaiian ʻŌlelo Hawaiʻi haw Polish Polski pl Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Linux/yum和rpm.html":{"url":"Linux/yum和rpm.html","title":"Yum 和 RPM","keywords":"","body":"Yum 和 RPM RedHat 系列软件安装大致可以分为两种： rpm 文件安装 - 使用 rpm 指令 类似 [ubuntu] deb 文件安装，使用 dpkg指令 yum 安装 - 类似 [ubuntu] apt 安装 RPM rpm 包命名规范 包名-版本信息-发布版本号.运行平台 zabbix-agent-4.4.0-1.el7.x86_64.rpm zabbix-release-4.4-1.el7.noarch.rpm # noarch 代表的是软件可以平台兼容 常用命令 查看已安装软件信息 rpm -qa - 查看系统中已经安装的软件 rpm -qf \\[文件绝对路径\\] - 查看一个已经安装的文件属于哪个软件包 rpm -ql \\[软件名\\] - 查看已安装软件包的安装路径，[软件名] 是 rpm 包去除平台信息和后缀后的信息 rpm -qi [软件名] - 查看已安装软件包的信息 rpm -qc [软件名] - 查看已安装软件的配置文件 rpm -qd [软件名] - 查看已经安装软件的文档安装位置 rpm -qR [软件名] - 查看已安装软件所依赖的软件包及文件 查看未安装软件信息 rpm -qpi [rpm文件] - 查看软件包的用途、版本等信息 rpm -qpl [rpm文件] - 查看软件包所包含的文件 rpm -qpc [rpm文件] - 查看软件包的配置文件 rpm -qpR [rpm文件] - 查看软件包的依赖关系 软件包的安装、升级、删除等 - rpm -ivh [rpm文件] - 安装 rpm -Uvh [rpm文件] - 升级 rpm -e [软件名] - 删除 rpm -e [软件名] --nodeps - 不管依赖问题，强制删除软件 rpm --import [签名文件] - 导入签名 YUM yum 可以更方便的添加、删除、更新 RPM 包，并且能自动解决包的倚赖问题 rpm -ivh https://opsx.alibaba.com/mirror/detail/1859610790?lang=zh-CN - 安装 yum yum check-update - 检查可以更新的软件包 yum -y update - 升级所有包同时也升级软件和系统内核 yum -y upgrade - 只升级所有包，不升级软件和系统内核 yum update [软件名] - 更新特定的软件包 yum install [rpm文件] - 安装 rpm 包 yum remove [rpm文件] - 删除 rpm 包 yum clean all - 清除缓存中旧的 rpm 头文件和包文件 yum clean packages - 清楚缓存中 rpm 包文件 yum clean headers - 清楚缓存中 rpm 的头文件 yum clean old headers - 清除缓存中旧的头文件 yum list - 列出资源库中所有可以安装或更新的 rpm 包 yum list google* - 可以在 rpm 包名中使用通配符,查询类似的 rpm 包 yum list updates - 列出资源库中所有可以更新的 rpm 包 yum list installed - 列出已经安装的所有的 rpm 包 yum list extras - 列出已经安装的但是不包含在资源库中的 rpm 包 `yum info ` - 列出资源库中所有可以安装或更新的 rpm 包的信息 yum info google* - 列出资源库中特定的可以安装或更新以及已经安装的 rpm 包的信息 yum info updates - 列出资源库中所有可以更新的 rpm 包的信息 yum info installed - 列出已经安装的所有的 rpm 包的信息 yum info extras - 列出已经安装的但是不包含在资源库中的 rpm 包的信息 yum search google - 搜索匹配特定字符的 rpm 包 yum provides google - 搜索包含特定文件的 rpm 包 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Linux/从BashShell启动“窥探”Linux环境变量相关文件.html":{"url":"Linux/从BashShell启动“窥探”Linux环境变量相关文件.html","title":"Linux环境变量详解","keywords":"","body":"从 Bash Shell 启动“窥探” Linux 环境变量相关文件（ 代码以 Ubuntu 18.04 LTS 为例 ） 本篇涉及的 Linux 文件，除了设置环境变量，往往还有很多其他用途；本篇内容参考多篇相关网络文章，并结合自己理解，可定会有错误或不准确的地方，望指正！ Linux Shell 在有像平时启动 Windows 立马出现的图形化界面之前，与计算机的交互只能输入命令。在 UNIX 系统或 Linux 系统中，用来解释和管理命令的程序称作 Shell Linux Shell 种类 名称 说明 Bash Shell 全称 Bourne Again Shell，现今大多数 Linux 发行版本都包含 C Shell ( csh ) BSD UNIX 用户中非常流行 Korn Shell ( ksh ) UNIX System V用户中非常流行 Tcsh Shell 一种改进的 C Shell Ash Shell 与 Bourne Shell 非常相似 Bash Shell 常用的环境配置文件 Linux Bash Shell 运行时，按照一定的顺序加载配置文件，初始化配置文件后，运行 Bash Shell Linux Bash 的配置文件大概分为两类：系统配置文件和用户配置文件 bash shell 系统配置文件/etc/profile、/etc/bash.bashrc、/etc/profile.d/*.sh bash shell 用户配置文件~/.bash_profile、~/.bash_login、~/.profile、~/.bashrc Bash 配置文件解读 文件 说明 /etc/profile 该文件为每个用户设置了用户环境信息。当首次登录时执行该文件，还可以在该文件里设置用户邮箱位置、历史文件大小、PATH 路径之类的环境变量。并且该文件还会从 /etc/profile.d/ 目录的配置文件中收集相关的 Shell 设置 /etc/bashrc 对于运行 Bash Shell 的用户来说，每次打开一个 Bash Shell 时都会执行该文件。可以在该文件里使用命令 alias 添加别名等。此外，每个用户可以用 ~/.bashrc 文件中信息重写 /etc/bashrc 中的已存在值 ~/.bash_profile 该文件内设置的信息只对当前用户有效。只有当用户登录时才会执行该文件，在默认情况下，它设置一些环境变量并执行 ~/.bashrc 文件。添加环境变量通常是在这个文件里 ~/.bashrc 该文件包含了特定于 Bash Shell 信息。当进行登录以及每次打开一个新的 Bash Shell 时都会读取该文件。此外，alias 添加别名通常是在该文件里 ~/.bash_logout 每次注销（ 即退出最后一个 Bash Shell ）执行该文件，并且默认清除屏幕 除了读取上述配置文件之外，在登陆 shell 中还会读取其他相关配置信息，如读取 ~/.bash_history、/etc/man.config、~/.bash_logout 等等 Bash Shell 环境配置文件加载顺序详解 登录 shell（ login shell ）配置文件载入顺序 取得 bash 时需要完整的登陆流程的，就称为 login shell 比如通过 ssh 方式连接，或者由 tty1 ~ tty6 登陆，需要输入用户的账号与密码，此时取得的 bash 就称为 login shell login shell 载入读取环境配置文件过程图 ~/.bash_profile、~/.bash_login、~/.profile、~/.bashrc文件若没有，可自行创建 前两列只有 login shell 情况下才会加载（ /etc/profile及　~/bash_profile 列 ） 非登录 shell（ non-login shell ）配置文件载入顺序 取得 bash 接口的方法不需要重复登陆的举动 比如你以 X window 登陆 Linux 后， 再以 X 的图形化接口启动终端机，此时该终端接口无需输入账号与密码，则为 non-login shell 比如你在原本的 bash 环境下再次下达 bash 这个命令，同样的也没有输入账号密码，那第二个 bash (子程序) 也是 non-login shell non login shell 载入读取环境配置文件过程图 CentOs Bash Shell 环境配置文件加载顺序情况 《鸟哥的 linux 私房菜》里的 CentOs Bash Shell 配置文件加载顺序 source 命令 对于 shell 环境变量修改之后需要立即生效的情形，可以使用 source 来立即生效（ 也可以用命令 \".\" ） source 接带路径的配置文件名 source filename # source /etc/profile . 接带路径的配置文件名 . filename（中间有空格） # . /etc/profile source filename 与 sh filename 、./filename的区别： source - 在当前 shell 内去读取、执行a.sh，而a.sh不需要有 \"执行权限\"，所有新建、改变变量的语句都会保存在当前 shell 里面 sh - 打开一个 subshell 去读取、执行 filename ，而 filename 不需要有 \"执行权限\" . - 打开一个 subshell 去读取、执行 filename ，但 filename 需要有 \"执行权限\" 在子 shell 中执行脚本里面的语句，该子 shell 继承父 shell 的环境变量，但子在 shell 中改变的变量不会被带回父 shell（除非使用 export） Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Linux/新创建主机常用初始化配置.html":{"url":"Linux/新创建主机常用初始化配置.html","title":"新建主机常用初始化配置","keywords":"","body":"新建主机常用初始化配置 修改 SELINUX # 查看 SELinux 是否运行 getenforce # disabled：表示 selinux 关闭，没有启动；其他两种 ( enforcing、permissive ) 均表示 selinux 启动了，只是运行的模式不一样 # 关闭SELinux # 临时生效，重启机器后失效 # 命令临时生效： setenforce 0 # 1 启用 # 0 告警，不启用 # 永久生效 # 操作前先备份 cp /etc/selinux/config /etc/selinux/config.bak # 更改 setlinux 级别 sed -i 's/SELINUX=enforcing/\\SELINUX=disabled/' /etc/selinux/config # 或 vim /etc/selinux/config # 修改SELINUX=disabled # 使用配置生效 reboot # 或 setenforce 0 #使配置立即生效 禁用防火墙 # 关闭 sudo systemctl stop firewalld # CentOS sudo systemctl stop ufw # Ubuntu # 禁用 sudo systemctl disable firewalld # CentOS sudo systemctl disable ufw # Ubuntu 查看是否能连接外网 ping www.baidu.com 更换国内软件源 # CentOS 7 阿里云软件源 $ wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo $ sed -i -e '/mirrors.cloud.aliyuncs.com/d' -e '/mirrors.aliyuncs.com/d' /etc/yum.repos.d/CentOS-Base.repo $ yum clean all $ yum makecache # ubuntu 18.04(bionic) 阿里云软件源 用你熟悉的编辑器打开： /etc/apt/sources.list 替换默认的 http://archive.ubuntu.com/ 为 mirrors.aliyun.com Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Linux/正则表达式学习.html":{"url":"Linux/正则表达式学习.html","title":"正则表达式","keywords":"","body":"正则表达式 常见正则表达式元字符 元字符 解释 命令 匹配结果 字符串 匹配字符串字面值 echo 'abc' | grep a abc . 匹配除 \\n 之外的任何字符 echo 'abc' | grep . abc ^ 匹配字符串起始部分 echo 'abc' | grep ^ab abc $ 匹配字符串终止部分 echo 'abc' | grep bc$ abc * 匹配 0 或 n 次前面出现的正则表达式 echo 'abc' | grep -E '[a-z]*' abc ? 匹配 0 或 1 次前面出现的正则表达式 echo 'abc' | grep -E 'a?' abc {N} 匹配 N 次连续前面出现的正则表达式 echo 'aabc' | grep -E a{2} aabc {M,N} 匹配 M~N 次连续前面出现的正则表达式 echo 'abaac' | grep -E 'a{1,2}' abaac [...] 匹配来自中括号内字符集的任意单一字符 echo 'abc' | grep -E '[ab]' abc [x-y ] 匹配 x~y 范围中的任意单一字符（包含两端边界值） echo '012abc' | grep -E '[0-9a-z]' 012abc ... 不匹配此字符集（包括某一范围的字符）中出现的任何一个字符 echo '012abc' | grep -E '0-1ab' 012abc (...) 匹配封闭的正则表达式，然后另存为子组 需要转义的特殊符号 \\\\ \\` \\* \\_ \\{\\} \\[\\] \\(\\) \\# \\+ \\- \\. \\! Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Linux/通过Linux开机启动项展开学习.html":{"url":"Linux/通过Linux开机启动项展开学习.html","title":"Linux开机启动项学习","keywords":"","body":"通过 Linux 开机启动项学习 目录 相关文章 一、简述 Linux 开机启动流程 二、开机启动相关文件 三、Linux 管理守护进程两种方式 四、设置开机启动方法 【相关文章】[Top] 计算机是如何启动的？- 阮一峰 Linux 的启动流程 - 阮一峰 Linux 守护进程的启动方法 - 阮一峰 Systemd 入门教程：命令篇 - 阮一峰 Systemd 入门教程：实战篇 - 阮一峰 一、简述 Linux 开机启动流程 [Top] 这个过程不涉及操作系统，只与主板的板载程序有关 详情可看计算机是如何启动的？ Linux 操作系统的启动流程 第一步、加载内核 内核在 /boot/ 目录下 第二步、启动初始化进程 内核文件加载以后，就开始运行第一个程序 /sbin/init，它的作用是初始化系统环境 由于 init 是第一个运行的程序，它的进程编号（ pid ）就是 1。其他所有进程都从它衍生，都是它的子进程 第三步、确定运行级别 许多程序需要开机启动。它们在 Windows 叫做 \"服务\"（ service ），在 Linux 就叫做\"守护进程\"（ daemon ） init 进程的一大任务，就是去运行这些开机启动的程序 Linux 允许为不同的场合，分配不同的开机启动程序，这就叫做 \"运行级别\"（ runlevel ）。也就是说，启动时根据 \"运行级别\"，确定要运行哪些程序 第四步、加载开机启动程序 七种预设的 \"运行级别\" 各自有一个目录，存放需要开机启动的程序。不难想到，如果多个 \"运行级别\" 需要启动同一个程序，那么这个程序的启动脚本，就会在每一个目录里都有一个拷贝。这样会造成管理上的困扰：如果要修改启动脚本，岂不是每个目录都要改一遍 Linux 的解决办法，就是七个 /etc/rcN.d 目录里列出的程序，都设为链接文件，指向另外一个目录 /etc/init.d，真正的启动脚本都统一放在这个目录中。init 进程逐一加载开机启动程序，其实就是运行这个目录里的启动脚本 第五步、用户登录 开机启动程序加载完毕以后，就要让用户登录了 一般来说，用户的登录方式有三种： （1）命令行登录 （2）ssh 登录 （3）图形界面登录 第六步、进入 login shell 用户登录时打开的 shell，就叫做 login shell 第七步，打开 non-login shell 用户进入操作系统以后，常常会再手动开启一个 shell。这个 shell 就叫做 non-login shell，意思是它不同于登录时出现的那个shell，不读取/etc/profile和.profile等配置文件 二、开机启动相关文件 [Top] /etc/rc[0-6].d目录 ls /etc/ | grep '^rc.*' rc0.d rc1.d rc2.d rc3.d rc4.d rc5.d rc6.d rc.local rcS.d 0 - 6 是 Linux 操作系统的运行级别，运行命令 runlevel 查看当前运行级 运行级别 说明 0 系统停机状态，系统默认运行级别不能设为0，否则不能正常启动 1 单用户，无网络连接，不运行守护进程，不允许非超级用户登录，用于系统维护，禁止远程登陆 2 多用户，无网络连接，不运行守护进程 3 多用户，正常启动系统，登陆后进入控制台命令行模式 4 用户自定义 5 多用户，带图形界面，X11 控制台 6 系统正常关闭并重启，默认运行级别不能设为6，否则不能正常启动 ls /etc/rc0.d/ K01alsa-utils K01dnsmasq K01irqbalance K01openipmi K01resolvconf K01tlp K02gdm3 K01bluetooth K01docker K01lightdm K01plymouth K01speech-dispatcher K01unattended-upgrades K04rsyslog K01cgroupfs-mount K01gdomap K01mysql K01polipo K01spice-vdagent K01uuidd K05hwclock.sh K01cups-browsed K01ipmievd K01nginx K01postfix K01thermald K02avahi-daemon K06networking 目录下文件的命名规则：S|K + nn + script S | K - S 开头命名的是开机要执行的脚本，K 开头命名的是关机要执行的脚本 nn - 取值 0 - 100，表示优先级，数字越大，优先级越低 script - 软链接指向的脚本的文件名 ls -l /etc/rc0.d/ 总用量 0 lrwxrwxrwx 1 root root 20 Mar 10 2018 K01alsa-utils -> ../init.d/alsa-utils lrwxrwxrwx 1 root root 19 Mar 10 2018 K01bluetooth -> ../init.d/bluetooth lrwxrwxrwx 1 root root 24 Jan 2 2019 K01cgroupfs-mount -> ../init.d/cgroupfs-mount lrwxrwxrwx 1 root root 22 Mar 10 2018 K01cups-browsed -> ../init.d/cups-browsed lrwxrwxrwx 1 root root 17 Mar 29 2019 K01dnsmasq -> ../init.d/dnsmasq lrwxrwxrwx 1 root root 16 Jan 14 2019 K01docker -> ../init.d/docker lrwxrwxrwx 1 root root 16 Dec 6 2018 K01gdomap -> ../init.d/gdomap lrwxrwxrwx 1 root root 17 Oct 13 14:44 K01ipmievd -> ../init.d/ipmievd lrwxrwxrwx 1 root root 20 Mar 10 2018 K01irqbalance -> ../init.d/irqbalance lrwxrwxrwx 1 root root 17 Mar 10 2018 K01lightdm -> ../init.d/lightdm lrwxrwxrwx 1 root root 15 Jun 9 18:52 K01mysql -> ../init.d/mysql lrwxrwxrwx 1 root root 15 Oct 6 15:12 K01nginx -> ../init.d/nginx lrwxrwxrwx 1 root root 18 Oct 13 14:44 K01openipmi -> ../init.d/openipmi lrwxrwxrwx 1 root root 18 Mar 10 2018 K01plymouth -> ../init.d/plymouth lrwxrwxrwx 1 root root 16 Oct 4 12:56 K01polipo -> ../init.d/polipo . . . 可见 /etc/rcX.d/ 目录下的文件都是软链接到 /etc/init.d 下的守护进程 ( daemon ) 启动文件 三、Linux 管理守护进程两种方式 [Top] 守护进程 守护进程 ( daemon ) 就是一直在后台运行的进程 许多程序需要开机启动，它们在 Windows 叫做 \"服务\"（service），在Linux就叫做 \"守护进程\"（daemon） 命名规则 通常在服务的名字后面加上 d，即表示守护进程，比如 sshd、teamviewerd 等等 守护进程两种管理方式 service service sshd start ---> 加载 /lib/systemd/system/ssh.service ---> /etc/init.d/sshd ---> /usr/sbin/sshd 参数1 参数2 ... ---> 成功启动 ssh 相关文件 - /etc/init.d、/usr/sbin/service 等等 which service - /usr/sbin/service file service - POSIX shell script file /etc/init.d/ssh - POSIX shell script - /etc/init.d 目录下全是守护进程的执行脚本 cat /usr/sbin/service - A convenient wrapper for the /etc/init.d init scripts 所以，service 其实就是一个在 /etc/init.d 目录下查找 $1 并执行的脚本 所以，service mysql start 其实就是 /etc/init.d/mysql start /etc/init.d 目录存在是为了封装直接使用命令操控守护进程传入各种参数等操作过程，通过查看该目录下脚本，简化言之就是通过调用 /usr/bin、/usr/sbin/等目录下守护进程对应可执行文件并传以各种参数，达到只需要 /etc/init.d/xxx start|stop|reload|.... 就可以操控守护进程的目的 systemctl 相关文件 - /etc/systemd/system、/lib/systemd/system(ubuntu)、/usr/lib/systemd/system(RedHat) 等等 可使用 man systemd.unit 查看各个文件解释 systemctl 是 Linux 系统最新初始化系统的守护进程 systemd 对应的进程管理命令 对于那些支持 systemd 的软件，安装的时候，会自动在 /usr/lib/systemd/system 目录添加一个配置文件 systemctl 兼容 service 四、设置开机启动方法 [Top] 1、 编辑/etc/rc.local文件 没有的话自己创建 #!/bin/sh # # This script will be executed *after* all the other init scripts. # You can put your own initialization stuff in here if you don't # want to do the full Sys V style init stuff. touch /var/lock/subsys/local /etc/init.d/mysqld start #mysql开机启动 /etc/init.d/nginx start #nginx开机启动 /etc/init.d/php-fpm start #php-fpm开机启动 /etc/init.d/memcached start #memcache开机启动 #在文件末尾（exit 0之前）加上你开机需要启动的程序或执行的命令即可（执行的程序需要写绝对路径，添加到系统环境变量的除外），如： /usr/local/thttpd/sbin/thttpd -C /usr/local/thttpd/etc/thttpd.conf 2、 使用 chkconfig \\ systemctl 命令 早期的 Linux 版本是用 chkconfig 命令来设置 rc 的 link，设置开机启动项；用 service 命令调用服务的 start、stop、restart、status 等函数。在现在主流 Linux 版本已经将这两个命令合并成一个 systemctl 命令了，映射关系如下: 任务 旧指令 ( chkconfig、service ) 新指令 ( systemctl ) 设置服务开机自启 chkconfig --level 3 httpd on systemctl enable httpd.service 禁止服务开机自启 chkconfig --level 3 httpd off systemctl disable httpd.service 查看服务状态 service httpd status systemctl status httpd.service 显示所有开机启动服务 chkconfig --list systemctl list-units --type=service 显示当前已启动的开机启动服务       --- systemctl list-units | grep enable 显示当前已启动的开机启动文件       --- systemctl list-files | grep enable 显示启动失败的开机启动服务       --- systemctl --failed 启动服务 service httpd start systemctl start httpd.service 关闭服务 service httpd stop systemctl stop httpd.service 重启服务 service httpd restart systemctl restart httpd.service 3、自己写一个shell脚本 将写好的脚本（ .sh 文件）放到目录 /etc/profile.d/ 下，系统启动后就会自动执行该目录下的所有 shell 脚本。 /etc/profile.d 文件夹中文件 4、添加一个开机启动服务 将你的启动脚本复制到/etc/init.d目录下，并设置脚本权限, 假设脚本为 test $ mv test /etc/init.d/test $ sudo chmod 755 /etc/init.d/test /etc/init.d 目录下的控制脚本接受参数 start | stop | restart | status | force-reload 将该脚本放倒启动列表中去 $ cd .etc/init.d $ sudo update-rc.d test defaults 95 其中数字 95 是脚本启动的顺序号，按照自己的需要相应修改即可。在你有多个启动脚本，而它们之间又有先后启动的依赖关系时你就知道这个数字的具体作用了。 update-rc.d 命令 : 为/etc/init.d目录下的脚本建立或删除到/etc/rc[0-6].d的软链接 update-rc.d 命令要在 etc/init.d/ 目录下执行，可能还需要 root 权限 增加一个服务 添加这个服务并让它开机自动执行 : update-rc.d apache2 defaults 并且可以指定该服务的启动顺序 : update-rc.d apache2 defaults 90 还可以更详细的控制start与kill顺序 : update-rc.d apache2 defaults 20 80 其中前面的 20 是 start 时的运行顺序级别，80 为 kill 时的级别。也可以写成 : update-rc.d apache2 start 20 2 3 4 5 . stop 80 0 1 6 .(其中 0 ～ 6 为运行级别) 删除一个服务 update-rc.d -f apache2 remove Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Linux/防火墙学习.html":{"url":"Linux/防火墙学习.html","title":"防火墙学习笔记","keywords":"","body":" 之前很少会需要修改防火墙，也一直懒得系统学习一下，尤其在 VPS 配置安全组时，只能照着教程改，但并不明白啥意思，总归还是太菜和太懒！最近接触 zabbix ，看来不得不学习一下了 防火墙学习笔记 背景补充 SELinux、Netfilter、iptables、firewall 和 ufw五者关系 SELinux ( Security-Enhanced Linux，安全增强式 Linux ) 是一个 Linux 内核的安全模块，其提供了访问控制安全策略机制 netfilter 是 Linux 内核中的一个软件框架，用于管理网络数据包。不仅具有网络地址转换（ NAT ）的功能，也具备数据包内容修改、以及数据包过滤等防火墙功能。利用运作于用户空间的应用软件，如 iptables、ebtables 和 arptables 等，来控制 netfilter，系统管理者可以管理通过 Linux 操作系统的各种网络数据包 iptables 是一个命令行工具，用来配置 netfilter 防火墙 firewall 是 centos7+、RHEL7+、Fedora 里面新的防火墙管理命令 ufw 是 Ubuntu 下的一个简易的防火墙配置工具 SELinux 是美国国家安全局 (NSA ) 对于强制访问控制的实现，是 Linux 历史上最杰出的新安全子系统，它不是用来防火墙设置的，但它对 Linux 系统的安全很有用。Linux 内核 ( Kernel ) 从 2.6 就有了SELinux ufw、firewall 其实都是对 iptables 的封装，底层执行的都是 iptables 命令；iptables 调用内核模块 netfilter 实施真正的操作 /etc/services文件详解 /etc/services 文件包含网络服务和它们映射端口的列表；inetd 或 xinetd ( Internet 守护程序 ) 会查看这些细节，以便在数据包到达各自的端口或服务有需求时，它会调用特定的程序 文件格式：service-name port/protocol [aliases..] [#comment] service-name 是网络服务的名称。例如 telnet、ftp 等 port/protocol 是网络服务使用的端口（一个数值 ）和服务通信使用的协议（ TCP/UDP ） alias 是服务的别名 comment 是你可以添加到服务的注释或说明，以 # 标记开头 最后两个字段是可选的，因此用 [ ] 表示 sudo vim /etc/services SELinux 很多教程安装配置的时候一上来就让我们关了 SELinux，知乎回答 SELinux 策略是白名单原则，所以你需要非常清楚你的各项操作都需要哪些访问权限，这个好像数量有点多了 不外乎不懂怎么用，关了一了百了，懂怎么用的不想折腾，还是关了一了百了 因为它在本来已经很安全的 Linux 上，凌驾于 root 权限之上，设置了很多额外的条条框框；如果你了解这些条条框框，那还好；但如果不了解，那 SELinux 可能并没有帮什么忙，却给你带来了很多不确定因素 常用命令 # 查看 SELinux 是否运行 getenforce # disabled：表示 selinux 关闭，没有启动；其他两种 ( enforcing、permissive ) 均表示 selinux 启动了，只是运行的模式不一样 # 关闭SELinux # 临时生效，重启机器后失效 # 命令临时生效： setenforce 0 # 1 启用 # 0 告警，不启用 # 永久生效 # 操作前先备份 cp /etc/selinux/config /etc/selinux/config.bak # 更改 setlinux 级别 sed -i 's/SELINUX=enforcing/\\SELINUX=disabled/' /etc/selinux/config # 或 vim /etc/selinux/config # 修改SELINUX=disabled # 使用配置生效 reboot # 或 setenforce 0 #使配置立即生效 netfilter netfilter 是 Linux 操作系统核心层内部的一个数据包处理模块 iptables 在 Linux 生态系统中，iptables 是使 用很广泛的防火墙工具之一，它基于内核的包过滤框架（packet filtering framework） netfilter iptables 是运行在用户态的一个程序，通过 netlink 和内核的 netfilter 框架打交道 iptables 是 Linux 下功能强大的应用层防火墙工具, 说到 iptables 必然提到Netfilter，iptables 是应用层的，其实质是一个定义规则的配置工具，而核心的数据包拦截和转发是 Netfiler 常用命令 # 安装 iptables yum install iptables-serices -y # 查看防火墙状态： service iptables status # 关闭防火墙（永久性,重启机器后也会保持生效) chkconfig iptables off # 开启防火墙 (永久性,重启机器后也会保持生效） chkconfig iptables on # 临时关闭防火墙（重启机器后失效) service iptables off # 临时开启防火墙（重启机器后失效) service iptables on iptables 深度详解 firewall firewall 的底层是使用 iptables 进行数据过滤，建立在 iptables 之上 firewall 是动态防火墙，使用了 D-BUS 方式，修改配置不会破坏已有的数据链接 firewalld firewalld - Dynamic Firewall Manager 常用命令 # 安装 firewall yum install firewalld firewall-config -y # 启动防火墙 systemctl start firewalld.service # 停止防火墙/关闭防火墙 systemctl stop firewalld.service # 重启防火墙 systemctl restart firewalld.service # 设置开机启用防火墙 systemctl enable firewalld.service # 设置开机不启动防火墙 systemctl disable firewalld.service 配置 修改 firewall 三种方法：firewall-config ( 图形化 )、firewall-cmd ( 命令行 )、配置文件内修改 firewalld 的配置文件是以 xml 的格式，存储在 /usr/lib/firewalld/（用户 和 /etc/firewalld/ 目录中 firewall-cmd firewall - cmd is the command line client of the firewalld daemon. It provides interface to manage runtime and permanent configuration. 常用命令 # 查看 firewall 状态 firewall-cmd --state # 列出开放的端口号 firewall-cmd --zone=public --list-ports # 新增开放端口号 firewall-cmd [--zone=] --add-port=[-]/ [--timeout=] [--permanent] # 例如： firewall-cmd --zone=public --add-port=80/tcp --permanent #说明: # --zone 网络区域定义了网络连接的可信等级 # 阻塞区域（block）：任何传入的网络数据包都将被阻止 # 工作区域（work）：相信网络上的其他计算机，不会损害你的计算机 # 家庭区域（home）：相信网络上的其他计算机，不会损害你的计算机 # 公共区域（public）：不相信网络上的任何计算机，只有选择接受传入的网络连接 # 隔离区域（DMZ）：也称为非军事区域，内外网络之间增加的一层网络，起到缓冲作用。对于隔离区域，只能选择接受传入的网络连接 # 信任区域（trusted）：所有的网络连接都可以接受 # 丢弃区域（drop）：任何传入的网络连接都被拒绝 # 内部区域（internal）：信任网络上的其他计算机，不会损害你的计算机。只有选择接受传入的网络连接 # 外部区域（external）：不相信网络上的其他计算机，不会损害你的计算机。只有选择接受传入的网络连接 # --add-port=80/tcp 添加端口，格式为：端口或端口范围/协议(udp/tcp) # --permanent 永久生效，没有此参数重启后失效 # 查看 firewall-cmd --zone=public --query-port=80/tcp # 删除 firewall-cmd --zone=public --remove-port=80/tcp --permanent # 查看当前活动的区域,并附带一个目前分配给它们的接口列表 firewall-cmd --get-active-zones # 查看默认区域 firewall-cmd --get-default-zone # 查看所有可用区域 firewall-cmd --get-zones # 列出指定域的所有设置 firewall-cmd --zone=public --list-all # 列出所有预设服务 firewall-cmd --get-services # (这样将列出 /usr/lib/firewalld/services/ 中的服务器名称。注意:配置文件是以服务本身命名的service-name. xml) # 列出所有区域的设置 firewall-cmd --list-all-zones # 设置默认区域 firewall-cmd --set-default-zone=dmz # 设置网络地址到指定的区域 firewall-cmd --permanent --zone=internal --add-source=192.168.122.0/24 # (--permanent参数表示永久生效设置,如果没有指定--zone参数,那么会加入默认区域) # 删除指定区域中的网路地址 # firewall-cmd --permanent --zone=internal --remove-source=192.168.122.0/24 # 添加、改变、删除网络接口 firewall-cmd --permanent --zone=internal --add-interface=eth0 firewall-cmd --permanent --zone=internal --change-interface=eth0 firewall-cmd --permanent --zone=internal --remove-interface=eth0 # 添加、删除服务 firewall-cmd --permanent --zone=public --add-service=smtp firewall-cmd --permanent --zone=public --remove-service=smtp # 列出、添加、删除端口 firewall-cmd --zone=public --list-ports firewall-cmd --permanent --zone=public --add-port=8080/tcp firewall-cmd --permanent --zone=public --remove-port=8080/tcp # 重新载入，每次执行完 firewall-cmd 都应该 reload 一次 # 注意: 这并不会中断已经建立的连接,如果打算中断,可以使用 --complete-reload 选项 firewall-cmd --reload zone 信任等级详解 ufw - uncomplicated firewall - 简易防火墙 ufw 是一个 Arch Linux、Debian 或 Ubuntu 中管理防火墙规则的前端；ufw 默认包含在 Ubuntu 中，但在 Arch 和 Debian 中需要自行安装 ufw 是基于 iptables 实现的防火墙管理工具，所以实际上 ufw 修改的是 iptables 的规则 配置 /etc/ufw - 一些 ufw 的环境设定文件 /etc/sysctl.conf - 若开启ufw之 后，/etc/ufw/sysctl.conf会覆盖默认的/etc/sysctl.conf文件，若你原来的/etc/sysctl.conf做了修改，启动ufw后，若/etc/ufw/sysctl.conf中有新赋值，则会覆盖/etc/sysctl.conf的，否则还以/etc /sysctl.conf为准 /etc/default/ufw - 当然你可以通过修改/etc/default/ufw中的IPT_SYSCTL=条目来设置使用哪个 sysctrl.conf 备份/还原规则 ufw 的所有规则文件都在路径/etc/ufw/，其中before.rules规则为 ufw 在运行用户自定义的规则之前运行的规则，相应的before6.rules对应 IPV6；after.rules为 ufw 启用用户自定义规则之后运行的规则；user.rules即为用户自定义的规则 所以可以通过直接备份这些配置文件的方式来备份防火墙规则，需要备份的文件有： /etc/ufw/*.rules /lib/ufw/*.rules /etc/default/ufw 这个配置文件如果没有修改过，可以不备份 修改配置文件之后需要重新加载配置文件：sudo ufw reload 常用命令 # 安装 ufw sudo apt-get install ufw # 查看防火墙状态 sudo ufw status # 启动、关闭、查看状态、开机启动、开机不启动防火墙 systemctl start|stop|status|enable|disable ufw # 开机启动、开机不启动防火墙 ( 默认设置是 disable ) sudo ufw enable|disable # 设置默认策略，即为拒绝所有传入连接，允许所有传出链接 sudo ufw default deny incoming sudo ufw default allow outgoing # 允许/拒绝访问 20 端口，20 后可跟 /tcp 或 /udp，表示 tcp 或 udp 封包 sudo ufw allow/deny 20[/tcp|/udp] # 删除上面定义的“允许/拒绝访问 20 端口”的规则 sudo ufw delete allow/deny 20[/tcp|/udp] # ufw 的 allow 不加 in/out 允许连接默认是指允许入站连接，如果要指定允许出站，可以加上 out，如： sudo ufw allow in port #允许 port 入站 sudo ufw allow out port #允许 port 出站 # 允许/拒绝访问某个 service 的端口 ( 在 /etc/services 文件中查看 service )，删除同前面加 delete # ufw 通过 /etc/services 文件得到 service 默认端口号 sudo ufw allow/deny [service] # 例如 sudo ufw allow http sudo ufw allow 80/tcp # 设置外来访问默认允许/拒绝 sudo ufw default allow/deny # 允许/拒绝特定端口范围连接 sudo ufw allow/deny 1000:2000[/tcp|/udp] # 允许/拒绝特定 IP，删除同前面加 delete sudo ufw allow/deny from 192.168.254.254 # 允许/拒绝特定 IP 特定端口的连接，删除同前面加 delete sudo ufw allow/deny from 111.111.111.111 to any port 22 # 允许/拒绝自10.0.1.0/10 的 tcp 封包访问本机的 25 端口，删除同前面加 delete sudo ufw allow/deny proto tcp from 10.0.1.0/10 to 127.0.0.1 port 25 # 查看所有规则的规则号 sudo ufw status numbered # 删除规则编号或删除指定实际规则 delete num/rule # 重置防火墙 # 该命令将禁用 ufw，删除所有已经定义的规则，所有规则将被重设为安装时的默认值，不过默认该命令会对已经设置的规则进行备份 sudo ufw reset # 批量禁止 IP，file.txt 里面是一个需要禁止的 IP 列表 while read line; do sudo ufw deny from $line; done Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Linux/本地显示远程服务器上的图形化界面.html":{"url":"Linux/本地显示远程服务器上的图形化界面.html","title":"本地显示远程服务器上的图形化界面","keywords":"","body":"本地显示远程服务器上的图形化界面 X11 Forwarding https://zhuanlan.zhihu.com/p/31012874 利用 X11Forwarding 远程启动 CentOS 服务器 GUI 图形界面程序 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Linux/Linux网络常用命令详解.html":{"url":"Linux/Linux网络常用命令详解.html","title":"Linux网络常用命令详解","keywords":"","body":" ip ifconfig netstat route --> net-tools brctl ---> bridge-utils ss ifdown br0 ifdown eth0 ifup br0 ifup eth0 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Linux/rdesktop安装的坑.html":{"url":"Linux/rdesktop安装的坑.html","title":"rdesktop安装的坑","keywords":"","body":"安装 rdesktop 最近需要使用 rdesktop 远程连接公司的 windows server，一直在用 rdesktop，但最近总是报“核心已转储”的错，搜了一圈发现竟然是最新版本的 rdesktop 存在 bug，需要安装旧版本的 rdesktop，并阻止其自动升级到故障版本 卸载并安装稳定的旧版本 sudo apt purge rdesktop wget http://mirrors.ustc.edu.cn/ubuntu/pool/universe/r/rdesktop/rdesktop_1.8.3-1_amd64.deb sudo dpkg -i rdesktop_1.8.3-1_amd64.deb 暂时阻止 rdesktop 升级到故障版本 sudo apt-mark hold rdesktop 查看被锁定的软件包 dpkg --get-selections | grep hold 解除软件包的锁定 sudo apt-mark unhold rdesktop 使用 $ rdesktop -g 50% -u administrator 192.168.7.19 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Linux/vncserver.html":{"url":"Linux/vncserver.html","title":"VNC Server","keywords":"","body":"VNC Server centos7 安装VNC Server Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Python/":{"url":"Python/","title":"Python","keywords":"","body":"Python 学习 基础库 sys、os（os.path、os.stat）、time、logging、prarmiko、re、random 运维常用 Python 库 1、psutil 是一个跨平台库，能够实现获取系统运行的进程和系统利用率（内存、CPU、磁盘、网络等），主要用于系统监控，分析和系统资源及进程的管理 2、IPy 辅助IP规划 3、dnspython Python实现的一个 DNS 工具包 4、difflib difflib 作为 Python 的标准模块，无需安装，作用是对比文本之间的差异 5、filecmp 系统自带，可以实现文件，目录，遍历子目录的差异，对比功能 6、smtplib 发送电子邮件模块 7、pycurl 是一个用 C 语言写的 libcurl Python 实现，功能强大，支持的协议有：FTP、HTTP、HTTPS、TELNET等，可以理解为 Linux 下 curl 命令功能的Python 封装 8、XlsxWriter 操作 Excel 工作表的文字、数字、公式、图表等 9、rrdtool 用于跟踪对象的变化，生成这些变化的走势图 10、scapy 是一个强大的交互式数据包处理程序，它能够对数据包进行伪造或解包，包括发送数据包、包嗅探、应答和反馈等功能 11、pyClamad 由 Clam Antivirus 开源的防毒软件，可以让 Python 模块直接使用 ClamAV 病毒扫描守护进程 calmd 12、pexpect 可以理解成 Linux 下 expect 的 Python 封装，通过 pexpect 我们可以实现对 ssh、ftp、passwd、telnet 等命令行进行自动交互，而无需人工干涉来达到自动化的目的 13、paramiko 是基于 Python 实现的 SSH2 远程安装连接，支持认证及密钥方式。可以实现远程命令执行、文件传输、中间 SSH 代理等功能。相对于pexpect，封装的层次更高，更贴近 SSH 协议的功能 14、fabric 是基于 Python 实现的 SSH 命令行工具，简化了 SSH 的应用程序部署及系统管理任务，它提供了系统基础的操作组件，可以实现本地或远程 shell 命令，包括命令执行、文件上传、下载及完整执行日志输出等功能。Fabric 在paramiko 的基础上做了更高一层的封装，操作起来更加简单 15、CGIHTTPRequestHandler 实现对 CGI 的支持 16、ansible 一种集成 IT 系统的配置管理，应用部署，执行特定任务的开源平台。基于 Python 实现，由 Paramiko 和 PyYAML 两个关键模块构建。Ansible 与 Saltstack 最大的区别是 Ansible 无需在被控主机上部署任何客户端，默认直接通过 SSH 通道进行远程命令执行或下发功能 17、YAML 是一种用来表达数据序列的编程语言 18、playbook 一个非常简单的配置管理和多主机部署系统 19、saltstack 是一个服务器基础架构集中化管理平台，一般可以理解为简化版的 puppet和加强版的 func。Saltstack 基于 Python 语言实现，结合轻量级消息队列 ZeroMQ，由 Python 第三方模块（Pyzmq、PyCrypto、Pyjinja2、python-msgpack 和 PyYAML 等）构建 20、func 为解决集群管理，监控问题需设计开发的系统管理基础框架 Python运维常用模块 csv：对于读取 csv 文件来说非常便利 collections：常见数据类型的实用扩展，包括 OrderedDict、defaultdict 和 namedtuple random：生成假随机数字，随机打乱序列并选择随机项 string：关于字符串的更多函数。此模块还包括实用的字母集合，例如 string.digits（包含所有字符都是有效数字的字符串） re：通过正则表达式在字符串中进行模式匹配 math：一些标准数学函数 os：与操作系统交互 os.path：os 的子模块，用于操纵路径名称 sys：直接使用 Python 解释器 json：适用于读写 json 文件（面向网络开发） 实用的第三方软件包 IPython - 更好的交互式 Python 解释器。 requests - 提供易于使用的方法来发出网络请求。适用于访问网络 API。 Flask - 一个小型框架，用于构建网络应用和 API。 Django - 一个功能更丰富的网络应用构建框架。Django 尤其适合设计复杂、内容丰富的网络应用。 Beautiful Soup - 用于解析 HTML 并从中提取信息。适合网页数据抽取。 pytest - 扩展了 Python 的内置断言，并且是最具单元性的模块。 PyYAML - 用于读写 YAML 文件。 NumPy - 用于使用 Python 进行科学计算的最基本软件包。它包含一个强大的 N 维数组对象和实用的线性代数功能等。 pandas - 包含高性能、数据结构和数据分析工具的库。尤其是，pandas 提供 dataframe！ matplotlib - 二维绘制库，会生成达到发布标准的高品质图片，并且采用各种硬拷贝格式和交互式环境。 ggplot - 另一种二维绘制库，基于 R’s ggplot2 库。 Pillow - Python 图片库可以向你的 Python 解释器添加图片处理功能。 pyglet - 专门面向游戏开发的跨平台应用框架。 Pygame - 用于编写游戏的一系列 Python 模块。 pytz - Python 的世界时区定义。 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Python/Python资源大全.html":{"url":"Python/Python资源大全.html","title":"Python 资源大全","keywords":"","body":"Python 资源大全中文版 我想很多程序员应该记得 GitHub 上有一个 Awesome - XXX 系列的资源整理。awesome-python 是 vinta 发起维护的 Python 资源列表，内容包括：Web 框架、网络爬虫、网络内容提取、模板引擎、数据库、数据可视化、图片处理、文本处理、自然语言处理、机器学习、日志、代码分析等。由伯乐在线持续更新。 Awesome 系列虽然挺全，但基本只对收录的资源做了极为简要的介绍，如果有更详细的中文介绍，对相应开发者的帮助会更大。这也是我们发起这个开源项目的初衷。 关于项目 我们要做什么？ 基于 awesome-python 列表，我们将对其中的各个资源项进行编译整理。此外还将从其他来源补充好资源。 整理后的内容，将收录在伯乐在线资源频道。可参考已整理的内容： 《Scrapy：Python 的爬虫框架》 《Flask：一个使用 Python 编写的轻量级 Web 应用框架》 如何为列表贡献新资源？ 欢迎大家为列表贡献高质量的新资源，提交 PR 时请参照以下要求： 请确保推荐的资源自己使用过 提交 PR 时请注明推荐理由 资源列表管理收到 PR 请求后，会定期（每周）在微博转发本周提交的 PR 列表，并在微博上面听取使用过这些资源的意见。确认通过后，会加入资源大全。 感谢您的贡献！ 本项目的参与者 维护者： 贡献者：艾凌风、Namco、Daetalus、黄利民、atupal、rainbow、木头lbj、beyondwu、cissoid、李广胜、polyval、冰斌、赵叶宇、л stalgic、硕恩、strongit、yuukilp、chenjiandongx、autopenguin、visonforcoding、Super赛亚人、Since-future、knktc 注：名单不分排名，不定期补充更新 资源列表 环境管理 管理 Python 版本和环境的工具 p：非常简单的交互式 python 版本管理工具。官网 pyenv：简单的 Python 版本管理工具。官网 Vex：可以在虚拟环境中执行命令。官网 virtualenv：创建独立 Python 环境的工具。官网 virtualenvwrapper：virtualenv 的一组扩展。官网 buildout：在隔离环境初始化后使用声明性配置管理。官网 包管理 管理包和依赖的工具。 pip：Python 包和依赖关系管理工具。官网 pip-tools：保证 Python 包依赖关系更新的一组工具。官网 pipenv：Python 官方推荐的新一代包管理工具。官网 poetry: 可完全取代 setup.py 的包管理工具。官网 conda：跨平台，Python 二进制包管理工具。官网 Curdling：管理 Python 包的命令行工具。官网 wheel：Python 分发的新标准，意在取代 eggs。官网 包仓库 本地 PyPI 仓库服务和代理。 warehouse：下一代 PyPI。官网 bandersnatch：PyPA 提供的 PyPI 镜像工具。官网 devpi：PyPI 服务和打包/测试/分发工具。官网 localshop：本地 PyPI 服务（自定义包并且自动对 PyPI 镜像）。官网 分发 打包为可执行文件以便分发。 PyInstaller：将 Python 程序转换成独立的执行文件（跨平台）。官网 cx_Freeze：将python程序转换为带有一个动态链接库的可执行文件。官网 dh-virtualenv：构建并将 virtualenv 虚拟环境作为一个 Debian 包来发布。官网 Nuitka：将脚本、模块、包编译成可执行文件或扩展模块。官网 py2app：将 Python 脚本变为独立软件包（Mac OS X）。官网 py2exe：将 Python 脚本变为独立软件包（Windows）。官网 pynsist：一个用来创建 Windows 安装程序的工具，可以在安装程序中打包 Python 本身。官网 构建工具 将源码编译成软件。 buildout：一个构建系统，从多个组件来创建，组装和部署应用。官网 BitBake：针对嵌入式 Linux 的类似 make 的构建工具。官网 fabricate：对任何语言自动找到依赖关系的构建工具。官网 PlatformIO：多平台命令行构建工具。官网 PyBuilder：纯 Python 实现的持续化构建工具。官网 SCons：软件构建工具。官网 交互式解析器 交互式 Python 解析器。 IPython：功能丰富的工具，非常有效的使用交互式 Python。官网 bpython：界面丰富的 Python 解析器。官网 ptpython：高级交互式 Python 解析器， 构建于 python-prompt-toolkit 之上。官网 文件 文件管理和 MIME（多用途的网际邮件扩充协议）类型检测。 aiofiles：基于 asyncio，提供文件异步操作。官网 imghdr：（Python 标准库）检测图片类型。官网 mimetypes：（Python 标准库）将文件名映射为 MIME 类型。官网 path.py：对 os.path 进行封装的模块。官网 pathlib：（Python3.4+ 标准库）跨平台的、面向对象的路径操作库。官网 python-magic：文件类型检测的第三方库 libmagic 的 Python 接口。官网 Unipath：用面向对象的方式操作文件和目录。官网 watchdog：管理文件系统事件的 API 和 shell 工具。官网 日期和时间 操作日期和时间的类库。 arrow：更好的 Python 日期时间操作类库。官网 Chronyk：Python 3 的类库，用于解析手写格式的时间和日期。官网 dateutil：Python datetime 模块的扩展。官网 delorean：解决 Python 中有关日期处理的棘手问题的库。官网 maya：人性化的时间处理库。官网 moment：一个用来处理时间和日期的 Python 库。灵感来自于 Moment.js。官网 pendulum：一个比 arrow 更具有明确的，可预测的行为的时间操作库。官网 PyTime：一个简单易用的 Python 模块，用于通过字符串来操作日期/时间。官网 pytz：现代以及历史版本的世界时区定义。将时区数据库引入 Python。官网 when.py：提供用户友好的函数来帮助用户进行常用的日期和时间操作。官网 文本处理 用于解析和操作文本的库。 通用 chardet：字符编码检测器，兼容 Python2 和 Python3。官网 difflib：(Python 标准库)帮助我们进行差异化比较。官网 ftfy：让 Unicode 文本更完整更连贯。官网 fuzzywuzzy：模糊字符串匹配。官网 Levenshtein：快速计算编辑距离以及字符串的相似度。官网 pangu.py：在中日韩语字符和数字字母之间添加空格。官网 pypinyin：汉字拼音转换工具 Python 版。官网 shortuuid：一个生成器库，用以生成简洁的，明白的，URL 安全的 UUID。官网 simplejson：Python 的 JSON 编码、解码器。官网 unidecode：Unicode 文本的 ASCII 转换形式 。官网 uniout：打印可读的字符，而不是转义的字符串。官网 xpinyin：一个用于把汉字转换为拼音的库。官网 yfiglet-figlet：pyfiglet -figlet 的 Python 实现。 flashtext: 一个高效的文本查找替换库。官网 Slug 化 awesome-slugify：一个 Python slug 化库，可以保持 Unicode。官网 python-slugify：Python slug 化库，可以把 unicode 转化为 ASCII。官网 unicode-slugify：一个 slug 工具，可以生成 unicode slugs ,需要依赖 Django 。官网 解析器 phonenumbers：解析，格式化，储存，验证电话号码。官网 PLY：lex 和 yacc 解析工具的 Python 实现。官网 Pygments：通用语法高亮工具。官网 pyparsing：生成通用解析器的框架。官网 python-nameparser：把一个人名分解为几个独立的部分。官网 python-user-agents：浏览器 user agent 解析器。官网 sqlparse：一个无验证的 SQL 解析器。官网 特殊文本格式处理 一些用来解析和操作特殊文本格式的库。 通用 tablib：一个用来处理中表格数据的模块。官网 Office Marmir：把输入的 Python 数据结构转换为电子表单。官网 openpyxl：一个用来读写 Excel 2010 xlsx/xlsm/xltx/xltm 文件的库。官网 pyexcel：一个提供统一 API，用来读写，操作 Excel 文件的库。官网 python-docx：读取，查询以及修改 Microsoft Word 2007/2008 docx 文件。官网 relatorio：模板化 OpenDocument 文件。官网 unoconv：在 LibreOffice/OpenOffice 支持的任意文件格式之间进行转换。官网 XlsxWriter：一个用于创建 Excel .xlsx 文件的 Python 模块。官网 xlwings：一个使得在 Excel 中方便调用 Python 的库（反之亦然），基于 BSD 协议。官网 xlwt：读写 Excel 文件的数据和格式信息。官网 / xlrd PDF PDFMiner：一个用于从 PDF 文档中抽取信息的工具。官网 PyPDF2：一个可以分割，合并和转换 PDF 页面的库。官网 ReportLab：快速创建富文本 PDF 文档。官网 Markdown Mistune：快速并且功能齐全的纯 Python 实现的 Markdown 解析器。官网 Python-Markdown：John Gruber’s Markdown 的 Python 版实现。官网 Python-Markdown2：纯 Python 实现的 Markdown 解析器，比 Python-Markdown 更快，更准确，可扩展。官网 YAML PyYAML：Python 版本的 YAML 解析器。官网 CSV csvkit：用于转换和操作 CSV 的工具。官网 Archive unp：一个用来方便解包归档文件的命令行工具。官网 自然语言处理 用来处理人类语言的库。 NLTK：一个先进的平台，用以构建处理人类语言数据的 Python 程序。官网 jieba：中文分词工具。官网 langid.py：独立的语言识别系统。官网 Pattern：Python 网络信息挖掘模块。官网 SnowNLP：一个用来处理中文文本的库。官网 TextBlob：为进行普通自然语言处理任务提供一致的 API。官网 TextGrocery：一简单高效的短文本分类工具，基于 LibLinear 和 Jieba。官网 thulac:清华大学自然语言处理与社会人文计算实验室研制推出的一套中文词法分析工具包官网 文档 用以生成项目文档的库。 Sphinx：Python 文档生成器。官网 awesome-sphinxdoc：官网 MkDocs：对 Markdown 友好的文档生成器。官网 pdoc：一个可以替换 Epydoc 的库，可以自动生成 Python 库的 API 文档。官网 Pycco：文学编程（literate-programming）风格的文档生成器。官网 readthedocs：一个基于 Sphinx/MkDocs 的在线文档托管系统，对开源项目免费开放使用。官网 配置 用来保存和解析配置的库。 config：logging 模块作者写的分级配置模块。官网 ConfigObj：INI 文件解析器，带验证功能。官网 ConfigParser：(Python 标准库) INI 文件解析器。官网 profig：通过多种格式进行配置，具有数值转换功能。官网 python-decouple：将设置和代码完全隔离。官网 命令行工具 用于创建命令行程序的库。 命令行程序开发 asciimatics：跨平台，全屏终端包（即鼠标/键盘输入和彩色，定位文本输出），完整的复杂动画和特殊效果的高级 API。官网 cement：Python 的命令行程序框架。官网 click：一个通过组合的方式来创建精美命令行界面的包。官网 cliff：一个用于创建命令行程序的框架，可以创建具有多层命令的命令行程序。官网 clint：Python 命令行程序工具。官网 colorama：跨平台彩色终端文本。官网 docopt：Python 风格的命令行参数解析器。官网 Gooey：一条命令，将命令行程序变成一个 GUI 程序。官网 python-prompt-toolkit：一个用于构建强大的交互式命令行程序的库。官网 python-fire：Google 出品的一个基于 Python 类的构建命令行界面的库。官网 Pythonpy：在命令行中直接执行任何 Python 指令。官网 生产力工具 aws-cli：Amazon Web Services 的通用命令行界面。官网 bashplotlib：在终端中进行基本绘图。官网 caniusepython3：判断是哪个项目妨碍你你移植到 Python3。官网 cookiecutter：从 cookiecutters（项目模板）创建项目的一个命令行工具。官网 doitlive：一个用来在终端中进行现场演示的工具。官网 pyftpdlib：一个速度极快和可扩展的 Python FTP 服务库。官网 howdoi：通过命令行获取即时的编程问题解答。官网 httpie：一个命令行 HTTP 客户端，cURL 的替代品，易用性更好。官网 PathPicker：从 bash 输出中选出文件。官网 percol：向 UNIX shell 传统管道概念中加入交互式选择功能。官网 SAWS：一个加强版的 AWS 命令行。官网 thefuck：修正你之前的命令行指令。官网 mycli：一个 MySQL 命令行客户端，具有自动补全和语法高亮功能。官网 pgcli：Postgres 命令行工具，具有自动补全和语法高亮功能。官网 try：一个从来没有更简单的命令行工具，用来试用 python 库。官网 下载器 用来进行下载的库. s3cmd：一个用来管理 Amazon S3 和 CloudFront 的命令行工具。官网 s4cmd：超级 S3 命令行工具，性能更加强劲。官网 you-get：一个 YouTube/Youku/Niconico 视频下载器，使用 Python3 编写。官网 youtube-dl：一个小巧的命令行程序，用来下载 YouTube 视频。官网 图像处理 用来操作图像的库. pillow：Pillow 是一个更加易用版的 PIL。官网 hmap：图像直方图映射。官网 imgSeek：一个使用视觉相似性搜索一组图片集合的项目。官网 nude.py：裸体检测。官网 pyBarcode：不借助 PIL 库在 Python 程序中生成条形码。官网 pygram：类似 Instagram 的图像滤镜。官网 python-qrcode：一个纯 Python 实现的二维码生成器。官网 Quads：基于四叉树的计算机艺术。官网 scikit-image：一个用于（科学）图像处理的 Python 库。官网 thumbor：一个小型图像服务，具有剪裁，尺寸重设和翻转功能。官网 wand：MagickWand的 Python 绑定。MagickWand 是 ImageMagick 的 C API 。官网 face_recognition：简单易用的 python 人脸识别库。官网 OCR 光学字符识别库。 pyocr：Tesseract 和 Cuneiform 的一个封装(wrapper)。官网 pytesseract：Google Tesseract OCR 的另一个封装(wrapper)。官网 python-tesseract：Google Tesseract OCR 的一个包装类。 音频 用来操作音频的库 audiolazy：Python 的数字信号处理包。官网 audioread：交叉库 (GStreamer + Core Audio + MAD + FFmpeg) 音频解码。官网 beets：一个音乐库管理工具及 MusicBrainz 标签添加工具。官网 dejavu：音频指纹提取和识别。官网 django-elastic-transcoder：Django + Amazon Elastic Transcoder。官网 eyeD3：一个用来操作音频文件的工具，具体来讲就是包含 ID3 元信息的 MP3 文件。官网 id3reader：一个用来读取 MP3 元数据的 Python 模块。官网 m3u8：一个用来解析 m3u8 文件的模块。官网 mutagen：一个用来处理音频元数据的 Python 模块。官网 pydub：通过简单、简洁的高层接口来操作音频文件。官网 pyechonest：Echo Nest API 的 Python 客户端。官网 talkbox：一个用来处理演讲/信号的 Python 库。官网 TimeSide：开源 web 音频处理框架。官网 tinytag：一个用来读取 MP3, OGG, FLAC 以及 Wave 文件音乐元数据的库。官网 mingus：一个高级音乐理论和曲谱包，支持 MIDI 文件和回放功能。官网 Video 用来操作视频和 GIF 的库。 moviepy：一个用来进行基于脚本的视频编辑模块，适用于多种格式，包括动图 GIFs。官网 scikit-video：SciPy 视频处理常用程序。官网 地理位置 地理编码地址以及用来处理经纬度的库。 GeoDjango：世界级地理图形 web 框架。官网 GeoIP：MaxMind GeoIP Legacy 数据库的 Python API。官网 geojson：GeoJSON 的 Python 绑定及工具。官网 geopy：Python 地址编码工具箱。官网 GeoIP2：GeoIP2 Webservice 客户端与数据库 Python API。官网 django-countries：一个 Django 应用程序，提供用于表格的国家选择功能，国旗图标静态文件以及模型中的国家字段。官网 HTTP 使用 HTTP 的库。 aiohttp：基于 asyncio 的异步 HTTP 网络库。官网 requests：人性化的 HTTP 请求库。官网 grequests：requests 库 + gevent ，用于异步 HTTP 请求.官网 httplib2：全面的 HTTP 客户端库。官网 treq：类似 requests 的 Python API 构建于 Twisted HTTP 客户端之上。官网 urllib3：一个具有线程安全连接池，支持文件 post，清晰友好的 HTTP 库。官网 数据库 Python 实现的数据库。 pickleDB：一个简单，轻量级键值储存数据库。官网 PipelineDB：流式 SQL 数据库。官网 TinyDB：一个微型的，面向文档型数据库。官网 ZODB：一个 Python 原生对象数据库。一个键值和对象图数据库。官网 数据库驱动 用来连接和操作数据库的库。 MySQL：awesome-mysql 系列 aiomysql：基于 asyncio 的异步 MySQL 数据库操作库。官网 mysql-python：Python 的 MySQL 数据库连接器。官网 ysqlclient：mysql-python 分支，支持 Python 3。 oursql：一个更好的 MySQL 连接器，支持原生预编译指令和 BLOBs。官网 PyMySQL：纯 Python MySQL 驱动，兼容 mysql-python。官网 PostgreSQL psycopg2：Python 中最流行的 PostgreSQL 适配器。官网 queries：psycopg2 库的封装，用来和 PostgreSQL 进行交互。官网 txpostgres：基于 Twisted 的异步 PostgreSQL 驱动。官网 其他关系型数据库 apsw：另一个 Python SQLite 封装。官网 dataset：在数据库中存储 Python 字典 pymssql：一个简单的 Microsoft SQL Server 数据库接口。官网 NoSQL 数据库 asyncio-redis：基于 asyncio 的 redis 客户端 (PEP 3156)。官网 cassandra-python-driver：Cassandra 的 Python 驱动。官网 HappyBase：一个为 Apache HBase 设计的，对开发者友好的库。官网 Plyvel：一个快速且功能丰富的 LevelDB 的 Python 接口。官网 py2neo：Neo4j restful 接口的 Python 封装客户端。官网 pycassa：Cassandra 的 Python Thrift 驱动。官网 PyMongo：MongoDB 的官方 Python 客户端。官网 redis-py：Redis 的 Python 客户端。官网 telephus：基于 Twisted 的 Cassandra 客户端。官网 txRedis：基于 Twisted 的 Redis 客户端。官网 ORM 实现对象关系映射或数据映射技术的库。 关系型数据库 Django Models：Django 的一部分。官网 SQLAlchemy：Python SQL 工具以及对象关系映射工具。官网 awesome-sqlalchemy 系列 Peewee：一个小巧，富有表达力的 ORM。官网 PonyORM：提供面向生成器的 SQL 接口的 ORM。官网 python-sql：编写 Python 风格的 SQL 查询。官网 NoSQL 数据库 django-mongodb-engine：Django MongoDB 后端。官网 PynamoDB：Amazon DynamoDB 的一个 Python 风格接口。官网 flywheel：Amazon DynamoDB 的对象映射工具。官网 MongoEngine：一个 Python 对象文档映射工具，用于 MongoDB。官网 hot-redis：为 Redis 提供 Python 丰富的数据类型。官网 redisco：一个 Python 库，提供可以持续存在在 Redis 中的简单模型和容器。官网 其他 butterdb：Google Drive 电子表格的 Python ORM。官网 Web 框架 全栈 Web 框架。 Django：Python 界最流行的 web 框架。官网 awesome-django 系列 Flask：一个 Python 微型框架。官网 awesome-flask 系列 pyramid：一个小巧，快速，接地气的开源 Python web 框架。 awesome-pyramid 系列 Bottle：一个快速小巧，轻量级的 WSGI 微型 web 框架。官网 CherryPy：一个极简的 Python web 框架，服从 HTTP/1.1 协议且具有 WSGI 线程池。官网 TurboGears：一个可以扩展为全栈解决方案的微型框架。官网 web.py：一个 Python 的 web 框架，既简单，又强大。官网 web2py：一个全栈 web 框架和平台，专注于简单易用。官网 Tornado：一个 web 框架和异步网络库。官网 sanic：基于 Python3.5+ 的异步网络框架。官网 权限 允许或拒绝用户访问数据或功能的库。 Carteblanche：站在用户和设计者角度开发的一个代码对齐模块，很好地处理了代码导航及权限。官网 django-guardian：Django 1.2+ 实现了单个对象权限。官网 django-rules：一个小巧但是强大的应用，提供对象级别的权限管理，且不需要使用数据库。官网 CMS 内容管理系统 odoo-cms: 一个开源的，企业级 CMS，基于 odoo。官网 django-cms：一个开源的，企业级 CMS，基于 Django。官网 djedi-cms：一个轻量级但却非常强大的 Django CMS ，考虑到了插件，内联编辑以及性能。官网 FeinCMS：基于 Django 构建的最先进的内容管理系统之一。官网 Kotti：一个高级的，Python 范的 web 应用框架，基于 Pyramid 构建。官网 Mezzanine：一个强大的，持续的，灵活的内容管理平台。官网 Opps：一个为杂志，报纸网站以及大流量门户网站设计的 CMS 平台，基于 Django。官网 Plone：一个构建于开源应用服务器 Zope 之上的 CMS。官网 Quokka：灵活，可扩展的小型 CMS，基于 Flask 和 MongoDB。官网 Wagtail：一个 Django 内容管理系统。官网 Widgy：最新的 CMS 框架，基于 Django。官网 电子商务 用于电子商务以及支付的框架和库。 django-oscar：一个用于 Django 的开源的电子商务框架。官网 django-shop：一个基于 Django 的店铺系统。官网 Cartridge：一个基于 Mezzanine 构建的购物车应用。官网 shoop：一个基于 Django 的开源电子商务平台。官网 alipay：非官方的 Python 支付宝 API。官网 merchant：一个可以接收来自多种支付平台支付的 Django 应用。官网 money：一个货币类库。带有可选的 CLDR 后端本地化格式，提供可扩展的货币兑换解决方案。官网 python-currencies：显示货币格式以及它的数值。官网 RESTful API 用来开发 RESTful APIs 的库 Django django-rest-framework：一个强大灵活的工具，用来构建 web API。官网 django-tastypie：为 Django 应用开发 API。官网 django-formapi：为 Django 的表单验证，创建 JSON APIs 。官网 Flask flask-api：为 flask 开发的，可浏览 Web APIs 。官网 flask-restful：为 flask 快速创建 REST APIs 。官网 flask-restless：为 SQLAlchemy 定义的数据库模型创建 RESTful APIs 。官网 flask-api-utils：为 Flask 处理 API 表示和验证。官网 eve：REST API 框架，由 Flask, MongoDB 等驱动。官网 Pyramid cornice：一个 Pyramid 的 REST 框架 。官网 与框架无关的 falcon：一个用来建立云 API 和 web app 后端的高性能框架。官网 sandman：为现存的数据库驱动系统自动创建 REST APIs 。官网 restless：框架无关的 REST 框架 ，基于从 Tastypie 学到的知识。官网 ripozo：快速创建 REST/HATEOAS/Hypermedia APIs。官网 验证 实现验证方案的库。 OAuth Authomatic：简单但是强大的框架，身份验证/授权客户端。官网 django-allauth：Django 的验证应用。官网 django-oauth-toolkit：为 Django 用户准备的 OAuth2。官网 django-oauth2-provider：为 Django 应用提供 OAuth2 接入。官网 Flask-OAuthlib：OAuth 1.0/a, 2.0 客户端实现，供 Flask 使用。官网 OAuthLib：一个 OAuth 请求-签名逻辑通用、 完整的实现。官网 python-oauth2：一个完全测试的抽象接口。用来创建 OAuth 客户端和服务端。官网 python-social-auth：一个设置简单的社会化验证方式。官网 rauth：OAuth 1.0/a, 2.0, 和 Ofly 的 Python 库。官网 sanction：一个超级简单的 OAuth2 客户端实现。官网 其他 jose：JavaScript 对象签名和加密草案的实现。官网 PyJWT：JSON Web 令牌草案 01。官网 python-jws：JSON Web 签名草案 02 的实现。官网 python-jwt：一个用来生成和验证 JSON Web 令牌的模块。官网 模板引擎 模板生成和词法解析的库和工具。 Jinja2：一个现代的，对设计师友好的模板引擎。官网 Chameleon：一个 HTML/XML 模板引擎。 模仿了 ZPT（Zope Page Templates）, 进行了速度上的优化。官网 Genshi：Python 模板工具，用以生成 web 感知的结果。官网 Mako：Python 平台的超高速轻量级模板。官网 队列 处理事件以及任务队列的库。 celery：一个异步任务队列/作业队列，基于分布式消息传递。官网 huey：小型多线程任务队列。官网 mrq：Mr. Queue -一个 Python 的分布式 worker 任务队列， 使用 Redis 和 gevent。官网 rq：简单的 Python 作业队列。官网 simpleq：一个简单的，可无限扩张的，基于亚马逊 SQS 的队列。官网 搜索 对数据进行索引和执行搜索查询的库和软件。 django-haystack：Django 模块化搜索。官网 elasticsearch-py：Elasticsearch 的官方底层 Python 客户端。官网 elasticsearch-dsl-py：Elasticsearch 的官方高级 Python 客户端。官网 solrpy：solr 的 Python 客户端。官网 Whoosh：一个快速的纯 Python 搜索引擎库。官网 动态消息 用来创建用户活动的库。 django-activity-stream：从你的站点行为中生成通用活动信息流。官网 Stream-Framework：使用 Cassandra 和 Redis 创建动态消息和通知系统。官网 资源管理 管理、压缩、缩小网站资源的工具。 django-compressor：将链接和内联的 JavaScript 或 CSS 压缩到一个单独的缓存文件中。官网 django-storages：一个针对 Django 的自定义存储后端的工具集合。官网 fanstatic：打包、优化，并且把静态文件依赖作为 Python 的包来提供。官网 File Conveyor：一个后台驻留的程序，用来发现和同步文件到 CDNs, S3 和 FTP。官网 Flask-Assets：帮你将 web 资源整合到你的 Flask app 中。官网 jinja-assets-compressor：一个 Jinja 扩展，用来编译和压缩你的资源。官网 webassets：为你的静态资源打包、优化和管理生成独一无二的缓存 URL。官网 缓存 缓存数据的库。 Beaker：一个缓存和会话库，可以用在 web 应用和独立 Python 脚本和应用上。官网 django-cache-machine：Django 模型的自动缓存和失效。官网 django-cacheops：具有自动颗粒化事件驱动失效功能的 ORM。官网 django-viewlet：渲染模板，同时具有额外的缓存控制功能。官网 dogpile.cache：dogpile.cache 是 Beaker 的下一代替代品，由同一作者开发。官网 HermesCache：Python 缓存库，具有基于标签的失效和 dogpile effect 保护功能。官网 johnny-cache：django 应用缓存框架。官网 pylibmc：libmemcached 接口的 Python 封装。官网 电子邮件 用来发送和解析电子邮件的库。 django-celery-ses：带有 AWS SES 和 Celery 的 Django email 后端。官网 envelopes：供人类使用的电子邮件库。官网 flanker：一个 email 地址和 Mime 解析库。官网 imbox：Python IMAP 库。官网 inbox.py：Python SMTP 服务器。官网 inbox：一个开源电子邮件工具箱。官网 lamson：Python 风格的 SMTP 应用服务器。官网 mailjet：Mailjet API 实现，用来提供批量发送邮件，统计等功能。官网 marrow.mailer：高性能可扩展邮件分发框架。官网 modoboa：一个邮件托管和管理平台，具有现代的、简约的 Web UI。官网 pyzmail：创建，发送和解析电子邮件。官网 Talon：Mailgun 库，用来抽取信息和签名。官网 yagmail：yagmail是一个GMAIL / SMTP客户端，旨在使其尽可能简单地发送电子邮件。官网 国际化 用来进行国际化的库。 Babel：一个 Python 的国际化库。官网 Korean：一个韩语词态库。官网 URL 处理 解析 URLs 的库 furl：一个让处理 URL 更简单小型 Python 库。官网 purl：一个简单的，不可变的 URL 类，具有简洁的 API 来进行询问和处理。官网 pyshorteners：一个纯 Python URL 缩短库。官网 shorturl：生成短小 URL 和类似 bit.ly 短链的 Python 实现。官网 webargs：一个解析 HTTP 请求参数的库，内置对流行 web 框架的支持，包括 Flask, Django, Bottle, Tornado 和 Pyramid。官网 HTML 处理 处理 HTML 和 XML 的库。 BeautifulSoup：以 Python 风格的方式来对 HTML 或 XML 进行迭代，搜索和修改。官网 bleach：一个基于白名单的 HTML 清理和文本链接库。官网 cssutils：一个 Python 的 CSS 库。官网 html5lib：一个兼容标准的 HTML 文档和片段解析及序列化库。官网 lxml：一个非常快速，简单易用，功能齐全的库，用来处理 HTML 和 XML。官网 MarkupSafe：为 Python 实现 XML/HTML/XHTML 标记安全字符串。官网 pyquery：一个解析 HTML 的库，类似 jQuery。官网 requests-html：人性化的，Pythonic 的 HTML 解析库。官网 untangle：将 XML 文档转换为 Python 对象，使其可以方便的访问。官网 xhtml2pdf：HTML/CSS 转 PDF 工具。官网 xmltodict：像处理 JSON 一样处理 XML。官网 爬取网络站点的库 Scrapy：一个快速高级的屏幕爬取及网页采集框架。官网 ScrapydWeb：一个用于 Scrapyd 集群管理的全功能 web UI，支持 Scrapy 日志分析和可视化，自动打包，定时器任务和邮件通知等特色功能。官网 cola：一个分布式爬虫框架。官网 Demiurge：基于 PyQuery 的爬虫微型框架。官网 feedparser：通用 feed 解析器。官网 Grab：站点爬取框架。官网 MechanicalSoup：用于自动和网络站点交互的 Python 库。官网 portia：Scrapy 可视化爬取。官网 pyspider：一个强大的爬虫系统。官网 RoboBrowser：一个简单的，Python 风格的库，用来浏览网站，而不需要一个独立安装的浏览器。官网 网页内容提取 用于进行网页内容提取的库。 Haul：一个可以扩展的图像爬取工具。官网 html2text：将 HTML 转换为 Markdown 格式文本。官网 lassie：人性化的网页内容检索库。官网 micawber：一个小型网页内容提取库，用来从 URLs 提取富内容。官网 newspaper：使用 Python 进行新闻提取，文章提取以及内容策展。官网 opengraph：一个用来解析开放内容协议(Open Graph Protocol)的 Python 模块。官网 python-goose：HTML 内容/文章提取器。官网 python-readability：arc90 公司 readability 工具的 Python 高速端口。官网 sanitize：为杂乱的数据世界带来调理性。官网 sumy：一个为文本文件和 HTML 页面进行自动摘要的模块。官网 textract：从任何格式的文档中提取文本，Word，PowerPoint，PDFs 等等。官网 表单 进行表单操作的库。 Deform：Python HTML 表单生成库，受到了 formish 表单生成库的启发。官网 django-bootstrap3：集成了 Bootstrap 3 的 Django。官网 django-crispy-forms：一个 Django 应用，他可以让你以一种非常优雅且 DRY（Don't repeat yourself） 的方式来创建美观的表单。官网 django-remote-forms：一个平台独立的 Django 表单序列化工具。官网 WTForms：一个灵活的表单验证和呈现库。官网 WTForms-JSON：一个 WTForms 扩展，用来处理 JSON 数据。官网 数据验证 数据验证库。多用于表单验证。 Cerberus：一个映射验证器（mappings-validator）。支持多种规则，提供归一化功能，可以方便地定制为 Python 风格的 schema 定义。官网 colander：一个用于对从 XML, JSON，HTML 表单获取的数据或其他同样简单的序列化数据进行验证和反序列化的系统。官网 kmatch：一种用于匹配/验证/筛选 Python 字典的语言。官网 schema：一个用于对 Python 数据结构进行验证的库。官网 Schematics：数据结构验证。官网 valideer：轻量级可扩展的数据验证和适配库。官网 voluptuous：一个 Python 数据验证库。主要是为了验证传入 Python 的 JSON，YAML 等数据。官网 jsonschema：JSON Schema的 python 实现，用于 JSON 数据的验证。官网 反垃圾技术 帮助你和电子垃圾进行战斗的库。 django-simple-captcha：一个简单、高度可定制的 Django 应用，可以为任何 Django 表单添加验证码。官网 django-simple-spam-blocker：一个用于 Django 的简单的电子垃圾屏蔽工具。官网 标记 用来进行标记的库。 django-taggit：简单的 Django 标记工具。官网 管理面板 管理界面库。 Ajenti：一个你的服务器值得拥有的管理面板。官网 django-suit：Django 管理界面的一个替代品 (仅对于非商业用途是免费的)。官网 django-xadmin：Django admin 的一个替代品，具有很多不错的功能。官网 flask-admin：一个用于 Flask 的简单可扩展的管理界面框架。官网 flower：一个对 Celery 集群进行实时监控和提供 web 管理界面的工具。官网 Grappelli：Django 管理界面的一个漂亮的皮肤。官网 Wooey：一个 Django 应用，可以为 Python 脚本创建 web 用户界面。官网 静态站点生成器 静态站点生成器是一个软件，它把文本和模板作为输入，然后输出 HTML 文件。 Pelican：使用 Markdown 或 ReST 来处理内容， Jinja 2 来制作主题。支持 DVCS, Disqus.。AGPL 许可。官网 Cactus：为设计师设计的静态站点生成器。官网 Hyde：基于 Jinja2 的静态站点生成器。官网 Nikola：一个静态网站和博客生成器。官网 Tinkerer：Tinkerer 是一个博客引擎/静态站点生成器，由 Sphinx 驱动。官网 Lektor：一个简单易用的静态 CMS 和博客引擎。官网 进程 操作系统进程启动及通信库。 envoy：比 Python subprocess 模块更人性化。官网 sarge：另一 种 subprocess 模块的封装。官网 sh：一个完备的 subprocess 替代库。官网 并发和并行 用以进行并发和并行操作的库。 multiprocessing：(Python 标准库) 基于进程的“线程”接口。官网 threading：(Python 标准库)更高层的线程接口。官网 eventlet：支持 WSGI 的异步框架。官网 gevent：一个基于协程的 Python 网络库，使用 greenlet。官网 Tomorrow：用于产生异步代码的神奇的装饰器语法实现。官网 uvloop：在 libuv 之上超快速实现 asyncio 事件循环。官网 网络 用于网络编程的库。 asyncio：(Python 标准库) 异步 I/O, 事件循环, 协程以及任务。官网 Twisted：一个事件驱动的网络引擎。官网 pulsar：事件驱动的并发框架。官网 diesel：基于 Greenlet 的事件 I/O 框架。官网 pyzmq：一个 ZeroMQ 消息库的 Python 封装。官网 Toapi：一个轻巧，简单，快速的 Flask 库，致力于为所有网站提供 API 服务。官网 txZMQ：基于 Twisted 的 ZeroMQ 消息库的 Python 封装。官网 WebSocket 帮助使用 WebSocket 的库。 AutobahnPython：给 Python 、使用的 WebSocket & WAMP 基于 Twisted 和 asyncio。官网 Crossbar：开源统一应用路由(Websocket & WAMP for Python on Autobahn)。官网 django-socketio：给 Django 用的 WebSockets。官网 WebSocket-for-Python：为 Python2/3 以及 PyPy 编写的 WebSocket 客户端和服务器库。官网 WSGI 服务器 兼容 WSGI 的 web 服务器 gunicorn：Pre-forked, 部分是由 C 语言编写的。官网 uwsgi：uwsgi 项目的目的是开发一组全栈工具，用来建立托管服务， 由 C 语言编写。官网 bjoern：异步，非常快速，由 C 语言编写。官网 fapws3：异步 (仅对于网络端)，由 C 语言编写。官网 meinheld：异步，部分是由 C 语言编写的。官网 netius：异步，非常快速。官网 paste：多线程，稳定，久经考验。官网 rocket：多线程。官网 waitress：多线程, 是它驱动着 Pyramid 框架。官网 Werkzeug：一个 WSGI 工具库，驱动着 Flask ，而且可以很方便大嵌入到你的项目中去。官网 RPC 服务器 兼容 RPC 的服务器。 SimpleJSONRPCServer：这个库是 JSON-RPC 规范的一个实现。官网 SimpleXMLRPCServer：(Python 标准库) 简单的 XML-RPC 服务器实现，单线程。官网 zeroRPC：zerorpc 是一个灵活的 RPC 实现，基于 ZeroMQ 和 MessagePack。官网 密码学 cryptography：这个软件包意在提供密码学基本内容和方法提供给 Python 开发者。官网 hashids：在 Python 中实现 hashids 。官网 Paramiko：SSHv2 协议的 Python (2.6+, 3.3+) ，提供客户端和服务端的功能。官网 Passlib：安全密码存储／哈希库，官网 PyCrypto：Python 密码学工具箱。官网 PyNacl：网络和密码学(NaCl) 库的 Python 绑定。官网 图形用户界面 用来创建图形用户界面程序的库。 curses：内建的 ncurses 封装，用来创建终端图形用户界面。官网 enaml：使用类似 QML 的 Declaratic 语法来创建美观的用户界面。官网 kivy：一个用来创建自然用户交互（NUI）应用程序的库，可以运行在 Windows, Linux, Mac OS X, Android 以及 iOS 平台上。官网 pyglet：一个 Python 的跨平台窗口及多媒体库。官网 PyQt：跨平台用户界面框架 Qt 的 Python 绑定 ，支持 Qt v4 和 Qt v5。官网 PySide：跨平台用户界面框架 Qt 的 Python 绑定 ，支持 Qt v4。官网 Tkinter：Tkinter 是 Python GUI 的一个事实标准库。官网 Toga：一个 Python 原生的, 操作系统原生的 GUI 工具包。官网 urwid：一个用来创建终端 GUI 应用的库，支持组件，事件和丰富的色彩等。官网 wxPython：wxPython 是 wxWidgets C++ 类库和 Python 语言混合的产物。官网 PyGObject：GLib/GObject/GIO/GTK+ (GTK+3) 的 Python 绑定。官网 Flexx：Flexx 是一个纯 Python 语言编写的用来创建 GUI 程序的工具集，它使用 web 技术进行界面的展示。官网 游戏开发 超赞的游戏开发库。 Cocos2d：cocos2d 是一个用来开发 2D 游戏， 示例和其他图形/交互应用的框架。基于 pyglet。官网 Panda3D：由迪士尼开发的 3D 游戏引擎，并由卡内基梅陇娱乐技术中心负责维护。使用 C++ 编写, 针对 Python 进行了完全的封装。官网 Pygame：Pygame 是一组 Python 模块，用来编写游戏。官网 PyOgre：Ogre 3D 渲染引擎的 Python 绑定，可以用来开发游戏和仿真程序等任何 3D 应用。官网 PyOpenGL：OpenGL 的 Python 绑定及其相关 APIs。官网 PySDL2：SDL2 库的封装，基于 ctypes。官网 RenPy：一个视觉小说（visual novel）引擎。官网 日志 用来生成和操作日志的库。 logging：(Python 标准库) 为 Python 提供日志功能。官网 logbook：Logging 库的替代品。官网 Eliot：为复杂的和分布式系统创建日志。官网 Raven：Sentry 的 Python 客户端。官网 Sentry：实时记录和收集日志的服务器。官网 测试 进行代码库测试和生成测试数据的库。 测试框架 unittest：(Python 标准库) 单元测试框架。官网 nose：nose 扩展了 unittest 的功能。官网 contexts：一个 Python 3.3+ 的 BDD 框架。受到 C# – Machine.Specifications 的启发。官网 hypothesis：Hypothesis 是一个基于先进的 Quickcheck 风格特性的测试库。官网 mamba：Python 的终极测试工具， 拥护 BDD。官网 PyAutoGUI：PyAutoGUI 是一个人性化的跨平台 GUI 自动测试模块。官网 pyshould：Should 风格的断言，基于 PyHamcrest。官网 pytest：一个成熟的全功能 Python 测试工具。官网 green：干净，多彩的测试工具。官网 pyvows：BDD 风格的测试工具，受 Vows.js 的启发。官网 Robot Framework：一个通用的自动化测试框架。官网 Web 测试 Selenium：Selenium WebDriver 的 Python 绑定。官网 locust：使用 Python 编写的，可扩展的用户加载测试工具。官网 sixpack：一个和语言无关的 A/B 测试框架。官网 splinter：开源的 web 应用测试工具。官网 Mock 测试 mock：(Python 标准库) 一个用于伪造测试的库。官网 doublex：Python 的一个功能强大的 doubles 测试框架。官网 freezegun：通过伪造日期模块来生成不同的时间。官网 httmock：针对 Python 2.6+ 和 3.2+ 生成 伪造请求的库。官网 httpretty：Python 的 HTTP 请求 mock 工具。官网 responses：伪造 Python 中的 requests 库的一个通用库。官网 VCR.py：在你的测试中记录和重放 HTTP 交互。官网 对象工厂 factoryboy：一个 Python 用的测试固件 (test fixtures) 替代库。官网 mixer：另外一个测试固件 (test fixtures) 替代库，支持 Django, Flask, SQLAlchemy, Peewee 等。官网 modelmommy：为 Django 测试创建随机固件。官网 代码覆盖率 coverage：代码覆盖率测量。官网 Codecov：一个代码覆盖率测试工具，为开源项目提供免费代码覆盖率测试服务。官网 伪数据 faker：一个 Python 库，用来生成伪数据。官网 fake2db：伪数据库生成器。官网 radar：生成随机的日期/时间。官网 错误处理 FuckIt.py：FuckIt.py 使用最先进的技术来保证你的 Python 代码无论对错都能继续运行。官网 代码分析和 Lint 工具 进行代码分析，解析和操作代码库的库和工具。 代码分析 coala：语言独立和易于扩展的代码分析应用程序。官网 code2flow：把你的 Python 和 JavaScript 代码转换为流程图。官网 pycallgraph：这个库可以把你的 Python 应用的流程(调用图)进行可视化。官网 pysonar2：Python 类型推断和检索工具。官网 Lint 工具 Flake8：模块化源码检查工具: pep8, pyflakes 以及 co。官网 Pylint：一个完全可定制的源码分析器。官网 YAPF: Google 的 Python 代码格式化工具。官网 pylama：Python 和 JavaScript 的代码审查工具。官网 代码格式化 autopep8：自动格式化 Python 代码，以使其符合 PEP8 规范。官网 black：一个坚定的 Python 代码格式化工具。官网 调试工具 用来进行代码调试的库。 调试器 ipdb：IPython 启用的 pdb。官网 pudb：全屏，基于控制台的 Python 调试器。官网 pyringe：可以在 Python 进程中附加和注入代码的调试器。官网 wdb：一个奇异的 web 调试器，通过 WebSockets 工作。官网 winpdb：一个具有图形用户界面的 Python 调试器，可以进行远程调试，基于 rpdb2。官网 django-debug-toolbar：为 Django 显示各种调试信息。官网 django-devserver：一个 Django 运行服务器的替代品。官网 flask-debugtoolbar：django-debug-toolbar 的 flask 版。官网 性能分析器 lineprofiler：逐行性能分析。官网 Memory Profiler：监控 Python 代码的内存使用。官网、内存 profiling：一个交互式 Python 性能分析工具。官网 其他 pyelftools：解析和分析 ELF 文件以及 DWARF 调试信息。官网 python-statsd：statsd 服务器的 Python 客户端。官网 科学计算和数据分析 用来进行科学计算和数据分析的库。 astropy：一个天文学 Python 库。官网 bcbio-nextgen：这个工具箱为全自动高通量测序分析提供符合最佳实践的处理流程。官网 bccb：生物分析相关代码集合。官网 Biopython：Biopython 是一组可以免费使用的用来进行生物计算的工具。官网 blaze：NumPy 和 Pandas 的大数据接口。官网 cclib：一个用来解析和解释计算化学软件包输出结果的库。官网 NetworkX：一个为复杂网络设计的高性能软件。官网 Neupy：执行和测试各种不同的人工神经网络算法。官网 Numba：Python JIT (just in time) 编译器，针对科学用的 Python ，由 Cython 和 NumPy 的开发者开发。官网 NumPy：使用 Python 进行科学计算的基础包。官网 Open Babel：一个化学工具箱，用来描述多种化学数据。官网 Open Mining：使用 Python 挖掘商业情报 (BI) (Pandas web 接口)。官网 orange：通过可视化编程或 Python 脚本进行数据挖掘，数据可视化，分析和机器学习。官网 Pandas：提供高性能，易用的数据结构和数据分析工具。官网 PyDy：PyDy 是 Python Dynamics 的缩写，用来为动力学运动建模工作流程提供帮助， 基于 NumPy, SciPy, IPython 和 matplotlib。官网 PyMC：马尔科夫链蒙特卡洛采样工具。官网 RDKit：化学信息学和机器学习软件。官网 SciPy：由一些基于 Python ，用于数学，科学和工程的开源软件构成的生态系统。官网 statsmodels：统计建模和计量经济学。官网 SymPy：一个用于符号数学的 Python 库。官网 zipline：一个 Python 算法交易库。官网 Bayesian-belief-networks：优雅的贝叶斯信念网络框架。官网 数据可视化 进行数据可视化的库。 参见: awesome-javascript。 matplotlib：一个 Python 2D 绘图库。官网 bokeh：用 Python 进行交互式 web 绘图。官网 ggplot：ggplot2 给 R 提供的 API 的 Python 版本。官网 plotly：协同 Python 和 matplotlib 工作的 web 绘图库。官网 pyecharts：基于百度 Echarts 的数据可视化库。官网 pygal：一个 Python SVG 图表创建工具。官网 pygraphviz：Graphviz 的 Python 接口。官网 PyQtGraph：交互式实时 2D/3D/ 图像绘制及科学/工程学组件。官网 SnakeViz：一个基于浏览器的 Python's cProfile 模块输出结果查看工具。官网 vincent：把 Python 转换为 Vega 语法的转换工具。官网 VisPy：基于 OpenGL 的高性能科学可视化工具。官网 计算机视觉 计算机视觉库。 OpenCV：开源计算机视觉库。官网 pyocr：Tesseract 和 Cuneiform 的包装库。官网 pytesseract：Google Tesseract OCR 的另一包装库。官网 SimpleCV：一个用来创建计算机视觉应用的开源框架。官网 机器学习 机器学习库。 参见: awesome-machine-learning. Caffe: 一个 Caffe 的 python 接口。官网 Caffe2：一个轻量级的，模块化的，可扩展的深度学习框架。官网 Crab：灵活、快速的推荐引擎。官网 gensim：人性化的话题建模库。官网 hebel：GPU 加速的深度学习库。官网 keras: 以 tensorflow/theano/CNTK 为后端的深度学习封装库，快速上手神经网络。官网 MXNet：一个高效和灵活的深度学习框架。官网 NuPIC：智能计算 Numenta 平台。官网 pattern：Python 网络挖掘模块。官网 PyBrain：另一个 Python 机器学习库。官网 pydeep：Python 深度学习库。官网 Pylearn2：一个基于 Theano 的机器学习库。官网 python-recsys：一个用来实现推荐系统的 Python 库。官网 Pytorch：一个具有张量和动态神经网络，并有强大 GPU 加速能力的深度学习框架。官网 scikit-learn：基于 SciPy 构建的机器学习 Python 模块。官网 skflow：一个 TensorFlow 的简化接口(模仿 scikit-learn)。官网 TensorFlow：谷歌开源的最受欢迎的深度学习框架。官网 Theano：一个快速数值计算库。官网 vowpalporpoise：轻量级 Vowpal Wabbit 的 Python 封装。官网 MapReduce MapReduce 框架和库。 dpark：Spark 的 Python 克隆版，一个类似 MapReduce 的框架。官网 dumbo：这个 Python 模块可以让人轻松的编写和运行 Hadoop 程序。官网 luigi：这个模块帮你构建批处理作业的复杂流水线。官网 mrjob：在 Hadoop 或 Amazon Web Services 上运行 MapReduce 任务。官网 PySpark：Spark 的 Python API 。官网 streamparse：运行针对事实数据流的 Python 代码。集成了 Apache Storm。官网 函数式编程 使用 Python 进行函数式编程。 CyToolz：Toolz 的 Cython 实现 : 高性能函数式工具。官网 fn.py：在 Python 中进行函数式编程 : 实现了一些享受函数式编程缺失的功能。官网 funcy：炫酷又实用的函数式工具。官网 Toolz：一组用于迭代器，函数和字典的函数式编程工具。官网 第三方 API 用来访问第三方 API 的库。 参见： List of Python API Wrappers and Libraries。 apache-libcloud：一个为各种云设计的 Python 库。官网 boto：Amazon Web Services 的 Python 接口。官网 django-wordpress：WordPress models and views for Django.官网 facebook-sdk：Facebook 平台的 Python SDK.官网 facepy：Facepy 让和 Facebook's Graph API 的交互变得更容易。官网 gmail：Gmail 的 Python 接口。官网 google-api-python-client：Python 用的 Google APIs 客户端库。官网 gspread：Google 电子表格的 Python API.官网 twython：Twitter API 的封装。官网 DevOps 工具 用于 DevOps 的软件和库。 Ansible：一个非常简单的 IT 自动化平台。官网 SaltStack：基础设施自动化和管理系统。官网 OpenStack：用于构建私有和公有云的开源软件。官网 Docker Compose：快速，分离的开发环境，使用 Docker。官网 Fabric：一个简单的，Python 风格的工具，用来进行远程执行和部署。官网 cuisine：为 Fabric 提供一系列高级函数。官网 Fabtools：一个用来编写超赞的 Fabric 文件的工具。官网 gitapi：Git 的纯 Python API。官网 hgapi：Mercurial 的纯 Python API。官网 honcho：Foreman 的 Python 克隆版，用来管理基于 Procfile 的应用。官网 pexpect：Controlling interactive programs in a pseudo-terminal like 在一个伪终端中控制交互程序，就像 GNU expect 一样。官网 psutil：一个跨平台进程和系统工具模块。官网 supervisor：UNIX 的进程控制系统。官网 任务调度 任务调度库。 APScheduler：轻巧但强大的进程内任务调度，使你可以调度函数。官网 django-schedule：一个 Django 排程应用。官网 doit：一个任务执行和构建工具。官网 gunnery：分布式系统使用的多用途任务执行工具 ，具有 web 交互界面。官网 Joblib：一组为 Python 提供轻量级作业流水线的工具。官网 Plan：如有神助地编写 crontab 文件。官网 schedule：人性化的 Python 任务调度库。官网 Spiff：使用纯 Python 实现的强大的工作流引擎。官网 TaskFlow：一个可以让你方便执行任务的 Python 库，一致并且可靠。官网 AirFlow：Airflow 是Airbnb公司开源的，是一个工作流分配管理系统，通过有向非循环图的方式管理任务流程，设置任务依赖关系和时间调度。官方 外来函数接口 使用外来函数接口的库。 cffi：用来调用 C 代码的外来函数接口。官网 ctypes：(Python 标准库) 用来调用 C 代码的外来函数接口。官网 PyCUDA：Nvidia CUDA API 的封装。官网 SWIG：简化的封装和接口生成器。官网 高性能 让 Python 更快的库。 Cython：优化的 Python 静态编译器。使用类型混合使 Python 编译成 C 或 C++ 模块来获得性能的极大提升。官网 PeachPy：嵌入 Python 的 x86-64 汇编器。可以被用作 Python 内联的汇编器或者是独立的汇编器，用于 Windows, Linux, OS X, Native Client 或者 Go 。官网 PyPy：使用 Python 实现的 Python。解释器使用黑魔法加快 Python 运行速度且不需要加入额外的类型信息。官网 Pyston：使用 LLVM 和现代 JIT 技术构建的 Python 实现，目标是为了获得很好的性能。官网 Stackless Python：一个强化版的 Python。官网 微软的 Windows 平台 在 Windows 平台上进行 Python 编程。 Python(x,y)：面向科学应用的 Python 发行版，基于 Qt 和 Spyder。官网 pythonlibs：非官方的 Windows 平台 Python 扩展二进制包。官网 PythonNet：Python 与 .NET 公共语言运行库 (CLR)的集成。官网 PyWin32：针对 Windows 的 Python 扩展。官网 WinPython：Windows 7/8 系统下便携式开发环境。官网 网络可视化和 SDN 用来进行网络可视化和 SDN(软件定义网络)的工具和库。 Mininet：一款流行的网络模拟器以及用 Python 编写的 API。官网 POX：一个针对基于 Python 的软件定义网络应用（例如 OpenFlow SDN 控制器）的开源开发平台。官网 Pyretic：火热的 SDN 编程语言中的一员，为网络交换机和模拟器提供强大的抽象能力。官网 SDX Platform：基于 SDN 的 IXP 实现，影响了 Mininet, POX 和 Pyretic。官网 NRU：一个基于组件的软件定义网络框架。官网 硬件 用来对硬件进行编程的库。 ino：操作 Arduino 的命令行工具。官网 Pyro：Python 机器人编程库。官网 PyUserInput：跨平台的，控制鼠标和键盘的模块。官网 scapy：一个非常棒的操作数据包的库。官网 wifi：一个 Python 库和命令行工具用来在 Linux 平台上操作 WiFi。官网 Pingo：Pingo 为类似 Raspberry Pi，pcDuino， Intel Galileo 等设备提供统一的 API 用以编程。官网 兼容性 帮助从 Python 2 向 Python 3 迁移的库。 Python-Future：这就是 Python 2 和 Python 3 之间丢失的那个兼容性层。官网 Python-Modernize：使 Python 代码更加现代化以便最终迁移到 Python 3。官网 Six：Python 2 和 3 的兼容性工具。官网 杂项 不属于上面任何一个类别，但是非常有用的库。 blinker：一个快速的 Python 进程内信号/事件分发系统。官网 itsdangerous：一系列辅助工具用来将可信的数据传入不可信的环境。官网 pluginbase：一个简单但是非常灵活的 Python 插件系统。官网 Pychievements：一个用来创建和追踪成就的 Python 框架。官网 Tryton：一个通用商务框架。官网 算法和设计模式 Python 实现的算法和设计模式。 algorithms：一个 Python 算法模块。官网 python-patterns：Python 设计模式的集合。官网 sortedcontainers：快速，纯 Python 实现的 SortedList，SortedDict 和 SortedSet 类型。官网 Python：使用Python实现的算法大全。官网 编辑器插件 编辑器和 IDE 的插件 Emacs Elpy：Emacs Python 开发环境。官网 Sublime Text SublimeJEDI：一个 Sublime Text 插件，用来使用超赞的自动补全库 Jedi。官网 Anaconda：Anaconda 把你的 Sublime Text 3 变成一个功能齐全的 Python IDE。官网 Vim YouCompleteMe：引入基于 Jedi 的 Python 自动补全引擎。官网 Jedi-vim：绑定 Vim 和 Jedi 自动补全库对 Python 进行自动补全。官网 Python-mode：将 Vim 变成 Python IDE 的一款多合一插件。官网 Visual Studio PTVS：Visual Studio 的 Python 工具。官网 集成开发环境 流行的 Python 集成开发环境。 PyCharm：商业化的 Python IDE ，由 JetBrains 开发。也有免费的社区版提供。官网 LiClipse：基于 Eclipse 的免费多语言 IDE 。使用 PyDev 来支持 Python 。官网 Spyder：开源 Python IDE。官网 自动聊天工具 用于开发聊天机器人的库 Errbot：最简单和最流行的聊天机器人用来实现自动聊天工具。官网 服务 在线工具和简化开发的 API 。 金融数据 Tushare ：一个可以提供免费股票、基金、期货、港股等金融数据的 Python 开源数据。官网 Ta-Lib ：金融数据技术分析库，可以依据原始金融数据计算各种技术指标,计算性能比较优异。官网 持续集成 参见: awesome-CIandCD. Travis CI：一个流行的工具，为你的开源和 私人 项目提供持续集成服务。(仅支持 GitHub)官网 CircleCI：一个持续集成工具，可以非常快速的进行并行测试。 (仅支持 GitHub)官网 Vexor CI：一个为私人 app 提供持续集成的工具，支持按分钟付费。官网 Wercker：基于 Docker 平台，用来构建和部署微服务。官网 代码质量 Codacy：自动化代码审查，更加快速的发布高质量代码。对于开源项目是免费的。官网 QuantifiedCode：一个数据驱动、自动、持续的代码审查工具。官网 资源 在这里可以找到新的 Python 库。 网站 r/Python CoolGithubProjects Django Packages Full Stack Python Python 3 Wall of Superpowers Python Hackers Python ZEEF Trending Python repositories on GitHub today PyPI Ranking 周刊 Import Python Newsletter Pycoder's Weekly Python Weekly Twitter @codetengu @getpy @planetpython @pycoders @pypi @pythontrending @PythonWeekly 学习指南 Scipy-lecture-notes：如何用 Python 来做学术？官网 SScientific-python-lectures：Python 科学计算的资料。官网 Mario-Level-1：用 Python 和 Pygame 写的超级马里奥第一关。官网 Python Koans：Python 的交互式学习工具。官网 Minecraft：用 python 写的 Minecraft 游戏。官网 pycrumbs：Python 资源大全。官网 python-patterns：使用 python 实现设计模式。官网 Projects：Python 项目大集合。官网 The Hitchhiker’s Guide to Python：旅行者的 Python 学习指南。官网 Code Like a Pythonista: Idiomatic Python：如何像 Python 高手(Pythonista)一样编程。官网 知名网站 值得关注的 Python 技术站点。 中文站点 伯乐在线 Python 频道：分享 Python 开发技术、相关的行业动态。官网 英文站点 《值得关注的 10 个 Python 英文博客》 微博、微信公众号 Python开发者 微博：@Python开发者 Python开发者：人生苦短，我用 Python。Python 越来越受广大程序员的喜爱。「Python开发者」是最受欢迎的、专注分享 Python 技术的微信公众号，主要分享 Python 相关的技术文章、工具资源和资讯等。 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Python/Python多环境管理工具.html":{"url":"Python/Python多环境管理工具.html","title":"Python多环境管理工具","keywords":"","body":"Python 多环境管理工具 Pyenv https://github.com/pyenv/pyenv 通过对 Python 版本进行管理，实现不同版本间的切换和使用 原理：通过改变环境变量实现 Python 多版本的切换 Virtualenv 通过创建虚拟隔离环境，实现系统 Python 环境和虚拟环境的 Python 隔离 原理：基于 Python 开发。在需要的地方使用 virtualenv 创建虚拟工作目录，使用时激活 - source 虚拟工作目录/bin/activate，然后安装的 Python 环境（标准库、第三方库等）都是只属于该目录，开发完成直接退出 - deactivate 即可回到系统环境 # 安装 pip install virtualenv Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Python/Django.html":{"url":"Python/Django.html","title":"Python Django 学习笔记","keywords":"","body":"Python Django 学习笔记 django-admin startproject teste - 修改时区 - python3 manage.py startapp blog - 注册 INSTALLED_APPS - 修改 blog 的 models.py - 注册模型 - python3 manage.py migrate - python3 manage.py migration - python3 manage.py runserver 命令行新建并初始化 Django 项目 $ django-admin startproject projectName 创建 Django 项目 新建的 projectName/ 目录就是根目录 manage.py：一个命令行工具，用于与 Django 进行不同方式的交互脚本，非常重要 外层的 projectName/ 目录与 Django 无关，只是你项目的容器，可以任意命名 内层的 projectName/ 目录是真正的项目文件包裹目录，它的名字是你引用内部文件的包名 projectName/__init__.py:一个定义包的空文件 projectName/settings.py:项目的主配置文件，非常重要 projectName/urls.py:路由文件，所有的任务都是从这里开始分配，相当于 Django 驱动站点的内容表格，非常重要 projectName/wsgi.py:一个基于 WSGI 的 web 服务器进入点，提供底层的网络通信功能，通常不用关心 模型转为数据库中的表 # 模型生产数据表 $ python manage.py makemigrations # 迁移数据表到数据库 $ python manage.py migrate 生成 Admin 用户 $ python manage.py createsuperuser 启动服务器 # 在 manage.py 文件层 pyhton3 manage.py runserver //默认运行在 localhost 的 8000 端口 # 修改运行的端口为 8080 python3 manage.py runserver 8080 # 修改服务器 ip 地址 python3 manage.py runserver 0.0.0.0:8000 //这时 Django 运行在8000端口，整个局域网内都将可以访问站点，而不只是是本机 注意： Django 的开发服务器具有自动重载功能，当你的代码有修改，每隔一段时间服务器将自动更新。但是，有一些例如增加文件的动作，不会触发服务器重载，这时就需要你自己手动重启 Web app 和 project 一个 project 可以包含 多个 web app；一个 web app 可以属于多个 project 一个 web app 常常实现某个功能，一个 project 往往是配置文件和多个 web app 的集合 app 的存放位置可以是任何地点，但是通常都将它们放在与 manage.py 脚本同级的目录下，这样方便导入文件 Django 项目中的内层 projectName/ 目录就是一个 web app，也可以在一个 Django project 里创建多个 app，使用命令：# 在 manage.py 层执行如下命令 python3 manage.py startapp appName 在 project 里新创建一个 app Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Python/IPython使用技巧.html":{"url":"Python/IPython使用技巧.html","title":"IPython 使用技巧","keywords":"","body":"IPython 使用技巧 Tab 键自动补全 %magic - 显示所有魔术命令的详细文档 %time 和 %timeit(多次执行输出平均值) - 测试代码执行时间 Ctrl + r - 搜索历史命令 ? - 打印变量详细信息 ?? - 打印函数源码及函数信息 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Python/Numpy.html":{"url":"Python/Numpy.html","title":"Python Numpy 学习","keywords":"","body":"Python Numpy 学习 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Python/Python小知识.html":{"url":"Python/Python小知识.html","title":"Python 学习遇到的问题解决或扩展小知识","keywords":"","body":"Python 小知识 目录 快速启动一个下载服务器 字符串转换为 JSON 格式 检查第三方库是否安装 # -*- coding: UTF-8 -*-和#coding=utf-8中文编码问题 列表特性 - 就地修改和有无返回值 快速启动一个下载服务器 [Top] # 当前目录下有 index.html，则渲染出该文件页面；若没有，则显示当前目录下的文件列表 $ python -m http.server 字符串转换为 JSON 格式 [Top] $ echo '{\"name\": \"xiaoming\", \"job\": \"doctor\", \"sex\": \"male\"}' | python -m json.tool { \"name\": \"xiaoming\", \"job\": \"doctor\", \"sex\": \"male\" } 检查第三方库是否安装 - [Top] $ python -c \"import django\" # -*- coding: UTF-8 -*-和#coding=utf-8中文编码问题 [Top] Python 中默认的编码格式是 ASCII 格式，在没修改编码格式时无法正确打印汉字，所以在读取中文时会报错 解决方法为只要在文件开头加入 # -*- coding: UTF-8 -*- 或者 #coding=utf-8 就行了 注意：#coding=utf-8 的 = 号两边不要空格。 列表特性 - 就地修改和有无返回值 【Top】 list(lst) del lst[x] lst.append(o) lst.clear() lst1.extend(lst2) lst.insert(x,o) lst.pop() lst.remove(o) lst.reverse() lst.sort() sorted(lst) 就地修改 返回值 lst：列表 x：元素索引 0：对象 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Python/Python模块管理总结.html":{"url":"Python/Python模块管理总结.html","title":"Python 模块管理总结","keywords":"","body":"Python 模块管理总结 一般安装尝试步骤：pip -> easy_install - > setuptools 一、pip pip 安装 模块安装 命令详解 扩展：配置 pip 国内镜像源 二、easy_install easy_install 安装 三、setuptools setuptools 安装 模块安装 模块卸载 常用命令 四、参考 pip pip 提供安装、卸载和显示已安装列表等，而 easy_install 只提供安装 pip 可通过 requirements.txt 集中管理依赖 pip 可以安装二进制格式( .whl ) pip 是先下载后安装，如果中途安装失败，也会清理干净，不会留下一个中间状态 pip 能自动安装依赖 如果用户没有将软件打包上传到 pypi.python.org ，则无法使用 pip 进行安装，只能尝试使用源码安装 pip 安装 下载地址：https://pypi.python.org/pypi/pip/ CentOS # CentOS 6- $ yum install -y epel-release #安装epel扩展 $ yum install -y python-setuptools $ easy_install pip # CentOS 7+ $ yum -y install epel-release $ yum install python-pip $ pip install --upgrade pip Ubuntu $ sudo apt install python3-pip 模块安装 在线终端安装模块 # 搜索 PyPI 是否存在 numpy $ pip search numpy # 搜索 numpy 的版本 $ pip install numpy== # 安装 $ pip install numpy==1.17.3 离线安装模块 whl 包 1、安装 pip 2、下载模块 wheel 包(whl 包) - https://pypi.org 3、安装 $ pip install [路径]/xxx.whl 命令详解 命令格式：pip command [options] command 子命令 说明 install、download、uninstall 安装、下载、卸载安装包 freeze 以 requirements.txt 格式输出已安装包，在其他服务器上执行 pip install -r requirements.txt 直接安装 python 包 list 列出当前系统已安装的包 show 查看已安装的包的信息，包括版本、依赖、许可证、作者、主页等信息 check 检查包的依赖是否完整 search 查找安装包 wheel 打包安装包到 wheel 格式 hash 计算安装包的 hash 值 completion 生成命令不全配置 debug 显示 debug 信息 help 查看 pip 及其子命令的帮助文档 常用命令 pip -h - 查看 pip 帮助信息 pip -h - 查看 pip command 帮助文档 pip search flask - 查找模块 pip install flask==0.8 - 安装特定版本的模块 pip install [模块名] -d [路径] - 下载模块源码到指定目录但不安装 pip install -d 路径 -r requirements.txt - 下载 requirements.txt 中模块但不安装，保存到指定路径 pip install -r requirements.txt - 安装 requirements.txt 中模块 pip install -U flask - 升级 flask pip install -U pip - 升级 pip pip uninstall flask - 删除已安装的模块 pip uninstall -r requirements.txt - 删除 requirements.txt 中的模块 pip freeze > [路径]/requirements.txt - 将系统已安装的模块列表写入 requirements.txt 文件 pip list - 查看已安装的模块列表 pip list -o - 查看可升级的模块列表 pip check flask - 检查模块（flask）的依赖是否完整 pip show -f flask - 显示模块 flask 所在目录 pip completion --bash >> ~/.profile; source ~/.profile - 开启 pip 命令 tab 键自动补全 ~/.pip/pip.conf - 指定 pip 全局镜像源 扩展：配置 pip 国内镜像源 豆瓣：https://pypi.douban.com/simple/ 阿里云：https://mirrors.aliyun.com/pypi/simple/ 中国科技大学：https://pypi.mirrors.ustc.edu.cn/simple/ 清华大学：https://pypi.tuna.tsinghua.edu.cn/simple/ # 临时使用 $ pip install -i https://pypi.douban.com/simple/ flask # 永久修改 # 创建 ~/.pip/pip.conf 并写入 $ cat ~/.pip/pip.conf [global] index-url = https://pypi.douban.com/simple/ # 命令行 $ pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple easy_install easy_install 和 pip 都是用来下载安装 Python 一个公共资源库 PyPI 的相关资源包的，pip 是 easy_install 的改进版，提供更好的提示信 息，删除 package 等功能。老版本的 python 中只有 easy_install， 没有 pip easy_install 安装 安装了 setuptools，easy_install 也就安装了 命令 setuptools setuptools 安装 下载地址：https://pypi.python.org/pypi/setuptools/ CentOS # setuptools-24.0.3.tar.gz的下载地址：https://pypi.python.org/packages/84/24/610d8bb87219ed6d0928018b7b35ac6f6f6ef27a71ed6a2d0cfb68200f65/setuptools-24.0.3.tar.gz $ tar zxvf setuptools-24.0.3.tar.gz $ cd setuptools-24.0.3 $ python setup.py build $ python setup.py install Ubuntu 命令sudo apt-get install python-setuptools 模块安装 在 PyPI 或 Github 上下载以 .tar.gz 或 .zip 格式的 Python 模块源码包 解压源码包并进入解压包目录(目录包含 setup.py 文件) python setup.py build - 构建安装包到 ./build 目录下 python setup.py install 安装 模块卸载 源码安装的 Python 模块，只需手动删除所有安装的模块即可，但问题往往是找不到安装了哪些模块 可以在安装时使用 python3 setup.py install --record log ，这样 log 文件里就记录了安装的文件路径，需要卸载时，只需执行 cat log ｜ xagrs rm -rf 常用命令 在包目录下执行 python setup.py -h - 查看帮助 python setup.py install - 安装 python setup.py build - 编译模块，生成文件放在 ./build/ 目录下 python setup.py --url - 输出本模块的 url python setup.py sdist - 发布一个 python 模块，将其打包成 tar.gz 或者 zip 压缩包 python setup.py bdist_rpm - 打包成 rpm 安装包 python setup.py bdist_wininst - 打包成 exe 安装包 参考 Python安装第三方模块总结 - 果冻想 Python 包管理工具解惑 - ZRONG's Blog Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Python/matplotlib.html":{"url":"Python/matplotlib.html","title":"matplotlib.md","keywords":"","body":"http://www.runoob.com/w3cnote/matplotlib-tutorial.html Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Python/re正则表达式.html":{"url":"Python/re正则表达式.html","title":"re正则表达式.md","keywords":"","body":"re 参考 Python正则表达式 正则表达式 - 廖雪峰 当我们在 Python 中使用正则表达式时，re 模块内部会干两件事情： 1、编译正则表达式，如果正则表达式的字符串本身不合法，会报错 2、用编译后的正则表达式去匹配字符串 如果一个正则表达式要重复使用几千次，出于效率的考虑，我们可以预编译（ re.compile ）该正则表达式，接下来重复使用时就不需要编译这个步骤了，直接匹配 常见正则表达式元字符 元字符 解释 命令 匹配结果 字符串 匹配字符串字面值 echo 'abc' | grep a abc . 匹配除 \\n 之外的任何字符 echo 'abc' | grep . abc ^ 匹配字符串起始部分 echo 'abc' | grep ^ab abc $ 匹配字符串终止部分 echo 'abc' | grep bc$ abc * 匹配 0 或 n 次前面出现的正则表达式 echo 'abc' | grep -E '[a-z]*' abc ? 匹配 0 或 1 次前面出现的正则表达式 echo 'abc' | grep -E 'a?' abc {N} 匹配 N 次连续前面出现的正则表达式 echo 'aabc' | grep -E a{2} aabc {M,N} 匹配 M~N 次连续前面出现的正则表达式 echo 'abaac' | grep -E 'a{1,2}' abaac [...] 匹配来自中括号内字符集的任意单一字符 echo 'abc' | grep -E '[ab]' abc [x-y ] 匹配 x~y 范围中的任意单一字符（包含两端边界值） echo '012abc' | grep -E '[0-9a-z]' 012abc ... 不匹配此字符集（包括某一范围的字符）中出现的任何一个字符 echo '012abc' | grep -E '0-1ab' 012abc (...) 匹配封闭的正则表达式，然后另存为子组 需要转义的特殊符号 \\\\ \\` \\* \\_ \\{\\} \\[\\] \\(\\) \\# \\+ \\- \\. \\! Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Python/图形界面学习.html":{"url":"Python/图形界面学习.html","title":"图形界面学习.md","keywords":"","body":" 在命令行中运行 python -m tkinter，应该会弹出一个 Tk 界面的窗口，表明 tkinter 包已经正确安装，而且告诉你 Tcl / Tk 的版本号，通过这个版本号，你就可以参考对应的 Tcl / Tk 文档了 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Python/常用图像库学习.html":{"url":"Python/常用图像库学习.html","title":"Python3 常用图像库","keywords":"","body":"Python3 常用图像库 知识背景补充 颜色和 RGBA、RGB RGBA - red、green、blue、alpha(透明度) - 这四个值都是从 0 - 255 alpha 的值决定当图片遮住背景图是，图片能透视的情况，A 取 255 时表示完全不透明 OpenCV Pillow ( PIL ) - Python Imaging Library pillow 是 PIL 的一个分支 python3 只能安装 pillow - sudo pip3 install pillow，但当 import 时，导入的是 PIL（这是为了保持与老模块 PIL 的向后兼容，所以在/usr /local/lib/python3.6/dist-packages/目录下包名仍然是 PIL，并且 import 后面只能接在此目录下的包的实际名字) PIL 最重要的类 - Image # 从 PIL 中导入 Image 类 >>> from PIL import Image # 打开一个图片 >>> img = Image.open('/home/xcq/test.jpg') # 显示图片 >>> img.show() # format 属性指定了图像文件的格式 >>> print(img.format) JPEG # size 属性是一个 2 个元素的元组，包含图像宽度和高度（像素） >>> print(img.size) (550, 747) # mode 属性定义了像素格式，常用的像素格式为：“L” (luminance)灰度图、“RGB”彩色图 >>> print(img.mode) RGB Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Python/进阶学习.html":{"url":"Python/进阶学习.html","title":"Python3 进阶学习笔记","keywords":"","body":"Python3 进阶学习笔记 函数标准参数、args 与 *kwargs Python 允许函数的在定义时不必确定形参的数量，用 '*' 表示不确定的形参 *args 和 **kwargs 是一种常用的不确定数量形参的表示，但只有 * 是必须的，所以也可以用类似 *var 和 **vars** 来表示 *args 表示不确定数量的非键值对参数 args 可以是元组 ( tuple ) 或列表 ( list ) 等 **kwargs 表示不确定数量的键值对参数 kwargs 可以是字典 ( dictionary ) 等 当要在一个函数中传入以上三种类型表示的形参，顺序如下：def some_func(fargs, *args, **kwargs): 匿名函数 - lambda 在 python 中，除了一般使用 def 定义的函数外，还有一种使用 lambda 定义的匿名函数。这种函数可以用在任何普通函数可以使用的地方，但在定义时被严格限定为单一表达式 # lambda 表达式格式： # lambda 变量 1 , 变量 2 ,...变量 N : 含有变量的表达式 # 例如： >>> x1 = 1 >>> x2 = 2 >>> test = lambda x1 , x2 : x1 + x2 >>> test(x1 , x2) 3 生成器 - Generators 生成器的基础 - 迭代 可迭代对象 - Iterable Python 中任意的对象，只要它定义了可以返回一个迭代器的 __iter__ 方法，或者定义了可以支持下标索引的 __getitem__ 方法，那么它就是一个可迭代对象。简单说，可迭代对象就是能提供迭代器的任意对象 迭代器 - Iterator 任意对象，只要定义了 next ( Python2 ) 或者 __next__ 方法，它就是一个迭代器 迭代 - Iteration 用简单的话讲，它就是从某个地方（ 比如一个列表 ）取出一个元素的过程。当我们使用一个循环来遍历某个东西时，这个过程本身就叫迭代 生成器 单纯由循环控制的迭代的执行往往会消耗大量内存，也会一次性产生所有结果，可以看出，对于每次只需要迭代过程中某一个结果的要求，使用迭代往往会浪费时间、空间，比如每次都要一个只需几次迭代就能得到的结果，但若由循环直接控制迭代则每次都要完成所有迭代，返回所有结果。利用生成器，则可以控制循环中的迭代 生成器也是一种迭代器，但是你只能对其迭代一次。这是因为它们并没有把所有的值存在内存中，而是在运行时生成值。你通过遍历来使用它们，要么用一个 “for” 循环，要么将它们传递给任意可以进行迭代的函数和结构 生成器最佳应用场景是：你不想同一时间将所有计算出来的大量结果集分配到内存当中，特别是结果集里还包含循环 各种推导式 - comprehensions 推导式（ 又称解析式 ）是 Python 的一种独有特性 推导式是可以从一个数据序列构建另一个新的数据序列的结构体，共有三种推导，在 Python2 和 3 中都有支持： 列表 ( list ) 推导式 字典 ( dict ) 推导式 集合 ( set ) 推导式 集合 - Set Set（ 集合 ）是一种数据结构，形式如： {1, 2, 3, 4}，集合中不能有重复的元素（ 和数学里的定义一样 ） 应用场景 检查列表中是否包含重复的元素 >>> some_list = [1, 2, 3, 1, 4, 2] >>> chongfu = [ x for x in some_list if some_list.count(x) > 1 ] >>> print(chongfu) [1, 2, 1, 2] >>> chongfu = set([ x for x in some_list if some_list.count(x) > 1 ]) >>> print(chongfu) {1, 2} 两个集合的交集 - intersection >>> set1 = set([1, 2, 3, 4, 5]) >>> set2 = set([1, 7, 8]) >>> print(set1.intersection(set2)) {1} >>> print(set2.intersection(set1)) {1} 两个集合的差集 - difference >>> set1 = set([1, 2, 3, 4, 5]) >>> set2 = set([1, 7, 8]) >>> print(set1.difference(set2)) {2, 3, 4, 5} >>> print(set2.difference(set1)) {8, 7} Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Shell/":{"url":"Shell/","title":"Shell","keywords":"","body":"Bash Shell Bahs 脚本教程 - 阮一峰 Bash 只有一种数据类型，就是字符串。不管用户输入什么数据，Bash 都视为字符串 Bash 没有数据类型的概念，所有的变量值都是字符串 Bash 规范 目录路径变量带不带 / 写路径变量和用路径变量有个头痛的问题就是目录的路径变量最后有没有 /，虽然 Linux 对于路径中的多个 / 都会自动识别成一个，但在使用向 rsync 时候，就得纠结路径变量最后有没有 / 目前我的想法是所有路径变量都不用 '/' 结尾 当 rm -rf 后包含变量时候必须谨慎 先来个及其危险的写法rm -rf /$fileName/ 上面当 $filename 为空时候，就会直接执行 rm -rf /，如果你在生产服务器中某个脚本包含这样的代码，就是个定时炸弹！每每想到这个，就脊背发凉 比较保险的写法cd /$filename/ && rm -rf ./ Bash 常用快捷键 命令 解释 Command 解释 Ctrl r 搜索使用过的命令 Ctrl g 从 Ctrl r 搜索中退出 Ctrl p 显示上一个命令，同向上 Ctrl n 显示下一个命令，同向下 Ctrl a 跳转行首 Ctrl e 跳转行末 Ctrl k 剪切至行末 Ctrl u 剪切至行首 Ctrl f 右移一个字符 Ctrl b 左移一个字符 Ctrl c 关闭一个前台进程 Ctrl d 关闭当前 Shell 会话 Ctrl w 剪切前一个单词 Ctrl y 粘贴 Ctrl z 暂停正在运行的任务 Ctrl h 删除前一个字符 Ctrl s 锁定界面 Ctrl q 解除锁定 Bash 脚本调试工具 - bashdb Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Shell/Shell小知识.html":{"url":"Shell/Shell小知识.html","title":"Shell小知识","keywords":"","body":"Linux Shell 学习时的小知识 目录 脚本常用通用方法 快速切出当前路径的目录名 计算脚本执行时间 if 条件判断的坑 打印主机ip 通过端口判断服务是否启动 Shell常用调试方法 tar zxvf 的坑 变量替换 shift nohup 和 & 区别 数组 命令后台运行 while read line 和 for rpm 离线安装步骤 使用 set 调试 shell 脚本 Shell 中的单引号和双引号区别 exit 退出值 Shebang 行 echo $(命令) 原样输出 单行命令拆成多行执行 exit 0 和 exit 1 特殊变量 让一个变量获得命令输出的结果 命令 > /dev/null 2 > &1和命令 &> /dev/null 数值比较 几种数值计算方法 数值进制间相互转换 等号两边不能有空格 [ $( )、` `、${ }、$(( ))、$[ ] 、[ ]、(( )) 和 [[ ]] 详解]（#---------和---详解) 用 cat、echo 命令向文件写入 杀死一个进程 删除空行 文件去重 截取文件开头几行、末尾几行和中间几行 修改文件以包含当前时间命名 查看当前主机公网 IP while 无限循环 进程查端口，端口查进程 查看其他主机开放的端口 快速查看配置文件中有效配置行 使用重定向新建文件 通用脚本开头 # Check Root [ $(id -u) != \"0\" ] && RED \"Error: You must be root to run this script\" && exit 1 # Script Path export BASEPATH=`dirname $(readlink -f ${BASH_SOURCE[0]})` && cd $BASEPATH # Time export TIME=`date +%Y%m%d_%H%M` # Information Notify function info() { (>&2 echo -e \"[\\e[34m\\e[1mINFO\\e[0m] $*\") } function error() { (>&2 echo -e \"[\\e[33m\\e[1mERROR\\e[0m] $*\") } function ok() { (>&2 echo -e \"[\\e[32m\\e[1m OK \\e[0m] $*\") } # LogFile function log() { (>&2 echo `date +\"%Y-%m-%d %H:%M:%S\"`' '\"$@\" >>\"$BASEPATH\"'/update.log') } # Color Fonts function GREEN() { echo -e \"\\033[32m $@ \\033[0m\" } function GREENF() { echo -en \"\\033[32m $@ \\033[0m\" } function RED() { echo -e \"\\033[31m $@ \\033[0m\" } function REDF() { echo -en \"\\033[31m $@ \\033[0m\" } function print_delim() { echo '============================' } 快速切出当前路径的目录名 $ basename `pwd` 计算脚本执行时间 START_TIME=$(($(date +%s%N)/1000000)) ...... function print_time() { END_TIME=$(($(date +%s%N)/1000000)) ELAPSED_TIME=$(echo \"scale=3; ($END_TIME - $START_TIME) / 1000\" | bc -l) MESSAGE=\"Took ${ELAPSED_TIME} seconds\" } if 条件判断的坑 Shell 的条件判断一直用的是 if then ... else ... fi，之前没遇到需要多加判断分支的情况，所以一直没遇到这个小坑: elif 后天需要加 then if [ $year -eq 2020 ] then echo 'Happy 2020 Year!' elif [ $year -eq 2021 ] then echo 'Happy Next Year!' else echo 'Day Day Happy!' fi 打印主机ip # hostname -I 192.168.7.12 172.17.0.1 # ip a 1: lo: mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 2: ens192: mtu 1500 qdisc mq state UP group default qlen 1000 link/ether 00:0c:29:70:19:ed brd ff:ff:ff:ff:ff:ff inet 192.168.7.12/19 brd 192.168.31.255 scope global noprefixroute dynamic ens192 valid_lft 25955sec preferred_lft 25955sec inet6 fe80::e6c4:2316:88fe:9d85/64 scope link noprefixroute valid_lft forever preferred_lft forever 3: docker0: mtu 1500 qdisc noqueue state UP group default link/ether 02:42:f4:62:f5:a4 brd ff:ff:ff:ff:ff:ff inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0 valid_lft forever preferred_lft forever inet6 fe80::42:f4ff:fe62:f5a4/64 scope link valid_lft forever preferred_lft forever 33: veth03e6e07@if32: mtu 1500 qdisc noqueue master docker0 state UP group default link/ether 2a:2f:f6:08:96:9b brd ff:ff:ff:ff:ff:ff link-netnsid 1 inet6 fe80::282f:f6ff:fe08:969b/64 scope link valid_lft forever preferred_lft forever 通过端口判断服务是否启动 以前判断服务是否启动都是使用 ps aux | grep -v grep | grep xxx 去且服务名，但有时不太准确。而通过切端口判断服务是否启动是一个很好的办法，但服务的端口一般可以改变，所以通过一下方法可以用 端口 + 服务名 双重判定服务是否启动 # 判断 jenkins 是否启动，假设端口修改为 12345 jenkins_pid=`netstat -ntlp | grep :12345 | awk '{print $7}' | awk -F\"/\" '{ print $1 }'` [ $jenkins_pid ] && echo 'jenkins 启动了' Shell常用调试方法 Maven - https://archive.apache.org/dist/maven/maven-3/ 常用的三种 Shell 脚本调试方法： 1、执行脚本时候 - bash -ex test.sh 2、脚本开头中添加 - set -ex 3、使用 bashdb 工具，可以设置断点、按行执行等 bashdb ``` shell下载软件 wget --no-check-certificate https://nchc.dl.sourceforge.net/project/bashdb/bashdb/4.2-0.92/bashdb-4.4-0.92.tar.gz 第二步：解压并进入目录 tar -zxvf 4.4-0.92.tar.gz cd 4.4-0.92 第三步：配置及编译安装 ./configure make && make install bashdb --debug 脚本名 一、列出代码和查询代码类： l 列出当前行以下的10行 列出正在执行的代码行的前面10行 . 回到正在执行的代码行 /pat/ 向后搜索pat ？pat？向前搜索pat 二、Debug控制类： h 帮助 help 命令 得到命令的具体信息 q 退出bashdb x 算数表达式 计算算数表达式的值，并显示出来 !! 空格Shell命令 参数 执行shell命令 使用bashdb进行debug的常用命令(cont.) 三、控制脚本执行类： n 执行下一条语句，遇到函数，不进入函数里面执行，将函数当作黑盒 s n 单步执行n次，遇到函数进入函数里面 b 行号n 在行号n处设置断点 del 行号n 撤销行号n处的断点 c 行号n 一直执行到行号n处 R 重新启动当前调试脚本 Finish 执行到程序最后 cond n expr 条件断点 ``` tar zxvf 的坑 执行 tar zxvf test.tar.gz -C /opt/，如果 /opt/ 下已经有 test.tar.gz 解压后的内容（比如解压后是 test 目录），在未删除直接执行解压命令，则只会覆盖 test.tar.gz 解压出来的相同文件，最好是提前判断解压路径下有无 test 目录，有的话提前删除 变量替换 变量替换可以根据变量的状态（是否为空、是否定义等）来改变它的值 形式 说明 ${var} 变量本来的值 ${var:-word} 如果变量 var 为空或已被删除(unset)，那么返回 word，但不改变 var 的值 ${var:=word} 如果变量 var 为空或已被删除(unset)，那么返回 word，并将 var 的值设置为 word ${var:?message} 如果变量 var 为空或已被删除(unset)，那么将消息 message 送到标准错误输出，可以用来检测变量 var 是否可以被正常赋值，若此替换出现在Shell脚本中，那么脚本将停止运行 ${var:+word} 如果变量 var 被定义，那么返回 word，但不改变 var 的值 ${value:offset} 或 ${value:offset:length} 从变量中提取子串，这里 offset 和 length 可以是算术表达式 ${#value} 变量的字符个数 (变量的字符个数，并不是变量个数） ${value#pattern} 或 ${value##pattern} 去掉 value 中与 pattern 相匹配的部分,条件是 value 的开头与 pattern 相匹配。#与##的区别：#是最短匹配模式，而##是最长匹配模式 ${value％pattern} 或 ${value％％pattern} 去掉 value 中与 pattern 相匹配的部分,条件是从 value 的尾部于 pattern 相匹配,%与%%的区别：%是最短匹配模式,而%%是最长匹配模式 ${value/pattern/string} 或 ${value//pattern/string} 进行变量内容的替换,把与 pattern 匹配的部分替换为 string 的内容,/ 和 // 的区别：/ 是只替换第一个，而 // 替换所有的 ${var/#pattern/string} 或 ${var/%pattern/string} 进行变量内容的替换,把与 pattern 匹配的部分替换为 string 的内容，% 和 # 的区别是：# 是从前面开始匹配，% 是从后面开始匹配 shift shift 命令用于对脚本传入参数的移动(左移)，通常用于在不知道传入参数个数的情况下依次遍历每个参数然后进行相应处理（常见于Linux中各种程序的启动脚本） **run.sh** #!/bin/bash while [ $# != 0 ] do echo \"第一个参数为：$1,参数个数为：$#\" shift done nohup 和 & 区别 使用 nohup 运行程序 结果默认会输出到 nohup.out 使用 Ctrl + C 发送 SIGINT 信号，程序关闭 关闭 session 发送 SIGHUP 信号，程序免疫 使用 & 后台运行程序 结果会输出到终端 使用 Ctrl + C 发送 SIGINT 信号，程序免疫 关闭 session 发送 SIGHUP 信号，程序关闭 数组 Bash Shell 只支持一维数组（不支持多维数组），初始化时不需要定义数组大小 数组元素的下标由 0 开始，使用括号表示一个数组，数组元素用\"空格\"符号分割开 数组元素可以是：字符串、数字等 读取数组格式：${array_name[index]} $ my_array=(1 \"1\" \"C\" D) $ for i in ${my_array[*]};do echo $i;done 1 1 C D 命令后台运行 1、支持后台运行，但是关闭终端的话，程序也会停止。使用 jobs -l 查看和使用 fg 命令将后台运行调到前台运行 $ [command] & 2、支持后台运行，关闭终端后，程序也会继续运行。使用 jobs 命令查看不到，需要使用 ps aux | grep -v grep | grep [command] 查看 $ nohup [command] & while read line 和 for while read line 是一次性将文件的一行读入并赋值给变量 line ，while 中使用重定向机制,文件中的所有信息都被读入并重定向给了整个 while 语句中的 line 变量 ``` shell从文件读取 while read line do command done 从命令输出读取 command1 | while read line do command2 done * for 是每次读取文件中一个以空格为分割符的字符串 ## rpm 离线安装步骤 > Linux 离线部署一般采用 docker 或 rpm 包安装 * yum 只下载不安装软件 rpm 包 ``` shell # 下载 vim 所有 rpm 包到当前目录下的 vim 文件夹 $ yum install --downloadonly --downloaddir=./ vim 检测是否还有遗漏的依赖 rpm $ yum -ivh ./*.rpm 使用 set 调试 shell 脚本 参考：http://www.ruanyifeng.com/blog/2017/11/bash-set.html set -u 或 set -o nounset - 遇到不存在的变量就会报错，并停止执行 默认遇到不存在的变量，Bash 忽略它。使用 set -u， set -x 或 set -o xtrace - 在运行结果之前，先输出执行的那一行命令 默认情况下，脚本执行后，屏幕只显示运行结果，没有其他内容。如果多个命令连续执行，它们的运行结果就会连续输出。有时会分不清，某一段内容是什么命令产生的 set -e 或 set -o errexit - 脚本只要发生错误，就终止执行 如果脚本里面有运行失败的命令（返回值非0），Bash 默认会继续执行后面的命令 set -e 根据返回值来判断，一个命令是否运行失败。但是，某些命令的非零返回值可能不表示失败，或者开发者希望在命令失败的情况下，脚本继续执行下去。这时可以暂时关闭 set -e，该命令执行结束后，再重新打开 set -e# set +e 表示关闭 -e 选项，set -e 表示重新打开 -e 选项 set +e command1 command2 set -e 不管有没有设置 set -e，手动确保命令执行失败退出或继续执行# 命令失败则一定退出 command || echo \"fail!\";exit 1 # 命令失败也一定继续执行 command || true set -o pipefail - 只要管道中一个子命令失败，整个管道命令就失败，脚本就会终止执行 $ cat script.sh #!/usr/bin/env bash set -eo pipefail foo | echo a echo bar $ bash script.sh a script.sh:行4: foo: 未找到命令 set -e 不适用于管道命令。Bash 会把管道最后一个子命令的返回值，作为整个命令的返回值。也就是说，只要最后一个子命令不失败，管道命令总是会执行成功，因此它后面命令依然会执行，set -e 就失效了# 管道连接多个 command，$? 是最后一个 command 的返回值 $ hello | echo \"hello\" hello -bash: hello: 未找到命令 $ echo $? 0 以上四个参数汇总 # 方法一 set -euxo pipefail # 方法二 set -eux set -o pipefail # 方法三，执行脚本时传入 $ bash -euxo pipefail script.sh Shell 中的单引号和双引号区别 参考：https://blog.csdn.net/fdl19881/article/details/7849286 结论：单引号和双引号都能关闭 shell 对特殊字符的处理。不同的是，双引号没有单引号严格，单引号关闭所有有特殊作用的字符，而双引号只要求 shell 忽略大多数。具体的说，双引号保留对美元符号、反引号、反斜杠的特殊解析。所以，在 sed 中需要引用变量则必须使用双引号；而 awk 中 '{print $0}' 的 $0 不是引用 shell 的 $0（即不是由 shell 解析），而是由 awk 程序解析 在 shell 终端输入一行命令然后按下 enter，这时 shell 会以进程方式执行提交的命令，而对于命令行中字符的解析，shell 有不同的方法： 简而言之，命令行的的字符都可按如下两种分类： literal：就是普通字符串，没有特殊意义，例如 abcd、123456 等等 meta：具有特定功能的保留元字符 IFS：由 三者之一组成 CR：由 产生 =：设定变量 $：做变量或运算替换(请不要与 shell prompt 搞混了) >：重定向 stdout ：重定向 stdin |：管道命令 &：重定向 file descriptor ，或将命令置于后台执行 ( )：將其內的命令置于 nested subshell 执行，或用于运算或命令替换 { }：將其內的命令置于 non-named function 中执行，或用在变量替换的界定范围 ;：在前一个命令结束时，而忽略其返回值，继续执行下一個命令 &&：在前一個命令结束时，若返回值为 true，继续执行下一個命令 ||：在前一個命令结束时，若返回值为 false，继续执行下一個命令 !：执行 history 列表中的命令 meta 往往具有多重意义，比如 $ 有时需要作为单纯的美元符号，但有时需要作为 $变量 使用。在 shell 中，是通过 quoting 开启和关闭 meta 功能，常用 quoting 有一下三种方法： hard quote：''（单引号），凡在 hard quote 中的所有 meta 均被关闭 soft quote：\"\"（双引号），在 soft quote 中的大部分 meta 都会被关闭，但某些保留（如 $ ） escape：\\ （反斜线），只有紧接在 escape（跳脱字符）之后的单一 meta 才被关闭 exit 退出值 0 表示正常，1 表示发生错误，2 表示用法不对，126 表示不是可执行脚本，127 表示命令没有发现。如果脚本被信号 N 终止，则退出值为 128 + N。简单来说，只要退出值非 0，就认为执行出错。 $ ls 参数 || echo $? ls: 无法访问'参数': 没有那个文件或目录 2 $ ./README.md || echo $? bash: ./README.md: 权限不够 126 $ 命令 || echo $? 命令：未找到命令 127 Shebang 行 Shebang 行位于脚本第一行，用于指定解释器，即这个脚本必须通过什么解释器执行 #!/usr/bin/env bash # 意思是让 Shell 查找 $PATH 环境变量里面第一个匹配的 bash # 这样执行脚本时就不用手动指定 Shell 解释器 $ ./script.sh # 若没有 Shebang 行，则需要如下： $ bash ./script.sh echo $(命令) 原样输出 # echo `命令` 打印的命令的输出是单行的，可以通过添加双引号保持命令的原样格式输出 $ echo `ls` abcdefghij001 abcdefghij002 abcdefghij003 abcdefghij004 abcdefghij005 abcdefghij006 abcdefghij007 abcdefghij008 abcdefghij009 abcdefghij010 abcdefghij011 abcdefghij012 abcdefghij013 $ echo \"`ls`\" abcdefghij001 abcdefghij002 abcdefghij003 abcdefghij004 abcdefghij005 abcdefghij006 abcdefghij007 abcdefghij008 abcdefghij009 abcdefghij010 abcdefghij011 abcdefghij012 abcdefghij013 单行命令拆成多行执行 $ echo foo bar # 等同于 $ echo foo \\ bar exit 0和exit 1 Linux exit 命令用于退出目前的 shell 执行 exit 可使 shell 以指定的状态值退出 若不设置状态值参数，则 shell 以预设值退出；状态值 0 代表执行成功，其他值代表执行失败 exit 也可用在 script，离开正在执行的 script，回到 shell 语法：exit [ 状态值 ] Ubuntu shell exit 特殊变量 $X 说明 $? 最近一次运行命令的结束代码（返回值 0 表示成功，非 0 表示失败） $$ 脚本运行的当前进程 ID 号（PID） $n(n=1,2...) 传递给该 shell 脚本的第 n 个参数，参数多于 9 个时候，使用${10}形式引用 $0 执行脚本本身的名字 $# 传递给脚本参数的个数 $* 脚本的所有参数列表,代表\"$1 $2 … $n\"，即当成一个整体输出，每一个变量参数之间以空格隔开 $@ 脚本的所有参数列表,代表\"$1\" \"$2\" … \"$n\" ，即每一个变量参数是独立的 ,也是全部输出 如果多个参数放在双引号里面，视为一个参数。$ ./script.sh \"a b\" a b $* 和 $@区别 #!/bin/bash # This script is to verify the difference between $* and $@ echo Dollar Star is $* echo \"Dollar Star in double quotes is $*\" echo Dollar At is $@ echo \"Dollar At in double quotes is $@\" echo echo \"Looping through Dollar Star\" for i in $* do echo \"parameter is $i\" done echo echo \"Looping through Dollar Star with double quotes\" for i in \"$*\" do echo \"Parameter is $i\" done echo echo \"Looping through Dollar At\" for i in $@ do echo \"Parameter is $i\" done echo echo \"Looping through Dollar At with double quotes\" for i in \"$@\" do echo \"Parameter is $i\" done $ bash test.sh 1 2 \" 3 4 \" 5 6 Dollar Star is 1 2 3 4 5 6 Dollar Star in double quotes is 1 2 3 4 5 6 Dollar At is 1 2 3 4 5 6 Dollar At in double quotes is 1 2 3 4 5 6 Looping through Dollar Star parameter is 1 parameter is 2 parameter is 3 parameter is 4 parameter is 5 parameter is 6 Looping through Dollar Star with double quotes Parameter is 1 2 3 4 5 6 Looping through Dollar At Parameter is 1 Parameter is 2 Parameter is 3 Parameter is 4 Parameter is 5 Parameter is 6 Looping through Dollar At with double quotes Parameter is 1 Parameter is 2 Parameter is 3 4 Parameter is 5 Parameter is 6 相同点如下： 1、直接输出不保留空格 2、带双引号输出会保留带引号的空格 3、不带双引号循环遍历的输出结果一样：每个字符串单独输出 不同点如下： 1、带双引号遍历$*相当于带双引号输出$* 2、带双引号遍历$@分别输出每个参数，带双引号的参数保留空格输出 $* 示例 让一个变量获得命令输出的结果 1、$(命令)表示 #!/bin/bash i=$(ls 123.txt) echo $i 2、反引号表示 #!/bin/bash i=`ls 123.txt` echo $i 命令 > /dev/null 2 > &1和命令 &> /dev/null 解释：无提示（包括 stdin 和 stderr ）执行 文件描述符 文件描述符是与文件输入、输出关联的整数。它们用来跟踪已打开的文件 最常见的文件描述符是 stidin、stdout、和 stderr 0 —— stdin（标准输入） 1 —— stdout （标准输出） 2 —— stderr （标准错误） 我们可以将某个文件描述符的内容重定向到另外一个文件描述符中 stdout （标准输出） stderr （标准错误） /dev/null /dev/null是一个特殊的设备文件，这个文件接收到的任何数据都会被丢弃。因此，null 这个设备通常也被成为位桶（ bit bucket ）或黑洞 重定向操作给这个/dev/null文件的所有东西都会被丢弃 扩展使用 # 将 stderr 单独定向到一个文件，将stdout重定向到另一个文件 $ ls 123.txt 1> stdout.txt 2> stderr.txt # 将 stderr 转换成 stdout，使得 stderr 和 stdout 都被重新定向到同一个文件中 $ ls 123.txt 1> output.txt 2>&1 # 或 $ ls 123.txt > output.txt 2>&1 # 或 $ ls 123.txt &> output.txt # 或 $ ls 123.txt >& output.txt > 或 1>（标准输出）：把 STDOUT 重定向到文件,将默认或正确的传到另一个终端 2>（标准错误）：把 STDERR 重定向到文件，可将错误信息传到另一个终端，正确留下 2>&1：将错误转为正确输出，老式“洗钱”方法 1>&2：将正确转为错误输出 &>or>&：正确、错误都输出，新式方法 数值比较 arg1 OP arg2 ( OP ) 说明 -eq arg1 is equal arg2 -ne arg1 is not-equal arg2 -lt arg1 is less-than arg2 -le arg1 is less-than-or-equal arg2 -gt arg1 is greater-than arg2 -ge arg1 is greater-than-or-equal arg2 几种数值计算方法 $ ((i=5%2)) $ echo $i # 1 $ let i=5%2 $ echo $i # 1 $ expr 5 % 2 # expr 之后的 5，%，2 之间必须有空格分开。如果进行乘法运算，需要对运算符进行转义，否则 Shell 会把乘号解释为通配符，导致语法错误 $ i=$(echo 5%2 | bc) $ echo $i # 1 $ i=$(echo \"5 2\" | awk `{print $1+$2;}`) $ echo $i # 1 let，expr，bc 都可以用来求模，运算符都是 %，而 let 和 bc可以用来求幂，运算符不一样，前者是**，后者是 ^ (()) 的运算效率最高，而 let 作为 Shell 内置命令，效率也很高，但是 expr，bc，awk 的计算效率就比较低 let 和 expr 都无法进行浮点运算，但是 bc 和 awk 可以 ``` shell $ echo \"scale=3; 1/12\" | bc0.083 $ echo \"1 12\" | awk '{printf(\"%0.3f\\n\",$1/$2)}' 0.083 ``` 数值进制间相互转换 ``` shell 八进制 12 转换为十进制 方法一、 $ echo \"obase=8;ibase=10;12\" | bc 10 obase - 进制源 ibase - 进制转换目标 bc 命令是任意精度计算器语言，通常在 linux 下当计算器用 方法二、 $ echo $((8#12) 10 ## 等号两边不能有空格 = 含有空格导致无法运行 正确 ## $( )、\\` \\`、${ }、$(( ))、$[ ] 、[ ]、(( )) 和 [[ ]] 详解 | | 说明 | 举例 | 例子说明 | | --- | --- | --- | --- | | $( ) | 命令替换 | `version=$(uname -r)` | 得到内核版本号 | | \\` \\` | 命令替换，同 $() | version=\\`uname -r\\` | 同上 | | ${ } | 用于变量替换 | `a=1; b=${a}` 其实这里用 $a 一样，但有时会有区别 | a 赋给 b | | $(( )) | 进行数学运算 | `echo $(( 1+2*3 ))` | 输入 1+2×3 的结果 | | $[ ] | 进行数学运算 | `echo $[ 1+2*3 ]` | 同上 | | [ ] | test 命令的另一种形式 | `if [ 1 eq 1 ]...` | 字面意思 | | (( )) | 是`[ ]`的针对数学比较表达式加强版 | | | | [[ ]] | 是`[ ]`的针对字符串表达式的加强版 | [[ $? != 0 ]] | | * \\` \\` 和 $( )：反引号几乎可以在所有 shell 上执行，而`$( )`有些不可以；多层使用反引号需要加`\\`，`$( )`更浅显易懂，不易出错 ``` shell $ cat a.txt b.txt $ cat b.txt c.txt $ cat c.txt Hello World! $ cat `cat \\`cat a.txt\\`` # ``内的反引号必须使用 \\` Hello World! $ cat $(cat $(cat a.txt)) Hello World! bash 只能作整数运算，对于浮点数是当作字符串处理的 [ ]：必须在左括号的右侧和右括号的左侧各加一个空格，否则会报错 更多资料 http://bbs.chinaunix.net/forum.php?mod=viewthread&tid=218853&page=7#pid1617953 https://www.cnblogs.com/zejin2008/p/8412680.html 用 cat、echo 命令向文件写入 cat # 文件不存在则自动创建 # EOF 为开头结尾标记，可以换成任意字符串 # 1. 覆盖 cat > test.sh 1 > 2 > EOF # 2. 追加 $ cat >> test.sh 1 > 2 > EOF echo # 文件不存在则自动创建 # 1. 覆盖 echo 'hello hello world'>hello # 2. 追加 echo 'hello hello world' >> hello 杀死一个进程 ps aux | grep 进程名 ---> kill -s 9 进程号 kill -s 9 `ps aux | grep 进程名 | grep -v grep | awk '{print $2}'` ps aux | grep 进程名 | grep -v grep | xrags kill -s 9 kill -s 9 `pgrep 进程名` pkill -s 9 进程名 kill [信号] [进程号] kill 给指定进程发送指定信号，默认发送 TERM 信号，这回杀死不能捕获该信号的进程，对于单纯 kill 杀不死的进程，可能需要使用 kill ( 9 ) 信号，因为该信号不能被任何进程捕获 当我们杀掉父进程时，其下的子进程也会被杀死 kill -9 常用来杀死僵尸进程 pkill -9 进程名 可以一次性杀死所有包含 进程名 的进程 killall -9 进程名全称 也是一次性杀死所有包含 进程名 的进程，但必须使用进程完整名称 kill -s singal 命令最长使用的信号： Signal Name Single Value Effect SIGHUP 1 挂起 SIGINT 2 中断（等同 Ctrl + C） 3 退出（同 Ctrl + \\） SIGKILL 9 发出强制杀死信号 SIGTERM 15 默认，发出终止信号 SIGSTOP 17, 19, 23 暂停（等同 Ctrl + Z） 删除空行 sed '/^$/d' file sed -n '/./p' file grep -v ^$ file awk '/./ {print}' file awk '{if($0!=\"\") print}' tr -s \"\\n\" 文件去重 # 1. awk （不排序直接去重，按原顺序输出） awk '!a[$0]++' file cat file | awk '!a[$0]++' # 2. sort + uniq (先排序再去重，打乱了顺序) cat file | sort | uniq 截取文件开头几行、末尾几行和中间几行 # 截取前 5 行 - head、sed、awk head -5 filename # 或 sed -n '1,5p' filename # 或 awk 'NR 修改文件以包含当前时间命名 $ ls hello_log.txt $ mv hello_log.txt $(date +%Y%m%d-%H%M%S)_hello_log.txt $ ls 20191113-205057_hello_log.txt $ tar cvf hello_log_$(date +%Y%m%d-%H%M%S).tar.gz 20191113-205057_hello_log.txt 20191113-205057_hello_log.txt $ ls 20191113-205057_hello_log.txt hello_log_20191113-205252.tar.gz 查看当前主机公网 IP # 只返回 ip $ curl ip.sb $ curl www.pubyun.com/dyndns/getip $ curl members.3322.org/dyndns/getip # 返回中文解析，包括 IP、地址、运营商 $ curl cip.cc while 无限循环 while : do echo '我是死循环' done while /bin/true do echo '我是死循环' done 进程查端口，端口查进程 进程 -> 端口 sudo netstat -tlpn | grep nginx sudo ss -tlpn | grep nginx sudo netstat -nap | grep \\ 端口 -> 进程 lsof -i:\\ sudo netstat -nap | grep \\ 查看其他主机开放的端口 sudo nmap -sS \\ $ sudo nmap -sS 47.101.133.201 Starting Nmap 7.60 ( https://nmap.org ) at 2019-11-26 19:40 CST Nmap scan report for 47.101.133.201 Host is up (0.045s latency). Not shown: 995 filtered ports PORT STATE SERVICE 22/tcp open ssh 80/tcp closed http 443/tcp closed https 1080/tcp closed socks 8080/tcp closed http-proxy Nmap done: 1 IP address (1 host up) scanned in 28.81 seconds 快速查看配置文件中有效配置行 配置文件往往动辄几百行，但可能只有几行是非注释非换行的有效配置，可以使用 egrep -v 排除空行和注释行，快速查看配置文件的有效配置行 # 查看 ansible 配置文件中的有效配置 ( 以 # 号开头是注释行 ) $ egrep -v \"(^$|^#)\" ./ansible.cfg 使用重定向新建文件 # 比 touch 新建少输入几个字符！ $ > new.txt Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Shell/Shell奇淫技巧.html":{"url":"Shell/Shell奇淫技巧.html","title":"Shell奇淫技巧","keywords":"","body":"Shell 奇淫技巧 commandlinefu.com 拥有 root 权限的普通用户使用 sudo 非交互式创建其他非 root 用户 用户：xcq 密码：xiechengqi 新建用户：xie xie 密码：xiechengqi $ echo -e 'xiechengqi/nxiechengqi/nxiechengqi/n' | sudo -S ls &> /dev/null && sudo useradd xie && echo 'xie:xiechengqi' | sudo chpasswd 拥有 root 权限的普通用户使用 sudo 非交互式修改其他非 root 用户密码 用户：xcq 密码：xiechengqi 其他用户：xie xie 修改后密码：xiechengqi echo -e 'xiechengqi/nxiechengqi/nxiechengqi/n' | sudo -S ls &> /dev/null && echo 'xie:xiechengqi' | sudo chpasswd 匹配变量名 ${!string*}或${!string@}返回所有匹配给定字符串 string 的变量名 $ echo ${!H*} HADOOP_HOME HISTCMD HISTCONTROL HISTFILE HISTFILESIZE HISTSIZE HOME HOSTNAME HOSTTYPE 匹配除.和..文件的所有隐藏文件 $ echo .[!.]* .git .github .gitignore .nojekyll 计算字符串的长度 ${#字符串} str=\"hello world!\" ${#str} 12：未找到命令 通过 username 返回 github 用户所有的 repos $ curl -s https://api.github.com/users//repos?per_page=1000 | grep git_url | awk '{print $2}' | sed 's/\"\\(.*\\)\",/\\1/' $ curl -s \"https://api.github.com/users//repos?per_page=1000\" | jq '.[].git_url' $ curl -s \"https://api.github.com/users//repos?per_page=1000\" | python $ curl -s https://api.github.com/users//repos?per_page=1000 | grep -oP '(? 显示所有进程的端口和 pid $ ss -plunt 单行显示所有可更新的 deb 包 $ apt list --upgradable | grep -v 'Listing...' | cut -d/ -f1 | tr '\\r\\n' ' ' | sed '$s/ $/\\n/' Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Shell/Shell百宝箱.html":{"url":"Shell/Shell百宝箱.html","title":"Shell百宝箱","keywords":"","body":"shell实例手册 0说明{ 手册制作: 雪松 更新日期: 2013-12-06 欢迎系统运维加入Q群: 198173206 请使用\"notepad++\"打开此文档,\"alt+0\"将函数折叠后方便查阅 请勿删除信息，转载请说明出处，抵制不道德行为。 错误在所难免，还望指正！ # shell实例手册最新下载地址: http://hi.baidu.com/quanzhou722/item/f4a4f3c9eb37f02d46d5c0d9 # LazyManage系统批量管理软件下载(shell): http://hi.baidu.com/quanzhou722/item/4ccf7e88a877eaccef083d1a # python实例手册下载地址: http://hi.baidu.com/quanzhou722/item/cf4471f8e23d3149932af2a7 } 1文件{ touch file # 创建空白文件 rm -rf 目录名 # 不提示删除非空目录(-r:递归删除 -f强制) dos2unix # windows文本转linux文本 unix2dos # linux文本转windows文本 enca filename # 查看编码 安装 yum install -y enca md5sum # 查看md5值 ln 源文件 目标文件 # 硬链接 ln -s 源文件 目标文件 # 符号连接 readlink -f /data # 查看连接真实目录 cat file | nl |less # 查看上下翻页且显示行号 q退出 head # 查看文件开头内容 head -c 10m # 截取文件中10M内容 split -C 10M # 将文件切割大小为10M tail -f file # 查看结尾 监视日志文件 file # 检查文件类型 umask # 更改默认权限 uniq # 删除重复的行 uniq -c # 重复的行出现次数 uniq -u # 只显示不重复行 paste a b # 将两个文件合并用tab键分隔开 paste -d'+' a b # 将两个文件合并指定'+'符号隔开 paste -s a # 将多行数据合并到一行用tab键隔开 chattr +i /etc/passwd # 设置不可改变位 more # 向下分面器 locate 字符串 # 搜索 wc -l file # 查看行数 cp filename{,.bak} # 快速备份一个文件 \\cp a b # 拷贝不提示 既不使用别名 cp -i rev # 将行中的字符逆序排列 comm -12 2 3 # 行和行比较匹配 iconv -f gbk -t utf8 原.txt > 新.txt # 转换编码 rename 原模式 目标模式 文件 # 重命名 可正则 watch -d -n 1 'df; ls -FlAt /path' # 实时某个目录下查看最新改动过的文件 cp -v /dev/dvd /rhel4.6.iso9660 # 制作镜像 diff suzu.c suzu2.c > sz.patch # 制作补丁 patch suzu.c - # 以指定的栏位来排序，范围由起始栏位到结束栏位的前一栏位。 -o # 将排序后的结果存入指定的文 n # 表示进行排序 r # 表示逆序 sort -n # 按数字排序 sort -nr # 按数字倒叙 sort -u # 过滤重复行 sort -m a.txt c.txt # 将两个文件内容整合到一起 sort -n -t' ' -k 2 -k 3 a.txt # 第二域相同，将从第三域进行升降处理 sort -n -t':' -k 3r a.txt # 以:为分割域的第三域进行倒叙排列 sort -k 1.3 a.txt # 从第三个字母起进行排序 sort -t\" \" -k 2n -u a.txt # 以第二域进行排序，如果遇到重复的，就删除 } find查找{ # linux文件无创建时间 # Access 使用时间 # Modify 内容修改时间 # Change 状态改变时间(权限、属主) # 时间默认以24小时为单位,当前时间到向前24小时为0天,向前48-72小时为2天 # -and 且 匹配两个条件 参数可以确定时间范围 -mtime +2 -and -mtime -4 # -or 或 匹配任意一个条件 find /etc -name http # 按文件名查找 find . -type f # 查找某一类型文件 find / -perm # 按照文件权限查找 find / -user # 按照文件属主查找 find / -group # 按照文件所属的组来查找文件 find / -atime -n # 文件使用时间在N天以内 find / -atime +n # 文件使用时间在N天以前 find / -mtime -n # 文件内容改变时间在N天以内 find / -mtime +n # 文件内容改变时间在N天以前 find / -ctime +n # 文件状态改变时间在N天前 find / -ctime -n # 文件状态改变时间在N天内 find / -size +1000000c -print # 查找文件长度大于1M字节的文件 find /etc -name \"passwd*\" -exec grep \"xuesong\" {} \\; # 按名字查找文件传递给-exec后命令 find . -name 't*' -exec basename {} \\; # 查找文件名,不取路径 find . -type f -name \"err*\" -exec rename err ERR {} \\; # 批量改名(查找err 替换为 ERR {}文件 find 路径 -name *name1* -or -name *name2* # 查找任意一个关键字 } vim编辑器{ gconf-editor # 配置编辑器 /etc/vimrc # 配置文件路径 vim +24 file # 打开文件定位到指定行 vim file1 file2 # 打开多个文件 vim -O2 file1 file2 # 垂直分屏 vim -on file1 file2 # 水平分屏 sp filename # 上下分割打开新文件 vsp filename # 左右分割打开新文件 Ctrl+W [操作] # 多个文件间操作 大写W # 操作: 关闭当前窗口c 屏幕高度一样= 增加高度+ 移动光标所在屏 右l 左h 上k 下j 中h 下一个w :n # 编辑下一个文件 :2n # 编辑下二个文件 :N # 编辑前一个文件 :rew # 回到首文件 :set nu # 打开行号 :set nonu # 取消行号 200G # 跳转到200 :nohl # 取消高亮 :set autoindent # 设置自动缩进 :set ff # 查看文本格式 :set binary # 改为unix格式 ctrl+ U # 向前翻页 ctrl+ D # 向后翻页 %s/字符1/字符2/g # 全部替换 X # 文档加密 } 归档解压缩{ tar zxvpf gz.tar.gz -C 放到指定目录 包中的目录 # 解包tar.gz 不指定目录则全解压 tar zcvpf /$path/gz.tar.gz * # 打包gz 注意*最好用相对路径 tar zcf /$path/gz.tar.gz * # 打包正确不提示 tar ztvpf gz.tar.gz # 查看gz tar xvf 1.tar -C 目录 # 解包tar tar -cvf 1.tar * # 打包tar tar tvf 1.tar # 查看tar tar -rvf 1.tar 文件名 # 给tar追加文件 tar --exclude=/home/dmtsai -zcvf myfile.tar.gz /home/* /etc # 打包/home, /etc ，但排除 /home/dmtsai tar -N \"2005/06/01\" -zcvf home.tar.gz /home # 在 /home 当中，比 2005/06/01 新的文件才备份 tar -zcvfh home.tar.gz /home # 打包目录中包括连接目录 zgrep 字符 1.gz # 查看压缩包中文件字符行 bzip2 -dv 1.tar.bz2 # 解压bzip2 bzip2 -v 1.tar # bzip2压缩 bzcat # 查看bzip2 gzip A # 直接压缩文件 # 压缩后源文件消失 gunzip A.gz # 直接解压文件 # 解压后源文件消失 gzip -dv 1.tar.gz # 解压gzip到tar gzip -v 1.tar # 压缩tar到gz unzip zip.zip # 解压zip zip zip.zip * # 压缩zip # rar3.6下载: http://www.rarsoft.com/rar/rarlinux-3.6.0.tar.gz rar a rar.rar *.jpg # 压缩文件为rar包 unrar x rar.rar # 解压rar包 7z a 7z.7z * # 7z压缩 7z e 7z.7z # 7z解压 } 文件ACL权限控制{ getfacl 1.test # 查看文件ACL权限 setfacl -R -m u:xuesong:rw- 1.test # 对文件增加用户的读写权限 -R 递归 } svn更新代码{ --force # 强制覆盖 /usr/bin/svn --username user --password passwd co $Code ${SvnPath}src/ # 检出整个项目 /usr/bin/svn --username user --password passwd export $Code$File ${SvnPath}src/$File # 导出个别文件 } 恢复rm删除的文件{ # debugfs针对 ext2 # ext3grep针对 ext3 # extundelete针对 ext4 df -T # 首先查看磁盘分区格式 umount /data/ # 卸载挂载,数据丢失请首先卸载挂载,或重新挂载只读 ext3grep /dev/sdb1 --ls --inode 2 # 记录信息继续查找目录下文件inode信息 ext3grep /dev/sdb1 --ls --inode 131081 # 此处是inode ext3grep /dev/sdb1 --restore-inode 49153 # 记录下inode信息开始恢复目录 } } 2软件{ rpm{ rpm -ivh lynx # rpm安装 rpm -e lynx # 卸载包 rpm -e lynx --nodeps # 强制卸载 rpm -qa # 查看所有安装的rpm包 rpm -qa | grep lynx # 查找包是否安装 rpm -ql # 软件包路径 rpm -Uvh # 升级包 rpm --test lynx # 测试 rpm -qc # 软件包配置文档 rpm --import /etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-6 # 导入rpm的签名信息 } yum{ yum list # 查找所有列表 yum install 包名 # 安装包和依赖包 yum -y update # 升级所有包版本,依赖关系，系统版本内核都升级 yum -y update 软件包名 # 升级指定的软件包 yum -y upgrade # 不改变软件设置更新软件，系统版本升级，内核不改变 yum search mail # yum搜索相关包 yum grouplist # 软件包组 yum -y groupinstall \"Virtualization\" # 安装软件包组 } yum扩展源{ # 包下载地址:http://download.fedoraproject.org/pub/epel # 选择版本 wget http://download.fedoraproject.org/pub/epel/5/i386/epel-release-5-4.noarch.rpm rpm -Uvh epel-release-5-4.noarch.rpm } 自定义yum源{ find /etc/yum.repos.d -name \"*.repo\" -exec mv {} {}.bak \\; vim /etc/yum.repos.d/yum.repo [yum] #http baseurl=http://10.0.0.1/centos5.5 #挂载iso #mount -o loop CentOS-5.8-x86_64-bin-DVD-1of2.iso /data/iso/ #本地 #baseurl=file:///data/iso/ enable=1 #导入key rpm --import /etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-5 } 编译{ 源码安装{ ./configure --help # 查看所有编译参数 ./configure --prefix=/usr/local/ # 配置参数 make # 编译 make install # 安装包 make clean # 清除编译结果 } perl程序编译{ perl Makefile.PL make make test make install } python程序编译{ python file.py } 编译c程序{ gcc -g hello.c -o hello } } } 3系统{ wall 　 　 # 给其它用户发消息 whereis ls # 查找命令的目录 which # 查看当前要执行的命令所在的路径 clear # 清空整个屏幕 reset # 重新初始化屏幕 cal # 显示月历 echo -n 123456 | md5sum # md5加密 mkpasswd # 随机生成密码 -l位数 -C大小 -c小写 -d数字 -s特殊字符 netstat -anlp | grep port # 是否打开了某个端口 ntpdate stdtime.gov.hk # 同步时间 tzselect # 选择时区 #+8=(5 9 1 1) # (TZ='Asia/Shanghai'; export TZ)括号内写入 /etc/profile /sbin/hwclock -w # 保存到硬件 /etc/shadow # 账户影子文件 LANG=en # 修改语言 vim /etc/sysconfig/i18n # 修改编码 LANG=\"en_US.UTF-8\" export LC_ALL=C # 强制字符集 vi /etc/hosts # 查询静态主机名 alias # 别名 watch uptime # 监测命令动态刷新 ipcs -a # 查看Linux系统当前单个共享内存段的最大值 lsof |grep /lib # 查看加载库文件 ldconfig # 动态链接库管理命令 dist-upgrade # 会改变配置文件,改变旧的依赖关系，改变系统版本 /boot/grub/grub.conf # grub启动项配置 sysctl -p # 修改内核参数/etc/sysctl.conf，让/etc/rc.d/rc.sysinit读取生效 mkpasswd -l 8 -C 2 -c 2 -d 4 -s 0 # 随机生成指定类型密码 echo 1 > /proc/sys/net/ipv4/tcp_syncookies # 使TCP SYN Cookie 保护生效 # \"SYN Attack\"是一种拒绝服务的攻击方式 开机启动脚本顺序{ /etc/profile /etc/profile.d/*.sh ~/bash_profile ~/.bashrc /etc/bashrc } 进程管理{ ps -eaf # 查看所有进程 kill -9 PID # 强制终止某个PID进程 kill -15 PID # 安全退出 需程序内部处理信号 cmd & # 命令后台运行 nohup cmd & # 后台运行不受shell退出影响 ctrl+z # 将前台放入后台(暂停) jobs # 查看后台运行程序 bg 2 # 启动后台暂停进程 fg 2 # 调回后台进程 pstree # 进程树 vmstat 1 9 # 每隔一秒报告系统性能信息9次 sar # 查看cpu等状态 lsof file # 显示打开指定文件的所有进程 lsof -i:32768 # 查看端口的进程 renice +1 180 # 把180号进程的优先级加1 ps aux |grep -v USER | sort -nk +4 | tail # 显示消耗内存最多的10个运行中的进程，以内存使用量排序.cpu +3 top{ 前五行是系统整体的统计信息。 第一行: 任务队列信息，同 uptime 命令的执行结果。内容如下： 01:06:48 当前时间 up 1:22 系统运行时间，格式为时:分 1 user 当前登录用户数 load average: 0.06, 0.60, 0.48 系统负载，即任务队列的平均长度。 三个数值分别为 1分钟、5分钟、15分钟前到现在的平均值。 第二、三行:为进程和CPU的信息。当有多个CPU时，这些内容可能会超过两行。内容如下： Tasks: 29 total 进程总数 1 running 正在运行的进程数 28 sleeping 睡眠的进程数 0 stopped 停止的进程数 0 zombie 僵尸进程数 Cpu(s): 0.3% us 用户空间占用CPU百分比 1.0% sy 内核空间占用CPU百分比 0.0% ni 用户进程空间内改变过优先级的进程占用CPU百分比 98.7% id 空闲CPU百分比 0.0% wa 等待输入输出的CPU时间百分比 0.0% hi 0.0% si 第四、五行:为内存信息。内容如下： Mem: 191272k total 物理内存总量 173656k used 使用的物理内存总量 17616k free 空闲内存总量 22052k buffers 用作内核缓存的内存量 Swap: 192772k total 交换区总量 0k used 使用的交换区总量 192772k free 空闲交换区总量 123988k cached 缓冲的交换区总量。 内存中的内容被换出到交换区，而后又被换入到内存，但使用过的交换区尚未被覆盖， 该数值即为这些内容已存在于内存中的交换区的大小。 相应的内存再次被换出时可不必再对交换区写入。 进程信息区,各列的含义如下: # 显示各个进程的详细信息 序号 列名 含义 a PID 进程id b PPID 父进程id c RUSER Real user name d UID 进程所有者的用户id e USER 进程所有者的用户名 f GROUP 进程所有者的组名 g TTY 启动进程的终端名。不是从终端启动的进程则显示为 ? h PR 优先级 i NI nice值。负值表示高优先级，正值表示低优先级 j P 最后使用的CPU，仅在多CPU环境下有意义 k %CPU 上次更新到现在的CPU时间占用百分比 l TIME 进程使用的CPU时间总计，单位秒 m TIME+ 进程使用的CPU时间总计，单位1/100秒 n %MEM 进程使用的物理内存百分比 o VIRT 进程使用的虚拟内存总量，单位kb。VIRT=SWAP+RES p SWAP 进程使用的虚拟内存中，被换出的大小，单位kb。 q RES 进程使用的、未被换出的物理内存大小，单位kb。RES=CODE+DATA r CODE 可执行代码占用的物理内存大小，单位kb s DATA 可执行代码以外的部分(数据段+栈)占用的物理内存大小，单位kb t SHR 共享内存大小，单位kb u nFLT 页面错误次数 v nDRT 最后一次写入到现在，被修改过的页面数。 w S 进程状态。 D=不可中断的睡眠状态 R=运行 S=睡眠 T=跟踪/停止 Z=僵尸进程 x COMMAND 命令名/命令行 y WCHAN 若该进程在睡眠，则显示睡眠中的系统函数名 z Flags 任务标志，参考 sched.h } linux操作系统提供的信号{ kill -l # 查看linux提供的信号 trap \"echo aaa\" 2 3 15 # shell使用 trap 捕捉退出信号 # 发送信号一般有两种原因: # 1(被动式) 内核检测到一个系统事件.例如子进程退出会像父进程发送SIGCHLD信号.键盘按下control+c会发送SIGINT信号 # 2(主动式) 通过系统调用kill来向指定进程发送信号 # 进程结束信号 SIGTERM 和 SIGKILL 的区别: SIGTERM 比较友好，进程能捕捉这个信号，根据您的需要来关闭程序。在关闭程序之前，您可以结束打开的记录文件和完成正在做的任务。在某些情况下，假如进程正在进行作业而且不能中断，那么进程可以忽略这个SIGTERM信号。 # 如果一个进程收到一个SIGUSR1信号，然后执行信号绑定函数，第二个SIGUSR2信号又来了，第一个信号没有被处理完毕的话，第二个信号就会丢弃。 SIGHUP 1 A # 终端挂起或者控制进程终止 SIGINT 2 A # 键盘终端进程(如control+c) SIGQUIT 3 C # 键盘的退出键被按下 SIGILL 4 C # 非法指令 SIGABRT 6 C # 由abort(3)发出的退出指令 SIGFPE 8 C # 浮点异常 SIGKILL 9 AEF # Kill信号 立刻停止 SIGSEGV 11 C # 无效的内存引用 SIGPIPE 13 A # 管道破裂: 写一个没有读端口的管道 SIGALRM 14 A # 闹钟信号 由alarm(2)发出的信号 SIGTERM 15 A # 终止信号,可让程序安全退出 kill -15 SIGUSR1 30,10,16 A # 用户自定义信号1 SIGUSR2 31,12,17 A # 用户自定义信号2 SIGCHLD 20,17,18 B # 子进程结束自动向父进程发送SIGCHLD信号 SIGCONT 19,18,25 # 进程继续（曾被停止的进程） SIGSTOP 17,19,23 DEF # 终止进程 SIGTSTP 18,20,24 D # 控制终端（tty）上按下停止键 SIGTTIN 21,21,26 D # 后台进程企图从控制终端读 SIGTTOU 22,22,27 D # 后台进程企图从控制终端写 缺省处理动作一项中的字母含义如下: A 缺省的动作是终止进程 B 缺省的动作是忽略此信号，将该信号丢弃，不做处理 C 缺省的动作是终止进程并进行内核映像转储(dump core),内核映像转储是指将进程数据在内存的映像和进程在内核结构中的部分内容以一定格式转储到文件系统，并且进程退出执行，这样做的好处是为程序员提供了方便，使得他们可以得到进程当时执行时的数据值，允许他们确定转储的原因，并且可以调试他们的程序。 D 缺省的动作是停止进程，进入停止状况以后还能重新进行下去，一般是在调试的过程中（例如ptrace系统调用） E 信号不能被捕获 F 信号不能被忽略 } } 日志管理{ history # 历时命令默认1000条 HISTTIMEFORMAT=\"%Y-%m-%d %H:%M:%S \" # 让history命令显示具体时间 history -c # 清除记录命令 cat $HOME/.bash_history # 历史命令记录文件 last # 查看登陆过的用户信息 who /var/log/wtmp # 查看登陆过的用户信息 lastlog # 用户最后登录的时间 lastb -a # 列出登录系统失败的用户相关信息 /var/log/btmp # 登录失败二进制日志记录文件 tail -f /var/log/messages # 系统日志 tail -f /var/log/secure # ssh日志 } selinux{ sestatus -v # 查看selinux状态 getenforce # 查看selinux模式 setenforce 0 # 设置selinux为宽容模式(可避免阻止一些操作) semanage port -l # 查看selinux端口限制规则 semanage port -a -t http_port_t -p tcp 8000 # 在selinux中注册端口类型 vi /etc/selinux/config # selinux配置文件 SELINUX=enfoceing # 关闭selinux 把其修改为 SELINUX=disabled } 查看剩余内存{ free -m #-/+ buffers/cache: 6458 1649 #6458M为真实使用内存 1649M为真实剩余内存(剩余内存+缓存+缓冲器) #linux会利用所有的剩余内存作为缓存，所以要保证linux运行速度，就需要保证内存的缓存大小 } 系统信息{ uname -a # 查看Linux内核版本信息 cat /proc/version # 查看内核版本 cat /etc/issue # 查看系统版本 lsb_release -a # 查看系统版本 需安装 centos-release locale -a # 列出所有语系 hwclock # 查看时间 who # 当前在线用户 w # 当前在线用户 whoami # 查看当前用户名 logname # 查看初始登陆用户名 uptime # 查看服务器启动时间 sar -n DEV 1 10 # 查看网卡网速流量 dmesg # 显示开机信息 lsmod # 查看内核模块 } 硬件信息{ more /proc/cpuinfo # 查看cpu信息 cat /proc/cpuinfo | grep name | cut -f2 -d: | uniq -c # 查看cpu型号和逻辑核心数 getconf LONG_BIT # cpu运行的位数 cat /proc/cpuinfo | grep physical | uniq -c # 物理cpu个数 cat /proc/cpuinfo | grep flags | grep ' lm ' | wc -l # 结果大于0支持64位 cat /proc/cpuinfo|grep flags # 查看cpu是否支持虚拟化 pae支持半虚拟化 IntelVT 支持全虚拟化 more /proc/meminfo # 查看内存信息 dmidecode # 查看全面硬件信息 dmidecode | grep \"Product Name\" # 查看服务器型号 dmidecode | grep -P -A5 \"Memory\\s+Device\" | grep Size | grep -v Range # 查看内存插槽 cat /proc/mdstat # 查看软raid信息 cat /proc/scsi/scsi # 查看Dell硬raid信息(IBM、HP需要官方检测工具) lspci # 查看硬件信息 lspci|grep RAID # 查看是否支持raid lspci -vvv |grep Ethernet # 查看网卡型号 lspci -vvv |grep Kernel|grep driver # 查看驱动模块 modinfo tg2 # 查看驱动版本(驱动模块) ethtool -i em1 # 查看网卡驱动版本 } 终端快捷键{ Ctrl+A 　 # 行前 Ctrl+E 　 # 行尾 Ctrl+S 　 # 终端锁屏 Ctrl+Q 　　 # 解锁屏 Ctrl+D 　　 # 退出 } 开机启动模式{ vi /etc/inittab id:3:initdefault: # 3为多用户命令 #ca::ctrlaltdel:/sbin/shutdown -t3 -r now # 注释此行 禁止 ctrl+alt+del 关闭计算机 } 终端提示显示{ echo $PS1 # 环境变量控制提示显示 PS1='[\\u@ \\H \\w \\A \\@#]\\$' PS1='[\\u@\\h \\W]\\$' } 定时任务{ at 5pm + 3 days /bin/ls # 单次定时任务 指定三天后下午5:00执行/bin/ls crontab -e # 编辑周期任务 #分钟 小时 天 月 星期 命令或脚本 1,30 1-3/2 * * * 命令或脚本 >> file.log 2>&1 echo \"40 7 * * 2 /root/sh\">>/var/spool/cron/root # 直接将命令写入周期任务 crontab -l # 查看自动周期性任务 crontab -r # 删除自动周期性任务 cron.deny和cron.allow # 禁止或允许用户使用周期任务 service crond start|stop|restart # 启动自动周期性服务 } date{ date -s 20091112 # 设日期 date -s 18:30:50 # 设时间 date -d \"7 days ago\" +%Y%m%d # 7天前日期 date -d \"5 minute ago\" +%H:%M # 5分钟前时间 date -d \"1 month ago\" +%Y%m%d # 一个月前 date +%Y-%m-%d -d '20110902' # 日期格式转换 date +%Y-%m-%d_%X # 日期和时间 date +%N # 纳秒 date -d \"2012-08-13 14:00:23\" +%s # 换算成秒计算(1970年至今的秒数) date -d \"@1363867952\" +%Y-%m-%d-%T # 将时间戳换算成日期 date -d \"1970-01-01 UTC 1363867952 seconds\" +%Y-%m-%d-%T # 将时间戳换算成日期 date -d \"`awk -F. '{print $1}' /proc/uptime` second ago\" +\"%Y-%m-%d %H:%M:%S\" # 格式化系统启动时间(多少秒前) } 最大连接数{ ulimit -SHn 65535 # 修改最大打开文件数(等同最大连接数) ulimit -a # 查看 /etc/security/limits.conf # 进程最大打开文件数 # nofile 可以被理解为是文件句柄数 文件描述符 还有socket数 * soft nofile 65535 * hard nofile 65535 # 最大进程数 * soft nproc 65535 * hard nproc 65535 # 如果/etc/security/limits.d/有配置文件，将会覆盖/etc/security/limits.conf里的配置 # 即/etc/security/limits.d/的配置文件里就不要有同样的参量设置 /etc/security/limits.d/90-nproc.conf # centos6.3的最大进程数文件 * soft nproc 65535 * hard nproc 65535 } sudo{ visudo # sudo命令权限添加 用户 别名(可用all)=NOPASSWD:命令1，命令2 wangming linuxfan=NOPASSWD:/sbin/apache start,/sbin/apache restart UserName ALL=(ALL) ALL peterli ALL=(ALL) NOPASSWD:/sbin/service Defaults requiretty # sudo不允许后台运行,注释此行既允许 Defaults !visiblepw # sudo不允许远程,去掉!既允许 } grub开机启动项添加{ vim /etc/grub.conf title ms-dos rootnoverify (hd0,0) chainloader +1 } stty{ #stty时一个用来改变并打印终端行设置的常用命令 stty iuclc # 在命令行下禁止输出大写 stty -iuclc # 恢复输出大写 stty olcuc # 在命令行下禁止输出小写 stty -olcuc # 恢复输出小写 stty size # 打印出终端的行数和列数 stty eof \"string\" # 改变系统默认ctrl+D来表示文件的结束 stty -echo # 禁止回显 stty echo # 打开回显 stty -echo;read;stty echo;read # 测试禁止回显 stty igncr # 忽略回车符 stty -igncr # 恢复回车符 stty erase '#' # 将#设置为退格字符 stty erase '^?' # 恢复退格字符 定时输入{ timeout_read(){ timeout=$1 old_stty_settings=`stty -g`　　# save current settings stty -icanon min 0 time 100　　# set 10seconds,not 100seconds eval read varname　　 # =read $varname stty \"$old_stty_settings\"　　 # recover settings } read -t 10 varname # 更简单的方法就是利用read命令的-t选项 } 检测用户按键{ #!/bin/bash old_tty_settings=$(stty -g) # 保存老的设置(为什么?). stty -icanon Keypress=$(head -c1) # 或者使用$(dd bs=1 count=1 2> /dev/null) echo \"Key pressed was \\\"\"$Keypress\"\\\".\" stty \"$old_tty_settings\" # 恢复老的设置. exit 0 } } iptables{ 内建三个表：nat mangle 和 filter filter预设规则表，有INPUT、FORWARD 和 OUTPUT 三个规则链 vi /etc/sysconfig/iptables # 配置文件 INPUT # 进入 FORWARD # 转发 OUTPUT # 出去 ACCEPT # 将封包放行 REJECT # 拦阻该封包 DROP # 丢弃封包不予处理 -A # 在所选择的链(INPUT等)末添加一条或更多规则 -D # 删除一条 -E # 修改 -p # tcp、udp、icmp 0相当于所有all !取反 -P # 设置缺省策略(与所有链都不匹配强制使用此策略) -s # IP/掩码 (IP/24) 主机名、网络名和清楚的IP地址 !取反 -j # 目标跳转，立即决定包的命运的专用内建目标 -i # 进入的（网络）接口 [名称] eth0 -o # 输出接口[名称] -m # 模块 --sport # 源端口 --dport # 目标端口 iptables -F # 将防火墙中的规则条目清除掉 # 注意: iptables -P INPUT ACCEPT iptables-restore /proc/sys/net/ipv4/ip_forward # 在内核里打开ip转发功能 iptables -t nat -A POSTROUTING -s 10.8.0.0/24 -j MASQUERADE # 添加网段转发 iptables -t nat -A POSTROUTING -s 10.0.0.0/255.0.0.0 -o eth0 -j SNAT --to 192.168.10.158 # 原IP网段经过哪个网卡IP出去 iptables -t nat -nL # 查看转发 } 端口映射{ # 内网通过有外网IP的机器映射端口 echo 1 > /proc/sys/net/ipv4/ip_forward # 在内核里打开ip转发功能 route add -net 10.10.20.0 netmask 255.255.255.0 gw 10.10.20.111 # 内网需要添加默认网关，并且网关开启转发 iptables -t nat -A PREROUTING -d 192.168.10.158 -p tcp --dport 9999 -j DNAT --to 10.10.20.55:22 iptables -t nat -nL # 查看转发 } } } 4服务{ /etc/init.d/sendmail start # 启动服务 /etc/init.d/sendmail stop # 关闭服务 /etc/init.d/sendmail status # 查看服务当前状态 /date/mysql/bin/mysqld_safe --user=mysql & # 启动mysql后台运行 vi /etc/rc.d/rc.local # 开机启动执行 可用于开机启动脚本 /etc/rc.d/rc3.d/S55sshd # 开机启动和关机关闭服务连接 # S开机start K关机stop 55级别 后跟服务名 ln -s -f /date/httpd/bin/apachectl /etc/rc.d/rc3.d/S15httpd # 将启动程序脚本连接到开机启动目录 ipvsadm -ln # lvs查看后端负载机并发 ipvsadm -C # lvs清除规则 xm list # 查看xen虚拟主机列表 virsh # 虚拟化(xen\\kvm)管理工具 yum groupinstall Virtual* ./bin/httpd -M # 查看httpd加载模块 httpd -t -D DUMP_MODULES # rpm包httpd查看加载模块 echo 内容| /bin/mail -s \"标题\" 收件箱 -- -f 发件人 # 发送邮件 \"`echo \"内容\"|iconv -f utf8 -t gbk`\" | /bin/mail -s \"`echo \"标题\"|iconv -f utf8 -t gbk`\" 收件箱 # 解决邮件乱码 /usr/local/nagios/bin/nagios -v /usr/local/nagios/etc/nagios.cfg # 检测nagios配置文件 chkconfig{ chkconfig 服务名 on|off|set # 设置非独立服务启状态 chkconfig --level 35 httpd off # 让服务不自动启动 chkconfig --level 35 httpd on # 让服务自动启动 35指的是运行级别 chkconfig --list # 查看所有服务的启动状态 chkconfig --list |grep httpd # 查看某个服务的启动状态 chkconfig –-list [服务名称] # 查看服务的状态 } httpd{ 编译参数{ # so模块用来提供DSO支持的apache核心模块 # 如果编译中包含任何DSO模块，则mod_so会被自动包含进核心。 # 如果希望核心能够装载DSO，但不实际编译任何DSO模块，则需明确指定\"--enable-so=static\" ./configure --prefix=/usr/local/apache --enable-so --enable-mods-shared=most --enable-rewrite --enable-forward # 实例编译 --with-mpm=worker # 已worker方式运行 --with-apxs=/usr/local/apache/bin/apxs # 制作apache的动态模块DSO rpm包 httpd-devel #编译模块 apxs -i -a -c mod_foo.c --enable-so # 让Apache可以支持DSO模式 --enable-mods-shared=most # 告诉编译器将所有标准模块都动态编译为DSO模块 --enable-rewrite # 支持地址重写功能 --enable-module=most # 用most可以将一些不常用的，不在缺省常用模块中的模块编译进来 --enable-mods-shared=all # 意思是动态加载所有模块，如果去掉-shared话，是静态加载所有模块 --enable-expires # 可以添加文件过期的限制，有效减轻服务器压力，缓存在用户端，有效期内不会再次访问服务器，除非按f5刷新，但也导致文件更新不及时 --enable-deflate # 压缩功能，网页可以达到40%的压缩，节省带宽成本，但会对cpu压力有一点提高 --enable-headers # 文件头信息改写，压缩功能需要 --disable-MODULE # 禁用MODULE模块(仅用于基本模块) --enable-MODULE=shared # 将MODULE编译为DSO(可用于所有模块) --enable-mods-shared=MODULE-LIST # 将MODULE-LIST中的所有模块都编译成DSO(可用于所有模块) --enable-modules=MODULE-LIST # 将MODULE-LIST静态连接进核心(可用于所有模块) # 上述 MODULE-LIST 可以是: 1、用引号界定并且用空格分隔的模块名列表 --enable-mods-shared='headers rewrite dav' 2、\"most\"(大多数模块) --enable-mods-shared=most 3、\"all\"(所有模块) } 转发{ #针对非80端口的请求处理 RewriteCond %{SERVER_PORT} !^80$ RewriteRule ^/(.*) http://fully.qualified.domain.name:%{SERVER_PORT}/$1 [L,R] RewriteCond %{HTTP_HOST} ^ss.aa.com [NC] RewriteRule ^(.*) http://www.aa.com/so/$1/0/p0? [L,R=301] #RewriteRule 只对?前处理，所以会把?后的都保留下来 #在转发后地址后加?即可取消RewriteRule保留的字符 #R的含义是redirect，即重定向，该请求不会再被apache交给后端处理，而是直接返回给浏览器进行重定向跳转。301是返回的http状态码，具体可以参考http rfc文档，跳转都是3XX。 #L是last，即最后一个rewrite规则，如果请求被此规则命中，将不会继续再向下匹配其他规则。 } } mysql源码安装{ groupadd mysql useradd mysql -g mysql -M -s /bin/false tar zxvf mysql-5.0.22.tar.gz cd mysql-5.0.22 ./configure --prefix=/usr/local/mysql \\ --with-client-ldflags=-all-static \\ --with-mysqld-ldflags=-all-static \\ --with-mysqld-user=mysql \\ --with-extra-charsets=all \\ --with-unix-socket-path=/var/tmp/mysql.sock make && make install # 生成mysql用户数据库和表文件，在安装包中输入 scripts/mysql_install_db --user=mysql vi ~/.bashrc export PATH=\"$PATH: /usr/local/mysql/bin\" # 配置文件,有large,medium,small三个，根据机器性能选择 cp support-files/my-medium.cnf /etc/my.cnf cp support-files/mysql.server /etc/init.d/mysqld chmod 700 /etc/init.d/mysqld cd /usr/local chmod 750 mysql -R chgrp mysql mysql -R chown mysql mysql/var -R cp /usr/local/mysql/libexec/mysqld mysqld.old ln -s /usr/local/mysql/bin/mysql /sbin/mysql ln -s /usr/local/mysql/bin/mysqladmin /sbin/mysqladmin ln -s -f /usr/local/mysql/bin/mysqld_safe /etc/rc.d/rc3.d/S15mysql5 ln -s -f /usr/local/mysql/bin/mysqld_safe /etc/rc.d/rc0.d/K15mysql5 } mysql常用命令{ ./mysql/bin/mysqld_safe --user=mysql & # 启动mysql服务 ./mysql/bin/mysqladmin -uroot -p -S ./mysql/data/mysql.sock shutdown # 停止mysql服务 mysqlcheck -uroot -p -S mysql.sock --optimize --databases account # 检查、修复、优化MyISAM表 mysqlbinlog slave-relay-bin.000001 # 查看二进制日志(报错加绝对路径) mysqladmin -h myhost -u root -p create dbname # 创建数据库 flush privileges; # 刷新 show databases; # 显示所有数据库 use dbname; # 打开数据库 show tables; # 显示选中数据库中所有的表 desc tables; # 查看表结构 drop database name; # 删除数据库 drop table name; # 删除表 create database name; # 创建数据库 select 列名称 from 表名称; # 查询 show grants for repl; # 查看用户权限 show processlist; # 查看mysql进程 select user(); # 查看所有用户 show slave status\\G; # 查看主从状态 show variables; # 查看所有参数变量 show table status # 查看表的引擎状态 drop table if exists user # 表存在就删除 create table if not exists user # 表不存在就创建 select host,user,password from user; # 查询用户权限 先use mysql create table ka(ka_id varchar(6),qianshu int); # 创建表 SHOW VARIABLES LIKE 'character_set_%'; # 查看系统的字符集和排序方式的设定 show variables like '%timeout%'; # 查看超时(wait_timeout) delete from user where user=''; # 删除空用户 delete from user where user='sss' and host='localhost' ; # 删除用户 ALTER TABLE mytable ENGINE = MyISAM ; # 改变现有的表使用的存储引擎 SHOW TABLE STATUS from 库名 where Name='表名'; # 查询表引擎 CREATE TABLE innodb (id int, title char(20)) ENGINE = INNODB # 创建表指定存储引擎的类型(MyISAM或INNODB) grant replication slave on *.* to '用户'@'%' identified by '密码'; # 创建主从复制用户 ALTER TABLE player ADD INDEX weekcredit_faction_index (weekcredit, faction); # 添加索引 alter table name add column accountid(列名) int(11) NOT NULL(字段不为空); # 插入字段 update host set monitor_state='Y',hostname='xuesong' where ip='192.168.1.1'; # 更新数据 自增表{ create table oldBoy (id INTEGER PRIMARY KEY AUTO_INCREMENT, name CHAR(30) NOT NULL, age integer , sex CHAR(15) ); # 创建自增表 insert into oldBoy(name,age,sex) values(%s,%s,%s) # 自增插入数据 } 登录mysql的命令{ # 格式： mysql -h 主机地址 -u 用户名 -p 用户密码 mysql -h110.110.110.110 -P3306 -uroot -p mysql -uroot -p -S /data1/mysql5/data/mysql.sock -A --default-character-set=GBK } shell执行mysql命令{ mysql -u$username -p$passwd -h$dbhost -P$dbport -A -e \" use $dbname; delete from data where date=('$date1'); \" # 执行多条mysql命令 mysql -uroot -p -S mysql.sock -e \"use db;alter table gift add column accountid int(11) NOT NULL;flush privileges;\" # 不登陆mysql插入字段 } 备份数据库{ mysqldump -h host -u root -p --default-character-set=utf8 dbname >dbname_backup.sql # 不包括库名，还原需先创建库，在use mysqldump -h host -u root -p --database --default-character-set=utf8 dbname >dbname_backup.sql # 包括库名，还原不需要创建库 /bin/mysqlhotcopy -u root -p # mysqlhotcopy只能备份MyISAM引擎 mysqldump -u root -p -S mysql.sock --default-character-set=utf8 dbname table1 table2 > /data/db.sql # 备份表 mysqldump -uroot -p123 -d database > database.sql # 备份数据库结构 innobackupex --user=root --password=\"\" --defaults-file=/data/mysql5/data/my_3306.cnf --socket=/data/mysql5/data/mysql.sock --slave-info --stream=tar --tmpdir=/data/dbbackup/temp /data/dbbackup/ 2>/data/dbbackup/dbbackup.log | gzip 1>/data/dbbackup/db50.tar.gz # xtrabackup备份需单独安装软件 优点: 速度快,压力小,可直接恢复主从复制 } 还原数据库{ mysql -h host -u root -p dbname } 5网络{ rz # 通过ssh上传小文件 sz # 通过ssh下载小文件 ifconfig eth0 down # 禁用网卡 ifconfig eth0 up # 启用网卡 ifup eth0:0 # 启用网卡 mii-tool em1 # 查看网线是否连接 traceroute www.baidu.com # 测试跳数 vi /etc/resolv.conf # 设置DNS nameserver IP 定义DNS服务器的IP地址 nslookup www.moon.com # 解析域名IP dig -x www.baidu.com # 解析域名IP curl -I www.baidu.com # 查看网页http头 tcpdump tcp port 22 # 抓包 lynx # 文本上网 wget -P 路径 http地址 # 下载 包名:wgetrc curl -d \"user=xuesong&pwd=123\" http://www.abc.cn/Result # 提交web页面表单 需查看表单提交地址 rsync -avzP -e \"ssh -p 22\" /dir user@$IP:/dir # 同步目录 # --delete 无差同步 删除目录下其它文件 ifconfig eth0:0 192.168.1.221 netmask 255.255.255.0 # 增加逻辑IP地址 mtr -r www.baidu.com # 测试网络链路节点响应时间 # trace ping 结合 echo 1 > /proc/sys/net/ipv4/icmp_echo_ignore_all # 禁ping ipcalc -m \"$ip\" -p \"$num\" # 根据IP和主机最大数计算掩码 dig +short txt hacker.wp.dg.cx # 通过 DNS 来读取 Wikipedia 的hacker词条 host -t txt hacker.wp.dg.cx # 通过 DNS 来读取 Wikipedia 的hacker词条 net rpc shutdown -I IP_ADDRESS -U username%password # 远程关掉一台WINDOWS机器 wget --random-wait -r -p -e robots=off -U Mozilla www.example.com # 递归方式下载整个网站 netstat{ -a # 显示所有连接中的Socket -t # 显示TCP连接 -u # 显示UDP连接 -n # 显示所有已建立的有效连接 netstat -anlp # 查看链接 netstat –r # 查看路由表 } ssh{ ssh -p 22 user@192.168.1.209 # 从linux ssh登录另一台linux ssh -p 22 root@192.168.1.209 CMD # 利用ssh操作远程主机 scp -P 22 文件 root@ip:/目录 # 把本地文件拷贝到远程主机 sshpass -p '密码' ssh -n root@$IP \"echo hello\" # 指定密码远程操作 ssh -o StrictHostKeyChecking=no $IP # ssh连接不提示yes ssh -t \"su -\" # 指定伪终端 客户端以交互模式工作 scp root@192.168.1.209:远程目录 本地目录 # 把远程指定文件拷贝到本地 ssh -N -L2001:remotehost:80 user@somemachine # 用SSH创建端口转发通道 ssh -t host_A ssh host_B # 嵌套使用SSH ssh -t -p 22 $user@$Ip /bin/su - root -c {$Cmd}; # 远程su执行命令 Cmd=\"\\\"/sbin/ifconfig eth0\\\"\" ssh-keygen -t rsa # 生成密钥 ssh-copy-id -i xuesong@10.10.10.133 # 传送key vi $HOME/.ssh/authorized_keys # 公钥存放位置 sshfs name@server:/path/to/folder /path/to/mount/point # 通过ssh挂载远程主机上的文件夹 fusermount -u /path/to/mount/point # 卸载ssh挂载的目录 ssh user@host cat /path/to/remotefile | diff /path/to/localfile - # 用DIFF对比远程文件跟本地文件 su - user -c \"ssh user@192.168.1.1 \\\"echo -e aa |mail -s test mail@163.com\\\"\" # 切换用户登录远程发送邮件 } 网卡配置文件{ vi /etc/sysconfig/network-scripts/ifcfg-eth0 DEVICE=eth0 BOOTPROTO=none BROADCAST=192.168.1.255 HWADDR=00:0C:29:3F:E1:EA IPADDR=192.168.1.55 NETMASK=255.255.255.0 NETWORK=192.168.1.0 ONBOOT=yes TYPE=Ethernet GATEWAY=192.168.1.1 } route { route # 查看路由表 route add default gw 192.168.1.1 dev eth0 # 添加默认路由 route add -net 172.16.0.0 netmask 255.255.0.0 gw 10.39.111.254 # 添加静态路由网关 route del -net 172.16.0.0 netmask 255.255.0.0 gw 10.39.111.254 # 删除静态路由网关 } 解决ssh链接慢{ sed -i 's/GSSAPIAuthentication yes/GSSAPIAuthentication no/' /etc/ssh/sshd_config sed -i '/#UseDNS yes/a\\UseDNS no' /etc/ssh/sshd_config /etc/init.d/sshd restart } ftp上传{ ftp -i -v -n $HOST END } nmap{ nmap -PT 192.168.1.1-111 # 先ping在扫描主机开放端口 nmap -O 192.168.1.1 # 扫描出系统内核版本 nmap -sV 192.168.1.1-111 # 扫描端口的软件版本 nmap -sS 192.168.1.1-111 # 半开扫描(通常不会记录日志) nmap -P0 192.168.1.1-111 # 不ping直接扫描 nmap -d 192.168.1.1-111 # 详细信息 nmap -D 192.168.1.1-111 # 无法找出真正扫描主机(隐藏IP) nmap -p 20-30,139,60000- # 端口范围 表示：扫描20到30号端口，139号端口以及所有大于60000的端口 nmap -P0 -sV -O -v 192.168.30.251 # 组合扫描(不ping、软件版本、内核版本、详细信息) # 不支持windows的扫描(可用于判断是否是windows) nmap -sF 192.168.1.1-111 nmap -sX 192.168.1.1-111 nmap -sN 192.168.1.1-111 } 流量切分线路{ # 程序判断进入IP线路，设置服务器路由规则控制返回 vi /etc/iproute2/rt_tables #添加一条策略 252 bgp2 #注意策略的序号顺序 ip route add default via 第二个出口上线IP(非默认网关) dev eth1 table bgp2 ip route add from 本机第二个ip table bgp2 #查看 ip route list table 252 ip rule list #成功后将语句添加开机启动 } snmp{ snmptranslate .1.3.6.1.2.1.1.3.0 # 查看映射关系 DISMAN-EVENT-MIB::sysUpTimeInstance snmpdf -v 1 -c public localhost # SNMP监视远程主机的磁盘空间 snmpnetstat -v 2c -c public -a 192.168.6.53 # SNMP获取指定IP的所有开放端口状态 snmpwalk -v 2c -c public 10.152.14.117 .1.3.6.1.2.1.1.3.0 # SNMP获取主机启动时间 # MIB安装(ubuntu) # sudo apt-get install snmp-mibs-downloader # sudo download-mibs snmpwalk -v 2c -c public 10.152.14.117 sysUpTimeInstance # SNMP通过MIB库获取主机启动时间 } } 6磁盘{ df -Ph # 查看硬盘容量 df -T # 查看磁盘分区格式 df -i # 查看inode节点 如果inode用满后无法创建文件 du -h 目录 # 检测目录下所有文件大小 du -sh * # 显示当前目录中子目录的大小 iostat -x # 查看磁盘io状态 mount # 查看分区挂载情况 fdisk -l # 查看磁盘分区状态 fdisk /dev/hda3 # 分区 mkfs -t ext3 /dev/hda3 # 格式化分区 fsck -y /dev/sda6 # 对文件系统修复 lsof |grep delete # 释放进程占用磁盘空间 列出进程后，查看文件是否存在，不存在则kill掉此进程 tmpwatch -afv 3 # 删除3小时内的临时文件 cat /proc/filesystems # 查看当前系统支持文件系统 mount -o remount,rw / # 修改只读文件系统为读写 smartctl -H /dev/sda # 检测硬盘状态 smartctl -i /dev/sda # 检测硬盘信息 smartctl -a /dev/sda # 检测所有信息 e2label /dev/sda5 # 查看卷标 e2label /dev/sda5 new-label # 创建卷标 ntfslabel -v /dev/sda8 new-label # NTFS添加卷标 tune2fs -j /dev/sda # ext2分区转ext3分区 mke2fs -b 2048 /dev/sda5 # 指定索引块大小 dumpe2fs -h /dev/sda5 # 查看超级块的信息 mount -t iso9660 /dev/dvd /mnt # 挂载光驱 mount -t ntfs-3g /dev/sdc1 /media/yidong # 挂载ntfs硬盘 mount -t nfs 10.0.0.3:/opt/images/ /data/img # 挂载nfs mount -o loop /software/rhel4.6.iso /mnt/ # 挂载镜像文件 创建swap文件方法{ dd if=/dev/zero of=/swap bs=1024 count=4096000 # 创建一个足够大的文件 # count的值等于1024 x 你想要的文件大小, 4096000是4G mkswap /swap # 把这个文件变成swap文件 swapon /swap # 启用这个swap文件 /swap swap swap defaults 0 0 # 在每次开机的时候自动加载swap文件, 需要在 /etc/fstab 文件中增加一行 cat /proc/swaps # 查看swap swapoff -a # 关闭swap swapon -a # 开启swap } 新硬盘挂载{ fdisk /dev/sdc p # 打印分区 d # 删除分区 n # 创建分区，（一块硬盘最多4个主分区，扩展占一个主分区位置。p主分区 e扩展） w # 保存退出 mkfs -t ext3 -L 卷标 /dev/sdc1 # 格式化相应分区 mount /dev/sdc1 /mnt # 挂载 vi /etc/fstab # 添加开机挂载分区 LABEL=/data /data ext3 defaults 1 2 # 用卷标挂载 /dev/sdb1 /data4 ext3 defaults 1 2 # 用真实分区挂载 /dev/sdb2 /data4 ext3 noatime,defaults 1 2 第一个数字\"1\"该选项被\"dump\"命令使用来检查一个文件系统应该以多快频率进行转储，若不需要转储就设置该字段为0 第二个数字\"2\"该字段被fsck命令用来决定在启动时需要被扫描的文件系统的顺序，根文件系统\"/\"对应该字段的值应该为1，其他文件系统应该为2。若该文件系统无需在启动时扫描则设置该字段为0 当以 noatime 选项加载（mount）文件系统时，对文件的读取不会更新文件属性中的atime信息。设置noatime的重要性是消除了文件系统对文件的写操作，文件只是简单地被系统读取。由于写操作相对读来说要更消耗系统资源，所以这样设置可以明显提高服务器的性能.wtime信息仍然有效，任何时候文件被写，该信息仍被更新。 } raid原理与区别{ raid0至少2块硬盘.吞吐量大,性能好,同时读写,但损坏一个就完蛋 raid1至少2块硬盘.相当镜像,一个存储,一个备份.安全性比较高.但是性能比0弱 raid5至少3块硬盘.分别存储校验信息和数据，坏了一个根据校验信息能恢复 raid6至少4块硬盘.两个独立的奇偶系统,可坏两块磁盘,写性能非常差 } } 7用户{ users # 显示所有的登录用户 groups # 列出当前用户和他所属的组 who -q # 显示所有的登录用户 groupadd # 添加组 useradd user # 建立用户 passwd 用户 # 修改密码 userdel -r # 删除帐号及家目录 chown -R user:group # 修改目录拥有者(R递归) chown y\\.li:mysql # 修改所有者用户中包含点\".\" umask # 设置用户文件和目录的文件创建缺省屏蔽值 chgrp # 修改用户组 finger # 查找用户显示信息 echo \"xuesong\" | passwd user --stdin # 非交互修改密码 useradd -g www -M -s /sbin/nologin www # 指定组并不允许登录的用户,nologin允许使用服务 useradd -g www -M -s /bin/false www # 指定组并不允许登录的用户,false最为严格 usermod -l 新用户名 老用户名 # 修改用户名 usermod -g user group # 修改用户所属组 usermod -d 目录 -m 用户 # 修改用户家目录 usermod -G group user # 将用户添加到附加组 gpasswd -d user group # 从组中删除用户 su - user -c \" #命令1; \" # 切换用户执行 恢复密码{ # 即进入单用户模式: 在linux出现grub后，在安装的系统上面按\"e\"，然后出现grub的配置文件，按键盘移动光标到第二行\"Ker……\"，再按\"e\"，然后在这一行的结尾加上：空格 single或者空格1回车，然后按\"b\"重启，就进入了\"单用户模式\" } 特殊权限{ s或 S （SUID）：对应数值4 s或 S （SGID）：对应数值2 t或 T ：对应数值1 大S：代表拥有root权限，但是没有执行权限 小s：拥有特权且拥有执行权限，这个文件可以访问系统任何root用户可以访问的资源 T或T（Sticky）：/tmp和 /var/tmp目录供所有用户暂时存取文件，亦即每位用户皆拥有完整的权限进入该目录，去浏览、删除和移动文件 } } 8脚本{ #!/bin/sh # 在脚本第一行脚本头 # sh为当前系统默认shell,可指定为bash等shell sh -x # 执行过程 sh -n # 检查语法 (a=bbk) # 括号创建子shell运行 basename /a/b/c # 从全路径中保留最后一层文件名或目录 dirname # 取路径 $RANDOM # 随机数 $$ # 进程号 source FileName # 在当前bash环境下读取并执行FileName中的命令 # 等同 . FileName sleep 5 # 间隔睡眠5秒 trap # 在接收到信号后将要采取的行动 trap \"\" 2 3 # 禁止ctrl+c $PWD # 当前目录 $HOME # 家目录 $OLDPWD # 之前一个目录的路径 cd - # 返回上一个目录路径 local ret # 局部变量 yes # 重复打印 yes |rm -i * # 自动回答y或者其他 ls -p /home # 查看目录所有文件夹 ls -d /home/ # 查看匹配完整路径 echo -n aa;echo bb # 不换行执行下一句话 将字符串原样输出 echo -e \"s\\tss\\n\\n\\n\" # 使转义生效 echo $a | cut -c2-6 # 取字符串中字元 echo {a,b,c}{a,b,c}{a,b,c} # 排列组合(括号内一个元素分别和其他括号内元素组合) echo $((2#11010)) # 二进制转10进制 echo aaa | tee file # 打印同时写入文件 默认覆盖 -a追加 echo {1..10} # 打印10个字符 printf '%10s\\n'|tr \" \" a # 打印10个字符 pwd | awk -F/ '{ print $2 }' # 返回目录名 tac file |sed 1,3d|tac # 倒置读取文件 # 删除最后3行 tail -3 file # 取最后3行 outtmp=/tmp/$$`date +%s%N`.outtmp # 临时文件定义 :(){ :|:& };: # 著名的 fork炸弹,系统执行海量的进程,直到系统僵死 echo -e \"\\e[32m....\\e[0m\" # 打印颜色 echo -e \"\\033[0;31mL\\033[0;32mO\\033[0;33mV\\033[0;34mE\\t\\033[0;35mY\\033[0;36mO\\033[0;32mU\\e[m\" # 打印颜色 xargs{ # 命令替换 -t 先打印命令，然后再执行 -i 用每项替换 {} find / -perm +7000 | xargs ls -l # 将前面的内容，作为后面命令的参数 seq 1 10 |xargs -i date -d \"{} days \" +%Y-%m-%d # 列出10天日期 } 正则表达式{ ^ # 行首定位 $ # 行尾定位 . # 匹配除换行符以外的任意字符 * # 匹配0或多个重复字符 + # 重复一次或更多次 ? # 重复零次或一次 ? # 结束贪婪因子 .*? 表示最小匹配 [] # 匹配一组中任意一个字符 [^] # 匹配不在指定组内的字符 \\ # 用来转义元字符 # 词尾定位符(支持vi和grep) love> x\\{m\\} # 重复出现m次 x\\{m,\\} # 重复出现至少m次 x\\{m,n\\} # 重复出现至少m次不超过n次 X? # 匹配出现零次或一次的大写字母 X X+ # 匹配一个或多个字母 X () # 括号内的字符为一组 (ab|de)+ # 匹配一连串的（最少一个） abc 或 def；abc 和 def 将匹配 [[:alpha:]] # 代表所有字母不论大小写 [[:lower:]] # 表示小写字母 [[:upper:]] # 表示大写字母 [[:digit:]] # 表示数字字符 [[:digit:][:lower:]] # 表示数字字符加小写字母 元字符{ \\d # 匹配任意一位数字 \\D # 匹配任意单个非数字字符 \\w # 匹配任意单个字母数字下划线字符，同义词是 [:alnum:] \\W # 匹配非数字型的字符 } 字符类:空白字符{ \\s # 匹配任意的空白符 \\S # 匹配非空白字符 \\b # 匹配单词的开始或结束 \\n # 匹配换行符 \\r # 匹配回车符 \\t # 匹配制表符 \\b # 匹配退格符 \\0 # 匹配空值字符 } 字符类:锚定字符{ \\b # 匹配字边界(不在[]中时) \\B # 匹配非字边界 \\A # 匹配字符串开头 \\Z # 匹配字符串或行的末尾 \\z # 只匹配字符串末尾 \\G # 匹配前一次m//g离开之处 } 捕获{ (exp) # 匹配exp,并捕获文本到自动命名的组里 (?exp) # 匹配exp,并捕获文本到名称为name的组里，也可以写成(?'name'exp) (?:exp) # 匹配exp,不捕获匹配的文本，也不给此分组分配组号 } 零宽断言{ (?=exp) # 匹配exp前面的位置 (?6?5:8)) # 判断两个值满足条件的赋值给变量 A=(a b c def) # 将变量定义为組数 $1 $2 $* # 位置参数 *代表所有 env # 查看环境变量 env | grep \"name\" # 查看定义的环境变量 set # 查看环境变量和本地变量 read name # 输入变量 readonly name # 把name这个变量设置为只读变量,不允许再次设置 readonly # 查看系统存在的只读文件 export name # 变量name由本地升为环境 export name=\"RedHat\" # 直接定义name为环境变量 export Stat$nu=2222 # 变量引用变量赋值 unset name # 变量清除 export -n name # 去掉只读变量 shift # 用于移动位置变量,调整位置变量,使$3的值赋给$2.$2的值赋予$1 name + 0 # 将字符串转换为数字 number \" \" # 将数字转换成字符串 定义变量类型{ declare 或 typeset -r 只读(readonly一样) -i 整形 -a 数组 -f 函数 -x export declare -i n=0 } 系统变量{ $0 # 脚本启动名(包括路径) $n # 第n个参数,n=1,2,…9 $* # 所有参数列表(不包括脚本本身) $@ # 所有参数列表(独立字符串) $# # 参数个数(不包括脚本本身) $$ # 当前程式的PID $! # 执行上一个指令的PID $? # 执行上一个指令的返回值 } 变量引用技巧{ ${name:+value} # 如果设置了name,就把value显示,未设置则为空 ${name:-value} # 如果设置了name,就显示它,未设置就显示value ${name:?value} # 未设置提示用户错误信息value ${name:=value} # 如未设置就把value设置并显示 ${#A} # 可得到变量中字节 ${#A[*]} # 数组个数 ${A[*]} # 数组所有元素 ${A[@]} # 数组所有元素(标准) ${A[2]} # 脚本的一个参数或数组第三位 ${A:4:9} # 取变量中第4位到后面9位 ${A/www/http} # 取变量并且替换每行第一个关键字 ${A//www/http} # 取变量并且全部替换每行关键字 定义了一个变量： file=/dir1/dir2/dir3/my.file.txt ${file#*/} # 去掉第一条 / 及其左边的字串：dir1/dir2/dir3/my.file.txt ${file##*/} # 去掉最后一条 / 及其左边的字串：my.file.txt ${file#*.} # 去掉第一个 . 及其左边的字串：file.txt ${file##*.} # 去掉最后一个 . 及其左边的字串：txt ${file%/*} # 去掉最后条 / 及其右边的字串：/dir1/dir2/dir3 ${file%%/*} # 去掉第一条 / 及其右边的字串：(空值) ${file%.*} # 去掉最后一个 . 及其右边的字串：/dir1/dir2/dir3/my.file ${file%%.*} # 去掉第一个 . 及其右边的字串：/dir1/dir2/dir3/my # # 是去掉左边(在键盘上 # 在 $ 之左边) # % 是去掉右边(在键盘上 % 在 $ 之右边) # 单一符号是最小匹配﹔两个符号是最大匹配 } } test条件判断{ # 符号 [ ] 等同 test命令 expression为字符串操作{ -n str # 字符串str是否不为空 -z str # 字符串str是否为空 } expression为文件操作{ -a # 并且，两条件为真 -b # 是否块文件 -p # 文件是否为一个命名管道 -c # 是否字符文件 -r # 文件是否可读 -d # 是否一个目录 -s # 文件的长度是否不为零 -e # 文件是否存在 -S # 是否为套接字文件 -f # 是否普通文件 -x # 文件是否可执行，则为真 -g # 是否设置了文件的 SGID 位 -u # 是否设置了文件的 SUID 位 -G # 文件是否存在且归该组所有 -w # 文件是否可写，则为真 -k # 文件是否设置了的粘贴位 -t fd # fd 是否是个和终端相连的打开的文件描述符（fd 默认为 1） -o # 或，一个条件为真 -O # 文件是否存在且归该用户所有 ! # 取反 } expression为整数操作{ expr1 -a expr2 # 如果 expr1 和 expr2 评估为真，则为真 expr1 -o expr2 # 如果 expr1 或 expr2 评估为真，则为真 } 两值比较{ 整数 字符串 -lt # 大于 -le = # 大于或等于 -eq == # 等于 -ne != # 不等于 } test 10 -lt 5 # 判断大小 echo $? # 查看上句test命令返回状态 # 结果0为真,1为假 test -n \"hello\" # 判断字符串长度是否为0 [ $? -eq 0 ] && echo \"success\" || exit　　　# 判断成功提示,失败则退出 } 重定向{ # 标准输出 stdout 和 标准错误 stderr 标准输入stdin cmd 1> fiel # 把 标准输出 重定向到 file 文件中 cmd > file 2>&1 # 把 标准输出 和 标准错误 一起重定向到 file 文件中 cmd 2> file # 把 标准错误 重定向到 file 文件中 cmd 2>> file # 把 标准错误 重定向到 file 文件中(追加) cmd >> file 2>&1 # 把 标准输出 和 标准错误 一起重定向到 file 文件中(追加) cmd file2 # cmd 命令以 file 文件作为 stdin(标准输入)，以 file2 文件作为 标准输出 cat <>file # 以读写的方式打开 file cmd delimiter >&n # 使用系统调用 dup (2) 复制文件描述符 n 并把结果用作标准输出 &- # 关闭标准输出 n&- # 表示将 n 号输出关闭 } 运算符{ $[]等同于$(()) # $[]表示形式告诉shell求中括号中的表达式的值 ~var # 按位取反运算符,把var中所有的二进制为1的变为0,为0的变为1 var\\>str # 右移运算符,把var中所有的二进制位向右移动str位,忽略最右移出的各位,最左的各位上补0,每次做一次右移就有实现var除以2 var&str # 与比较运算符,var和str对应位,对于每个二进制来说,如果二都为1,结果为1.否则为0 var^str # 异或运算符,比较var和str对应位,对于二进制来说如果二者互补,结果为1,否则为0 var|str # 或运算符,比较var和str的对应位,对于每个二进制来说,如二都该位有一个1或都是1,结果为1,否则为0 运算符优先级{ 级别 运算符 说明 1 =,+=,-=,/=,%=,*=,&=,^=,|=,>== # 赋值运算符 2 || # 逻辑或 前面不成功执行 3 && # 逻辑与 前面成功后执行 4 | # 按位或 5 ^ # 按异位与 6 & # 按位与 7 ==,!= # 等于/不等于 8 =, # 大于或等于/小于或等于/大于/小于 9 \\> # 按位左移/按位右移 (无转意符号) 10 +,- # 加减 11 *,/,% # 乘,除,取余 12 ! ,~ # 逻辑非,按位取反或补码 13 -,+ # 正负 } } 数学运算{ $(( )) # 整数运算 + - * / ** # 分別为 \"加、減、乘、除、密运算\" & | ^ ! # 分別为 \"AND、OR、XOR、NOT\" 运算 % # 余数运算 let{ let # 运算 let x=16/4 let x=5**5 } expr{ expr 14 % 9 # 整数运算 SUM=`expr 2 \\* 3` # 乘后结果赋值给变量 LOOP=`expr $LOOP + 1` # 增量计数(加循环即可) LOOP=0 expr length \"bkeep zbb\" # 计算字串长度 expr substr \"bkeep zbb\" 4 9 # 抓取字串 expr index \"bkeep zbb\" e # 抓取第一个字符数字串出现的位置 expr 30 / 3 / 2 # 运算符号有空格 expr bkeep.doc : '.*' # 模式匹配(可以使用expr通过指定冒号选项计算字符串中字符数) expr bkeep.doc : '\\(.*\\).doc' # 在expr中可以使用字符串匹配操作，这里使用模式抽取.doc文件附属名 数值测试{ #如果试图计算非整数，则会返回错误 rr=3.4 expr $rr + 1 expr: non-numeric argument rr=5 expr $rr + 1 6 } } bc{ echo \"m^n\"|bc # 次方计算 seq -s '+' 1000 |bc # 从1加到1000 seq 1 1000 |tr \"\\n\" \"+\"|sed 's/+$/\\n/'|bc # 从1加到1000 } } grep{ -c # 显示匹配到得行的数目，不显示内容 -h # 不显示文件名 -i # 忽略大小写 -l # 只列出匹配行所在文件的文件名 -n # 在每一行中加上相对行号 -s # 无声操作只显示报错，检查退出状态 -v # 反向查找 -e # 使用正则表达式 -A3 # 打印匹配行和下三行 -w # 精确匹配 -wc # 精确匹配次数 -o # 查询所有匹配字段 -P # 使用perl正则表达式 grep -v \"a\" txt # 过滤关键字符行 grep -w 'a\\>' txt # 精确匹配字符串 grep -i \"a\" txt # 大小写敏感 grep \"a[bB]\" txt # 同时匹配大小写 grep '[0-9]\\{3\\}' txt # 查找0-9重复三次的所在行 grep -E \"word1|word2|word3\" file # 任意条件匹配 grep word1 file | grep word2 |grep word3 # 同时匹配三个 echo quan@163.com |grep -Po '(? /dev/null 2>&1 then echo \"abc\" else echo \"null\" fi } } tr{ -c # 用字符串1中字符集的补集替换此字符集，要求字符集为ASCII -d # 删除字符串1中所有输入字符 -s # 删除所有重复出现字符序列，只保留第一个:即将重复出现字符串压缩为一个字符串 [a-z] # a-z内的字符组成的字符串 [A-Z] # A-Z内的字符组成的字符串 [0-9] # 数字串 \\octal # 一个三位的八进制数，对应有效的ASCII字符 [O*n] # 表示字符O重复出现指定次数n。因此[O*2]匹配OO的字符串 tr中特定控制字符表达方式{ \\a Ctrl-G \\007 # 铃声 \\b Ctrl-H \\010 # 退格符 \\f Ctrl-L \\014 # 走行换页 \\n Ctrl-J \\012 # 新行 \\r Ctrl-M \\015 # 回车 \\t Ctrl-I \\011 # tab键 \\v Ctrl-X \\030 } tr A-Z a-z # 将所有大写转换成小写字母 tr \" \" \"\\n\" # 将空格替换为换行 tr -s \"[\\012]\" unixfile # Mac -> UNIX tr \"\\n\" \"\\r\" macfile # UNIX -> Mac tr -d \"\\r\" unixfile # DOS -> UNIX Microsoft DOS/Windows 约定，文本的每行以回车字符(\\r)并后跟换行符(\\n)结束 awk '{ print $0\"\\r\" }' dosfile # UNIX -> DOS：在这种情况下，需要用awk，因为tr不能插入两个字符来替换一个字符 } seq{ # 不指定起始数值，则默认为 1 -s # 选项主要改变输出的分格符, 预设是 \\n -w # 等位补全，就是宽度相等，不足的前面补 0 -f # 格式化输出，就是指定打印的格式 seq 10 100 # 列出10-100 seq 1 10 |tac # 倒叙列出 seq -s '+' 90 100 |bc # 从90加到100 seq -f 'dir%g' 1 10 | xargs mkdir # 创建dir1-10 seq -f 'dir%03g' 1 10 | xargs mkdir # 创建dir001-010 } trap{ 信号 说明 HUP(1) # 挂起，通常因终端掉线或用户退出而引发 INT(2) # 中断，通常因按下Ctrl+C组合键而引发 QUIT(3) # 退出，通常因按下Ctrl+\\组合键而引发 ABRT(6) # 中止，通常因某些严重的执行错误而引发 ALRM(14) # 报警，通常用来处理超时 TERM(15) # 终止，通常在系统关机时发送 trap捕捉到信号之后，可以有三种反应方式： 1、执行一段程序来处理这一信号 2、接受信号的默认操作 3、忽视这一信号 第一种形式的trap命令在shell接收到 signal list 清单中数值相同的信号时，将执行双引号中的命令串： trap 'commands' signal-list # 单引号，要在shell探测到信号来的时候才执行命令和变量的替换，时间一直变 trap \"commands\" signal-list # 双引号，shell第一次设置信号的时候就执行命令和变量的替换，时间不变 } awk{ # 默认是执行打印全部 print $0 # 1为真 打印$0 # 0为假 不打印 -F # 改变FS值(分隔符) ~ # 域匹配 == # 变量匹配 !~ # 匹配不包含 = # 赋值 != # 不等于 += # 叠加 \\b # 退格 \\f # 换页 \\n # 换行 \\r # 回车 \\t # 制表符Tab \\c # 代表任一其他字符 -F\"[ ]+|[%]+\" # 多个空格或多个%为分隔符 [a-z]+ # 多个小写字母 [a-Z] # 代表所有大小写字母(aAbB...zZ) [a-z] # 代表所有大小写字母(ab...z) [:alnum:] # 字母数字字符 [:alpha:] # 字母字符 [:cntrl:] # 控制字符 [:digit:] # 数字字符 [:graph:] # 非空白字符(非空格、控制字符等) [:lower:] # 小写字母 [:print:] # 与[:graph:]相似，但是包含空格字符 [:punct:] # 标点字符 [:space:] # 所有的空白字符(换行符、空格、制表符) [:upper:] # 大写字母 [:xdigit:] # 十六进制的数字(0-9a-fA-F) [[:digit:][:lower:]] # 数字和小写字母(占一个字符) 内建变量{ $n # 当前记录的第 n 个字段，字段间由 FS 分隔 $0 # 完整的输入记录 ARGC # 命令行参数的数目 ARGIND # 命令行中当前文件的位置 ( 从 0 开始算 ) ARGV # 包含命令行参数的数组 CONVFMT # 数字转换格式 ( 默认值为 %.6g) ENVIRON # 环境变量关联数组 ERRNO # 最后一个系统错误的描述 FIELDWIDTHS # 字段宽度列表 ( 用空格键分隔 ) FILENAME # 当前文件名 FNR # 同 NR ，但相对于当前文件 FS # 字段分隔符 ( 默认是任何空格 ) IGNORECASE # 如果为真（即非 0 值），则进行忽略大小写的匹配 NF # 当前记录中的字段数(列) NR # 当前行数 OFMT # 数字的输出格式 ( 默认值是 %.6g) OFS # 输出字段分隔符 ( 默认值是一个空格 ) ORS # 输出记录分隔符 ( 默认值是一个换行符 ) RLENGTH # 由 match 函数所匹配的字符串的长度 RS # 记录分隔符 ( 默认是一个换行符 ) RSTART # 由 match 函数所匹配的字符串的第一个位置 SUBSEP # 数组下标分隔符 ( 默认值是 /034) BEGIN # 先处理(可不加文件参数) END # 结束时处理 } 内置函数{ gsub(r,s) # 在整个$0中用s替代r 相当于 sed 's///g' gsub(r,s,t) # 在整个t中用s替代r index(s,t) # 返回s中字符串t的第一位置 length(s) # 返回s长度 match(s,r) # 测试s是否包含匹配r的字符串 split(s,a,fs) # 在fs上将s分成序列a sprint(fmt,exp) # 返回经fmt格式化后的exp sub(r,s) # 用$0中最左边最长的子串代替s 相当于 sed 's///' substr(s,p) # 返回字符串s中从p开始的后缀部分 substr(s,p,n) # 返回字符串s中从p开始长度为n的后缀部分 } awk判断{ awk '{print ($1>$2)?\"第一排\"$1:\"第二排\"$2}' # 条件判断 括号代表if语句判断 \"?\"代表then \":\"代表else awk '{max=($1>$2)? $1 : $2; print max}' # 条件判断 如果$1大于$2,max值为为$1,否则为$2 awk '{if ( $6 > 50) print $1 \" Too high\" ;\\ else print \"Range is OK\"}' file awk '{if ( $6 > 50) { count++;print $3 } \\ else { x+5; print $2 } }' file } awk循环{ awk '{i = 1; while ( i 500' # 算术运算(第三个字段和第四个字段乘积大于500则显示) awk '{print NR\" \"$0}' # 加行号 awk '/tom/,/suz/' # 打印tom到suz之间的行 awk '{a+=$1}END{print a}' # 列求和 awk 'sum+=$1{print sum}' # 将$1的值叠加后赋给sum awk '{a+=$1}END{print a/NR}' # 列求平均值 awk -F'[ :\\t]' '{print $1,$2}' # 以空格、:、制表符Tab为分隔符 awk '{print \"'\"$a\"'\",\"'\"$b\"'\"}' # 引用外部变量 awk '{if(NR==52){print;exit}}' # 显示第52行 awk '/关键字/{a=NR+2}a==NR {print}' # 取关键字下第几行 awk 'gsub(/liu/,\"aaaa\",$1){print $0}' # 只打印匹配替换后的行 ll | awk -F'[ ]+|[ ][ ]+' '/^$/{print $8}' # 提取时间,空格不固定 awk '{$1=\"\";$2=\"\";$3=\"\";print}' # 去掉前三列 echo aada:aba|awk '/d/||/b/{print}' # 匹配两内容之一 echo aada:abaa|awk -F: '$1~/d/||$2~/b/{print}' # 关键列匹配两内容之一 echo Ma asdas|awk '$1~/^[a-Z][a-Z]$/{print }' # 第一个域匹配正则 echo aada:aaba|awk '/d/&&/b/{print}' # 同时匹配两条件 awk 'length($1)==\"4\"{print $1}' # 字符串位数 awk '{if($2>3){system (\"touch \"$1)}}' # 执行系统命令 awk '{sub(/Mac/,\"Macintosh\",$0);print}' # 用Macintosh替换Mac awk '{gsub(/Mac/,\"MacIntosh\",$1); print}' # 第一个域内用Macintosh替换Mac awk -F '' '{ for(i=1;ia) a=$1 fi}END{print a}' # 列求最大值 设定一个变量开始为0，遇到比该数大的值，就赋值给该变量，直到结束 awk 'BEGIN{a=11111}{if ($1= 0 ) {print $0,$i}}' # 求余数 awk '{b=a;a=$1; if(NR>1){print a-b}}' # 当前行减上一行 awk '{a[NR]=$1}END{for (i=1;i /dev/null 2>&1\") == 0 ) {print $1,\"Y\"} else {print $1,\"N\"} }' a # 执行系统命令判断返回状态 awk '{for(i=1;i>insert_1.txt # 处理sql语句 取本机IP{ /sbin/ifconfig |awk -v RS=\"Bcast:\" '{print $NF}'|awk -F: '/addr/{print $2}' /sbin/ifconfig |awk -v RS='inet addr:' '$1!=\"eth0\"&&$1!=\"127.0.0.1\"{print $1}'|awk '{printf\"%s|\",$0}' /sbin/ifconfig |awk '{printf(\"line %d,%s\\n\",NR,$0)}' # 指定类型(%d数字,%s字符) } 查看磁盘空间{ df -h|awk -F\"[ ]+|%\" '$5>14{print $5}' df -h|awk 'NR!=1{if ( NF == 6 ) {print $5} else if ( NF == 5) {print $4} }' df -h|awk 'NR!=1 && /%/{sub(/%/,\"\");print $(NF-1)}' df -h|sed '1d;/ /!N;s/\\n//;s/ \\+/ /;' #将磁盘分区整理成一行 可直接用 df -P } 排列打印{ awk 'END{printf \"%-10s%-10s\\n%-10s%-10s\\n%-10s%-10s\\n\",\"server\",\"name\",\"123\",\"12345\",\"234\",\"1234\"}' txt awk 'BEGIN{printf \"|%-10s|%-10s|\\n|%-10s|%-10s|\\n|%-10s|%-10s|\\n\",\"server\",\"name\",\"123\",\"12345\",\"234\",\"1234\"}' awk 'BEGIN{ print \" *** 开 始 *** \"; print \"+-----------------+\"; printf \"|%-5s|%-5s|%-5s|\\n\",\"id\",\"name\",\"ip\"; } $1!=1 && NF==4{printf \"|%-5s|%-5s|%-5s|\\n\",$1,$2,$3\" \"$11} END{ print \"+-----------------+\"; print \" *** 结 束 *** \" }' txt } 老男孩awk经典题{ 分析图片服务日志，把日志（每个图片访问次数*图片大小的总和）排行，也就是计算每个url的总访问大小 说明：本题生产环境应用：这个功能可以用于IDC网站流量带宽很高，然后通过分析服务器日志哪些元素占用流量过大，进而进行优化或裁剪该图片，压缩js等措施。 本题需要输出三个指标： 【被访问次数】 【访问次数*单个被访问文件大小】 【文件名（带URL）】 测试数据 59.33.26.105 - - [08/Dec/2010:15:43:56 +0800] \"GET /static/images/photos/2.jpg HTTP/1.1\" 200 11299 awk '{array_num[$7]++;array_size[$7]+=$10}END{for(i in array_num) {print array_num[i]\" \"array_size[i]\" \"i}}' } awk练习题{ wang 4 cui 3 zhao 4 liu 3 liu 3 chang 5 li 2 1 通过第一个域找出字符长度为4的 2 当第二列值大于3时，创建空白文件，文件名为当前行第一个域$1 (touch $1) 3 将文档中 liu 字符串替换为 hong 4 求第二列的和 5 求第二列的平均值 6 求第二列中的最大值 7 将第一列过滤重复后，列出每一项，每一项的出现次数，每一项的大小总和 1、字符串长度 awk 'length($1)==\"4\"{print $1}' 2、执行系统命令 awk '{if($2>3){system (\"touch \"$1)}}' 3、gsub(/r/,\"s\",域) 在指定域(默认$0)中用s替代r (sed 's///g') awk '{gsub(/liu/,\"hong\",$1);print $0}' a.txt 4、列求和 awk '{a+=$2}END{print a}' 5、列求平均值 awk '{a+=$2}END{print a/NR}' awk '{a+=$2;b++}END{print a,a/b}' 6、列求最大值 awk 'BEGIN{a=0}{if($2>a) a=$2 }END{print a}' 7、将第一列过滤重复列出每一项，每一项的出现次数，每一项的大小总和 awk '{a[$1]++;b[$1]+=$2}END{for(i in a){print i,a[i],b[i]}}' } } sed{ # 先读取资料、存入模式空间、对其进行编辑、再输出、再用下一行替换模式空间内容 # 调试工具sedsed (参数 -d) http://aurelio.net/sedsed/sedsed-1.0 -n # 输出由编辑指令控制(取消默认的输出,必须与编辑指令一起配合) -i # 直接对文件操作 -e # 多重编辑 -r # 正则可不转移特殊字符 b # 跳过匹配的行 p # 打印 d # 删除 s # 替换 g # 配合s全部替换 i # 行前插入 a # 行后插入 r # 读 y # 转换 q # 退出 & # 代表查找的串内容 * # 任意多个 前驱字符(前导符) ? # 0或1个 最小匹配 没加-r参数需转义 \\? $ # 最后一行 .* # 匹配任意多个字符 \\(a\\) # 保存a作为标签1(\\1) 模式空间{ # 模式空间(两行两行处理) 模式匹配的范围，一般而言，模式空间是输入文本中某一行，但是可以通过使用N函数把多于一行读入模式空间 # 暂存空间里默认存储一个空行 n # 读入下一行(覆盖上一行) h # 把模式空间里的行拷贝到暂存空间 H # 把模式空间里的行追加到暂存空间 g # 用暂存空间的内容替换模式空间的行 G # 把暂存空间的内容追加到模式空间的行后 x # 将暂存空间的内容于模式空间里的当前行互换 ！ # 对其前面的要匹配的范围取反 D # 删除当前模式空间中直到并包含第一个换行符的所有字符(/.*/匹配模式空间中所有内容，匹配到就执行D,没匹配到就结束D) N # 追加下一个输入行到模式空间后面并在第二者间嵌入一个换行符，改变当前行号码,模式匹配可以延伸跨域这个内嵌换行 p # 打印模式空间中的直到并包含第一个换行的所有字符 } 标签函数{ : lable # 建立命令标记，配合b，t函数使用跳转 b lable # 分支到脚本中带有标记的地方，如果分支不存在则分支到脚本的末尾。 t labe # 判断分支，从最后一行开始，条件一旦满足或者T,t命令，将导致分支到带有标号的命令出，或者到脚本末尾。与b函数不同在于t在执行跳转前会先检查其前一个替换命令是否成功，如成功，则执行跳转。 sed -e '{:p1;/A/s/A/AA/;/B/s/B/BB/;/[AB]\\{10\\}/b;b p1;}' # 文件内容第一行A第二行B:建立标签p1;两个替换函数(A替换成AA,B替换成BB)当A或者B达到10个以后调用b,返回 echo 'sd f f [a b c cddd eee]' | sed ':n;s#\\(\\[[^ ]*\\) *#\\1#;tn' #标签函数t使用方法,替换[]里的空格 } 引用外部变量{ sed -n ''$a',10p' sed -n \"\"$a\",10p\" } sed 10q # 显示文件中的前10行 (模拟\"head\") sed -n '$=' # 计算行数(模拟 \"wc -l\") sed -n '5,/^no/p' # 打印从第5行到以no开头行之间的所有行 sed -i \"/^$f/d\" a 　　 　# 删除匹配行 sed -i '/aaa/,$d' # 删除匹配行到末尾 sed -i \"s/=/:/\" c # 直接对文本替换 sed -i \"/^pearls/s/$/j/\" # 找到pearls开头在行尾加j sed '/1/,/3/p' file # 打印1和3之间的行 sed -n '1p' 文件 # 取出指定行 sed '5i\\aaa' file # 在第5行之前插入行 sed '5a\\aaa' file # 在第5行之后抽入行 echo a|sed -e '/a/i\\b' # 在匹配行前插入一行 echo a|sed -e '/a/a\\b' # 在匹配行后插入一行 echo a|sed 's/a/&\\nb/g' # 在匹配行后插入一行 seq 10| sed -e{1,3}'s/./a/' # 匹配1和3行替换 sed -n '/regexp/!p' # 只显示不匹配正则表达式的行 sed '/regexp/d' # 只显示不匹配正则表达式的行 sed '$!N;s/\\n//' # 将每两行连接成一行 sed '/baz/s/foo/bar/g' # 只在行中出现字串\"baz\"的情况下将\"foo\"替换成\"bar\" sed '/baz/!s/foo/bar/g' # 将\"foo\"替换成\"bar\"，并且只在行中未出现字串\"baz\"的情况下替换 echo a|sed -e 's/a/#&/g' # 在a前面加#号 sed 's/foo/bar/4' # 只替换每一行中的第四个字串 sed 's/\\(.*\\)foo/\\1bar/' # 替换每行最后一个字符串 sed 's/\\(.*\\)foo\\(.*foo\\)/\\1bar\\2/' # 替换倒数第二个字符串 sed 's/[0-9][0-9]$/&5' # 在以[0-9][0-9]结尾的行后加5 sed -n ' /^eth\\|em[01][^:]/{n;p;}' # 匹配多个关键字 sed -n -r ' /eth|em[01][^:]/{n;p;}' # 匹配多个关键字 echo -e \"1\\n2\"|xargs -i -t sed 's/^/1/' {} # 同时处理多个文件 sed '/west/,/east/s/$/*VACA*/' # 修改west和east之间的所有行，在结尾处加*VACA* sed 's/[^1-9]*\\([0-9]\\+\\).*/\\1/' # 取出第一组数字，并且忽略掉开头的0 sed -n '/regexp/{g;1!p;};h' # 查找字符串并将匹配行的上一行显示出来，但并不显示匹配行 sed -n ' /regexp/{n;p;}' # 查找字符串并将匹配行的下一行显示出来，但并不显示匹配行 sed -n 's/\\(mar\\)got/\\1ianne/p' # 保存\\(mar\\)作为标签1 sed -n 's/\\([0-9]\\+\\).*\\(t\\)/\\2\\1/p' # 保存多个标签 sed -i -e '1,3d' -e 's/1/2/' # 多重编辑(先删除1-3行，在将1替换成2) sed -e 's/@.*//g' -e '/^$/d' # 删除掉@后面所有字符，和空行 sed -n -e \"{s/文本(正则)/替换的内容/p}\" # 替换并打印出替换行 sed -n -e \"{s/^ *[0-9]*//p}\" # 打印并删除正则表达式的那部分内容 echo abcd|sed 'y/bd/BE/' # 匹配字符替换 sed '/^#/b;y/y/P/' 2 # 非#号开头的行替换字符 sed '/suan/r 读入文件' # 找到含suan的行，在后面加上读入的文件内容 sed -n '/no/w 写入文件' # 找到含no的行，写入到指定文件中 sed '/regex/G' # 在匹配式样行之后插入一空行 sed '/regex/{x;p;x;G;}' # 在匹配式样行之前和之后各插入一空行 sed 'n;d' # 删除所有偶数行 sed 'G;G' # 在每一行后面增加两空行 sed '/^$/d;G' # 在输出的文本中每一行后面将有且只有一空行 sed 'n;n;n;n;G;' # 在每5行后增加一空白行 sed -n '5~5p' # 只打印行号为5的倍数 seq 1 30|sed '5~5s/.*/a/' # 倍数行执行替换 sed -n '3,${p;n;n;n;n;n;n;}' # 从第3行开始，每7行显示一次 sed -n 'h;n;G;p' # 奇偶调换 seq 1 10|sed '1!G;h;$!d' # 倒叙排列 ls -l|sed -n '/^.rwx.*/p' # 查找属主权限为7的文件 sed = filename | sed 'N;s/\\n/\\t/' # 为文件中的每一行进行编号(简单的左对齐方式) sed 's/^[ \\t]*//' # 将每一行前导的\"空白字符\"(空格，制表符)删除,使之左对齐 sed 's/^[ \\t]*//;s/[ \\t]*$//' # 将每一行中的前导和拖尾的空白字符删除 echo abcd\\\\nabcde |sed 's/\\\\n/@/g' |tr '@' '\\n' # 将换行符转换为换行 cat tmp|awk '{print $1}'|sort -n|sed -n '$p' # 取一列最大值 sed -n '{s/^[^\\/]*//;s/\\:.*//;p}' /etc/passwd # 取用户家目录(匹配不为/的字符和匹配:到结尾的字符全部删除) sed = filename | sed 'N;s/^/ /; s/ *\\(.\\{6,\\}\\)\\n/\\1 /' # 对文件中的所有行编号(行号在左，文字右端对齐) /sbin/ifconfig |sed 's/.*inet addr:\\(.*\\) Bca.*/\\1/g' |sed -n '/eth/{n;p}' # 取所有IP 修改keepalive配置剔除后端服务器{ sed -i '/real_server.*10.0.1.158.*8888/,+8 s/^/#/' keepalived.conf sed -i '/real_server.*10.0.1.158.*8888/,+8 s/^#//' keepalived.conf } 模仿rev功能{ echo 123 |sed '/\\n/!G;s/\\(.\\)\\(.*\\n\\)/&\\2\\1/;//D;s/.//;' /\\n/!G; 　　　　　　# 没有\\n换行符，要执行G,因为保留空间中为空，所以在模式空间追加一空行 s/\\(.\\)\\(.*\\n\\)/&\\2\\1/; # 标签替换 &\\n23\\n1$ (关键在于& ,可以让后面//匹配到空行) //D; 　　　　　　# D 命令会引起循环删除模式空间中的第一部分，如果删除后，模式空间中还有剩余行，则返回 D 之前的命令，重新执行，如果 D 后，模式空间中没有任何内容，则将退出。 //D 匹配空行执行D,如果上句s没有匹配到,//也无法匹配到空行, \"//D;\"命令结束 s/.//; 　　　　　　# D结束后,删除开头的 \\n } } dialog菜单{ # 默认将所有输出用 stderr 输出，不显示到屏幕 使用参数 --stdout 可将选择赋给变量 # 退出状态 0正确 1错误 窗体类型{ --calendar # 日历 --checklist # 允许你显示一个选项列表，每个选项都可以被单独的选择 (复选框) --form # 表单,允许您建立一个带标签的文本字段，并要求填写 --fselect # 提供一个路径，让你选择浏览的文件 --gauge # 显示一个表，呈现出完成的百分比，就是显示出进度条。 --infobox # 显示消息后，（没有等待响应）对话框立刻返回，但不清除屏幕(信息框) --inputbox # 让用户输入文本(输入框) --inputmenu # 提供一个可供用户编辑的菜单（可编辑的菜单框） --menu # 显示一个列表供用户选择(菜单框) --msgbox(message) # 显示一条消息,并要求用户选择一个确定按钮(消息框) --password # 密码框，显示一个输入框，它隐藏文本 --pause # 显示一个表格用来显示一个指定的暂停期的状态 --radiolist # 提供一个菜单项目组，但是只有一个项目，可以选择(单选框) --tailbox # 在一个滚动窗口文件中使用tail命令来显示文本 --tailboxbg # 跟tailbox类似，但是在background模式下操作 --textbox # 在带有滚动条的文本框中显示文件的内容 (文本框) --timebox # 提供一个窗口，选择小时，分钟，秒 --yesno(yes/no) # 提供一个带有yes和no按钮的简单信息框 } 窗体参数{ --separate-output # 对于chicklist组件,输出结果一次输出一行,得到结果不加引号 --ok-label \"提交\" # 确定按钮名称 --cancel-label \"取消\" # 取消按钮名称 --title \"标题\" # 标题名称 --stdout # 将所有输出用 stdout 输出 --backtitle \"上标\" # 窗体上标 --no-shadow # 去掉窗体阴影 --menu \"菜单名\" 20 60 14 # 菜单及窗口大小 --clear # 完成后清屏操作 --no-cancel # 不显示取消项 --insecure # 使用星号来代表每个字符 --begin # 指定对话框左上角在屏幕的上的做坐标 --timeout # 超时,返回的错误代码255,如果用户在指定的时间内没有给出相应动作,就按超时处理 --defaultno # 使选择默认为no --default-item # 设置在一份清单，表格或菜单中的默认项目。通常在框中的第一项是默认 --sleep 5 # 在处理完一个对话框后静止(延迟)的时间(秒) --max-input size # 限制输入的字符串在给定的大小之内。如果没有指定，默认是2048 --keep-window # 退出时不清屏和重绘窗口。当几个组件在同一个程序中运行时，对于保留窗口内容很有用的 } dialog --title \"Check me\" --checklist \"Pick Numbers\" 15 25 3 1 \"one\" \"off\" 2 \"two\" \"on\" # 多选界面[方括号] dialog --title \"title\" --radiolist \"checklist\" 20 60 14 tag1 \"item1\" on tag2 \"item2\" off # 多选界面(圆括号) dialog --title \"title\" --menu \"MENU\" 20 60 14 tag1 \"item1\" tag2 \"item2\" # 单选界面 dialog --title \"Installation\" --backtitle \"Star Linux\" --gauge \"Linux Kernel\" 10 60 50 # 进度条 dialog --title \"标题\" --backtitle \"Dialog\" --yesno \"说明\" 20 60 # 选择yes/no dialog --title \"公告标题\" --backtitle \"Dialog\" --msgbox \"内容\" 20 60 # 公告 dialog --title \"hey\" --backtitle \"Dialog\" --infobox \"Is everything okay?\" 10 60 # 显示讯息后立即离开 dialog --title \"hey\" --backtitle \"Dialog\" --inputbox \"Is okay?\" 10 60 \"yes\" # 输入对话框 dialog --title \"Array 30\" --backtitle \"All \" --textbox /root/txt 20 75 # 显示文档内容 dialog --title \"Add\" --form \"input\" 12 40 4 \"user\" 1 1 \"\" 1 15 15 0 \"name\" 2 1 \"\" 2 15 15 0 # 多条输入对话框 dialog --title \"Password\" --insecure --passwordbox \"请输入密码\" 10 35 # 星号显示输入--insecure dialog --stdout --title \"日历\" --calendar \"请选择\" 0 0 9 1 2010 # 选择日期 dialog --title \"title\" --menu \"MENU\" 20 60 14 tag1 \"item1\" tag2 \"item2\" 2>tmp # 取到结果放到文件中(以标准错误输出结果) a=`dialog --title \"title\" --stdout --menu \"MENU\" 20 60 14 tag1 \"item1\" tag2 \"item2\"` # 选择操作赋给变量(使用标准输出) dialog菜单实例{ while : do clear menu=`dialog --title \"title\" --stdout --menu \"MENU\" 20 60 14 1 system 2 custom` [ $? -eq 0 ] && echo \"$menu\" || exit # 判断dialog执行,取消退出 while : do case $menu in 1) list=\"1a \"item1\" 2a \"item2\"\" # 定义菜单列表变量 ;; 2) list=\"1b \"item3\" 2b \"item4\"\" ;; esac result=`dialog --title \"title\" --stdout --menu \"MENU\" 20 60 14 $list` [ $? -eq 0 ] && echo \"$result\" || break # 判断dialog执行,取消返回菜单,注意:配合上层菜单循环 read done done } } select菜单{ # 输入项不在菜单自动会提示重新输入 select menuitem in pick1 pick2 pick3 退出 do echo $menuitem case $menuitem in 退出) exit ;; *) select area in area1 area2 area3 返回 do echo $area case area in 返回) break ;; *) echo \"对$area操作\" ;; esac done ;; esac done } shift{ ./cs.sh 1 2 3 #!/bin/sh until [ $# -eq 0 ] do echo \"第一个参数为: $1 参数个数为: $#\" #shift 命令执行前变量 $1 的值在shift命令执行后不可用 shift done } getopts给脚本加参数{ #!/bin/sh while getopts name do case $name in a) aflag=1 ;; b) bflag=1 bval=$OPTARG ;; \\?) echo \"USAGE:`basename $0` [-a] [-b value]\" exit 1 ;; esac done if [ ! -z $aflag ] ; then echo \"option -a specified\" echo \"$aflag\" echo \"$OPTIND\" fi if [ ! -z $bflag ] ; then echo \"option -b specified\" echo \"$bflag\" echo \"$bval\" echo \"$OPTIND\" fi echo \"here $OPTIND\" shift $(($OPTIND -1)) echo \"$OPTIND\" echo \" `shift $(($OPTIND -1))` \" } tclsh{ set foo \"a bc\" # 定义变量 set b {$a}; # 转义 b的值为\" $a \" ,而不是变量结果 set a 3; incr a 3; # 数字的自增. 将a加3,如果要减3,则为 incr a –3; set c [expr 20/5]; # 计算 c的值为4 puts $foo; # 打印变量 set qian(123) f; # 定义数组 set qian(1,1,1) fs; # 多维数组 parray qian; # 打印数组的所有信息 string length $qian; # 将返回变量qian的长度 string option string1 string2; # 字符相关串操作 # option 的操作选项: # compare 按照字典的排序方式进行比较。根据string1 string2分别返回-1,0,1 # first 返回string2中第一次出现string1的位置，如果没有出现string1则返回-1 # last 和first相反 # trim 从string1中删除开头和结尾的出现在string2中的字符 # tolower 返回string1中的所有字符被转换为小写字符后的新字符串 # toupper 返回string1中的所有字符串转换为大写后的字符串 # length 返回string1的长度 set a 1;while {$a \"$RemoteKey\"/authorized_keys\" /usr/bin/expect -c \" set timeout 10 spawn ssh -o StrictHostKeyChecking=no $RemoteUser@$Ip {$Cmd}; expect { password: { send_user RemotePasswd\\n send ${RemotePasswd}\\r; interact; } eof { send_user eof\\n } } \" } telnet{ #!/bin/bash Ip=\"10.0.1.53\" a=\"\\{\\'method\\'\\:\\'doLogin\\'\\,\\'params\\'\\:\\{\\'uName\\'\\:\\'bobbietest\\'\\}\" /usr/bin/expect -c\" set timeout 15 spawn telnet ${Ip} 8000 expect \"Escape\" send \"${a}\\\\r\" expect { -re \"\\\"err.*none\\\"\" { exit 0 } timeout { exit 1 } eof { exit 2 } } \" echo $? } } } } 9实例{ 从1叠加到100{ echo $[$(echo +{1..100})] echo $[(100+1)*(100/2)] seq -s '+' 100 |bc } 判断参数是否为空-空退出并打印null{ #!/bin/sh echo $1 name=${1:?\"null\"} echo $name } 循环数组{ for ((i=0;i /dev/null 2>&1 then if echo $a | grep -e '^[0-9]\\{4\\}-[01][0-9]-[0-3][0-9]$' then break else echo \"您输入的日期不合法，请从新输入！\" fi else echo \"您输入的日期不合法，请从新输入！\" fi done echo \"日期为$a\" } 打印日期段所有日期{ #!/bin/bash qsrq=20010101 jsrq=20010227 n=0 >tmp while :;do current=$(date +%Y%m%d -d\"$n day $qsrq\") if [[ $current == $jsrq ]];then echo $current >>tmp;break else echo $current >>tmp ((n++)) fi done rq=`awk 'NR==1{print}' tmp` } 打印提示{ cat EOF } 登陆远程执行命令{ # 特殊符号需要 \\ 转义 ssh root@ip EOF } 数学计算的小算法{ #!/bin/sh A=1 B=1 while [ $A -le 10 ] do SUM=`expr $A \\* $B` echo \"$SUM\" if [ $A = 10 ] then B=`expr $B + 1` A=1 fi A=`expr $A + 1` done } 横竖转换{ cat a.txt | xargs # 列转行 cat a.txt | xargs -n1 # 行转列 sed '{N;s/\\n//}' file # 将两行合并一行(去掉换行符) awk '{printf(NR%2!=0)?$0\" \":$0\" \\n\"}' # 将两行合并一行 awk '{printf\"%s \",$0}' # 将所有行合并 awk '{if (NR%4==0){print $0} else {printf\"%s \",$0}}' file # 将4行合并为一行(可扩展) 竖行转横行{ cat file|tr '\\n' ' ' echo $(cat file) #!/bin/sh for i in `cat file` do a=${a}\" \"${i} done echo $a } } 取用户的根目录{ #! /bin/bash while read name pass uid gid gecos home shell do echo $home done \" then if echo \"$line\" | grep -v \"#include \" then sed -i ''$i'i\\\\/\\/All header files are include' incl i=`expr $i + 1` fi fi lastrow=\"$line\" done } 查询数据库其它引擎{ #/bin/bash path1=/data/mysql/data/ dbpasswd=db123 #MyISAM或InnoDB engine=InnoDB if [ -d $path1 ];then dir=`ls -p $path1 |awk '/\\/$/'|awk -F'/' '{print $1}'` for db in $dir do number=`mysql -uroot -p$dbpasswd -A -S \"$path1\"mysql.sock -e \"use ${db};show table status;\" |grep -c $engine` if [ $number -ne 0 ];then echo \"${db}\" fi done fi } 批量修改数据库引擎{ #/bin/bash for db in test test1 test3 do tables=`mysql -uroot -pdb123 -A -S /data/mysql/data/mysql.sock -e \"use $db;show tables;\" |awk 'NR != 1{print}'` for table in $tables do mysql -uroot -pdb123 -A -S /data/mysql/data/mysql.sock -e \"use $db;alter table $table engine=MyISAM;\" done done } 将shell取到的数据插入mysql数据库{ mysql -u$username -p$passwd -h$dbhost -P$dbport -A -e \" use $dbname; insert into data values ('','$ip','$date','$time','$data') \" } 两日期间隔天数{ D1=`date -d '20070409' +\"%s\"` D2=`date -d '20070304 ' +\"%s\"` D3=$(($D1 - $D2)) echo $(($D3/60/60/24)) } while执行ssh只循环一次{ cat - # 让cat读连接文件stdin的信息 seq 10 | while read line; do ssh localhost \"cat -\"; done # 显示的9次是被ssh吃掉的 seq 10 | while read line; do ssh -n localhost \"cat -\"; done # ssh加上-n参数可避免只循环一次 } ssh批量执行命令{ #版本1 #!/bin/bash while read line do Ip=`echo $line|awk '{print $1}'` Passwd=`echo $line|awk '{print $2}'` ssh -n localhost \"cat -\" sshpass -p \"$Passwd\" ssh -n -t -o StrictHostKeyChecking=no root@$Ip \"id\" done$tmpfile # 创建文件标示4，以读写方式操作管道$tmpfile rm $tmpfile # 将创建的管道文件清除 thred=4 # 指定并发个数 seq=(1 2 3 4 5 6 7 8 9 21 22 23 24 25 31 32 33 34 35) # 创建任务列表 # 为并发线程创建相应个数的占位 { for (( i = 1;i&4 # 将占位信息写入管道 for id in ${seq} # 从任务列表 seq 中按次序获取每一个任务 do read # 读取一行，即fd4中的一个占位符 (./ur_command ${id};echo >&4 ) & # 在后台执行任务ur_command 并将任务 ${id} 赋给当前任务；任务执行完后在fd4种写入一个占位符 done &- # 关闭管道 } shell并发函数{ function ConCurrentCmd() { #进程数 Thread=30 #列表文件 CurFileName=iplist.txt #定义fifo文件 FifoFile=\"$$.fifo\" #新建一个fifo类型的文件 mkfifo $FifoFile #将fd6与此fifo类型文件以读写的方式连接起来 exec 6<>$FifoFile rm $FifoFile #事实上就是在文件描述符6中放置了$Thread个回车符 for ((i=0;i&6 #此后标准输入将来自fd5 exec 5&6 #当进程结束以后,再向fd6中追加一个回车符,即补上了read -u6减去的那个 } & done #等待所有后台子进程结束 wait #关闭df6 exec 6>&- #关闭df5 exec 5>&- } } 函数{ ip(){ echo \"a 1\"|awk '$1==\"'\"$1\"'\"{print $2}' } web=a ip $web } 检测软件包是否存在{ rpm -q dialog >/dev/null if [ \"$?\" -ge 1 ];then echo \"install dialog,Please wait...\" yum -y install dialog rpm -q dialog >/dev/null [ $? -ge 1 ] && echo \"dialog installation failure,exit\" && exit echo \"dialog done\" read fi } 游戏维护菜单-修改配置文件{ #!/bin/bash conf=serverlist.xml AreaList=`awk -F '\"' '/ /dev/null 2>&1 then complaint='申诉成功' elif echo $results | grep '该IP的脱离申请已被他人提交' > /dev/null 2>&1 then complaint='申诉重复' elif echo $results | grep '申请由于近期内有被拒绝的记录' > /dev/null 2>&1 then complaint='申诉拒绝' else complaint='异常' fi else IpStatus='正常' complaint='无需申诉' fi echo \"$Ip $IpStatus $complaint\" >> $(date +%Y%m%d_%H%M%S).log done } Web Server in Awk{ #gawk -f file BEGIN { x = 1 # script exits if x \\ Simple gawk server\\ \\ xterm\\ xcalc\\ xload\\ terminate script\\ \\ \" return tmp } function Bye() { tmp = \"\\ Simple gawk server\\ Script Terminated...\\ \" return tmp } function RunApp(app) { if (app == \"xterm\") {system(\"xterm&\"); return} if (app == \"xcalc\" ) {system(\"xcalc&\"); return} if (app == \"xload\" ) {system(\"xload&\"); return} if (app == \"exit\") {x = 0} } } } Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Shell/Shell文本处理常用工具补遗.html":{"url":"Shell/Shell文本处理常用工具补遗.html","title":"Shell文本处理常用工具补遗","keywords":"","body":"Shell 文本处理常用工具补遗 sort uniq count cut wc find xargs tr paste join paste split sort 对文本的行排序 sort 将文件的每一行作为一个单位，相互比较，默认比较原则是从首字符向后，依次按 ASCII 码值进行比较，最后将它们按升序输出 sort [选项] file [选项] -r - 逆序排序 ( 从大到小 ) -u - 去掉重复的行 -k N - 指定按第N列排序 -n - 按数字进行排序，sort 默认是按字符进行排序 -d - 按字典序进行排序 -t - 指定分隔符，默认分隔符是制表符 -k [n,m] - 按照指定的字段范围排序。从第 n 个字段开始，到第 m 个字段（ 默认到行尾 ） -f - 忽略大小写 -b - 忽略每行前面的空白部分 -o - 将排序后的结果存入指定的文件 常用命令 # 以冒号分割 /etc/passwd 每行，并按第 1 列字符排序 $ cat /etc/passwd | sort -t ':' -k1 # 以冒号分割 /etc/passwd 每行，并按第 3 列数字排序 $ cat /etc/passwd | sort -t ':' -k 3n $ cat /etc/passwd | sort -n -t \":\" -k 3 $ cat /etc/passwd | sort -n -t \":\" -k 3,3 # -k 3 ：代表从第三个字段到行尾都排序（第一个字段先排序，如果一致，则第二个字段再排序，直到行尾） # -k 3,3：代表仅对第三个字段进行排序，后面字段按原来顺序 uniq 检查并删除文本中相邻重复出现的行 uniq [选项] 文件 [选项] 空 - 默认将相邻或连续相同的行删除到只剩一行，并输出 -c 在每列旁边显示该行重复出现的次数 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Shell/句子解析.html":{"url":"Shell/句子解析.html","title":"句子解析","keywords":"","body":"句子解析 目录 [ $# -lt 1 ] && echo \"please input the income file\" && exit -1 [ ! -f $1 ] && echo \"$1 is not a file\" && exit -1 for i in ${seq -f %03g 1 12};do wget \"https://img.ivsky.com/img/tupian/pre/201812/29/lvyouyou_nongtian-$i.jpg\"; done for i in {1..5} ; do echo -n \"$i \"; done hash $1 &> /dev/null echo \"`date +%F' '%H:%M:%S`\" [ [ -d $dirname ] || mkdir -p $dirname &> /dev/null -e ${dirname}${filename} ] || touch ${dirname}${filename} &> /dev/null cat /etc/passwd|grep -v nologin|grep -v halt|grep -v shutdown|awk -F\":\" '{ print $1\"|\"$3\"|\"$4 }' egrep -v \"(^$|^#)\" /etc/ansible/ansible.cfg 运行即崩溃 df -h | grep -vi \"filesystem\" [ ! -d \"${INSTALL_DIR}\" ] && mkdir -p ${INSTALL_DIR} kill pgrep java SCRIPTDIR=$(dirname $(readlink -f ${BASH_SOURCE[0]})) [ \".$1\" != \".\" ] ps aux | head -1;ps aux | grep -v PID | sort -rn -k +3 | head ps aux | head -1;ps aux | grep -v PID | sort -rn -k +4 | head find / -size +100M -exec ls -lh {} \\; find . -name \"*.pyc\" -type f -print -exec rm -rf {} \\; find . -name \"*.pyc\" -type f -print0 | xargs -0 rm -f [ $# -lt 1 ] && echo \"please input the income file\" && exit -1 解释：脚本不带参数时，输出 \"please input the income file\" 并以 -1 （非零表示执行失败）状态值退出 [ $# -lt 1 ] ：$# 是传入脚本参数个数，-lt是小于 &&：当前面出现第一个 false，则false后面都不执行；前面都是 true，则接着执行后面的语句 [ ! -f $1 ] && echo \"$1 is not a file\" && exit -1 解释：传入脚本的第一个参数不是文件格式时，输出 \"$1 is not a file\" 并以 -1 （非零表示执行失败）状态值退出 for i in `seq -f %03g 1 12`; do wget \"https://img.ivsky.com/img/tupian/pre/201812/29/lvyouyou_nongtian-$i.jpg\"; done 解释：wget 下载 https://img.ivsky.com/img/tupian/pre/201812/29/lvyouyou_nongtian-(001-012).jpg seq：打印一个数字序列 seq -f %03g 1 12： -f - 指定打印的格式 % - 后面指定数字的位数 默认是%g %3g - 打印 3 位数不足部分是空格 %03g - 打印 3 位数不足部分是 0 还可以在%前面加上固定的字符串： $ seq -f \"str%03g\" 9 11 str009 str010 str011 for i in {1..5}; do echo -n \"$i \"; done 解释：打印输出 \"1 2 3 4 5 \" {1..5}：中间是两点.. echo -n：输出不换行 hash $1 &> /dev/null hash git &> /dev/null && echo \"当前系统已经安装了 git\" || echo \"当前系统没有安装 git\" 解释：判断第一个参数是否存在于当前系统命令，无输出；判断当前系统是否安装了 git hash：返回 0 ( 命令已存在于当前系统 ) 或 1 echo `date +'%Y-%m-%d %H:%M:%S'` # 显示的是本地时区的时间 echo `date -u -d\"+8 hour\" +'%Y-%m-%d %H:%M:%S'` 解释：格式化输出时间，注意 date 后面是空格、加号 解释：先打印 UTC 时间，在转换成中国时间 (CST)，这样即使本地时区未设置成中国地区，也显示的是 CST 中国地区时间 [ -d $dirname ] || mkdir -p $dirname &> /dev/null [ -e ${dirname}${filename} ] || touch ${dirname}${filename} &> /dev/null 解释：dirname 文件夹和 ${dirname}${filename} 文件存在则无反应，不存在则创建之 $ cat /etc/passwd | grep -v nologin | grep -v halt | grep -v shutdown | awk -F\":\" '{ print $1\"|\"$3\"|\"$4 }' root|0|0 sync|5|0 admin|1000|1000 xcq|1001|1001 解释：格式化输出 Linux 用户列表 grep -v：输出显示不匹配的行 awk -F\":\" '{ print $1\"|\"$3\"|\"$4 }'：使用 \":\" 分割输入字符串，并输出第 1、3、4 列内容 egrep -v \"(^$|^#)\" /etc/ansible/ansible.cfg 输出非空行和非注释的内容 ls {1{,0,1,2,3,4,5,6,7,8,9}{,0,1,2,3,4,5,6,7,8,9},2{0,1,2,3,4,5}{,0,1,2,3,4,5}}.{1{,0,1,2,3,4,5,6,7,8,9}{,0,1,2,3,4,5,6,7,8,9},2{0,1,2,3,4,5}{,0,1,2,3,4,5}}.{1{,0,1,2,3,4,5,6,7,8,9}{,0,1,2,3,4,5,6,7,8,9},2{0,1,2,3,4,5}{,0,1,2,3,4,5}}.{1{,0,1,2,3,4,5,6,7,8,9}{,0,1,2,3,4,5,6,7,8,9},2{0,1,2,3,4,5}{,0,1,2,3,4,5}} 2> /dev/null 解释：匹配当前目录下以正规 ip 地址作为名字的文件，但运行即崩溃 $ df -h | grep -vi 'filesystem' df -h | grep -vi 'filesystem' udev 976M 0 976M 0% /dev tmpfs 200M 6.9M 193M 4% /run /dev/vda1 40G 16G 23G 42% / tmpfs 997M 0 997M 0% /dev/shm tmpfs 5.0M 0 5.0M 0% /run/lock tmpfs 997M 0 997M 0% /sys/fs/cgroup grep -v：反向匹配 grep -i：匹配忽略大小写 解释：对性能输出进行匹配剪切时往往将第一行表头去掉，这样会更方便 [ ! -d \"${INSTALL_DIR}\" ] && mkdir -p ${INSTALL_DIR} # [ ! -f \"./install.sh\" ] && touch ./install.sh [ -d xxx ]：检测目录是否存在 [ -f xxx ]：检测文件是否存在，使用 man test 可以查看相关命令 解释：检测 ${INSTALL_DIR} 目录是否存在，不存在则创建 kill `pgrep java` 解释：pgrep 进程名 返回匹配到的进程的 PID SCRIPTDIR=$(dirname $(readlink -f ${BASH_SOURCE[0]})) 解释：Shell 脚本中定义当前脚本执行目录的路径 [ \".$1\" != \".\" ] 解释： 判断脚本传入的第一个参数是否为空 ps aux | head -1;ps aux | grep -v PID | sort -rn -k +3 | head 解释： 查看占用 CPU 资源最多的 10 个进程 ps aux | head -1;ps aux | grep -v PID | sort -rn -k +4 | head 解释： 查看占用内存资源最多的 10 个进程 find / -size +100M -exec ls -lh {} \\; 解释： 查找大于 100M 的文件 find . -name \"*.txt\" -type f -print -exec rm -rf {} \\; 解释：删除一个目录下所有某个格式的文件 find . -name \"*.txt\" -type f -print0 | xargs -0 rm -f -print0 选项将 \\0 作为 find 输出的分隔符 xargs -0 将 \\0 作为输入定界符 解释： 删除一个目录下所有某个格式的文件 find -type f -name '*.c' -print0 | xargs -0 wc -l 解释：找到路径下所有 c 文件，并统计行数（引号必不可少） Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Shell/识别是否是root用户.html":{"url":"Shell/识别是否是root用户.html","title":"识别是否是root用户","keywords":"","body":"案例一、 #!/usr/bin/env bash Green_background_prefix=\"\\033[42;37m\" && Font_color_suffix=\"\\033[0m\" check_root(){ [[ $EUID != 0 ]] && echo -e \"${Error} 当前非ROOT账号(或没有ROOT权限)，无法继续操作，请更换ROOT账号或使用$ {Green_background_prefix}sudo su${Font_color_suffix} 命令获取临时ROOT权限（执行后可能会提示输入当前账号的密码）。\" && exit 1 } check_root echo echo -e —— 开启转义，即可读取 '\\n' 为换行 shell 脚本中 echo 显示内容带颜色显示，echo 显示带颜色，需要使用参数 -e 例如： echo -e \"\\033[41;36m something here \\033[0m\" 其中 41 的位置代表底色， 36 的位置是代表字的颜色 注： 字背景颜色和文字颜色之间是英文的 \"\" 文字颜色后面有个 m 字符串前后可以没有空格，如果有的话，输出也是同样有空格 下面是相应的字和背景颜色，可以自己来尝试找出不同颜色搭配 字颜色：30—–37 　　echo -e “\\033[30m 黑色字 \\033[0m” 　　echo -e “\\033[31m 红色字 \\033[0m” 　　echo -e “\\033[32m 绿色字 \\033[0m” 　　echo -e “\\033[33m 黄色字 \\033[0m” 　　echo -e “\\033[34m 蓝色字 \\033[0m” 　　echo -e “\\033[35m 紫色字 \\033[0m” 　　echo -e “\\033[36m 天蓝字 \\033[0m” 　　echo -e “\\033[37m 白色字 \\033[0m” 字背景颜色范围：40—–47 echo -e “\\033[40;37m 黑底白字 \\033[0m” 　　echo -e “\\033[41;37m 红底白字 \\033[0m” 　　echo -e “\\033[42;37m 绿底白字 \\033[0m” 　　echo -e “\\033[43;37m 黄底白字 \\033[0m” 　　echo -e “\\033[44;37m 蓝底白字 \\033[0m” 　　echo -e “\\033[45;37m 紫底白字 \\033[0m” 　　echo -e “\\033[46;37m 天蓝底白字 \\033[0m” 　　echo -e “\\033[47;30m 白底黑字 \\033[0m” 最后面控制选项说明 　　\\33[0m 关闭所有属性 　　\\33[1m 设置高亮度 　　\\33[4m 下划线 　　\\33[5m 闪烁 　　\\33[7m 反显 　　\\33[8m 消隐 　　\\33[30m — \\33[37m 设置前景色 　　\\33[40m — \\33[47m 设置背景色 　　\\33[nA 光标上移n行 　　\\33[nB 光标下移n行 　　\\33[nC 光标右移n行 　　\\33[nD 光标左移n行 　　\\33[y;xH设置光标位置 　　\\33[2J 清屏 　　\\33[K 清除从光标到行尾的内容 　　\\33[s 保存光标位置 　　\\33[u 恢复光标位置 　　\\33[?25l 隐藏光标 　　\\33[?25h 显示光标 案例二、id -u（显示当前用户的 uid ） [ $(id -u) != \"0\" ] && echo \"Error: You must be root to run this script\" && exit 1 或 [ `id -u` != \"0\" ] && echo \"Error: You must be root to run this script\" && exit 1 案例三、whoami（显示当前用户的用户名） # != 两边一定要有空格，中括号内两侧也一定要有一个空格 [ $(whoami) != \"root\" ] && echo \"Error: You must be root to run this script\" && exit 1 或 [ `whoami` != \"root\" ] && echo \"Error: You must be root to run this script\" && exit 1 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Shell/识别系统.html":{"url":"Shell/识别系统.html","title":"识别系统","keywords":"","body":"#!/usr/bin/env bash check_sys(){ if [[ -f /etc/redhat-release ]]; then release='centos' elif cat /etc/issue | grep -q -E -i 'debian'; then release='debian' elif cat /etc/issue | grep -q -E -i 'ubuntu'; then release='ubuntu' elif cat /etc/issue | grep -q -E -i 'centos|red hat|redhat'; then release='centos' elif cat /proc/version | grep -q -E -i 'debian'; then release='debian' elif cat /proc/version | grep -q -E -i 'centos|red hat|redhat'; then release='centos' elif cat /proc/version | grep -q -E -i 'ubuntu'; then release='ubuntu' fi echo $release } check_sys grep -q, --quiet, --silent 不显示所有常规输出 -i, --ignore-case 忽略大小写 -E, --extended-regexp 将范本样式为延伸的普通表示法来使用，意味着使用能使用扩展正则表达式 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Vim/":{"url":"Vim/","title":"Vim","keywords":"","body":"Vim 学习 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Vim/Vim小知识.html":{"url":"Vim/Vim小知识.html","title":"Vim小知识","keywords":"","body":"Vim 小知识 奇淫技巧 :w !sudo tee % - 保存的时提示你没有权限，可以临时提权保存 全部 tab 替换为空格 # 不加感叹号!，则只处理行首的 tab :set ts=4 :set expandtab :%retab! 全部空格替换为 tab :set ts=4 :set noexpandtab :%retab! # 不加感叹号!，则只处理首行的空格 :g/^$/d - 删除空行 :g/^\\s*$/d - 删除空行以及只有空格的行 :g/^\\s*#/d - 删除以 # 开头或 空格# 或 tab# 开头的行 :g/^\\s*;/d - 对于 php.ini 配置文件，注释为 ; 开头 :/bbs/d - 如果当前行包含 bbs ，则删除当前行 :2,/bbs/d - 删除从第二行到包含 bbs 的区间行 :/bbs/,$d - 删除从包含 bbs 的行到最后一行区间的行 :g/bbs/d - 删除所有包含 bbs 的行 :g/.bbs/d - 删除匹配 bbs 且前面只有一个字符的行 :g/^bbs/d - 删除匹配 bbs 且以它开头的行 :g/bbs$/d - 删除匹配 bbs 且以它结尾的行 :%s/\\;.\\+//g - .ini 的注释是以 ; 开始的，如果注释不在行开头，那么删除 ; 及以后的字符 %s/\\#.*//g - 删除 # 之后所有字符 快捷键 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Vim/Vim编辑器再学习.html":{"url":"Vim/Vim编辑器再学习.html","title":"Vim编辑器再学习","keywords":"","body":"Vim 编辑器再学习 使用 Ubuntu 已经两年了，对于 Vim 的利用只能算是小半桶水水平，一直感觉利用 Vim 编程非常麻烦，几次尝试系统学习 Vim，并从此转换到 Vim 使用者一族，但都半途而废。现在终于下定决心，即使摸着石头也要过了这条 “河”。我认为这就好比当年从 Windows 迁移到 Linux 上，一开始一直犹犹豫豫，但后来看到一片令我茅塞顿开的文章，那天下午我就开始了 Linux 的生涯，凡事都要迈出第一步嘛！ 对于大多数用户来说，Vim 有着一个比较陡峭的学习曲线。这意味着开始学习的时候可能会进展缓慢，但是一旦掌握一些基本操作之后，能大幅度提高编辑效率。在Vim 用户手册中更加详细的描述了 Vim 的基础和进阶功能。可以在Vim中输入 :help user-manual 进入用户手册。手册除了原始的英文版本之外，也被志愿者翻译成了各国文字，其中包括中文。 --- Wiki 通篇教程以 Ubuntu 18.04 LTS 为例 参考 && 扩展 vim字符串替换及小技巧 Vim 安装、卸载 Vim Github : https://github.com/vim/vim 安装方法 安装很简单，方法如下，具体步骤百度、Google 一下即可 Github 源码安装 本地软件源安装：sudo apt install vim 添加软件源安装 卸载 卸载有些地方需要注意 老版本 Vim 完全卸载 首先检查本地安装的 Vim 相关的软件 dpkg -l | grep vim apt 卸载 sudo apt-get remove vim sudo apt-get remove vim-runtime sudo apt-get remove vim -tiny sudo apt-get remove vim-common sudo apt-get remove vim-doc sudo apt-get remove vim-scripts 使用包管理器 apt 卸载 # 卸载 Vim，只删除 Vim 包本身 sudo apt remove vim # 卸载 Vim 及其依赖软件包 sudo apt remove --auto-remove vim # 清除 Vim 配置/数据，注意清除的配置及数据无法恢复 sudo apt purge vim # & sudo apt purge --auto-remove vim Vim 的配置 Vim 配置文件 - vimrc 系统级 Vim 配置文件 /etc/vim/vimrc 系统的每个用户在打开 Vim 时都会载入它 /usr/share/vim/vimrc 是一个链接到 /etc/vim/vimrc 的链接文件lrwxrwxrwx 1 root root 14 Apr 11 2018 vimrc -> /etc/vim/vimrc 用户级 Vim 配置文件 ~/.vimrc 在 Linux 和 Mac OS X 中，这个文件位于你的 home 文件夹，并以 .vimrc 命名；在 Windows 中，这个文件位于你的 home 文件夹，并以 _vimrc命名 应该在这里编辑自己的 Vim 配置信息，这个文件里不要有重复的配置，比如 filetype plugin indent on 和 filetype plugin on filetype indent on 重复。之前直接复制了别人的部分配置，正巧就发生了上面的重复，直接导致 vim 缓冲区出现问题，导致无法正常打开文件，而且这样的错误很难发现排除 VimScript - Vim 的自定义配置 简介 一门用于定制 Vim 的脚本语言 vimrc 和 Vim 中的插件（ .vim ）都是使用 Vim 脚本语言 - vimscript 编写的 Vimscript VimScript 系统学习：http://learnvimscriptthehardway.onefloweroneworld.com/ 我的学习 VimScript 笔记 记录一些 vimrc 的技巧用法 要让 .vimrc 变更内容生效，一般的做法是先保存 .vimrc 再重启 vim 。增加如下设置，可以实现保存 .vimrc (:w) 时自动重启加载autocmd BufWritePost $MYVIMRC source $MYVIMRC 设置 html / css / python 等文件的默认模板 在~/.vim/vimfiles目录下建一个自定义后缀的模板文件，比如 template.html，在里面输入你自己想要初始化模板的内容 在 ~/.vimrc 或 /etc/vim/vimrc 文件中添加 autocmd BufNewFile *.html 0r ~/.vim/vimfiles/template.html 支持中文不乱码 # 设置编码 set fileencodings=utf-8,ucs-bom,gb18030,gbk,gb2312,cp936 set termencoding=utf-8 set encoding=utf-8 与 Vim 编码有关的变量包括：encoding、fileencoding、termencoding encoding 选项用于缓存的文本、寄存器、Vim 脚本文件等 fileencoding 选项是 Vim 写入文件时采用的编码类型 termencoding 选项表示输出到终端时采用的编码类型 显示空格和 tab 键 set listchars=tab:>-,trail:- Vim 编辑器中默认不显示文件中的 tab 和空格符，方便定位输入错误 括号自动补全 inoremap ( ()i inoremap [ []i inoremap { {}i buffer \\ tab \\ windows 详解 A buffer is the in-memory text of a file A window is a viewport on a buffer A tab page is a collection of windows Buffer A buffer is an area of Vim’s memory used to hold text read from a file. In addition, an empty buffer with no associated file can be created to allow the entry of text. – vim.wikia Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Vim/VimScript学习笔记.html":{"url":"Vim/VimScript学习笔记.html","title":"VimScript 学习笔记","keywords":"","body":"VimScript 学习笔记 常用命令 命令 详解 例子 说明 :echo 打印信息 :echo 'hello' 打印输出 'hello' :echom 打印信息，并保存信息 :echom 'hello' 打印输出并保存 'hello'，使用命令 :messages 可以查看 :message :map \\ :noremap 常规模式、视图模式下都适用的映射，加 nore 表示非递归映射，默认是递归映射 :map - x 在各种模式下，用 - 代替 x （删除光标后一个字符） :nmap \\ :nnoremap 模式映射 :nmap \\ dd 在 Normal 模式下，用 \\ 代替 dd （删除整行） :vmap \\ :vnoremap 视图映射 :vmap \\ U 在 visual 模式下，用 \\ 代替 U (将选中文本转换成大写格式） :imap \\ :inoremap 插入映射 :imap \\ 在 Insert 模式下，用 \\ 代替 esc 键 （退出 Insert 模式到 Normal 模式） :cmap \\ :cnoremap 命令行映射 : 命令详解补充 递归映射和非递归映射 map a b map b c 对于上面例子 递归映射：等价于map a c 非递归映射：a 只能映射到 b ，b 只能映射到 c ，a 无法映射到 c 映射键常用表示 键盘上的键位 在 vim 中的表示 大小写英文字母 - eg:a、A 就是大小写英文字母 - a、A 符号 - eg:: 就是符号 - : Ctrl esc enter backspace ↑ ↓ ← → Ctrl + a Ctrl + esc Ctrl + w + w w Shift Shift + F1 cmd 或 Win Alt 或 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Vim/vim从入门到精通[转载].html":{"url":"Vim/vim从入门到精通[转载].html","title":"Vim 从入门到精通","keywords":"","body":"Vim 从入门到精通 本文主要在翻译 mhinz/vim-galore 的基础添加了一些我在使用 Vim 及开发 Vim 插件的过程中积累的一些知识和常用插件列表。 简介 什么是 Vim？ Vim 哲学 入门 精简的 vimrc Windows 系统 Linux 或者 Mac OS 我正在使用什么样的 Vim 备忘录 基础 缓冲区，窗口，标签 已激活、已载入、已列出、已命名的缓冲区 参数列表 按键映射 映射前置键 寄存器 范围 标注 补全 动作，操作符，文本对象 自动命令 变更历史，跳转历史 内容变更历史记录 全局位置信息表，局部位置信息表 宏 颜色主题 折叠 会话 局部化 用法 获取离线帮助 获取离线帮助（补充） 获取在线帮助 执行自动命令 用户自定义事件 事件嵌套 剪切板 剪贴板的使用（Windows, OSX） 剪贴板的使用（Linux, BSD, ...） 打开文件时恢复光标位置 临时文件 备份文件 交换文件 撤销文件 viminfo 文件 临时文件管理设置示例 编辑远程文件 插件管理 多行编辑 使用外部程序和过滤器 Cscope 1. 构建数据库 2. 添加数据库 3. 查询数据库 MatchIt 在 Vim 8 中安装 在 Vim 7 或者更早的版本中安装 简短的介绍 技巧 跳至选择的区域另一端 聪明地使用 n 和 N 聪明地使用命令行历史 智能 Ctrl-l 禁用错误报警声音和图标 快速移动当前行 快速添加空行 运行时检测 查看启动时间 NUL 符用新行表示 快速编辑自定义宏 快速跳转到源(头)文件 在 GUI 中快速改变字体大小 根据模式改变光标类型 防止水平滑动的时候失去选择 选择当前行至结尾，排除换行符 重新载入保存文件 更加智能的当前行高亮 更快的关键字补全 改变颜色主题的默认外观 命令 :global 和 :vglobal - 在所有匹配行执行命令 :normal 和 :execute - 脚本梦之队 重定向消息 调试 常规建议 调整日志等级 查看启动日志 查看运行时日志 Vim 脚本调试 语法文件调试 杂项 附加资源 Vim 配置集合 常见问题 编辑小文件时很慢 编辑大文件的时候很慢 持续粘贴（为什么我每次都要设置 'paste' 模式） 在终端中按 ESC 后有延时 无法重复函数中执行的搜索 进阶阅读 加入我们 参考资料 简介 什么是 Vim？ Vim 是一个历史悠久的文本编辑器，可以追溯到 qed>)。 Bram Moolenaar 于 1991 年发布初始版本。 Linux、Mac 用户，可以使用包管理器安装 Vim，对于 Windows 用户，可以从 我的网盘 下载。 该版本可轻易添加 python 、python3 、lua 等支持，只需要安装 python、lua 即可。 项目在 Github 上开发，项目讨论请订阅 vim_dev 邮件列表。 通过阅读 Why, oh WHY, do those #?@! nutheads use vi? 来对 Vim 进行大致的了解。 Vim 哲学 Vim 采用模式编辑的理念，即它提供了多种模式，按键在不同的模式下作用不同。 你可以在普通模式 下浏览文件，在插入模式下插入文本， 在可视模式下选择行，在命令模式下执行命令等等。起初这听起来可能很复杂， 但是这有一个很大的优点：不需要通过同时按住多个键来完成操作， 大多数时候你只需要依次按下这些按键即可。越常用的操作，所需要的按键数量越少。 和模式编辑紧密相连的概念是 操作符 和 动作。操作符 指的是开始某个行为， 例如：修改、删除或者选择文本，之后你要用一个 动作 来指定需要操作的文本区域。 比如，要改变括号内的文本，需要执行 ci( （读做 change inner parentheses）； 删除整个段落的内容，需要执行 dap （读做：delete around paragraph）。 如果你能看见 Vim 老司机操作，你会发现他们使用 Vim 脚本语言就如同钢琴师弹钢琴一样。复杂的操作只需要几个按键就能完成。他们甚至不用刻意去想，因为这已经成为肌肉记忆了。这减少认识负荷并帮助人们专注于实际任务。 入门 Vim 自带一个交互式的教程，内含你需要了解的最基础的信息，你可以通过终端运行以下命令打开教程： $ vimtutor 不要因为这个看上去很无聊而跳过，按照此教程多练习。你以前用的 IDE 或者其他编辑器很少是有“模式”概念的，因此一开始你会很难适应模式切换。但是你 Vim 使用的越多，肌肉记忆 将越容易形成。 Vim 基于一个 vi 克隆，叫做 Stevie>)，支持两种运行模式：\"compatible\" 和 \"nocompatible\"。在兼容模式下运行 Vim 意味着使用 vi 的默认设置，而不是 Vim 的默认设置。除非你新建一个用户的 vimrc 或者使用 vim -N 命令启动 Vim，否则就是在兼容模式下运行 Vim！请大家不要在兼容模式下运行 Vim。 下一步 创建你自己的 vimrc。 在第一周准备备忘录。 通读基础章节了解 Vim 还有哪些功能。 按需学习！Vim 是学不完的。如果你遇到了问题，先上网寻找解决方案，你的问题可能已经被解决了。Vim 拥有大量的参考文档，知道如何利用这些参考文档很有必要：获取离线帮助。 浏览附加资源。 最后一个建议：使用插件之前，请先掌握 Vim 的基本操作。很多插件都只是对 Vim 自带功能的封装。 返回主目录 :arrow_heading_up: 精简的 vimrc Vim 启动是会按照一定的优先顺序来搜索配置文件，这个顺序，可以通过 :version 命令查看。下面分 Windows 系统， 和 *niux 系统分别来说明 Vim 是如何载入配置文件的。 Windows 系统 system vimrc file: \"$VIM\\vimrc\" user vimrc file: \"$HOME\\_vimrc\" 2nd user vimrc file: \"$HOME\\vimfiles\\vimrc\" 3rd user vimrc file: \"$VIM\\_vimrc\" user exrc file: \"$HOME\\_exrc\" 2nd user exrc file: \"$VIM\\_exrc\" system gvimrc file: \"$VIM\\gvimrc\" user gvimrc file: \"$HOME\\_gvimrc\" 2nd user gvimrc file: \"$HOME\\vimfiles\\gvimrc\" 3rd user gvimrc file: \"$VIM\\_gvimrc\" defaults file: \"$VIMRUNTIME\\defaults.vim\" system menu file: \"$VIMRUNTIME\\menu.vim\" 我们们只看上面这一段，Vim 会优先读取 user vimrc file: $HOME\\_vimrc, 当这一文件不存在是， Vim 再去寻找 2nd user vimrc file: $HOME\\vimfiles\\vimrc; 倘若这个文件还是不存在，那么 Vim 会去继续寻找 3rd user vimrc file: $VIM\\_vimrc。 了解以上顺序后，就不会再因为 Vim 总是不读取配置文件而感到烦恼了。 Linux 或者 Mac OS 同 Windows 系统类似，也可以使用 :version 命令查看 vim 载入配置的优先顺序。 系统 vimrc 文件: \"/etc/vimrc\" 用户 vimrc 文件: \"$HOME/.vimrc\" 第二用户 vimrc 文件: \"~/.vim/vimrc\" 用户 exrc 文件: \"$HOME/.exrc\" defaults file: \"$VIMRUNTIME/defaults.vim\" $VIM 预设值: \"/etc\" $VIMRUNTIME 预设值: \"/usr/share/vim/vim81\" 你可以在网上找到许多精简的 vimrc 配置文件，我的版本可能并不是最简单的版本，但是我的版本提供了一套我认为良好的，非常适合入门的设置。 最终你需要阅读完那些设置，然后自行决定需要使用哪些。:-) 精简的 vimrc 地址：minimal-vimrc 如果你有兴趣，这里是我（原作者）的 vimrc。 建议：大多数插件作者都维护不止一个插件并且将他们的 vimrc 放在 Github 上展示（通常放在叫做 \"vim-config\" 或者 \"dotfiles\" 的仓库中），所以当你发现你喜欢的插件时，去插件维护者的 Github 主页看看有没有这样的仓库。 返回主目录 :arrow_heading_up: 我正在使用什么样的 Vim 使用 :version 命令将向你展示当前正在运行的 Vim 的所有相关信息，包括它是如何编译的。 第一行告诉你这个二进制文件的编译时间和版本号，比如：7.4。接下来的一行呈现 Included patches: 1-1051，这是补丁版本包。因此你 Vim 确切的版本号是 7.4.1051。 另一行显示着一些像 Tiny version without GUI 或者 Huge version with GUI 的信息。很显然这些信息告诉你当前的 Vim 是否支持 GUI，例如：从终端中运行 gvim 或者从终端模拟器中的 Vim 内运行 :gui 命令。另一个重要的信息是 Tiny 和 Huge。Vim 的特性集区分被叫做 tiny，small，normal，big and huge，所有的都实现不同的功能子集。 :version 主要的输出内容是特性列表。+clipboard 意味这剪贴板功能被编译支持了，-clipboard 意味着剪贴板特性没有被编译支持。 一些功能特性需要编译支持才能正常工作。例如：为了让 :prof 工作，你需要使用 huge 模式编译的 Vim，因为那种模式启用了 +profile 特性。 如果你的输出情况并不是那样，并且你是从包管理器安装 Vim 的，确保你安装了 vim-x，vim-x11，vim-gtk，vim-gnome 这些包或者相似的，因为这些包通常都是 huge 模式编译的。 你也可以运行下面这段代码来测试 Vim 版本以及功能支持： \" Do something if running at least Vim 7.4.42 with +profile enabled. if (v:version > 704 || v:version == 704 && has('patch42')) && has('profile') \" do stuff endif 相关帮助： :h :version :h feature-list :h +feature-list :h has-patch 返回主目录 :arrow_heading_up: 备忘录 为了避免版权问题，我只贴出链接： http://people.csail.mit.edu/vgod/vim/vim-cheat-sheet-en.png https://cdn.shopify.com/s/files/1/0165/4168/files/preview.png http://www.nathael.org/Data/vi-vim-cheat-sheet.svg http://michael.peopleofhonoronly.com/vim/vim_cheat_sheet_for_programmers_screen.png http://www.rosipov.com/images/posts/vim-movement-commands-cheatsheet.png 或者在 Vim 中快速打开备忘录：vim-cheat40。 返回主目录 :arrow_heading_up: 基础 缓冲区，窗口，标签 Vim 是一个文本编辑器。每次文本都是作为缓冲区的一部分显示的。每一份文件都是在他们自己独有的缓冲区打开的，插件显示的内容也在它们自己的缓冲区中。 缓冲区有很多属性，比如这个缓冲区的内容是否可以修改，或者这个缓冲区是否和文件相关联，是否需要同步保存到磁盘上。 窗口 是缓冲区上一层的视窗。如果你想同时查看几个文件或者查看同一文件的不同位置，那样你会需要窗口。 请别把他们叫做 分屏 。你可以把一个窗口分割成两个，但是这并没有让这两个窗口完全 分离 。 窗口可以水平或者竖直分割并且现有窗口的高度和宽度都是可以被调节设置的，因此，如果你需要多种窗口布局，请考虑使用标签。 标签页 （标签）是窗口的集合。因此当你想使用多种窗口布局时候请使用标签。 简单的说，如果你启动 Vim 的时候没有附带任何参数，你会得到一个包含着一个呈现一个缓冲区的窗口的标签。 顺带提一下，缓冲区列表是全局可见的，你可以在任何标签中访问任何一个缓冲区。 返回主目录 :arrow_heading_up: 已激活、已载入、已列出、已命名的缓冲区 用类似 vim file1 的命令启动 Vim 。这个文件的内容将会被加载到缓冲区中，你现在有一个已载入的缓冲区。如果你在 Vim 中保存这个文件，缓冲区内容将会被同步到磁盘上（写回文件中）。 由于这个缓冲区也在一个窗口上显示，所以他也是一个已激活的缓冲区。如果你现在通过 :e file2 命令加载另一个文件，file1 将会变成一个隐藏的缓冲区，并且 file2 变成已激活缓冲区。 使用 :ls 我们能够列出所有可以列出的缓冲区。插件缓冲区和帮助缓冲区通常被标记为不可以列出的缓冲区，因为那并不是你经常需要在编辑器中编辑的常规文件。通过 :ls! 命令可以显示被放入缓冲区列表的和未被放入列表的缓冲区。 未命名的缓冲区是一种没有关联特定文件的缓冲区，这种缓冲区经常被插件使用。比如 :enew 将会创建一个无名临时缓冲区。添加一些文本然后使用 :w /tmp/foo 将他写入到磁盘，这样这个缓冲区就会变成一个已命名的缓冲区。 返回主目录 :arrow_heading_up: 参数列表 全局缓冲区列表是 Vim 的特性。在这之前的 vi 中，仅仅只有参数列表，参数列表在 Vim 中依旧可以使用。 每一个通过 shell 命令传递给 Vim 的文件名都被记录在一个参数列表中。可以有多个参数列表：默认情况下所有参数都被放在全局参数列表下，但是你可以使用 :arglocal 命令去创建一个新的本地窗口的参数列表。 使用 :args 命令可以列出当前参数。使用 :next，:previous，:first，:last 命令可以在切换在参数列表中的文件。通过使用 :argadd，:argdelete 或者 :args 等命令加上一个文件列表可以改变参数列表。 偏爱缓冲区列表还是参数列表完全是个人选择，我的印象中大多数人都是使用缓冲区列表的。 然而参数列表在有些情况下被大量使用：批处理 使用 :argdo！ 一个简单的重构例子： :args **/*.[ch] :argdo %s/foo/bar/ge | update 这条命令将替换掉当前目录下以及当前目录的子目录中所有的 C 源文件和头文件中的“foo”，并用“bar”代替。 相关帮助：:h argument-list 返回主目录 :arrow_heading_up: 按键映射 使用 :map 命令家族你可以定义属于你自己的快捷键。该家族的每一个命令都限定在特定的模式下。从技术上来说 Vim 自带高达 12 中模式，其中 6 种可以被映射。另外一些命令作用于多种模式： 递归 非递归 模式 :map :noremap normal, visual, operator-pending :nmap :nnoremap normal :xmap :xnoremap visual :cmap :cnoremap command-line :omap :onoremap operator-pending :imap :inoremap insert 例如：这个自定义的快捷键只在普通模式下工作。 :nmap :echo \"foo\" 使用 :nunmap 可以取消这个映射。 对于更少数，不常见的模式（或者他们的组合），查看 :h map-modes。 到现在为止还好，对新手而言有一个问题会困扰他们：:nmap 是递归执行的！结果是，右边执行可能的映射。 你自定义了一个简单的映射去输出“Foo”： :nmap b :echo \"Foo\" 但是如果你想要映射 b （回退一个单词）的默认功能到一个键上呢？ :nmap a b 如果你敲击a，我们期望着光标回退到上一个单词，但是实际情况是“Foo”被输出到命令行里！因为在右边，b 已经被映射到别的行为上了，换句话说就是 :echo \"Foo\"。 解决此问题的正确方法是使用一种 非递归 的映射代替： :nnoremap a b 经验法则：除非递归是必须的，否则总是使用非递归映射。 通过不给一个右值来检查你的映射。比如:nmap 显示所以普通模式下的映射，:nmap 显示所有以 键开头的普通模式下的映射。 如果你想禁止用标准映射，把他们映射到特殊字符 上，例如：:noremap 。 相关帮助： :h key-notation :h mapping :h 05.3 返回主目录 :arrow_heading_up: 映射前置键 映射前置键（Leader 键）本身就是一个按键映射，默认为 \\。我们可以通过在 map 中调用 来为把它添加到其他按键映射中。 nnoremap h :helpgrep 这样，我们只需要先按 \\ 然后连续按 \\h 就可以激活这个映射 :helpgrep。如果你想通过先按 空格 键来触发，只需要这样做： let g:mapleader = ' ' nnoremap h :helpgrep 此处建议使用 g:mapleader，因为在 Vim 脚本中，函数外的变量缺省的作用域是全局变量，但是在函数内缺省作用域是局部变量，而设置快捷键前缀需要修改全局变量 g:mapleader 的值。 另外，还有一个叫 的，可以把它理解为局部环境中的 ，默认值依然为 \\。当我们需要只对某一个条件下（比如，特定文件类型的插件）的缓冲区设置特别的 键，那么我们就可以通过修改当前环境下的 来实现。 注意：如果你打算设置 Leader 键，请确保在设置按键映射之前，先设置好 Leader 键。如果你先设置了含有 Leader 键的映射，然后又修改了 Leader 键，那么之前映射内的 Leader 键是不会因此而改变的。你可以通过执行 :nmap 来查看普通模式中已绑定给 Leader 键的所有映射。 请参阅 :h mapleader 与 :h maploacalleader 来获取更多帮助。 返回主目录 :arrow_heading_up: 寄存器 寄存器就是存储文本的地方。我们常用的「复制」操作就是把文本存储到寄存器，「 粘贴」 操作就是把文本从寄存器中读出来。顺便，在 Vim 中复制的快捷键是 y，粘贴的快捷键是 p。 Vim 为我们提供了如下的寄存器： 类型 标识 读写者 是否为只读 包含的字符来源 Unnamed \" vim 否 最近一次的复制或删除操作 (d, c, s, x, y) Numbered 0至9 vim 否 寄存器 0: 最近一次复制。寄存器 1: 最近一次删除。寄存器 2: 倒数第二次删除，以此类推。对于寄存器 1 至 9，他们其实是只读的最多包含 9 个元素的队列。这里的队列即为数据类型 queue>) Small delete - vim 否 最近一次行内删除 Named a至z, A至Z 用户 否 如果你通过复制操作存储文本至寄存器 a，那么 a 中的文本就会被完全覆盖。如果你存储至 A，那么会将文本添加给寄存器 a，不会覆盖之前已有的文本 Read-only :与.和% vim 是 :: 最近一次使用的命令，.: 最近一次添加的文本，%: 当前的文件名 Alternate buffer # vim 否 大部分情况下，这个寄存器是当前窗口中，上一次访问的缓冲区。请参阅 :h alternate-file 来获取更多帮助 Expression = 用户 否 复制 VimL 代码时，这个寄存器用于存储代码片段的执行结果。比如，在插入模式下复制 =5+5，那么这个寄存器就会存入 10 Selection +和* vim 否 * 和 + 是 剪贴板 寄存器 Drop ~ vim 是 最后一次拖拽添加至 Vim 的文本（需要 \"+dnd\" 支持，暂时只支持 GTK GUI。请参阅 :help dnd 及 :help quote~） Black hole _ vim 否 一般称为黑洞寄存器。对于当前操作，如果你不希望在其他寄存器中保留文本，那就在命令前加上 _。比如，\"_dd 命令不会将文本放到寄存器 \"、1、+ 或 * 中 Last search pattern / vim 否 最近一次通过 /、? 或 :global 等命令调用的匹配条件 只要不是只读的寄存器，用户都有权限修改它的内容，比如： :let @/ = 'register' 这样，我们按 n 的时候就会跳转到单词\"register\" 出现的地方。 有些时候，你的操作可能已经修改了寄存器，而你没有察觉到。请参阅 :h registers 获取更多帮助。 上面提到过，复制的命令是 y，粘贴的命令是 p 或者 P。但请注意，Vim 会区分「字符选取」与「行选取」。请参阅 :h linewise 获取更多帮助。 行选取： 命令 yy 或 Y 都是复制当前行。这时移动光标至其他位置，按下 p 就可以在光标下方粘贴复制的行，按下 P 就可以在光标上方粘贴至复制的行。 字符选取： 命令 0yw 可以复制第一个单词。这时移动光标至其他位置，按下 p 就可以在当前行、光标后的位置粘贴单词，按下 P 就可以在当前行、光标前的位置粘贴单词。 将文本存到指定的寄存器中： 命令 \"aY 可以将当前行复制，并存储到寄存器 a 中。这时移动光标至其他位置，通过命令 \"AY 就可以把这一行的内容扩展到寄存器 a 中，而之前存储的内容也不会丢失。 为了便于理解和记忆，建议大家现在就试一试上面提到的这些操作。操作过程中，你可以随时通过 :reg 来查看寄存器的变化。 有趣的是： 在 Vim 中，y 是复制命令，源于单词 \"yanking\"。而在 Emacs 中，\"yanking\" 代表的是粘贴（或者说，重新插入刚才删掉的内容），而并不是复制。 返回主目录 :arrow_heading_up: 范围 范围 (Ranges) 其实很好理解，但很多 Vim 用户的理解不到位。 很多命令都可以加一个数字，用于指明操作范围 范围可以是一个行号，用于指定某一行 范围也可以是一对通过 , 或 ; 分割的行号 大部分命令，默认只作用于当前行 只有 :write 和 :global 是默认作用于所有行的 范围的使用是十分直观的。以下为一些例子（其中，:d 为 :delete 的缩写）： 命令 操作的行 :d 当前行 :.d 当前行 :1d 第一行 :$d 最后一行 :1,$d 所有行 :%d 所有行（这是 1,$ 的语法糖） :.,5d 当前行至第 5 行 :,5d 同样是当前行至第 5 行 :,+3d 当前行及接下来的 3 行 :1,+3d 第一行至当前行再加 3 行 :,-3d 当前行及向上的 3 行（Vim 会弹出提示信息，因为这是一个保留的范围） :3,'xdelete 第三行至标注 为 x 的那一行 :/^foo/,$delete 当前行以下，以字符 \"foo\" 开头的那一行至结尾 :/^foo/+1,$delete 当前行以下，以字符 \"foo\" 开头的那一行的下一行至结尾 需要注意的是，; 也可以用于表示范围。区别在于，a,b 的 b 是以当前行作为参考的。而 a;b 的 b 是以 a 行作为参考的。举个例子，现在你的光标在第 5 行。这时 :1,+1d 会删除第 1 行至第 6 行，而 :1;+1d 会删除第 1 行和第 2 行。 如果你想设置多个寻找条件，只需要在条件前加上 /，比如： :/foo//bar//quux/d 这就会删除当前行之后的某一行。定位方式是，先在当前行之后寻找第一个包含 \"foo\" 字符的那一行，然后在找到的这一行之后寻找第一个包含 \"bar\" 字符的那一行，然后再在找到的这一行之后寻找第一个包含 \"quux\" 的那一行。删除的就是最后找到的这一行。 有时，Vim 会在命令前自动添加范围。举个例子，如果你先通过 V 命令进入行选取模式，选中一些行后按下 : 进入命令模式，这时候你会发现 Vim 自动添加了 ' 范围。这表示，接下来的命令会使用之前选取的行号作为范围。但如果后续命令不支持范围，Vim 就会报错。为了避免这样的情况发生，有些人会设置这样的按键映射：:vnoremap foo :command，组合键 Ctrl + u 可以清除当前命令行中的内容。 另一个例子是在普通模式中按下 !!，命令行中会出现 :.!。如果这时你如果输入一个外部命令，那么当前行的内容就会被这个外部命令的输出替换。你也可以通过命令 :?^$?+1,/^$/-1!ls 把当前段落的内容替换成外部命令 ls 的输出，原理是向前和向后各搜索一个空白行，删除这两个空白行之间的内容，并将外部命令 ls 的输出放到这两个空白行之间。 请参阅以下两个命令来获取更多帮助： :h cmdline-ranges :h 10.3 返回主目录 :arrow_heading_up: 标注 你可以使用标注功能来标记一个位置，也就是记录文件某行的某个位置。 标注 设置者 使用 a-z 用户 仅对当前的一个文件生效，也就意味着只可以在当前文件中跳转 A-Z 用户 全局标注，可以作用于不同文件。大写标注也称为「文件标注」。跳转时有可能会切换到另一个缓冲区 0-9 viminfo 0 代表 viminfo 最后一次被写入的位置。实际使用中，就代表 Vim 进程最后一次结束的位置。1 代表 Vim 进程倒数第二次结束的位置，以此类推 如果想跳转到指定的标注，你可以先按下 ' / g' 或者 ` / g` 然后按下标注名。 如果你想定义当前文件中的标注，可以先按下 m 再按下标注名。比如，按下 mm 就可以把当前位置标注为 m。在这之后，如果你的光标切换到了文件的其他位置，只需要通过 'm 或者 `m即可回到刚才标注的行。区别在于，'m会跳转回被标记行的第一个非空字符，而`m会跳转回被标记行的被标记列。根据 viminfo 的设置，你可以在退出 Vim 的时候保留小写字符标注。请参阅:h viminfo-' 来获取更多帮助。 如果你想定义全局的标注，可以先按下 m 再按下大写英文字符。比如，按下 mM 就可以把当前文件的当前位置标注为 M。在这之后，就算你切换到其他的缓冲区，依然可以通过 'M 或 `M 跳转回来。 关于跳转，还有以下的方式： 按键 跳转至 '[ 与 `[ 上一次修改或复制的第一行或第一个字符 '] 与 `] 上一次修改或复制的最后一行或最后一个字符 ' 与 ` 上一次在可视模式下选取的第一行或第一个字符 '> 与 `> 上一次在可视模式下选取的最后一行或最后一个字符 '' 与 `' 上一次跳转之前的光标位置 '\" 与 `\" 上一次关闭当前缓冲区时的光标位置 '^ 与 `^ 上一次插入字符后的光标位置 '. 与 `. 上一次修改文本后的光标位置 '( 与 `( 当前句子的开头 ') 与 `) 当前句子的结尾 '{ 与 `{ 当前段落的开头 '} 与 `} 当前段落的结尾 标注也可以搭配 范围 一起使用。前面提到过，如果你在可视模式下选取一些文本，然后按下 :，这时候你会发现命令行已经被填充了 :'。对照上面的表格，现在你应该明白了，这段代表的就是可视模式下选取的范围。 请使用 :marks 命令来显示所有的标注，参阅 :h mark-motions 来获取关于标注的更多帮助。 返回主目录 :arrow_heading_up: 补全 Vim 在插入模式中为我们提供了多种补全方案。如果有多个补全结果，Vim 会弹出一个菜单供你选择。 常见的补全有标签、项目中引入的模块或库中的方法名、文件名、字典及当前缓冲区的字段。 针对不同的补全方案，Vim 为我们提供了不同的按键映射。这些映射都是在插入模式中通过 Ctrl + x 来触发： 映射 类型 帮助文档 整行 :h i^x^l 当前缓冲区中的关键字 :h i^x^n 字典（请参阅 :h 'dictionary'）中的关键字 :h i^x^k 同义词字典（请参阅 :h 'thesaurus'）中的关键字 :h i^x^t 当前文件以及包含的文件中的关键字 :h i^x^i 标签 :h i^x^] 文件名 :h i^x^f 定义或宏定义 :h i^x^d Vim 命令 :h i^x^v 用户自定义补全（通过 'completefunc' 定义） :h i^x^u Omni Completion（通过 'omnifunc' 定义） :h i^x^o s 拼写建议 :h i^Xs 尽管用户自定义补全与 Omni Completion 是不同的，但他们做的事情基本一致。共同点在于，他们都是一个监听当前光标位置的函数，返回值为一系列的补全建议。用户自定义补全是由用户定义的，基于用户的个人用途，因此你可以根据自己的喜好和需求随意定制。而 Omni Completion 是针对文件类型的补全，比如在 C 语言中补全一个结构体（struct）的成员（members），或者补全一个类的方法，因而它通常都是由文件类型插件设置和调用的。 如果你设置了 'complete' 选项，那么你就可以在一次操作中采用多种补全方案。这个选项默认包含了多种可能性，因此请按照自己的需求来配置。你可以通过 来调用下一个补全建议，或通过 来调用上一个补全建议。当然，这两个映射同样可以直接调用补全函数。请参阅 :h i^n 与 :h 'complete' 来获得更多帮助。 如果你想配置弹出菜单的行为，请一定要看一看 :h 'completeopt' 这篇帮助文档。默认的配置已经不错了，但我个人（原作者）更倾向于把 \"noselect\" 加上。 请参阅以下文档获取更多帮助： :h ins-completion :h popupmenu-keys :h new-omni-completion 返回主目录 :arrow_heading_up: 动作，操作符，文本对象 动作也就是指移动光标的操作，你肯定很熟悉 h、j、k 和 l，以及 w 和 b。但其实，/ 也是一个动作。他们都可以搭配数字使用，比如 2?the 可以将光标移动到倒数第二个 \"the\" 出现的位置。 以下会列出一些常用的动作。你也可以通过 :h navigation 来获取更多的帮助。 操作符是对某个区域文本执行的操作。比如，d、~、gU 和 > 都是操作符。这些操作符既可以在普通模式下使用，也可以在可视模式下使用。在普通模式中，顺序是先按操作符，再按动作指令，比如 >j。在可视模式中，选中区域后直接按操作符就可以，比如 Vjd。 与动作一样，操作符也可以搭配数字使用，比如 2gUw 可以将当前单词以及下一个单词转成大写。由于动作和操作符都可以搭配数字使用，因此 2gU2w 与执行两次 gU2w 效果是相同的。 请参阅 :h operator 来查看所有的操作符。你也可以通过 :set tildeop 命令把 ~ 也变成一个操作符 值得注意的是，动作是单向的，而文本对象是双向的。文本对象不仅作用于符号（比如括号、中括号和大括号等）标记的范围内，也作用于整个单词、整个句子等其他情况。 文本对象不能用于普通模式中移动光标的操作，因为光标还没有智能到可以向两个方向同时跳转。但这个功能可以在可视模式中实现，因为在对象的一端选中的情况下，光标只需要跳转到另一端就可以了。 文本对象操作一般用 i 或 a 加上对象标识符操作，其中 i 表示在对象内（英文 inner）操作，a 表示对整个对象（英文 around）操作，这时开头和结尾的空格都会被考虑进来。举个例子，diw 可以删除当前单词，ci( 可以改变括号中的内容。 文本对象同样可以与数字搭配使用。比如，像 ((( ))) 这样的文本，假如光标位于最内层的括号上或最内层的括号内，那么 d2a( 将会删除从最内层开始的两对括号，以及他们之间的所有内容。其实，d2a( 这个操作等同于 2da(。在 Vim 的命令中，如果有两处都可以接收数字作为参数，那么最终结果就等同于两个数字相乘。在这里，d 与 a( 都是可以接收参数的，一个参数是 1，另一个是 2，我们可以把它们相乘然后放到最前面。 请参阅 :h text-objects 来获取更多关于文本对象的帮助。 返回主目录 :arrow_heading_up: 自动命令 在特定的情况下，Vim 会传出事件。如果你想针对这些事件执行回调方法，那么就需要用到自动命令这个功能。 如果没有了自动命令，那你基本上是用不了 Vim 的。自动命令一直都在执行，只是很多时候你没有注意到。不信的话，可以执行命令 :au ，不要被结果吓到，这些是当前有效的所有自动命令。 请使用 :h {event} 来查看 Vim 中所有事件的列表，你也可以参考 :h autocmd-events-abc 来获取关于事件的更多帮助。 一个很常用的例子，就是针对文件类型执行某些设置： autocmd FileType ruby setlocal shiftwidth=2 softtabstop=2 comments-=:# 但是缓冲区是如何知道当前的文件中包含 Ruby 代码呢？这其实是另一个自动命令检测的到的，然后把文件类型设置成为 Ruby，这样就触发了上面的 FileType 事件。 在配置 vimrc 的时候，一般第一行加进去的就是 filetype on。这就意味着，Vim 启动时会读取 filetype.vim 文件，然后根据文件类型来触发相应的自动命令。 如果你勇于尝试，可以查看下 :e $VIMRUNTIME/filetype.vim，然后在输出中搜索 \"Ruby\"。这样，你就会发现其实 Vim 只是通过文件扩展名 .rb 判断某个文件是不是 Ruby 的。 注意：对于相同事件，如果有多个自动命令，那么自动命令会按照定义时的顺序执行。通过 :au 就可以查看它们的执行顺序。 au BufNewFile,BufRead *.rb,*.rbw setf ruby BufNewFile 与 BufRead 事件是被写在 Vim 源文件中的。因此，每当你通过 :e 或者类似的命令打开文件，这两个事件都会触发。然后，就是读取 filetype.vim 文件来判断打开的文件类型。 简单来说，事件和自动命令在 Vim 中的应用十分广泛。而且，Vim 为我们留出了一些易用的接口，方便用户配置适合自己的事件驱动回调。 请参阅 :h autocommand 来获取更多帮助 返回主目录 :arrow_heading_up: 变更历史，跳转历史 在 Vim 中，用户最近 100 次的文字改动都会被保存在变更历史中。如果在同一行有多个小改动，那么 Vim 会把它们合并成一个。尽管内容改动会合并，但作用的位置还是会只记录下最后一次改动的位置。 在你移动光标或跳转的时候，每一次的移动或跳转前的位置会被记录到跳转历史中。类似地，跳转历史也可以最多保存 100 条记录。对于每个窗口，跳转记录是独立的。但当你分离窗口时（比如使用 :split 命令），跳转历史会被复制过去。 Vim 中的跳转命令，包括 '、` 、G、/、?、n、N、%、(、)、[[、]]、{、}、:s、:tag、L、M、H 以及开始编辑一个新文件的命令。 列表 显示所有条目 跳转到上一个位置 跳转到下一个位置 跳转历史 :jumps [count] [count] 变更历史 :changes [count]g; [count]g, 如果你执行第二列的命令显示所有条目，这时 Vim 会用 > 标记来为你指示当前位置。通常这个标记位于 1 的下方，也就代表最后一次的位置。 如果你希望关闭 Vim 之后还保留这些条目，请参阅 :h viminfo-' 来获取更多帮助。 注意：上面提到过，最后一次跳转前的位置也会记录在标注中，也可以通过连按 `` 或 '' 跳转到那个位置 请参阅以下两个命令来获取更多帮助： :h changelist :h jumplist 返回主目录 :arrow_heading_up: 内容变更历史记录 Vim 会记录文本改变之前的状态。因此，你可以使用「撤销」操作 u 来取消更改，也可以通过「重做」操作 Ctrl + r 来恢复更改。 值得注意的是，Vim 采用 tree>) 数据结构来存储内容变更的历史记录，而不是采用 queue>)。你的每次改动都会成为存储为树的节点。而且，除了第一次改动（根节点），之后的每次改动都可以找到一个对应的父节点。每一个节点都会记录改动的内容和时间。其中，「分支」代表从任一节点到根节点的路径。当你进行了撤销操作，然后又输入了新的内容，这时候就相当于创建了分支。这个原理和 git 中的 branch（分支）十分类似。 考虑以下这一系列按键操作： ifoo obar obaz u oquux 那么现在，Vim 中会显示三行文本，分别是 \"foo\"、\"bar\" 和 \"quux\"。这时候，存储的树形结构如下： foo(1) / bar(2) / \\ baz(3) quux(4) 这个树形结构共包含四次改动，括号中的数字就代表时间顺序。 现在，我们有两种方式遍历这个树结构。一种叫「按分支遍历」，一种叫「按时间遍历」。 撤销 u 与重做 Ctrl + r 操作是按分支遍历。对于上面的例子，现在我们有三行字符。这时候按 u 会回退到 \"bar\" 节点，如果再按一次 u 则会回退到 \"foo\" 节点。这时，如果我们按下 Ctrl + r 就会前进至 \"bar\" 节点，再按一次就回前进至 \"quux\" 节点。在这种方式下，我们无法访问到兄弟节点（即 \"baz\" 节点）。 与之对应的是按时间遍历，对应的按键是 g- 和 g+。对于上面的例子，按下 g- 会首先回退到 \"baz\" 节点。再次按下 g- 会回退到 \"bar\" 节点。 命令/按键 执行效果 [count]u 或 :undo [count] 回退到 [count] 次改动之前 [count] 或 :redo [count] 重做 [count] 次改动 U 回退至最新的改动 [count]g- 或 :earlier [count]? 根据时间回退到 [count] 次改动之前。\"?\" 为 \"s\"、\"m\"、\"h\"、\"d\" 或 \"f\"之一。例如，:earlier 2d 会回退到两天之前。:earlier 1f 则会回退到最近一次文件保存时的内容 [count]g+ 或 :later [count]? 类似 g-，但方向相反 内容变更记录会储存在内存中，当 Vim 退出时就会清空。如果需要持久化存储内容变更记录，请参阅备份文件，交换文件，撤销文件以及 viminfo 文件的处理章节的内容。 如果你觉得这一部分的内容难以理解，请参阅 undotree，这是一个可视化管理内容变更历史记录的插件。类似的还有 vim-mundo。 请参阅以下链接获取更多帮助： :h undo.txt :h usr_32 返回主目录 :arrow_heading_up: 全局位置信息表，局部位置信息表 在某一个动作返回一系列「位置」的时候，我们可以利用「全局位置信息表」和「局部位置信息表」来存储这些位置信息，方便以后跳转回对应的位置。每一个存储的位置包括文件名、行号和列号。 比如，编译代码是出现错误，这时候我们就可以把错误的位置直接显示在全局位置信息表，或者通过外部抓取工具使位置显示在局部位置信息表中。 尽管我们也可以把这些信息显示到一个空格缓冲区中，但用这两个信息表显示的好处在于接口调用很方便，而且也便于浏览输出。 Vim 中，全局位置信息表只能有一个，但每一个窗口都可以有自己的局部位置信息表。这两个信息表的外观看上去很类似，但在操作上会稍有不同。 以下为两者的操作比较： 动作 全局位置信息表 局部位置信息表 打开窗口 :copen :lopen 关闭窗口 :cclose :lclose 下一个条目 :cnext :lnext 上一个条目 :cprevious :lprevious 第一个条目 :cfirst :lfirst 最后一个条目 :clast :llast 请参阅 :h :cc 以及底下的内容，来获取更多命令的帮助。 应用实例： 如果我们想用 grep 递归地在当前文件夹中寻找某个关键词，然后把输出结果放到全局位置信息表中，只需要这样： :let &grepprg = 'grep -Rn $* .' :grep! foo :copen 执行了上面的代码，你就能看到所有包含字符串 \"foo\" 的文件名以及匹配到的相关字段都会显示在全局位置信息表中。 返回主目录 :arrow_heading_up: 宏 你可以在 Vim 中录制一系列按键，并把他们存储到寄存器中。对于一些需要临时使用多次的一系列操作，把它们作为宏保存起来会显著地提升效率。对于一些复杂的操作，建议使用 Vim 脚本来实现。 首先，按下 q，然后按下你想要保存的寄存器，任何小写字母都可以。比如我们来把它保存到 q 这个寄存器中。按下 qq，你会发现命令行里已经显示了 \"recording @q\"。 如果你已经录制完成，那么只需要再按一次 q 就可以结束录制。 如果你想调用刚才录制的宏，只需要 [count]@q 如果你想调用上一次使用的宏，只需要 [count]@@ 实例 1： 一个插入字符串 \"abc\" 后换行的宏，重复调用十次： qq iabc q 10@q （对于上面这个功能，你同样可以通过如下的按键： oabc 然后 ESC 然后 10. 来实现）。 实例 2： 一个在每行前都加上行号的宏。从第一行开始，行号为 1，后面依次递增。我们可以通过 Ctrl + a 来实现递增的行号，在定义宏的时候，它会显示成 ^A。 qq 0yf jP0^A q 1000 @q 这里能实现功能，是因为我们假定了文件最多只有 1000 行。但更好的方式是使用「递归」宏，它会一直执行，知道不能执行为止： qq 0yf jP0^A@q q @q （对于上面这个插入行号的功能，如果你不愿意使用宏，同样可以通过这段按键操作来实现：:%s/^/\\=line('.') . '. '）。 这里向大家展示了如何不用宏来达到相应的效果，但要注意，这些不用宏的实现方式只适用于这些简单的示例。对于一些比较复杂的自动化操作，你确实应该考虑使用宏。 请参阅以下文档获取更多帮助： :h recording :h 'lazyredraw' 返回主目录 :arrow_heading_up: 颜色主题 颜色主题可以把你的 Vim 变得更漂亮。Vim 是由多个组件构成的，我们可以给每一个组件都设置不同的文字颜色、背景颜色以及文字加粗等等。比如，我们可以通过这个命令来设置背景颜色： :highlight Normal ctermbg=1 guibg=red 执行后你会发现，现在背景颜色变成红色了。请参阅 :h :highlight 来获取更多帮助。 其实，颜色主题就是一系列的 :highlight 命令的集合。 事实上，大部分颜色主题都包含两套配置。一套适用于例如 xterm 和 iTerm 这样的终端环境（使用前缀 cterm），另一套适用于例如 gvim 和 MacVim 的图形界面环境（使用前缀 gui）。对于上面的例子，ctermbg 就是针对终端环境的，而 guibg 就是针对图形界面环境的。 如果你下载了一个颜色主题，并且在终端环境中打开了 Vim，然后发现显示的颜色与主题截图中差别很大，那很可能是配置文件只设置了图形界面环境的颜色。反之同理，如果你使用的是图形界面环境，发现显示颜色有问题，那就很可能是配置文件只设置了终端环境的颜色。 第二种情况（图形界面环境的显示问题）其实不难解决。如果你使用的是 Neovim 或者 Vim 7.4.1830 的后续版本，可以通过打开真彩色设置来解决显示问题。这就可以让终端环境的 Vim 使用 GUI 的颜色定义，但首先，你要确认一下你的终端环境和环境内的组件（比如 tmux）是否都支持真彩色。可以看一下这篇文档，描述的十分详细。 请参阅以下文档或链接来获取更多帮助： :h 'termguicolors' 主题列表 自定义主题中的颜色 返回主目录 :arrow_heading_up: 折叠 每一部分文字（或者代码）都会有特定的结构。对于存在结构的文字和代码，也就意味着它们可以按照一定的逻辑分割成不同区域。Vim 中的折叠功能，就是按照特定的逻辑把文字和代码折叠成一行，并显示一些简短的描述。折叠功能涉及到很多操作，而且折叠功能可以嵌套使用。 在 Vim 中，有以下 6 中折叠类型： 折叠方式 概述 diff 在「比较窗口」中折叠未改变的文本 expr 使用 'foldexpr' 来创建新的折叠逻辑 indent 基于缩进折叠 manual 使用 zf、zF 或 :fold 来自定义折叠 marker 根据特定的文本标记折叠（通常用于代码注释） syntax 根据语法折叠，比如折叠 if 代码块 注意：折叠功能可能会显著地影响性能。如果你在使用折叠功能的时候出现了打字卡顿之类的问题，请考虑使用 FastFold 插件。这个插件可以让 Vim 按需更新折叠内容，而不是一直调用。 请参阅以下文档获取更多帮助： :h usr_28 :h folds 会话 如果你保存了当前的「视图」（请参阅 :h :mkview），那么当前窗口、配置和按键映射都会被保存下来（请参阅 :h :loadview）。 「会话」就是存储所有窗口的相关设置，以及全局设置。简单来说，就是给当前的 Vim 运行实例拍个照，然后把相关信息存储到会话文件中。存储之后的改动就不会在会话文件中显示，你只需要在改动后更新一下会话文件就可以了。 你可以把当前工作的「项目」存储起来，然后可以在不同的「项目」之间切换。 现在就来试试吧。打开几个窗口和标签，然后执行 :mksession Foo.vim。如果你没有指定文件名，那就会默认保存为 Session.vim。这个文件会保存在当前的目录下，你可以通过 :pwd 来显示当前路径。重启 Vim 之后，你只需要执行 :source Foo.vim，就可以恢复刚才的会话了。所有的缓冲区、窗口布局、按键映射以及工作路径都会恢复到保存时的状态。 其实 Vim 的会话文件就只是 Vim 命令的集合。你可以通过命令 :vs Foo.vim 来看看会话文件中究竟有什么。 你可以决定 Vim 会话中究竟要保存哪些配置，只需要设置一下 'sessionoptions' 就可以了。 为了方便开发，Vim 把最后一次调用或写入的会话赋值给了一个内部变量 v:this_session。 请参阅以下文档来获取更多帮助： :h Session :h 'sessionoptions' :h v:this_session 局部化 以上提到的很多概念，都有一个局部化（非全局）的版本： 全局 局部 作用域 帮助文档 :set :setlocal 缓冲区或窗口 :h local-options :map :map 缓冲区 :h :map-local :autocmd :autocmd * 缓冲区 :h autocmd-buflocal :cd :lcd 窗口 :h :lcd : : 缓冲区 :h maploacalleader 变量也有不同的作用域，详细内容请参考 Vim scripting 的文档。 用法 获取离线帮助 Vim 自带了一套很完善的帮助文档，它们是一个个有固定排版格式的文本文件，通过标签可以访问这些文件的特定位置。 在开始之前先读一下这个章节：:help :help。执行这个命令以后会在新窗口打开 $VIMRUNTIME/doc/helphelp.txt 文件并跳转到这个文件中 :help 标签的位置。 一些关于帮助主题的简单规则： 用单引号把文本包起来表示选项，如：:h 'textwidth' 以小括号结尾表示 VimL 函数，如：:h reverse() 以英文冒号开头表示命令，如：:h :echo 使用快捷键 （这是 ctrl+d）来列出所有包含你当前输入的内容的帮助主题。如：:h tab 会列出所有包含 tab 主题，从 softtabstop 到 setting-guitablabel （译者注：根据安装的插件不同列出的选项也会不同）。 你想查看所有的 VimL 方法吗？很简单，只要输入：:h () 就可以了。你想查看所有与窗口相关的函数吗？输入 :h win*()。 相信你很快就能掌握这些技巧，但是在刚开始的时候，你可能对于该通过什么进行查找一点线索都没有。这时你可以想象一些与要查找的内容相关的关键字，再让 :helpgrep 来帮忙。 :helpgrep backwards 上面的命令会在所有的帮助文件中搜索“backwards”，然后跳转到第一个匹配的位置。所有的匹配位置都会被添加到全局位置信息表，用 :cp / :cn 可以在匹配位置之间进行切换。或者用 :copen 命令来打开全局位置信息表，将光标定位到你想要的位置，再按 回车就可以跳转到该匹配项。详细说明请参考 :h quickfix。 获取离线帮助（补充） 这个列表最初发表在 vim_dev，由 @chrisbra 编辑的，他是 Vim 开发人员中最活跃的一个。 经过一些微小的改动后，重新发布到了这里。 如果你知道你想要找什么，使用帮助系统的搜索会更简单一些，因为搜索出的主题都带有固定的格式。 而且帮助系统中的主题包含了你当前使用的 Vim 版本的所特有特性，而网上那些已经过时或者是早期发布的话题是不会包含这些的。 因此学习使用帮助系统以及它所用的语言是很有必要的。这里是一些例子（不一定全，我有可能忘了一些什么）。 （译者注：下面列表中提及的都是如何指定搜索主题以便快速准确的找到你想要的帮助） 选项要用单引号引起来。用 :h 'list' 来查看列表选项帮助。只有你明确的知道你要找这么一个选项的时候才可以这么做，不然的话你可以用 :h options.txt 来打开所有选项的帮助页面，再用正则表达式进行搜索，如：/width。某些选项有它们自己的命名空间，如：:h cpo-a，:h cpo-A， :h cpo-b 等等。 普通模式的命令不能用冒号作为前缀。使用 :h gt 来转到“gt”命令的帮助页面。 正则表达式以“/”开头，所以 :h /\\+ 会带你到正则表达式中量词“+”的帮助页面。 组合键经常以一个字母开头表示它们可以在哪些模式中使用。如：:h i_CTRL-X 会带你到插入模式下的 CTRL-X 命令的用法帮助页面，这是一个自动完成类的组合键。需要注意的是某些键是有固定写法的，如 Control 键写成 CTRL。还有，查找普通模式下的组合键帮助时，可以省略开头的字母“n”，如：:h CTRL-A。而 :h c_CTRL-A（译者注：原文为 :h c_CRTL-R，感觉改为 A 更符合上下文语境）会解释 CTRL-A 在命令模式下输入命令时的作用；:h v_CTRL-A 说的是在可见模式下把光标所在处的数字加 1；:h g_CTRL-A 则说的是 g 命令（你需要先按 \"g\" 的命令）。这里的 \"g\" 代表一个普通的命令，这个命令总是与其它的按键组合使用才生效，与 \"z\" 开始的命令相似。 寄存器是以 \"quote\" 开头的。如：:h quote: （译者注：原文为:h quote，感觉作者想以\":\"来举例）来查看关于\":\"寄存器的说明。 关于 Vim 脚本（VimL）的帮助都在 :h eval.txt 里。而某些方面的语言可以使用 :h expr-X 获取帮助，其中的 'X' 是一个特定的字符，如：:h expr-! 会跳转到描述 VimL 中'!'（非）的章节。另外一个重要提示，可以使用 :h function-list 来查看所有函数的简要描述，列表中包括函数名和一句话描述。 关于映射都可以在 :h map.txt 中找到。通过 :h mapmode-i 来查找 :imap 命令的相关信息；通过 :h map-topic 来查找专门针对映射的帮助（译者注：topic 为一个占位符，正如上面的字符 'X' 一样，在实际使用中需要替换成相应的单词）（如：:h :map-local 查询本地 buffer 的映射，:h map-bar 查询如何在映射中处理'|')。 命令定义用 \"command-\" 开头，如用 :h command-bar 来查看自定义命令中'!'的作用。 窗口管理类的命令是以 \"CTRL-W\" 开头的，所以你可以用 :h CTRL-W_* 来查找相应的帮助（译者注：'*'同样为占位符）（如：:h CTRL-W_p 查看切换到之前访问的窗口命令的解释）。如果你想找窗口处理的命令，还可以通过访问 :h windows.txt 并逐行向下浏览，所有窗口管理的命令都在这里了。 执行类的命令以\":\"开头，即：:h :s 讲的是 \":s\" 命令。 在输入某个话题时按 CTRL-D，让 Vim 列出所有的近似项辅助你输入。 用 :helpgrep 在所有的帮助页面（通常还包括了已安装的插件的帮助页面）中进行搜索。参考 :h :helpgrep 来了解如何使用。当你搜索了一个话题之后，所有的匹配结果都被保存到了全局位置信息表（或局部位置信息表）当中，可以通过 :copen 或 :lopen 打开。在打开的窗口中可能通过 / 对搜索结果进行进一步的过滤。 :h helphelp 里介绍了如何使用帮助系统。 用户手册。它采用了一种对初学者更加友好的方式来展示帮助话题。用 :h usr_toc.txt 打开目录（你可能已经猜到这个命令的用处了）。浏览用户手册能帮助你找出某些你想了解的话题，如你可以在第 24 章看到关于“复合字符”以及“输入特殊字符”的讲解（用 :h usr_24.txt 可以快速打开相关章节）。 高亮分组的帮助以 hl- 开头。如：:h hl-WarningMsg 说的是警告信息分组的高亮。 语法高亮以:syc- 开头，如：:h :syn-conceal 讲的是 :syn 命令的对于隐藏字符是如何显示的。 快速修复命令以 :c 开头，而位置列表命令以 :l 开头。 :h BufWinLeave 讲的是 BufWinLeave 自动命令。还有，:h autocommand-events （译者注：原文是 :h autocommands-events，但是没有该帮助）讲的是所有可用的事件。 启动参数都以“-”开头，如：:h -f 会告诉你 Vim 中 “-f” 参数的作用。 额外的特性都以“+”开头，如：:h +conceal 讲的是关于隐藏字符的支持。 错误代码可以在帮助系统中直接查到。:h E297 会带你到关于这一错误的详细解释。但是有时并没有转到错误描述，而是列出了经常导出这一错误的 Vim 命令，如 :h E128 （译者注：原文为:h hE128，但是并没有该帮助）会直接跳转到 :function 命令。 关于包含的语法文件的文档的帮助话题格式是 :h ft-*-syntax。如：:h ft-c-syntax 说的就是 C 语言语法文件以及它所提供的选项。有的语法文件还会带有自动完成（:h ft-php-omni）或文件类型插件（:h ft-tex-plugin）相关的章节可以查看。 另外在每个帮助页的顶端通常会包含一个用户文档链接（更多的从从用户的角度出发来主角命令的功能和用法，不涉及那么多细节）。如：:h pattern.txt 里包含了 :h 03.9 和 :h usr_27 两个章节的链接。 获取在线帮助 如果你遇到了无法解决的问题，或者需要指引的话，可以参考 Vim 使用邮件列表。 IRC 也是一个很不错的资源。 Freenode 上的 #vim 频道很庞大，并且里面有许多乐于助人的人。 如果你想给 Vim 提交 Bug 的话，可以使用 vim_dev 邮件列表。 执行自动命令 你可以触发任何事件，如：:doautocmd BufRead。 用户自定义事件 对于插件而言，创建你自己的自定义事件有时非常有用。 function! Chibby() \" A lot of stuff is happening here. \" And at last.. doautocmd User ChibbyExit endfunction 现在你插件的用户可以在 Chibby 执行完成之后做任何他想做的事情： autocmd User ChibbyExit call ChibbyCleanup() 顺便提一句，如果在使用 :autocmd 或 :doautocmd 时没有捕捉异常，那么会输出 \"No matching autocommands\" 信息。这也是为什么许多插件用 silent doautocmd ... 的原因。但是这也会有不足，那就是你不能再在 :autocmd 中使用 echo \"foo\" 了，取而代之的是你要使用 unsilent echo \"foo\" 来输出。 这就是为什么要在触发事件之前先判断事件是否存在的原因， if exists('#User#ChibbyExit') doautocmd User ChibbyExit endif 帮助文档：:h User 事件嵌套 默认情况下，自动命令不能嵌套！如果某个自动命令执行了一个命令，这个命令再依次触发其它的事件，这是不可能的。 例如你想在每次启动 Vim 的时候自动打开你的 vimrc 文件： autocmd VimEnter * edit $MYVIMRC 当你启动 Vim 的时候，它会帮你打开你的 vimrc 文件，但是你很快会注意到这个文件没有任何的高亮，尽管平时它是正常可以高亮的。 问题在于你的非嵌套自动命令 :edit 不会触发“BufRead”事件，所以并不会把文件类型设置成“vim”，进而 $VIMRUNTIME/syntax/vim.vim 永远不会被引入。详细信息请参考：:au BufRead *.vim。要想完成上面所说的需求，使用下面这个命令： autocmd VimEnter * nested edit $MYVIMRC 帮助文档：:h autocmd-nested 剪切板 如果你想在没有 GUI 支持的 Unix 系统中使用 Vim 的 'clipboard' 选项，则需要 +clipboard 以及可选的 +xterm_clipboard 两个特性支持。 帮助文档： :h 'clipboard' :h gui-clipboard :h gui-selections 另外请参考：持续粘贴（为什么我每次都要设置 'paste' 模式 剪贴板的使用（Windows, OSX） Windows 自带了剪贴板.aspx>)，OSX 则带了一个粘贴板 在这两个系统中都可以用大家习惯用的 ctrl+c / cmd+c 复制选择的文本，然后在另外一个应用中用 ctrl+v / cmd+v 进行粘贴。 需要注意的是复制的文本已经被发送到了剪贴板，所以你在粘贴复制的内容之前关闭这个应用是没有任何问题的。 每次复制的时候，都会向剪贴板寄存器 * 中写入数据。 而在 Vim 中分别使用 \"*y 和 \"*p 来进行复制（yank) 和 粘贴（paste)。 如果你不想每次操作都要指定 * 寄存器，可以在你的 vimrc 中添加如下配置： set clipboard=unnamed 通常情况下复制/删除/放入操作会往 \" 寄存器中写入数据，而加上了上面的配置之后 * 寄存器也会被写入同样数据，因此简单的使用 y 和 p 就可以复制粘贴了。 我再说一遍：使用上面的选项意味着每一次的复制/粘贴，即使在同一个 Vim 窗口里，都会修改剪贴板的内容。你自己决定上面的选项是否适合。 如果你觉得输入 y 还是太麻烦的话，可以使用下面的设置把在可视模式下选择的内容发送到剪贴板： set clipboard=unnamed,autoselect set guioptions+=a 帮助文档： :h clipboard-unnamed :h autoselect :h 'go_a' 剪贴板的使用（Linux, BSD, ...） 如果你的系统使用了 X 图形界面，事情会变得有一点不同。X 图形界面实现了 X 窗口系统协议, 这个协议在 1987 年发布的主版本 11，因此 X 也通常被称为 X11。 在 X10 版本中，剪贴缓冲区被用来实现像 clipboard 一样由 X 来复制文本，并且可以被所有的程序访问。现在这个机制在 X 中还存在，但是已经过时了，很多程序都不再使用这一机制。 近年来数据在程序之间是通过选择进行传递的。一共有三种选择，经常用到的有两种：PRIMARY 和 CLIPBOARD。 选择的工作工模大致是这样的： Program A： Program A：声称对 CLIPBOARD 的所有权 Program B： Program B：发现CLIPBOARD的所有权被Program A持有 Program B：从Program A请求数据 Program A：响应这个请求并发送数据给Program B Program B：从Program A接收数据并插入到窗口中 选择 何时使用 如何粘贴 如何在 Vim 中访问 PRIMARY 选择文本 鼠标中键, shift+insert * 寄存器 CLIPBOARD 选择文本并按 ctrl+c ctrl+v +寄存器 注意：X 服务器并不会保存选择（不仅仅是 CLIPBOARD 选择）！因此在关闭了相应的程序后，你用 ctrl+c 复制的内容将丢失。 使用 \"*p 来贴粘 PRIMARY 选择中的内容，或者使用 \"+y1G 来将整个文件的内容复制到 CLIPBOARD 选择。 如果你需要经常访问这两个寄存器，可以考虑使用如下配置： set clipboard^=unnamed \" * 寄存器 \" 或者 set clipboard^=unnamedplus \" + 寄存器 （^= 用来将设置的值加到默认值之前，详见：:h :set^=） 这会使得所有复制/删除/放入操作使用 * 或 + 寄存器代替默认的未命令寄存器 \"。之后你就可以直接使用 y 或 p 访问你的 X 选择了。 帮助文档： :h clipboard-unnamed :h clipboard-unnamedplus 打开文件时恢复光标位置 如果没有这个设置，每次打开文件时光标都将定位在第一行。而加入了这个设置以后，你就可以恢复到上次关闭文件时光标所在的位置了。 将下面的配置添加到你的 vimrc 文件： autocmd BufReadPost * \\ if line(\"'\\\"\") > 1 && line(\"'\\\"\") 这是通过判断之前的光标位置是否存在（文件可能被其它程序修改而导致所记录的位置已经不存在了），如果存在的话就执行 g`\" （转到你离开时的光标位置但是不更改跳转列表）。 这需要使用 viminfo 文件：:h viminfo-。 临时文件 根据选项的不同， Vim 最多会创建 4 种工作文件。 备份文件 你可以让 Vim 在将修改写入到文件之前先备份原文件。默认情况下， Vim 会保存一个备份文件但是当修改成功写入后会立即删除它（:set writebackup）。如果你想一直保留这个备份文件的话，可以使用 :set backup。而如果你想禁用备份功能的话，可以使用 :set nobackup nowritebackup。 咱们来看一下上次我在 vimrc 中改了什么： $ diff ~/.vim/vimrc ~/.vim/files/backup/vimrc-vimbackup 390d389 帮助文档：:h backup 交换文件 假设你有一个非常棒的科幻小说的构思。在按照故事情节已经写了好几个小时几十万字的时候..忽然停电了！而那时你才想起来你上次保存 ~/来自外太空的邪恶入侵者.txt 是在.. 好吧，你从来没有保存过。 但是并非没有希望了！在编辑某个文件的时候， Vim 会创建一个交换文件，里面保存的是对当前文件所有未保存的修改。自己试一下，打开任意的文件，并使用 :swapname 获得当前的交换文件的保存路径。你也可以将 :set noswapfile 加入到 vimrc 中来禁用交换文件。 默认情况下，交换文件会自动保存在被编辑文件所在的目录下，文件名以 .file.swp 后缀结尾，每当你修改了超过 200 个字符或是在之前 4 秒内没有任何动作时更新它的内容，在你不再编辑这个文件的时候会被删除。你可以自己修改这些数字，详见：:h 'updatecount' 和 :h 'updatetime'。 而在断电时，交换文件并不会被删除。当你再次打开 vim ~/来自外太空的邪恶入侵者.txt 时， Vim 会提示你恢复这个文件。 帮助文档：:h swap-file 和 :h usr_11 撤销文件 内容变更历史记录是保存在内存中的，并且会在 Vim 退出时清空。如果你想让它持久化到磁盘中，可以设置 :set undofile。这会把文件 ~/foo.c 的撤销文件保存在 ~/foo.c.un~。 帮助文档：:h 'undofile' 和 :h undo-persistence viminfo 文件 备份文件、交换文件和撤销文件都是与文本状态相关的，而 viminfo 文件是用来保存在 Vim 退出时可能会丢失的其它的信息的。包括历史记录（命令历史、搜索历史、输入历史）、寄存器内容、标注、缓冲区列表、全局变量等等。 默认情况下，viminfo 被保存在 ~/.viminfo。 帮助文档：:h viminfo 和 :h 'viminfo' 临时文件管理设置示例 如果你跟我一样，也喜欢把这些文件放到一个位置（如：~/.vim/files）的话，可以使用下面的配置： \" 如果文件夹不存在，则新建文件夹 if !isdirectory($HOME.'/.vim/files') && exists('*mkdir') call mkdir($HOME.'/.vim/files') endif \" 备份文件 set backup set backupdir =$HOME/.vim/files/backup/ set backupext =-vimbackup set backupskip = \" 交换文件 set directory =$HOME/.vim/files/swap// set updatecount =100 \" 撤销文件 set undofile set undodir =$HOME/.vim/files/undo/ \" viminfo 文件 set viminfo ='100,n$HOME/.vim/files/info/viminfo 注意：如果你在一个多用户系统中编辑某个文件时， Vim 提示你交换文件已经存在的话，可能是因为有其他的用户此时正在编辑这个文件。而如果将交换文件放到自己的 home 目录的话，这个功能就失效了。因此服务器非常不建议将这些文件修改到 HOME 目录，避免多人同时编辑一个文件，却没有任何警告。 编辑远程文件 Vim 自带的 netrw 插件支持对远程文件的编辑。实际上它将远程的文件通过 scp 复制到本地的临时文件中，再用那个文件打开一个缓冲区，然后在保存时把文件再复制回远程位置。 下面的命令在你本地的 VIM 配置与 SSH 远程服务器上管理员想让你使用的配置有冲突时尤其有用： :e scp://bram@awesome.site.com/.vimrc 如果你已经设置了 ~/.ssh/config，SSH 会自动读取这里的配置： Host awesome HostName awesome.site.com Port 1234 User bram 如果你的 ~/.ssh/config 中有以上的内容，那么下面的命令就可以正常执行了： :e scp://awesome/.vimrc 可以用同样的方法编辑 ~/.netrc, 详见：:h netrc-netrc。 确保你已经看过了 :h netrw-ssh-hack 和 :h g:netrw_ssh_cmd。 另外一种编辑远程文件的方法是使用 sshfs，它会用 FUSE 来挂载远程的文件系统到你本地的系统当中。 插件管理 Pathogen是第一个比较流行的插件管理工具。实际上它只是修改了 runtimepath （:h 'rtp'） 来引入所有放到该目录下的文件。你需要自己克隆插件的代码仓库到那个目录。 真正的插件管理工具会在 Vim 中提供帮助你安装或更新插件的命令。以下是一些常用的插件管理工具： dein plug vim-addon-manager vundle 多行编辑 这是一种可以同时输入多行连续文本的技术。参考这个示例。 用 切换到可视块模式。然后向下选中几行，按 I 或 A （译者注：大写字母，即 shift+i 或 shift+a）然后开始输入你想要输入的文本。 在刚开始的时候可能会有些迷惑，因为文本只出现在了当前编辑的行，只有在当前的插入动作结束后，之前选中的其它行才会出现插入的文本。 举一个简单的例子：3jItext。 如果你要编辑的行长度不同，但是你想在他们后面追加相同的内容的话，可以试一下这个：3j$Atext。 有时你可能需要把光标放到当前行末尾之后，默认情况下你是不可能做到的，但是可能通过设置 virtualedit 选项达到目的： set virtualedit=all 设置之后 $10l 或 90| 都会生效，即使超过了行尾的长度。 详见 :h blockwise-examples。在开始的时候可能会觉得有些复杂，但是它很快就会成为你的第二天性的。 如果你想探索更有趣的事情，可以看看多光标 使用外部程序和过滤器 免责声明：Vim 是单线程的，因此在 Vim 中以前端进程执行其它的程序时会阻止其它的一切。当然你可以使用 Vim 程序接口，如 Lua，并且使用它的多线程支持，但是在那期间， Vim 的处理还是被阻止了。Neovim 添加了任务 API 解决了此问题。 （据说 Bram 正在考虑在 Vim 中也添加任务控制。如果你使用了较新版本的的 Vim ，可以看一下 :helpgrep startjob。） 使用 :! 启动一个新任务。如果你想列出当前工作目录下的所有文件，可以使用 :!ls。 用 | 来将结果通过管道重定向，如：:!ls -l | sort | tail -n5。 没有使用范围时（译者注：范围就是 : 和 ! 之间的内容，. 表示当前行，+4 表示向下偏移 4 行，$ 表示最末行等，多行时用 , 将它们分开，如 .,$ 表示从当前行到末行），:! 会显示在一个可滚动的窗口中（译者注：在 GVim 和在终端里运行的结果稍有不同）。相反的，如果指定了范围，这些行会被过滤>)。这意味着它们会通过管道被重定向到过滤程序的 stdin，在处理后再通过过滤程序的 stdout 输出，用输出结果替换范围内的文本。例如：为接下来的 5 行文本添加行号，可以使用： :.,+4!nl -ba -w1 -s' ' 由于手动添加范围很麻烦， Vim 提供了一些辅助方法以方便的添加范围。如果需要经常带着范围的话，你可以在可见模式中先选择，然后再按 : （译者注：选中后再按 ! 更方便）。还可以使用 ! 来取用一个 motion 的范围，如 !ipsort （译者注：原文为 !ip!sort ，但经过实验发现该命令执行报错，可能是因为 Vim 版本的原因造成的，新版本使用 ip 选择当前段落后自动在命令后添加了 ! ，按照作者的写法来看，可能之前的版本没有自动添加 ! ）可以将当前段落的所有行按字母表顺序进行排序。 一个使用过滤器比较好的案例是Go 语言。它的缩进语法非常个性，甚至还专门提供了一个名为 gofmt 的过滤器来对 Go 语言的源文件进行正确的缩进。Go 语言的插件通常会提供一个名为 :Fmt 的函数，这个函数就是执行了 :%!gofmt 来对整个文件进行缩进。 人们常用 :r !prog 将 prog 程序的插入放到当前行的下面，这对于脚本来说是很不错的选择，但是在使用的过程中我发现 !!ls 更加方便，它会用输出结果替换当前行的内容。（译者注：前面命令中的 prog 只是个占位符，在实际使用中需要替换成其它的程序，如 :r !ls，这就与后面的 !!ls 相对应了，两者唯一的不同是第一个命令不会覆盖当前行内容，但是第二个命令会） 帮助文档： :h filter :h :read! Cscope Cscope 的功能比 ctags 要完善，但是只支持 C（通过设置 cscope.files 后同样支持 C++以及 Java）。 鉴于 Tag 文件只是知道某个符号是在哪里定义的，cscope 的数据库里的数据信息就多的多了： 符号是在哪里定义的？ 符号是在哪里被使用的？ 这个全局符号定义了什么？ 这个变量是在哪里被赋值的？ 这个函数在源文件的哪个位置？ 哪些函数调用了这个函数？ 这个函数调用了哪些函数？ \"out of space\"消息是从哪来的？ 在目录结构中当前的源文件在哪个位置？ 哪些文件引用了这个头文件？ 1. 构建数据库 在你项目的根目录执行下面的命令： $ cscope -bqR 这条命令会在当前目录下创建三个文件：cscope{,.in,.po}.out 。把它们想象成你的数据库。 不幸的时 cscope 默认只分析 *.[c|h|y|l] 文件。如果你想在 Java 项目中使用 cscope ，需要这样做： $ find . -name \"*.java\" > cscope.files $ cscope -bq 2. 添加数据库 打开你新创建的数据库连接： :cs add cscope.out 检查连接已经创建成功： :cs show （当然你可以添加多个连接。） 3. 查询数据库 :cs find 如：:cs find d foo 会列出 foo(...) 调用的所有函数。 Kind 说明 s symbol：查找使用该符号的引用 g global：查找该全局符号的定义 c calls：查找调用当前方法的位置 t text：查找出现该文本的位置 e egrep：使用 egrep 搜索当前单词 f file：打开文件名 i includes：查询引入了当前文件的文件 d depends：查找当前方法调用的方法 推荐一些比较方便的映射，如： nnoremap cs :cscope find s =expand('') nnoremap cg :cscope find g =expand('') nnoremap cc :cscope find c =expand('') nnoremap ct :cscope find t =expand('') nnoremap ce :cscope find e =expand('') nnoremap cf :cscope find f =expand('') nnoremap ci :cscope find i ^=expand('')$ nnoremap cd :cscope find d =expand('') 所以 :tag （或 ）跳转到标签定义的文件，而 :cstag 可以达到同样的目的，同时还会打开 cscope 的数据库连接。'cscopetag' 选项使得 :tag 命令自动的像 :cstag 一样工作。这在你已经使用了基于标签的映射时会非常方便。 帮助文档：:h cscope MatchIt 由于 Vim 是用 C 语言编写的，因此许多功能都假设使用类似 C 语言的语法。默认情况下，如果你的光标在 { 或 #endif , 就可以使用 % 跳转到与之匹配的 } 或 #ifdef。 Vim 自带了一个名为 matchit.vim 的插件，但是默认没有启用。启用后可以用 % 在 HTML 相匹配的标签或 VimL 的 if/else/endif 块之间进行跳转，它还带来了一些新的命令。 在 Vim 8 中安装 \" vimrc packadd! matchit 在 Vim 7 或者更早的版本中安装 \"vimrc runtime macros/matchit.vim 由于 matchit 的文档很全面，我建议安装以后执行一次下面的命令： :!mkdir -p ~/.vim/doc :!cp $VIMRUNTIME/macros/matchit.vim ~/.vim/doc :helptags ~/.vim/doc 简短的介绍 至此这个插件已经可以使用了。 参考 :h matchit-intro 来获得支持的命令以及 :h matchit-languages 来获得支持的语言。 你可以很方便的定义自己的匹配对，如： autocmd FileType python let b:match_words = '\\:\\:\\' 之后你就可以在任何的 Python 文件中使用 % （向前）或 g% （向后）在这三个片断之间跳转了。 帮助文档： :h matchit-install :h matchit :h b:match_words 技巧 跳至选择的区域另一端 在使用 v 或者 V 选择某段文字后，可以用 o 或者 O 按键跳至选择区域的开头或者结尾。 :h v_o :h v_O 聪明地使用 n 和 N n 与 N 的实际跳转方向取决于使用 / 还是 ? 来执行搜索，其中 / 是向后搜索，? 是向前搜索。一开始我（原作者）觉得这里很难理解。 如果你希望 n 始终为向后搜索，N 始终为向前搜索，那么只需要这样设置： nnoremap n 'Nn'[v:searchforward] nnoremap N 'nN'[v:searchforward] 聪明地使用命令行历史 我（原作者）习惯用 Ctrl + p 和 Ctrl + n 来跳转到上一个/下一个条目。其实这个操作也可以用在命令行中，快速调出之前执行过的命令。 不仅如此，你会发现 上 和 下 其实更智能。如果命令行中已经存在了一些文字，我们可以通过按方向键来匹配已经存在的内容。比如，命令行中现在是 :echo，这时候我们按 上，就会帮我们补全成 :echo \"Vim rocks!\"（前提是，之前输入过这段命令）。 当然，Vim 用户都不愿意去按方向键，事实上我们也不需要去按，只需要设置这样的映射： cnoremap cnoremap 这个功能，我（原作者）每天都要用很多次。 智能 Ctrl-l Ctrl + l 的默认功能是清空并「重新绘制」当前的屏幕，就和 :redraw! 的功能一样。下面的这个映射就是执行重新绘制，并且取消通过 / 和 ? 匹配字符的高亮，而且还可以修复代码高亮问题（有时候，由于多个代码高亮的脚本重叠，或者规则过于复杂，Vim 的代码高亮显示会出现问题）。不仅如此，还可以刷新「比较模式」（请参阅 :help diff-mode）的代码高亮： nnoremap l :nohlsearch:diffupdate:syntax sync fromstart 禁用错误报警声音和图标 set noerrorbells set novisualbell set t_vb= 请参阅 Vim Wiki: Disable beeping。 快速移动当前行 有时，我（原作者）想要快速把当前行上移或下移一行，只需要这样设置映射： nnoremap [e :execute 'move -1-'. v:count1 nnoremap ]e :execute 'move +'. v:count1 这个映射，同样可以搭配数字使用，比如连续按下 2 ] e 就可以把当前行向下移动两行。 快速添加空行 nnoremap [ :put! =repeat(nr2char(10), v:count1)'[ nnoremap ] :put =repeat(nr2char(10), v:count1) 设置之后，连续按下 5 [ 空格 在当前行上方插入 5 个空行。 运行时检测 需要的特性：+profile Vim 提供了一个内置的运行时检查功能，能够找出运行慢的代码。 :profile 命令后面跟着子命令来确定要查看什么。 如果你想查看所有的： :profile start /tmp/profile.log :profile file * :profile func * Vim 不断地在内存中检查信息，只在退出的时候输出出来。（Neovim 已经解决了这个问题用 :profile dump 命令） 看一下 /tmp/profile.log 文件，检查时运行的所有代码都会被显示出来，包括每一行代码运行的频率和时间。 大多数代码都是用户不熟悉的插件代码，如果你是在解决一个确切的问题， 直接跳到这个日志文件的末尾，那里有 FUNCTIONS SORTED ON TOTAL TIME 和 FUNCTIONS SORTED ON SELF TIME 两个部分，如果某个 function 运行时间过长一眼就可以看到。 查看启动时间 感觉 Vim 启动的慢？到了研究几个数字的时候了： vim --startuptime /tmp/startup.log +q && vim /tmp/startup.log 第一栏是最重要的因为它显示了绝对运行时间，如果在前后两行之间时间差有很大的跳跃，那么是第二个文件太大或者含有需要检查的错误的 VimL 代码。 NUL 符用新行表示 文件中的 NUL 符 （\\0），在内存中被以新行（\\n）保存，在缓存空间中显示为 ^@。 更多信息请参看 man 7 ascii 和 :h NL-used-for-Nul 。 快速编辑自定义宏 这个功能真的很实用！下面的映射，就是在一个新的命令行窗口中读取某一个寄存器（默认为 *）。当你设置完成后，只需要按下 回车 即可让它生效。 在录制宏的时候，我经常用这个来更改拼写错误。 nnoremap m :='let @'. v:register .' = '. string(getreg(v:register)) 只需要连续按下 leader m 或者 \" leader m 就可以调用了。 请注意，这里之所以要写成 是为了确保 执行了。请参阅 :h c_^R^R 快速跳转到源(头)文件 这个技巧可以用在多种文件类型中。当你从源文件或者头文件中切换到其他文件的时候，这个技巧可以设置「文件标记」（请参阅 :h marks），然后你就可以通过连续按下 ' C 或者 ' H 快速跳转回去（请参阅 :h 'A）。 autocmd BufLeave *.{c,cpp} mark C autocmd BufLeave *.h mark H 注意：由于这个标记是设置在 viminfo 文件中，因此请先确认 :set viminfo? 中包含了 :h viminfo-'。 在 GUI 中快速改变字体大小 印象中，我（原作者）记得一下代码是来自 tpope's 的配置文件： command! Bigger :let &guifont = substitute(&guifont, '\\d\\+$', '\\=submatch(0)+1', '') command! Smaller :let &guifont = substitute(&guifont, '\\d\\+$', '\\=submatch(0)-1', '') 根据模式改变光标类型 我（原作者）习惯在普通模式下用块状光标，在插入模式下用条状光标（形状类似英文 \"I\" 的样子），然后在替换模式中使用下划线形状的光标。 if empty($TMUX) let &t_SI = \"\\]50;CursorShape=1\\x7\" let &t_EI = \"\\]50;CursorShape=0\\x7\" let &t_SR = \"\\]50;CursorShape=2\\x7\" else let &t_SI = \"\\Ptmux;\\\\]50;CursorShape=1\\x7\\\\\\\" let &t_EI = \"\\Ptmux;\\\\]50;CursorShape=0\\x7\\\\\\\" let &t_SR = \"\\Ptmux;\\\\]50;CursorShape=2\\x7\\\\\\\" endif 原理很简单，就是让 Vim 在进入和离开插入模式的时候，输出一些序列，请参考 escape sequence。Vim 与终端之间的中间层，比如 tmux 会处理并执行上面的代码。 但上面这个还是有一个缺点的。终端环境的内部原理不尽相同，对于序列的处理方式也稍有不同。因此，上面的代码可能无法在你的环境中运行。甚至，你的运行环境也有可能不支持其他光标形状，请参阅你的 Vim 运行环境的文档。 好消息是，上面这个代码，可以在 iTerm2 中完美运行。 防止水平滑动的时候失去选择 如果你选中了一行或多行，那么你可以用 或 > 来调整他们的缩进。但在调整之后就不会保持选中状态了。 你可以连续按下 g v 来重新选中他们，请参考 :h gv。因此，你可以这样来配置映射： xnoremap >gv 设置好之后，在可视模式中使用 >>>>> 就不会再出现上面提到的问题了。 选择当前行至结尾，排除换行符 在 Vim 里，我们可以同过 v$ 选择当前行至结尾，但此时会把最后一个换行符也选中，通常需要按额外的 h 来取消最后选中最后一个换行符号。 Vim 提供了一个 g_ 快捷键，可以移动光标至最后一个非空字符。因此，为达到次效果，可以使用 vg_。当然，如果觉得按三个键比较麻烦， 可以添加一个映射： nnoremap L g_ 这样就可以通过 vL 达到一样的效果了。 重新载入保存文件 通过自动命令，你可以在保存文件的同时触发一些其他功能。比如，如果这个文件是一个配置文件，那么就重新载入；或者你还可以对这个文件进行代码风格检查。 autocmd BufWritePost $MYVIMRC source $MYVIMRC autocmd BufWritePost ~/.Xdefaults call system('xrdb ~/.Xdefaults') 更加智能的当前行高亮 我（原作者）很喜欢「当前行高亮」（请参阅 :h cursorline）这个功能，但我只想让这个效果出现在当前窗口，而且在插入模式中关闭这个效果： autocmd InsertLeave,WinEnter * set cursorline autocmd InsertEnter,WinLeave * set nocursorline 更快的关键字补全 关键字补全（ 或 ）功能的工作方式是，无论 'complete' 设置中有什么，它都会尝试着去补全。这样，一些我们用不到的标签也会出现在补全列表中。而且，它会扫描很多文件，有时候运行起来非常慢。如果你不需要这些，那么完全可以像这样把它们禁用掉： set complete-=i \" disable scanning included files set complete-=t \" disable searching tags 改变颜色主题的默认外观 如果你想让状态栏在颜色主题更改后依然保持灰色，那么只需要这样设置： autocmd ColorScheme * highlight StatusLine ctermbg=darkgray cterm=NONE guibg=darkgray gui=NONE 同理，如果你想让某一个颜色主题（比如 \"lucius\"）的状态栏为灰色（请使用 :echo color_name 来查看当前可用的所有颜色主题）： autocmd ColorScheme lucius highlight StatusLine ctermbg=darkgray cterm=NONE guibg=darkgray gui=NONE 命令 下面的命令都比较有用，最好了解一下。用 :h : 来了解更多关于它们的信息，如：:h :global。 :global 和 :vglobal - 在所有匹配行执行命令 在所有符合条件的行上执行某个命令。如： :global /regexp/ print 会在所有包含 \"regexp\" 的行上执行 print 命令（译者注：regexp 有正则表达式的意思，该命令同样支持正则表达式，在所有符合正则表达式的行上执行指定的命令）。 趣闻：你们可能都知道老牌的 grep 命令，一个由 Ken Thompson 编写的过滤程序。它是干什么用的呢？它会输出所有匹配指定正则表达式的行！现在猜一下 :global /regexp/ print 的简写形式是什么？没错！就是 :g/re/p 。 Ken Thompsom 在编写 grep 程序的时候是受了 vi :global 的启发。（译者注： https://robots.thoughtbot.com/how-grep-got-its-name） 既然它的名字是 :global，理应仅作用在所有行上，但是它也是可以带范围限制的。假设你想使用 :delete 命令删除从当前行到下一个空行（由正则表达式 ^$ 匹配）范围内所有包含 \"foo\" 的行： :,/^$/g/foo/d 如果要在所有 不 匹配的行上执行命令的话，可以使用 :global! 或是它的别名 :vglobal （ V 代表的是 inVerse ）。 :normal 和 :execute - 脚本梦之队 这两个命令经常在 Vim 的脚本里使用。 借助于 :normal 可以在命令行里进行普通模式的映射。如：:normal! 4j 会令光标下移 4 行（由于加了\"!\"，所以不会使用自定义的映射 \"j\"）。 需要注意的是 :normal 同样可以使用范围数（译者注：参考 :h range 和 :h :normal-range 了解更多），故 :%norm! Iabc 会在所有行前加上 \"abc\"。 借助于 :execute 可以将命令和表达式混合在一起使用。假设你正在编辑一个 C 语言的文件，想切换到它的头文件： :execute 'edit' fnamemodify(expand('%'), ':r') . '.h' （译者注：头文件为与与源文件同名但是扩展名为 .h 的文件。上面的命令中 expand 获得当前文件的名称，fnamemodify 获取不带扩展名的文件名，再连上 '.h' 就是头文件的文件名了，最后在使用 edit 命令打开这个头文件。） 这两个命令经常一起使用。假设你想让光标下移 n 行： :let n = 4 :execute 'normal!' n . 'j' 重定向消息 许多命令都会输出消息，:redir 用来重定向这些消息。它可以将消息输出到文件、寄存器或是某个变量中。 \" 将消息重定向到变量 `neatvar` 中 :redir => neatvar \" 打印所有寄存器的内容 :reg \" 结束重定向 :redir END \" 输出变量 :echo neatvar \" 恶搞一下，我们把它输出到当前缓冲区 :put =neatvar 再 Vim 8 中，可以更简单的方式即位： :put =execute('reg') （译者注：原文最后一条命令是 :put =nicevar 但是实际会报变量未定义的错误） （实测 neovim/vim8 下没问题） 帮助文档：:h :redir 调试 常规建议 如果你遇到了奇怪的行为，尝试用这个命令重现它： vim -u NONE -N 这样会在不引用 vimrc（默认设置）的情况下重启 vim，并且在 nocompatible 模式下（使用 vim 默认设置而不是 vi 的）。（搜索 :h --noplugin 命令了解更多启动加载方式） 如果仍旧能够出现该错误，那么这极有可能是 vim 本身的 bug，请给 vim_dev 发送邮件反馈错误，多数情况下问题不会立刻解决，你还需要进一步研究 许多插件经常会提供新的（默认的/自动的）操作。如果在保存的时候发生了，那么请用 :verb au BufWritePost 命令检查潜在的问题 如果你在使用一个插件管理工具，将插件行注释调，再进行调试。 问题还没有解决？如果不是插件的问题，那么肯定是你的自定义的设置的问题，可能是你的 options 或 autocmd 等等。 到了一行行代码检查的时候了，不断地排除缩小检查范围知道你找出错误，根据二分法的原理你不会花费太多时间的。 在实践过程中，可能就是这样，把 :finish 放在你的 vimrc 文件中间，Vim 会跳过它之后的设置。如果问题还在，那么问题就出在:finish之前的设置中，再把:finish放到前一部分设置的中间位置。否则问题就出现在它后面的半部分设置，那么就把:finish放到后半部分的中间位置。不断的重复即可找到。 调整日志等级 Vim 现在正在使用的另一个比较有用的方法是增加 debug 信息输出详细等级。现在 Vim 支持 9 个等级，可以用:h 'verbose'命令查看。 :e /tmp/foo :set verbose=2 :w :set verbose=0 这可以显示出所有引用的文件、没有变化的文件或者各种各样的作用于保存的插件。 如果你只是想用简单的命令来提高等级，也是用 :verbose ，放在其他命令之前，通过计数来指明等级，默认是 1. :verb set verbose \" verbose=1 :10verb set verbose \" verbose=10 通常用等级 1 来显示上次从哪里设置的选项 :verb set ai? \" Last set from ~/.vim/vimrc 一般等级越高输出信息月详细。但是不要害怕，亦可以把输出导入到文件中： :set verbosefile=/tmp/foo | 15verbose echo \"foo\" | vsplit /tmp/foo 你可以一开始的时候就打开 verbosity，用 -V 选项，它默认设置调试等级为 10。 例如：vim -V5 查看启动日志 查看运行时日志 Vim 脚本调试 如果你以前使用过命令行调试器的话，对于:debug命令你很快就会感到熟悉。 只需要在任何其他命令之前加上:debug就会让你进入调试模式。也就是，被调试的 Vim 脚本会在第一行停止运行，同时该行会被显示出来。 想了解可用的 6 个调试命令，可以查阅:h >cont和阅读下面内容。需要指出的是，类似 gdb 和其他相似调试器，调试命令可以使用它们的简短形式：c、 q、n、s、 i和 f。 除了上面的之外，你还可以自由地使用任何 Vim 的命令。比如，:echo myvar，该命令会在当前的脚本代码位置和上下文上被执行。 只需要简单使用:debug 1，你就获得了REPL调试特性。 当然，调试模式下是可以定义断点的，不然的话每一行都去单步调试就会十分痛苦。（断点之所以被叫做断点，是因为运行到它们的时候，运行就会停止下来。因此，你可以利用断点跳过自己不感兴趣的代码区域）。请查阅:h :breakadd、 :h :breakdel和 :h :breaklist获取更多细节。 假设你需要知道你每次在保存一个文件的时候有哪些代码在运行： :au BufWritePost \" signify BufWritePost \" * call sy#start() :breakadd func *start :w \" Breakpoint in \"sy#start\" line 1 \" Entering Debug mode. Type \"cont\" to continue. \" function sy#start \" line 1: if g:signify_locked >s \" function sy#start \" line 3: endif > \" function sy#start \" line 5: let sy_path = resolve(expand('%:p')) >q :breakdel * 正如你所见，使用命令会重复之前的调试命令，也就是在该例子中的s命令。 :debug命令可以和verbose选项一起使用。 语法文件调试 语法文件由于包含错误的或者复制的正则表达式，常常会使得 Vim 的运行较慢。如果 Vim 在编译的时候包含了+profile feature特性，就可以给用户提供一个超级好用的:syntime命令。 :syntime on \" 多次敲击来重绘窗口，这样的话就会使得相应的语法规则被重新应用一次 :syntime off :syntime report 输出结果包含了很多的度量维度。比如，你可以通过结果知道哪些正则表达式耗时太久需要被优化；哪些正则表达式一直在别使用但重来没有一次成功匹配。 请查阅:h :syntime。 杂项 附加资源 资源名称 简介 七个高效的文本编辑习惯 作者：Bram Moolenaar（即 Vim 的作者） 七个高效的文本编辑习惯 2.0（PDF 版） 同上 IBM DeveloperWorks: 使用脚本编写 Vim 编辑器 Vim 脚本编写五辑 《漫漫 Vim 路》 使用魔抓定制 Vim 插件 《 Vim 实践 (第 2 版)》 轻取 Vim 最佳书籍 Vimcasts.org Vim 录屏演示 为什么是个脚本都用 vi？ 常见误区释疑 你不爱 vi，所以你不懂 Vim 简明,扼要,准确的干货 Vim 配置集合 目前，网上有很多流行 Vim 配置集合，对于 Vim 配置集合，个人认为有利有弊。 对于维护的比较好的配置，比如 SpaceVim 还是值得尝试的，可以节省很多自行配置的时间。 当然，网上还有很多其他很流行的配置，比如： k-vim amix's vimrc janus 常见问题 编辑小文件时很慢 有两个因素对性能影响非常大： 过于复杂的 正则表达式 。尤其是 Ruby 的语法文件，以前会造成性能下降。（见调试语法文件） 屏幕重绘 。有一些功能会强制重绘所有行。 典型肇事者 原因 解决方案 :set cursorline 会导致所有行重绘 :set nocursorline :set cursorcolumn 会导致所有行重绘 :set nocursorcolumn :set relativenumber 会导致所有行重绘 :set norelativenumber :set foldmethod=syntax 如果语法文件已经很慢了，这只会变得更慢 :set foldmethod=manual，:set foldmethod=marker 或者使用快速折叠插件 :set synmaxcol=3000 由于内部表示法，Vim 处理比较长的行时会有问题。让它高亮到 3000 列…… :set synmaxcol=200 matchparen.vim Vim 默认加载的插件，用正则表达式查找配对的括号 禁用插件：:h matchparen 注意：只有在你真正遇到性能问题的时候才需要做上面的调整。在大多数情况下使用上面提到的选项是完全没有问题的。 编辑大文件的时候很慢 Vim 处理大文件最大的问题就是它会一次性读取整个文件。这么做是由于缓冲区的内部机理导致的（在 vim_dev 中讨论）。 如果只是想查看的话，tail hugefile | vim - 是一个不错的选择。 如果你能接受没有语法高亮，并且禁用所有插件和设置的话，使用： $ vim -u NONE -N 这将会使得跳转变快很多，尤其是省去了基于很耗费资源的正则表达式的语法高亮。你还可以告诉 Vim 不要使用交换文件和 viminfo 文件，以避免由于写这些文件而造成的延时： $ vim -n -u NONE -i NONE -N 简而言之，尽量避免使用 Vim 写过大的文件。 持续粘贴（为什么我每次都要设置 'paste' 模式） 持续粘贴模式让终端模拟器可以区分输入内容与粘贴内容。 你有没有遇到过往 Vim 里粘贴代码之后被搞的一团糟？ 这在你使用 cmd+v、shirt-insert、middle-click 等进行粘贴的时候才会发生。 因为那样的话你只是向终端模拟器扔了一大堆的文本。 Vim 并不知道你刚刚是粘贴的文本，它以为你在飞速的输入。 于是它想缩进这些行但是失败了。 这明显不是个问题，如果你用 Vim 的寄存器粘贴，如：\"+p ，这时 Vim 就知道了你在粘贴，就不会导致格式错乱了。 使用 :set paste 就可以解决这个问题正常进行粘贴。见 :h 'paste' 和 :h 'pastetoggle' 获取更多信息。 如果你受够了每次都要设置 'paste' 的话，看看这个能帮你自动设置的插件：bracketed-paste。 点此查看该作者对于这个插件的更多描述。 Neovim 尝试把这些变得更顺畅，如果终端支持的话，它会自动开启持续粘贴模式，无须再手动进行切换。 在终端中按 ESC 后有延时 如果你经常使用命令行，那么肯定要接触 终端模拟器 ，如 xterm、gnome-terminal、iTerm2 等等（与实际的终端不同）。 终端模拟器与他们的祖辈一样，使用 转义序列 （也叫 控制序列 ）来控制光标移动、改变文本颜色等。转义序列就是以转义字符开头的 ASCII 字符串（用脱字符表示法表示成 ^[ ）。当遇到这样的字符串后，终端模拟器会从终端信息数据库中查找对应的动作。 为了使用问题更加清晰，我会先来解释一下什么是映射超时。在映射存在歧义的时候就会产生映射超时： :nnoremap ,a :echo 'foo' :nnoremap ,ab :echo 'bar' 上面的例子中两个映射都能正常工作，但是当输入 ,a 之后，Vim 会延时 1 秒，因为它要确认用户是否还要输入那个 b。 转义序列会产生同样的问题： 作为返回普通模式或取消某个动作的按键而被大量使用 光标键使用转义序列进行的编码 Vim 期望 Alt （也叫作 Mate Key ）会发送一个正确的 8-bit 编码的高位，但是许多终端模拟器并不支持这个（也可能默认没有启用），而只是发送一个转义序列作为代替。 你可以这样测试上面所提到的事情： vim -u NONE -N 然后输入 i ，你会看到一个以 ^[ 开头的字符串，表明这是一个转义序列，^[ 就是转义字符。 简而言之，Vim 在区分录入的 和转义序列的时候需要一定的时间。 默认情况下，Vim 用 :set timeout timeoutlen=1000，就是说它会用 1 秒的时间来区分有歧义的映射 以及 按键编码。这对于映射来说是一个比较合理的值，但是你可以自行定义按键延时的长短，这是解决该问题最根本的办法： set timeout \" for mappings set timeoutlen=1000 \" default value set ttimeout \" for key codes set ttimeoutlen=10 \" unnoticeable small value 在 :h ttimeout 里你可以找到一个关于这些选项之间关系的小表格。 而如果你在 tmux 中使用 Vim 的话，别忘了把下面的配置加入到你的 ~/.tmux.conf文件中： set -sg escape-time 0 无法重复函数中执行的搜索 在命令中的搜索（/、:substitute 等）内容会改变“上次使用的搜索内容”。（它保存在/寄存器中，用 :echo @/ 可以输出它里面的内容） 简单的文本变化可以通过 . 重做。（它保存在 . 寄存器，用 :echo @. 可以输出它的内容） 而在你在函数中进行这些操作的时候，一切就会变得不同。因此你不能用 N/n 查找某个函数刚刚查找的内容，也不能重做函数中对文本的修改。 帮助文档：:h function-search-undo。 进阶阅读 Vim 插件开发指南 常用插件列表 加入我们 可以协助我们核对翻译，或者从章节列表中认领章节进行翻译。 参考资料 Nifty Little Nvim Techniques to Make My Life Easier -- Series 1 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Vim/插件列表.html":{"url":"Vim/插件列表.html","title":"Vim 插件列表","keywords":"","body":"插件列表 颜色主题 按功能分类 文本对齐 语法检查 代码补全 Cycle 代码注释 自动补全括号 模糊搜索 文本搜索 代码对齐线 Navigation 插件管理 代码片段 状态栏 Surround Taking notes Testing 文本对象 Tmux 编辑历史管理 版本控制 Writing Misc 编程语言 C、C++ Clojure Elixir Go HTML Java Javascript Lua PHP Python TeX VimL 颜色主题 以下为一些比较流行的颜色主题： acme-colors apprentice base16 gotham gruvbox janah jellybeans lucius molokai nofrils oceanic-next paramount railscasts seoul256 solarized (or solarized8 or flattened) tomorrow vividchalk yowish zenburn Alternatively, generate your own colorscheme using themer or Colortemplate. 按功能分类 文本对齐 tabular vim-easy-align vim-lion 语法检查 ale neomake syntastic 代码补全 asyncomplete.vim completor.vim deoplete.nvim neocomplete.vim nvim-completion-manager supertab vim-mucomplete VimCompletesMe YouCompleteMe Cycle switch.vim vim-speeddating 代码注释 nerdcommenter tcomment_vim vim-commentary 自动补全括号 auto-pairs delimitMate vim-endwise 模糊搜索 Command-T (requires +ruby) ctrlp.vim denite.nvim (requires +python3) fzf (and fzf.vim) unite.vim vim-fz 文本搜索 ctrlsf.vim ferret vim-grepper 代码对齐线 indentLine vim-indent-guides Navigation nerdtree tagbar vim-dirvish vim-easymotion vim-sneak vim-vinegar vimfiler.vim (depends on other plugins) Also see fuzzy finders. 插件管理 apt-vim dein.vim minpac vim-addon-manager vim-pathogen vim-plug vundle.vim 代码片段 neosnippet.vim (depends on other plugins) ultisnips vim-snipmate (depends on other plugins) xptemplate 状态栏 lightline.vim powerline vim-airline vim-flagship Surround vim-operator-surround vim-sandwich vim-surround Taking notes vim-dotoo vim-journal vim-notes vim-orgmode vim-pad vimwiki Testing vim-test 文本对象 targets.vim vim-exchange vim-indent-object vim-matchup vim-textobj-user Tmux tmux-complete.vim vim-dispatch vim-tmux-navigator vitality.vim 编辑历史管理 vim-mundo gundo.vim undotree 版本控制 agit.vim committia.vim gist-vim github-issues.vim gitv gv.vim nerdtree-git-plugin vim-auto-programming vim-fugitive vim-gitgutter vim-github-dashboard vim-lawrencium vim-signify vimagit git-messenger.vim Writing vim-grammarous vim-online-thesaurus Misc calendar.vim CoVim FastFold goyo.vim is.vim NrrwRgn sideways.vim splitjoin.vim unicode.vim vim-abolish vim-bracketed-paste vim-devicons vim-diff-enhanced vim-diminactive vim-fixkey vim-gnupg vim-gutentags vim-hackernews vim-move vim-multiple-cursors vim-projectionist vim-qf vim-rsi vim-sleuth vim-startify vim-unimpaired 编程语言 C、C++ a.vim clang_complete color_coded lh-cpp vim-cpp-enhanced-highlight Clojure paredit rainbow_parentheses.vim vim-clojure-highlight vim-fireplace vim-salve vim-sexp-mappings-for-regular-people vim-sexp Elixir alchemist.vim vim-elixir vim-mix-format Go gofmt.vim hl-goimport.vim vim-go vim-godebug HTML emmet-vim html5.vim Java vim-javacomplete2 Javascript es.next.syntax.vim javascript-libraries-syntax.vim node-vim-debugger tern_for_vim vim-esformatter vim-flow vim-javascript-syntax vim-javascript vim-node vim-prettier yajs.vim yats.vim Lua vim-lua-ftplugin vim-lua-inspect PHP php.vim vim-php-cs-fixer vim-php-namespace vim-php-refactoring-toolbox Python braceless.vim impsort.vim jedi-vim python-mode SimpylFold vim-flake8 TeX vimtex VimL exception.vim helpful.vim vader.vim vim-lookup vim-scriptease vim-themis Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Vim/YouCompleteMe安装.html":{"url":"Vim/YouCompleteMe安装.html","title":"YouCompleteMe安装","keywords":"","body":" YouCompleteMe 一开始折腾 Vundle 时就想装，第一次安装耗时 2 天，浏览器导航条开页面开的只有一条图标了，还是没装上，装到怀疑人生！后来又反反复复折腾了两三次，又没装上！今天，改变策略，“啃”英文手册，豁然开朗！有时候 Google 搜索再多不如一步一步照着文档来，思维定式，认为中文安装博客很多，随便就装上了，但每个人安装环境都不一样，即使操作系统一样也没用！以后安装只看官方文档了！！！ 预备环境 Ubuntu 18.04 Vundle vim >= 7.4.1578 vim :version YoucompleteMe git 库 - https://github.com/ycm-core/YouCompleteMe.git - 浏览器翻墙下，命令行下要人命 其他需要用到再加 流程 在 ~/.vimrc 的 Vundle Plugin 中加入：Plugin 'Valloric/YouCompleteMe' 不要运行 :PluginInstall 或 :PluginUpdate，不然就卡那了 下载解压生成 Youcomplete git 库到 ~/.vim/bundle/YoucompleteMe/ cd ~/.vim/bundle/YoucompleteMe/ 安装 YCM 依赖：git submodule update --init --recursive 较慢，逃不掉的 之后需要针对是否支持 C 语言家族、Java、JavaScript、Go 等等安装不同依赖和执行不同编译操作 不指定语言 cd ~/.vim/bundle/YouCompleteMe ./install.py C Family 预备环境 libclang >= 9.0.0 clangd >= 9.0.0 http://releases.llvm.org/download.html Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Vim/vimrc示例1.html":{"url":"Vim/vimrc示例1.html","title":"vimrc示例","keywords":"","body":"set nocompatible \" be iMproved, required 不用vi的模式 filetype off \" required \" set the runtime path to include Vundle and initialize 这是vundle的路径 set rtp+=~/.vim/bundle/Vundle.vim call vundle#begin() \" vundle函数开始 \" alternatively, pass a path where Vundle should install plugins \"call vundle#begin('~/some/path/here') \" 科普： \" 插件的来源有3个：github仓库，vundle自带，vim-scripts. \" (注：如果插件在本地仓库，建议推到github) \" 1. 对于github仓库： 仿照下面的写法，行开头都是Plugin的，要写作者和插件名 \" 2. 对于vundle自带： 仿照下面的写法，行开头都是Bundle的，直接写插件名 \" 3. 对于vim-scripts：仿照下面的下发，行开头是Plugin，直接写插件名 \" 这是来源于github仓库的插件的写法 \" ==>> 管理自己(必须) Plugin 'VundleVim/Vundle.vim' \" 这是来源于http://vim-scripts.org/vim/scripts.html的插件的写法 \" ==>> 不知道这插件干啥的 \" Plugin 'L9' \" 这是vundle自带的插件的写法，择需下载即可 \" Bundle 'EasyMotion' \" =============================================================================== \" =>> 辅助使用git，一般可能不需要 \" Plugin 'tpope/vim-fugitive' \" ==>> 代码自动补全的插件，需要先install一些东西来支持。不想用. \" Plugin 'Valloric/YouCompleteMe' \" 记得安装好之后就去~/.vim/bundle/YouCompleteMe/，接下来仍需要做的是： \" sudo apt-get install build-essential cmake c的make工具 \" sudo apt-get install python-dev 确定你有python，因为安装配置的需要 \" ./install.py --clang-completer 这样可以支持c的各种家族 \" 若想支持更多，那就换成将下行代码运行，至少支持c# Go JS typeScript \" ./install.py --clang-completer --omnisharp-completer --gocode-completer --tern-completer \" ==>> 字体包，支持airline用的 Plugin 'powerline/fonts' \" 到~/.vim/bundle/fonts中运行install.sh，可能需要改其中的路径到~/.fonts中 \" 然后将终端中的字体设置为带powline的，不能使用自系统等宽，否则无效。 \" 推荐：ubuntu mono derivative powline 13 \" ==>> 主题包，支持airline用的 \" 在下面的 let g:airline_theme=\"bubblegum\"就可使用主题 Plugin 'vim-airline/vim-airline-themes' \" ==>> 状态栏，字体不好就难看点。 Plugin 'bling/vim-airline' let g:airline_theme=\"bubblegum\" \"目前用的主题 let g:airline_powerline_fonts = 1 \"这个是安装字体后 必须设置此项 let g:Powerline_symbols=\"fancy\" if !exists('g:airline_symbols') let g:airline_symbols = {} endif \" 启用：可以切换到其他buffer文件 let g:airline#extensions#tabline#enabled = 1 \" 显示最顶上的buffer栏 let g:airline#extensions#tabline#buffer_nr_show = 1 \" 下面2个是设置切换Buffer快捷键，很多会冲突，看着设置即可 nnoremap :bn nnoremap .. :bp \" 关闭状态显示空白符号计数,用处不大\" let g:airline#extensions#whitespace#enabled = 0 let g:airline#extensions#whitespace#symbol = '!' set laststatus=2 set t_Co=256 \" let Powerline_symbols='compatible' \" ==>> 代码对齐的插件 \" 常用方法1) Plugin 'godlygeek/tabular' \" ==>> 显示列对齐线插件 Plugin 'Yggdroot/indentLine' let g:indentLine_char = '┆' let g:indentLine_enabled = 1 let g:indentLine_color_term = 239 \" ==>> 右边栏：变量及函数列表，按F9即可弹出/关闭 Bundle 'Tagbar' map :TagbarToggle let g:tagbar_width=30 let g:tagbar_autofocus=1 \" ==>>左边栏：目录树，按F8即可弹出/关闭 Bundle 'The-NERD-tree' map :NERDTreeToggle \" 设置为自动启动，打开vim时默认是打开此栏的 autocmd VimEnter NERDTree autocmd StdinReadPre let s:std_in=1 autocmd VimEnter if argc() == 0 && !exists(\"s:std_in\") | NERDTree | endif autocmd bufenter if ( winnr(\"$\") == 1 && exists(\"b:NERDTreeType\") && b:NERDTreeType == \"primary\" ) | q | endif \" ==>> 底栏：文件名搜索，不用关闭vim即可搜索文件并可以跳转 Bundle 'ctrlp.vim' \" 自动忽略一些后缀 set wildignore+=/tmp/,.so,.swp,.zip,.png,.jpg,.jpeg,.gif,~ \" MacOSX/Linux let g:ctrlp_map = ',,' \" 注意：快捷键为连续按两次逗号，而不是ctrl+p let g:ctrlp_open_multiple_files = 'v' let g:ctrlp_cmd = 'CtrlP' \" 另一种打开方式是冒号再输入CtrlP打开 let g:ctrlp_working_path_mode = '0' \"disable work path mode \" 用正则表达式忽略一些后缀 let g:ctrlp_custom_ignore = { \\ 'dir': '\\v[\\/].(git|hg|svn)$', \\ 'file': '\\v.(log|jpg|png|jpeg)$', \\ } \" ==>> 用于批量注释，用法请自行google Bundle 'The-NERD-Commenter' \" 注释时自动加一个空格 let g:NERDSpaceDelims=1 \" ==>> 支持更精确地跳转光标 Bundle 'EasyMotion' \" 一般无需设置 \" 按词往上或下: \\b \\w \" 按行往上或下: \\j \\k \" ==>> 字符串查找(在查找之前先在终端中加入如下命令，直接用cr即可创建数据库文件) \" ==>> cscope很像ctags的反向操作，能找到哪里调用了这个函数。 \" 如下命令用于生成ctags文件和cscope文件 \" 终端命令$ctags -R --fields=+IS && cscope -Rbkq \" 如下是cscope的快捷键配置 Bundle 'cscope.vim' nnoremap fa :call cscope#findInteractive(expand('')) nnoremap l :call ToggleLocationList() \" s: Find this C symbol nnoremap fs :call cscope#find('s', expand('')) \" g: Find this definition nnoremap fg :call cscope#find('g', expand('')) \" d: Find functions called by this function nnoremap fd :call cscope#find('d', expand('')) \" c: Find functions calling this function nnoremap fc :call cscope#find('c', expand('')) \" t: Find this text string nnoremap ft :call cscope#find('t', expand('')) \" e: Find this egrep pattern nnoremap fe :call cscope#find('e', expand('')) \" f: Find this file nnoremap ff :call cscope#find('f', expand('')) \" i: Find files #including this file nnoremap fi :call cscope#find('i', expand('')) let g:cscope_ignore_files = '.Z$|.zip$|.zipx$|.lib' \" 忽视一些后缀 let g:cscope_silent = 1 \" ==>> 辅助cscope的，能自动加载cscope.out文件，若没找到，还能自动往上层目录 Bundle 'autoload_cscope.vim' let g:autocscope_menus=0 \"关掉默认的快捷键(上面已经定义了) \" ==>>主题插件Bundle 'molokai' Bundle 'Solarized' \" All of your Plugins must be added before the following line call vundle#end() \" required 函数结束 filetype plugin indent on \" required \" ==========================以下是一些个人的喜好配置了================================= \" 键映射 :let mapleader = \"\\\" \" 快捷键映射：ctrl+\\ 在插入模式直接保存并退出 :map! :q \" 快捷键映射： 打开/关闭代码块折叠，比如函数什么的折叠起来比较容易看 map za \" 快捷键映射： 打开/关闭折叠（递归式）。比较少用，不用了。 \" map zA \" 可视模式下，ctrl+c为复制到系统的剪贴板。注意需要先apt-get安装vim-nox和vim-gnome。 \" vmap \"+y \" \" 任何模式下，ctrl+v为粘贴。两个安装项同上。 \" map \"+p \" 在用的主题 colorscheme molokai \" 夜间主题，颜色不错。 \" colo evening \" 语法高亮 syntax enable \" 突出当前行 set cursorline \" 突出当前列 \"set cursorcolumn \" 显示行号 set nu \" tab缩进为4个空格大小 set tabstop=4 \" 右下角显示当前列号 set ruler \" 自动缩进的大小为4空格 set shiftwidth=4 \" set smarttab \" 空格代替tab set expandtab \" 开启缩进 set cindent \" 关闭备份功能 set nobackup set noswapfile \" 任何模式下，鼠标永远启动，但是复制到粘贴板的功能就禁用了 set mouse=a \" 新文件编码默认编码:utf-8 set fileencoding=utf-8 \" 打开折叠功能 set foldmethod=syntax \" 默认情况下不折叠 set foldlevel=99 \" 在状态栏显示正在输入的命令 set showcmd \" 自动往上层目录查找tags文件(找定义ctrl+] 回跳ctrl+t) set tags=tags; \" 用vim直接打开一个文件时会自动切到该文件目录下，不太喜欢 \" set autochdir \" 搜索高亮 set hlsearch Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Vim/vimrc备份.html":{"url":"Vim/vimrc备份.html","title":"vimrc备份","keywords":"","body":"\" 语法高亮 syntax on \" 修改tab键为4个空格 set ts=4 set sw=4 \" 光标匹配 set showmatch \" 匹配括号高亮的时间（单位是十分之一秒） set matchtime=1 \" 搜索结果高亮 set hlsearch \" 用浅色高亮当前行 autocmd InsertEnter se cul\" 开启实时搜索，搜索时，每输入一个字符，就自动跳到第一个匹配的结果 set incsearch \" 搜索忽略大小写 set ignorecase \" vim 自身命令行模式智能补全 set wildmenu \" 不创建备份文件 set nobackup \" 不创建交换文件 set noswapfile \" 保留撤销历史 set undofile set undodir=~/.vim/.undo// \" 出错时不发出响声 set noerrorbells \" 命令模式 tab 键补全 set wildmenu set wildmode=longest:list,full \" 不与 Vi 兼容 set nocompatible \" 显示模式 set showmode \" 支持鼠标 set mouse=a \" utf-8 编码 set encoding=utf-8 \" 启动 pathogen 插件管理器 \" execute pathogen#infect() \" 开启文件类型侦查 \"\"filetype on \" 根据侦查到的不同类型加载对应的插件，比如C++文件加载C++对应的插件 filetype plugin on \" 为特定文件类型载入相关缩进文件 filetype indent on \" 显示当前行号列号 \"set ruler \" 显示行号 set number \" 显示中文帮助 set helplang=cn \" 历史记录数 set history=1000 \" 让配置变更成保存时自动重启加载生效 autocmd BufWritePost $MYVIMRC source $MYVIMRC \" 设置默认模板文件 autocmd BufNewFile .html 0r /home/xcq/.vim/vimfiles/template.html autocmd BufNewFile .py 0r /home/xcq/.vim/vimfiles/template.py autocmd BufNewFile .c 0r /home/xcq/.vim/vimfiles/template.c \" autocmd BufNewFile *.html 0r /home/xcq/.vim/vimfiles/template.py \" 映射快捷键 \" 读写模式 \" 括号自动补全 \"\"inoremap ( ()i \"\"inoremap { {}i \"\"inoremap [ []i \"\"inoremap \" \"\"i \" Ctrl+i---->ESC键 imap \" 配置 Plugin NERDTree \"\" 将F2设置为开关:NERDTree的快捷键map :NERDTree \"map :silent! NERDTreeToggle \"\" 窗口尺寸 let g:NERDTreeSize=30 \"\" 窗口位置 let g:NERDTreeWinPos='right' \"\" 修改树的显示图标 let g:NERDTreeDirArrowExpandable = '+' let g:NERDTreeDirArrowCollapsible = '-' \"\" 当NERDTree为剩下的唯一窗口时自动关闭 autocmd bufenter if (winnr(\"$\") == 1 && exists(\"b:NERDTree\") && b:NERDTree.isTabTree()) | q | endif \"\" 打开vim时自动打开NERDTree \"autocmd vimenter NERDTree \"\" 打开NERDTree窗口时,自动显示Bookmarks \"let NERDTreeShowBookmarks=1 \" Vundle 环境设置 filetype off set rtp+=~/.vim/bundle/Vundle.vim \" Vundle 管理的插件列表必须位于 vundle#begin() 和 vundle#end() 之间 \" 删除插件方法：先在下面删除对应行，在 :BundleClean call vundle#begin() Plugin 'VundleVim/Vundle.vim' Plugin 'scrooloose/nerdtree' Plugin 'chemzqm/wxapp.vim' \" 插件列表结束 call vundle#end() Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Vim/Tmux快捷键.html":{"url":"Vim/Tmux快捷键.html","title":"Tmux快捷键","keywords":"","body":"Tmux 概念 Session 一组窗口的集合，通常用来概括同一个任务。session 可以有自己的名字便于任务之间的切换 Window 单个可见窗口。Windows 有自己的编号，也可以认为和 ITerm2中的 Tab 类似 Pane 窗格，被划分成小块的窗口，类似于 Vim 中 C-w +v 后的效果 快捷键 tmux command tmux 启动 tmux tmux ls 显示 tmux 会话 tmux a [or attach] 还原并附加到分离时的 Session tmux a -t 会话名 还原并附加到指定的 Session tmux new -s 会话名 创建新 Session tmux kill-session -t 会话名 销毁 Session prefix command - Ctrl b - 前置操作 prefix-command Ctrl + b (默认) ? 帮助 t 显示时间 x [or exit] 销毁 window、session、pane $ 重命名当前 Session s 查看/切换 session d 离开 Session c 新建 window 空格 切换到上一个活动的 window n[0,1,2...] 使用 window 编号切换 ， 重命名 window & 关闭 window % 水平拆分出一个新 pane \" 垂直拆分出一个新 pane o 切换到下一个 pane 方向键 切换到上下左右的 pane q 查看所有 pane 编号 z 暂时 pane 放到最大，再次 z 恢复 配置 若没有配置文件的话先创建: touch ~/.tmux.conf prefix command 默认是 Ctrl b ，但比较违反人体工学，所以可以把大写键 caps lock 改为 Ctrl 键，然后设置 prefix command 为 Ctrl a Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Ansible/":{"url":"Ansible/","title":"Ansible","keywords":"","body":"Ansible 学习 Ansible 中文 wiki 果冻想 Ansible 系列 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Ansible/术语表.html":{"url":"Ansible/术语表.html","title":"术语表","keywords":"","body":"Ansible 术语表 动作(Action) 一个动作属于一个任务的一部分，指定运行的模块，然后传递参数给此模块。每个任务之一一个动作，但是它可以有不同的参数。 Ad Hoc 指的是使用 /usr/bin/ansible 运行 Ansible 直接执行一些命令，而不是使用 /usr/bin/ansible-playbook 执行剧本。一个 ad-hoc 命令例子，可以是在你的基础设施里面重启50台机器。任何你可以做的东西， ad-hoc 都可以实现通过写一个剧本, 剧本肯定也组合了其它的一些操作。 Async 指的是一个任务配置为运行在后台，而不是等它完成。如果你有一个很长的任务要执行，而且时长可能超出 SSH 登录时长， 那么运行那个任务在 async 方式比较有意义。Async 方式可以每隔一段时间 poll 一次，等待此任务完成。它可以调整为把任务踢出去，然后不再理会它，以便后来使用。Async方式可以在 /usr/bin/ansible 和 /usr/bin/ansible-playbook下面。 Callback Plugin 指一些用户编写的代码可以从 Ansible 运行结果获取数据,并做出一些处理。 一些提供的在 Github 项目上的事例实现了自定义日志，发邮件，甚至播放声音效果。 Check Mode 指的是运行 Ansible 使用 --ckeck 选项，但是系统本身却不作出任何改变，仅仅输出可能发生的改变。这就像在其它系统上叫做 “dry run”的方式， 用户应该被警告因为这个方式没考虑到命令失败的问题，或者冲突影响。使用这个可以知道哪些东西可能会发生，但是这不是一个好的替代 staging 环境。 Connection Type, Connection Plugin Ansible 默认用可插拨的库和远端系统通信。 Ansible 支持天然的 OpenSSH (‘ssh’) 或者 Python 实现的 ‘paramiko’ 库。如果你在使用最近的 Ansible 版本，最好使用 OpenSSH ，同时支持 Kerberos 和 jump hosts。这在文档开始部分就有提到。也有一些加速方式的连接类型，但是必须 bootstrapped 基于SSH类型的连接，但是它非常快，就像在本地系统上运行一样。用户也可以写他们自己的连接类型插件。 Conditionals 一个条件式是根据一个表达式正确或错误判断是否在一个机器上执行给定的任务。 Ansible 的条件表达式由 ‘when’ 提供，在playbook文档里面有讨论。 Diff Mode --diff``标识可以传递给 Ansible 来展示模板文件如何改变的，或者使用 ``--check 模式时它们可能发生的改变 。这些 diffs 统一为diff格式。 Facts Facts 是发现远端节点的信息。当它们被用在模板的时候， facts只能被引用，而不能被设置。Facts是当运行 plays 时候执行内部的’setup’模块自动收集的。你不需要明确的调用 setup 模块，它自己运行，但是当你想节省时间的时候你可以禁止它。为了方便用户转向其他系统配置工具， fact 模块可以拉取 facts 从 Chef的’ohai’ 和 Puppet的’facter’工具。 Filter Plugin 过滤插件式大多数用户从来不需要了解的东西。这允许创在新的 Jinja2 过滤，而这只对那些知道什么是 Jinja2 过滤的人有帮助。如果你需要他们，你可以从 API docs 部分学习如何写他们。 Forks Ansible 与远端节点交流是通过并行的机制，并行机制的方式可以通过传递 ``–forks``参数设置，或者在配置文件里面编辑。默认是保守的5个线程。如果你有足够的内存，你可以很容易的设置为50或者更多值。 Gather Facts (Boolean) 上面已经提到了Facts。有时候在运行多个 playbook ，可能不想收集一些fact ，而且以后也不会用到这些值。在playbook里面设置 gather_facts:False 指示跳过收集 facts。 Globbing Globbing 是一个一种基于通配符的方式挑选许多主机，而不是明确指定主机的名字，或者它们的组名。例如 ，使用 “www*”，来匹配所有以 “www” 开头的所有主机。这个理念直接被吸收进 Func 。除此之外，不同的 set 操作也可以通过 globbing 实现。 Group 组由几个主机组成，可以方便的当做一个目标看待，同时可以共享变量。 Group Vars group_vars 文件位于一个目录下面，同时在 inventory 旁边，有一个可选的文件名在每个组后面。这是一个方便的位置来存放变量，提供给每个组，由其是复杂的数据结构，因此这些变量不需要嵌入在 inventory 文件或 playbook 文件里面。 Handlers Handler 仅仅是普通的任务在Ansible playbook里面(请参考tasks)。但是仅仅当任务包含 “notify” 指令和指示它改变了一些东西的时候才运行。例如，如果一个配置文件改变了，然后任务引用这个配置文件模板通知服务器重启 handler 。这意味着服务可以被反弹仅仅他们需要重启的时候。Handler 不仅仅可以用于重启服务，但是重启服务是最通用的用法。 Host 一个host 只是简单的 Ansible 管理的远端机器。它们可以被分配私有的变量，可以被组织为一个组。所有的组有可以访问一个名字，也可以是IP地址，如果他们在默认的SSH端口不能访问，可以指定一个一个可选的端口号 Host Specifier 每一个 Play 映射为一系列的 tasks (可以是定义的role，purpose，或系统指令) 到一些系统的集合 “hosts:” 指令在每个play中通常叫做主机指定。 它可以挑选一个系统，一个或更多组，甚至一些主机在其他组不在某个组里面，但是在另外一个组里面。 Host Vars 就像”Group Vars”，一个名称为 “host_vars/” 的目录在 inventory 文件旁，可以在 invetory 文件的主机名后面包含这个文件，使用 YAML 格式。这提供一个方便的位置分配变量给这个主机而不要在 inventory 文件里面嵌入太多变量。Host Vars 文件还可以用于定义复杂的在 inventory 文件里面不断出现的数据结构。 Lazy Evaluation 总的来说， Ansible 评估任何变量在 playbook 内容在最新的可能的时间里，也就是意味着如果你定义了一个数据结构，这个数据结构自身也可以定义变量值在里面，然后每件事情就像你期望的那样工作。 这也意味着 变量字符串可以包含其它的变量在字符串里面。 Lookup Plugin 一个查询插件是从外界得到数据进入 Ansible 。这些东西就像 “with_items” ，一个基础的循环插件，但是也有其它的查询插件就像 “with_file”, 从文件加载数据，甚至有一些逡巡环境变量， DNS 文本记录，或者键值存储。 查询插件也可以被 templates 访问 ，{{ lookup('file','/path/to/file') }}. Multi-Tier IT 系统不是一次在同一时间只管理一个系统，而是在多个系统之间交互，一组系统，在一个定义好的顺序里面。例如，一个 web server 可能需要在数据库服务器之前更新，web server的部分内容又要在 THAT 数据库服务之后更新，同时不同的负载均衡器和监控服务器也需要被联系到。 Ansible 看待系统为整个工作流和拓扑，而不是简单的一次一个系统。 Idempotency 改变类的命令仅仅在他们需要使用的时候才被使用，最好描述系统的状态而不是如何到达系统某个状态的过程。打个比方，从美国的卡罗莱纳州到加利福尼亚州包括驾驶很长一段距离的车，但是如果我是在阿拉斯加州，则需要乘坐地铁。 Ansible的资源就像你说，“把我放到加利福尼亚”然后决定如何到达那里。如果你已经在加利福尼亚，没有什么会发生，然后他会让你知道什么都没有发生，不需要改变什么东西。 Includes Playbook 文件可以包含其它的 plays，任务列表也可以扩展在其它文件的外部任务，就像处理器。 Include 可以被参数化的，也就是装载文件可以传递变量。例如，一个Include 表演设置Wordpress 博客站点，需要传递”user”参数,然后这个表演(play)可以 include 多于一次的博客站点，例如叫做 “alice” 和 “bob” Inventory 一个描述主机和组的 Ansible 文件。Inventory 可以通过 “Inventory Script” 提供，有时也叫做 “External Inventory Script” Inventory Script 一个简单的从外部资源寻找主机,主机组的成员，和变量信息的程序 – 可以是个 SQL 数据库，一个 CMDB 解决方案，或者是 LDAP。这个概念来自 Puppet (叫”External Nodes Classifier”)，工作方式也是类似的。 Jinja2 Jinja2 是 Ansible 模板的首选语言。它非常简单，很容易阅读和书写。 JSON Ansible 从远端机器上返回的数据使用 JSON 类型。这使得模块可以使用任何语言编写，而不仅仅是Python。 Library 许多模块的集合供 /usr/bin/ansible 或 Ansible Playbook 使用。 Limit Groups 通过传递 --limit somegroup 参数给 ansible 或 ansible-playbook ，命令可以限制为一些主机的子集 。 例如这可以使目标为全部的服务器到只允许一个服务器运行 playbook 。 Local Connection 通过在 playbook 中使用 “connection:local” ，或者传递 “-c local” 给 /usr/bin/ansible ，这指明了我们正在管理本地主机而不是远端机器。 Local Action local_action 指令在 playbook 意味着给予的步骤仅仅会在本地机器上运行， 但是这变量 ‘’可以被传递到远端机器引用。这可以被用于触发器，例如，rsync 操作。 Loops 通常来说， Ansible 不是一个编程语言。它跟喜欢声明，尽管不同的结果像 “with_items” 使得指定的任务重复的实验多个 items 在一个列表里面。特定的模块，例如 yum 和 apt ，对这更喜欢，可以安装多个包，然后加速了配置的总时间。 Modules Module 是 Ansible 运行远端机器的单元。模块可以使用通过 /usr/bin/ansible 或者 /usr/bin/ansible-playbook 。模块可以通过任何语言编写包括 Perl，Bash，Ruby，但是使用Python 可以利用一些有用的社区库代码。模块仅仅返回一些 JSON 格式数据或简单的 key=value 集合。一旦模块在远端执行之后，他们就被移除了，隐私不需 daemon 长时间运行。Ansible 把模块的集合看做 ‘library’ Notify 等级改变的事件和通知处理任务需要在 play 的最后运行。如果一个 handler 被多个任务通知，它会仍然仅仅运行一次。 Handler仅仅按照列表运行一次，而不是他们被notified 的顺序。 Orchestration 一些软件自动化系统使用这个单词意味着不同的事情。 Ansible使用它作为一个导演执导一个曲子。一个数据中心或云架构充满多个系统，表演很多角色 – web servers，database servers，负载均衡器，监控系统， 持续集成系统等。在具体表演过程中，必须要安排好特定的步骤。一些系统执行一些步骤，然后其它系统，然后先前的系统执行更多的步骤。同时，发送邮件也可能是需要的到 web service 联系人。 Ansible 编排了所有过程的模型。 paramiko 默认， Ansible 管理机器使用 SSH。而 Ansible 默认使用的 python 提供的库叫 paramiko。 paramiko库非常的快和很容易管理，渴望支持 Kerberos 或 jump Host 的用户转向使用 SSH 作为连接类型了。在他们的 playbook里面使用 “-c ssh” 选项即可。 Playbooks Playbooks 是一种语言，Ansible 用于编排，配置，管理和部署吸引。他们被叫做 Playbooks 的部分原因是依据它行为的类比，使用它应该是一件有趣的事情。他们不是 工作书。 Plays 一个 playbook 就是一系列的 plays。一个 play 就是在一些主机中挑选指定的主机和主机组，然后运行任务在这些主机上，定义这些主机的角色和他们会怎么样表演。 Pull Mode Pull 模式是节点每隔 N 分钟检查特定的主机。它使用 ansible-pull 程序，pull模式有很多选择性。Ansible-pull 在任务计划中检查配置指令熟悉怒，使用连接插件，在本地管理机器。 Push Mode push 模式是 Ansible 的默认模式。事实上，这也不算是个模式 – 你不去想它的时候 ansible 就是这么工作的。Push 方式通过复杂的编排进程，而不要等到节点检查，对节点有个很好的粒度控制。 Register Variable Ansible 运行的结果可以存储在一个变量里面以便模板或条件语句使用，用于定义这个变量的关键字叫做 ‘register’。你可以定义无限制的变量名用于 registertion. Resource Model Ansible 模块工作在资源上。例如，file 模块会挑选指定的文件然后确保资源的属性匹配指定的模型。例如，我们想改变 /etc/motd 的属主为 ‘root’，如果它还没设置为 root,或者设置权限为‘0644’,如果还没有设置为 0644 。资源模型是幂等性( ‘idemotent’ )意味着改变命令不会运行除非需要的时候，Ansible会把系统变为期望的状态而不管当前的状态是什么。 Roles 一个 Role 可以包含特定的变量值，特定的任务，特定的触发器等东西。因为 Role 的文件结构，roles 可以是再次利用的单元，可以让你在其它 playbooks 中共享一些行为。 Rolling Update 一次处理某组主机的 N 个节点，避免一次全部更新导致系统离线。 例如，在一个 500 节点的 web 拓扑里，最好一次更新 10~20 台机器一次。Ansible 中的 ‘seria’ 关键字控制 rolling updtae的池。默认是一次全部处理。OS 配置可以不使用 rolling update 模型，但是可以这么做。 Runner Ansible 核心的组件是 /usr/bin/ansible 指令，它背后有强大的力量，激发 playbook 中的每个任务。 Runner 一般是 Ansible 开发者经常谈论的，但是它对用户来说不是经常用到的词汇。 Serial 参考 “Rolling Update”. Sudo Ansible 不要求一定用 root 登录，它是无守护进程模式的(这可能是个安全问题，在敏感的环境里面)。 Ansible可以记录一些运行 sudo 命令的操作，可以运行无密码的和有密码的 sudo。 一些操作不需要使用 sudo (像 scp 文件传输)可以通过 Ansible 的 copy,template,和 fetch 模块实现。 SSH (Native) OpenSSH 作为 Ansible 的传输被指定使用 “-c ssh”，这可以很有用当你想登陆通过 Kerberized SSH 或者 SSH jump hosts 等待。在 1.2.1版本，ssh被用作默认，之前使用 ‘paramiko’ 作为默认。使用一个客户端 支持 ControlMaster 和 ControlPersist 是被推荐的对于管理大量主机。如果你不需要使用 Kerbers，jump hosts或者其它的特性， 选择 paramiko 是不错的选择。Ansible 会发出警告，如果它没有检测到 ControlMaster/ControlPersist 兼容性。 Tags Ansible 允许给playbook里面的资源通过自定义的关键字打上标签，然后只运行与关键字一致的部分代码。 例如，可能有个完成的 OS 配置，然后特定的步骤标记为 “ntp” ，然后运行 “ntp” 步骤来重新配置时间服务器信息。 Tasks Playbooks 包含 Tasks， Tasks 结合一个动作使用一个名称和一些可选的关键字。处理器也是 tasks，但是他们是特殊的 tasks 不运行，除非他们被通知一个 tasks 报道的远端吸引变化。 Templates Ansible 很容易的传输文件到远端系统上面，但是它经常需要替换一些变量在其它的文件里面。变量可以来自 清单文件，Host Vars， Group Vars,或者 Facts。Templates 使用 Jinja2 模板引擎同样可以包含逻辑控制像循环和 if 语句。 Transport Ansible 使用 “Connection Plugins” 定义可用的传输类型。这只是 Ansible 如何到达管理的系统。Rransports 包括 paramiko, SSH (using OpenSSH), 和 local. When 一个可选的关键字来决定这个任务是不是应该指向，如果再 “when:” 关键字这里的表达式是是不正确的，这个任务会被忽略。 Van Halen 没有其它的原因，Michael 真的很喜欢他们，所有的 Ansible 版本代号都是以 Van Halen 的歌曲命名。 Vars (Variables) 和 Facts 相反， 变量是一些值，或字典，列表的名称(可以是标量值–整数，布尔型，或字符串，字典，列表)，然后变量可以应用在模板和剧本里面。他们是声明的东西，不是获取远程系统的当前状态或性质(这是Facts) YAML Ansible 不想强迫人们编写编程语言的代码实现自动化基础设施部署,所以 Ansible 使用YAML来定义剧本还配置语言和变量文件。YAML很棒因为它有很少的语法，然后非常干净,容易浏览。对人来说，这是一个很好的数据格式的配置文件,机器也可读。YAML非常流行在动态语言社区，编程语言也有库可用来序列化这种语言. Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Ansible/Ansible必知单词.html":{"url":"Ansible/Ansible必知单词.html","title":"Ansible 常用单词","keywords":"","body":"Ansible 常用单词 automation - 自动化 orchestrate - 编排 continuous deployments - CD - 持续部署 Continuous Integration - CI - 持续集成 zero downtime rolling updates - 不停机滚动更新 security and reliability - 安全性和可靠性 agent-less - 无代理的 scenarios - 场景 advanced - 进阶的 additional - 额外的 Control Node - 控制节点 Managed Node - 被管理节点 interpreter - 解释器 independently - 独立地 adjustable - 可调整的 reference - 参考 precedence - 优先权 inspect - 检查 ecosystem - 生态系统 handlers - 处理程序，处理器 diretives - 指令 invoke - 调用 illustrate - 说明 temporary - 临时的 privilege escalation - 提升权限 inherit - 继承 nested - 嵌套的 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Ansible/Ansible学习.html":{"url":"Ansible/Ansible学习.html","title":"Ansible 学习笔记","keywords":"","body":"Ansible 学习笔记 Ansible Galaxy 使用 Ansible 实现数据中心自动化管理 Ansible 的核心组件包括：Modules、Inventory、Playbook、Roles 和 Plugins 目录 单词解释 Ansible 架构 配置文件 - ansible.cfg 主机清单 - Inventory 模块 - Module 变量 - Variable Ansible 命令 - Ad-Hoc Command 剧本 - Playbook 角色 - Role 单词解释 Ad-Hoc：拉丁文常用语，意为特设的、临时的。Ansible 官方使用 Ad-Hoc Command 作为“临时命令”之意，也就是 Ansible 命令 Tasks：任务，由模板定义的操作列表 Variables：变量 Templates：模板，即使用模板语法的文件 Handlers：处理器 ，当某条件满足时，触发执行的操作 Roles：角色 Control node ：安装了 Ansible 的主机 Managed nodes：Ansible 管理的网络设备或服务器 Ansible 架构 用户可以通过编写 Playbook 或使用 Ad-HOC 命令直接操控 Ansible，也可以通过公有、私有云或 CMDB(Configuration Management Database) 操控 Ansible Ansible 组成： Inventory - 被管理主机清单 APIs - 提供 Ansible 与云端的传输服务 Plugins Modules Ansible 可管理对象：主机和网络设备 配置文件 - ansible.cfg 配置文件中的几乎所有参数都可以在 Ad-Hoc 命令行和 Playbook 文件中重新赋值 配置文件加载顺序：ANSIBLE_CONFIG -> ./ansible.cfg -> ~/.ansible.cfg -> /etc/ansible/ansible.cfg ANSIBLE_CONFIG：首先，Ansible 命令会先检查环境变量 ANSIBLE_CONFIG，及这个环境变量将指向的配置文件 ./ansible.cfg：其次，将会检查当前目录下的 ansible.cfg 配置文件 ~/.ansible.cfg：再次，将会检查当前用户 home 目录下的~/.ansible.cfg配置文件 /etc/ansible/ansible.cfg：最后，将会检查在安装 Ansible 时自动生产的配置文件 常用配置项 [defaults] 配置项 说明 默认值 inventory ansible inventory文件路径 /etc/ansible/hosts library ansible模块文件路径 /usr/share/my_modules/ remote_tmp ansible远程主机脚本临时存放目录 ~/.ansible/tmp local_tmp ansible管理节点脚本临时存放目录 ~/.ansible/tmp forks ansible执行并发数 5 poll_interval ansible异步任务查询间隔 15 sudo_user ansible sudo用户 root ask_sudo_pass 运行ansible是否提示输入sudo密码 True ask_pass 运行ansible是否提示输入密码 True transport ansible远程传输模式 smart remote_port 远程主机SSH端口 22 module_lang ansible模块运行默认语言环境 C gathering facts信息收集开关定义 smart roles_path ansible role存放路径 /etc/ansible/roles timeout ansible SSH连接超时时间 10 remote_user ansible远程认证用户 root log_path ansible日志记录文件 /var/log/ansible.log module_name ansible默认执行模块 command executable ansible命令执行shell /bin/sh hash_behaviour ansible主机变量重复处理方式 replace private_role_vars 默认情况下，角色中的变量将在全局变量范围中可见。 为了防止这种情况，可以启用以下选项，只有tasks的任务和handlers得任务可以看到角色变量 yes vault_password_file 指定vault密码文件路径 无 ansible_managed 定义的一个Jinja2变量，可以插入到Ansible配置模版系统生成的文件中 Ansible managed display_skipped_hosts 开启显示跳过的主机 True error_on_undefined_vars 开启错误，或者没有定义的变量 False action_plugins ansible action插件路径 无 cache_plugins ansible cache插件路径 无 callback_plugins ansible callback插件路径 无 connection_plugins ansible connection插件路径 无 lookup_plugins ansible lookup插件路径 无 inventory_plugins ansible inventory插件路径 无 vars_plugins ansible vars插件路径 无 filter_plugins ansible filter插件路径 无 terminal_plugins ansible terminal插件路径 无 strategy_plugins ansible strategy插件路径 无 fact_caching 定义ansible facts缓存方式 memory fact_caching_connection 定义ansible facts缓存路径 无 [privilege_escalation] - 权限升级 配置项 说明 默认值 become 是否开启become模式 True become_method 定义become方式 sudo become_user 定义become方式 root become_ask_pass 是否定义become提示密码 False 主机清单 - Inventory 被管理主机 ( managed nodes ) 的清单，inventory 也被称做 hostfile inventory 是 .ini 格式编写的 主机清单默认路径为： /etc/ansible/hosts 静态主机清单： Ad-Hoc 命令。ansible -i 或 ansible-play -i 修改 ansible.cfg。设置 ansible.cfg 中 [default] 下的 inventory 为指定 hosts 文件路径 多个主机清单文件。先创建一个 inventory/ 文件夹，然后将 ansible.cfg 中的 inventory 设置为 inventory 文件夹路径 动态主机清单： 可以用自定义脚本从 CMDB 系统和 Zabbix 监控系统等拉取所有的主机信息，脚本可以使用任何语言编写，但是脚本使用参数有一定的规范并且对脚本执行的结果也有要求，应用时只需要把 ansible.cfg 文件中 inventory 设置为执行脚本路径即可 如果 inventory 文件被标记为可执行，则 Ansible 会假设这是一个动态的 inventory 脚本并且执行它而不是读取它的内容 - chmod +x 文件名 动态 inventory 脚本必须支持两个命令行参数： --host= - 列出主机的详细信息 --list - 列出群组 静态主机清单与 动态主机清单结合使用 将动态 inventory 和 静态 inventory 放在同一目录下 在 ansible.cfg 中将 hostfile 的值, 指向该目录即可；或在 Ansible 命令行使用 -i 参数指定目录 Inventory 行为参数 参数名 参数说明 默认值 ansible_ssh_host 登录主机的hostname或ip 主机名 ansible_ssh_port ssh 目的端口 22 ansible_ssh_user ssh 登录使用的用户名 root ansible_ssh_pass ssh 认证使用的密码 None ansible_sudo 主机的sudo用户 ansible_sudo_pass 主机的sudo密码 ansible_sudo_exe 主机的sudo路径 ansible_connection 连接主机的模式 smart ansible_ssh_private_key_file ssh 认证使用的私钥 None ansible_shell_type 主机shell类型 sh ansible_python_interpreter 主机python解释器路径 /usr/bin/python ansible_*_interpreter 类似python解释器的其他语言版 None ansible.cfg 设置 Inventory 行为参数 可以在 ansible.cfg 的 [defaults] 中改变一些行为参数的默认值: inventory 行为参数 ansible.cfg 选项 ansible_ssh_port remote_port ansible_ssh_user remote_user ansible_ssh_private_key_file private_key_file ansible_shell_type, shell 的名称 executable, shell 的绝对路径 变量 - Variable 变量定义 Ansible 变量支持布尔型、字符串、列表和字典 列表（键值）格式 : # playbooks/group_vars/production db_primary_host: prod.db.com db_primary_port: 5432 db_replica_host: rep.db.com db_name: mydb db_user: root db_pass: 123456 # 访问方法: {{ db_primary_host }} 字典格式 : # playbooks/group_vars/production db: user: root password: 123456 name: mydb primary: host: primary.db.com port: 5432 replica: host: replica.db.com port: 5432 # 访问方法 {{ db.primary.host }} 主机清单中定义变量 定义主机和群组相关变量 主机变量和群组变量 在主机清单文件中，只能将变量指定为布尔型和字符串 上面介绍的 inventory 行为参数其实就是具有特殊意义的 Ansible 变量，可以针对主机定义任意的变量名并指定相应的值 主机变量 192.168.13.12 color=green 192.168.13.14 color=red 群组变量 ｀[:vars]｀ [all:var] color=green 主机变量和群组变量文件 可以为每个主机和群组创建独立的变量文件，使用 YAML 格式编写，可以是列表、字典格式 主机变量文件：host_vars 目录中寻找；比如 www.xcq.com 主机变量文件就是｀host_vars/www.xcq.com` 群组变量文件：group_vars 目录中寻找；比如 web 群组变量文件就是 group_vars/web 这个两个目录和 playbook 和 inventory 文件平级 Ansible 命令行中定义变量 ansible-playbook [xxx.yml] -e [变量名]=[值] 这样设置的变量拥有最高优先级，可以覆盖已经定义的变量 $ ansible-playbook example.yml -e token=123 Playbook 中定义变量 vars --- - name: webserver configuration play hosts: webservers vars: http_port: 80 max_clients: 200 vars_files # playbook --- - name: webserver configuration play hosts: webservers vars: - nginx.yml # nginx.yml http_port: 80 max_clients: 200 facts 不同方法定义变量的优先级 ansible-playbook [xxx.yml] -e [变量名]=[值] 这个优先级排序中没提到的其他方法 主机清单（在 inventory 文件或 YAML 文件定义的主机和群组变量） Fact role 的 defaults/main.yml 文件 变量使用 Playbook 中使用变量 Template 中使用变量 模块 - Module ansible-doc -l - 列出所有模块 ansible-doc - 列出指定模块的详细说明及用法 Bash 中的常用命令 cd、yum、apt 等，在 Ansible 中就对应于模块 Bash 中命令可以跟参数；同样，Ansible 中 module 也可以跟参数 Ansible 自带的模块都是用 Python 编写的 Ansible 提供了一些常用功能的模块,用户也可以使用 Python 自定义模块 命令行中使用 module ansible -m -a '' Playbook 脚本中使用 module tasks 中的每一个 action 都是对应 module 的一次调用 : tasks: - name: ensure apache is at the latest version yum: pkg=httpd state=latest Ansible 管理被控端的两种方式 Ad-hoc command 和 playbook 可以看成是 Linux 下的命令和 shell 脚本之间的关系 Ansible 命令 - Ad-Hoc Commands 常用命令 ansible ansible-config ansible-console ansible-galaxy ansible-inventory ansible-playbook ansible-pull ansible-vault Ansible 命令执行过程 加 -vvv 可查看执行过程 1、加载配置文件，默认是 /etc/ansible/ansible.cfg 2、加载模块文件 3、生成对应的临时 py 文件，并将文件传输到被控主机的对应用户 ~/.ansible/tmp/ansible-tmp-xxx/xxx.py 4、被控主机 py 文件加执行权限（ +x ） 5、执行 py 文件并返回结果 6、删除本地和被控主机上的临时 py 文件，sleep 0 退出 剧本 - Playbooks Playbook 语法 - YAML 一个Playbook 包含一个或多个 Play 一个Play 必须包含 hosts 和 tasks，也可能有 variables、roles、handlers 等 每一个 task 只能包含一个模块 playbook 其实就是一个字典列表，也就是一个 playbook 就是一个 play 列表 --- - name: webserver configuration play hosts: webservers vars: http_port: 80 max_clients: 200 tasks: - name: ensure that apache is installed yum: name=httpd state=present - name: write the apache config file template: src=httpd.j2 dest=/etc/httpd.conf notify: - restart apache - name: ensure apache is running service: name=httpd state=started handlers: - name: restart apache service: name=httpd state=restarted 当时用 Playbook 进行虚拟化环境初始化时候，可以分为两个 Play 进行。第一个 Play 用于本机运行和创建主机，第二个 Play 用于配置主机 Handlers Roles Facts Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Ansible/Ansible常用模板.html":{"url":"Ansible/Ansible常用模板.html","title":"Ansible常用模板.md","keywords":"","body":" Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Docker/":{"url":"Docker/","title":"Docker","keywords":"","body":" Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Docker/Docker基础学习.html":{"url":"Docker/Docker基础学习.html","title":"Docker 基础学习笔记","keywords":"","body":"Docker 基础学习笔记 参考 && 扩展 Docker 最佳实践之多阶段构建 如何 10 步 Docker 化一个应用 10张图带你深入理解Docker容器和镜像 Dockerfile 最佳实践及示例 Docker容器安全性分析 目录 Docker 常用命令 Docker 基础架构 Docker 原理简述 Dockerfile - 构建自定义镜像 Docker 多阶段构建 Docker Compose - 编排操控容器 Docker Machine - 创建管理容器宿主机 Docker Swarm Docker 可视化管理 - Portainer Docker 常用命令 [Top] 命令手册查看 docker | man docker man docker | docker -h docker-machine docker-machine --help docker docker [options] COMMAND docker version - 显示 docker 版本信息 docker search 关键字 - 默认从 docker hub 搜索指定镜像 docker pull 镜像名:tag - 拉取镜像 docker images - 列出已安装的镜像 docker rmi [i-id] - 删除指定镜像 docker rm [c-id] - 删除指定容器 docker ps - 查看运行中的容器 -a 查看所有容器 docker start|stop|restart [c-id]|[c-name] - 通过容器 id 或容器名运行 / 关闭容器 docker run - 在隔离容器中运行命令 docker run --name [c-name] -d -p 3306:3306 mysql - docker 启动容器 --name - 自定义容器名 -p - 端口映射，-p 宿主机端口:容器端口 -d - 守护进程 docker run volume - 数据卷、数据卷容器 docker run -v|--volume[=[[HOST-DIR:]CONTAINER-DIR[:OPTIONS]]] ... - 添加一个数据卷 docker rm -v - 删除容器和容器绑定的数据卷 docker run --rm - 在关闭容器后也会自动删除容器和容器绑定的数据卷 docker run -it -v /dbdata --name dbdata ubuntu - 创建一个数据卷容器 dbdata ，并在其中创建一个数据卷挂载到 /dbdata docker run -it --volumes-from dbdata --name db1 ubuntu - 创建 db1 容器，并从 dbdata 容器挂载数据卷 docker logs container-name/[c-id] - 查看容器日志 Ctrl+P+Q - 退出容器交互式界面，但不关闭容器 docker attach - 将本地输入、输出、错误流附加到正在运行的容器 docker commit—从当前更改的容器状态创建新镜像 docker exec—在活动或正在运行的容器中运行命令 docker exec -it container command docker history [i-id] - 显示镜像历史记录 docker info - 显示系统范围信息 docker inspect [img|con] - 查找 docker 指定容器和镜像的系统级信息 docker login --username=xxx --email=xxx - 登录到本地注册表或 Docker Hub docker pull - 从本地注册表或 Docker Hub 中提取镜像或存储库 docker inspect --format=\"{\\{ \\.Volumes }}\" [container] - 查看宿主机上对应容器数据卷位置 docker network - 管理网络 docker network ls docker network connect docker network create docker network disconnect docker network inspect docker network prune docker network rm Docker 基础架构 [Top] 常说的 Docker 又称为 Docker Engine C/S 架构 - 客户端、服务器两大组件 客户端可以通过 socket 或 RESTful API 与服务器进行通信 Docker Engine = Docker 守护进程 + REST API （指定与守护进程交互的接口） + 命令行接口（CLI）（与守护进程通信，通过封装 REST API） 服务端 四大组件 1、dockerd $ ps -ef | grep dockerd root 3769 1 0 Dec02 ? 00:01:08 /usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock 2、docker-proxy dockerd 子进程，当容器启动并使用端口映射时才会执行，负责配置容器的端口映射规则 $ ps aux | grep docker-proxy root 24923 0.0 0.0 700716 4656 ? Sl 13:19 0:00 /usr/bin/docker-proxy -proto tcp -host-ip 0.0.0.0 -host-port 8011 -container-ip 172.17.0.2 -container-port 80 root 24937 0.0 0.0 626728 3824 ? Sl 13:19 0:00 /usr/bin/docker-proxy -proto tcp -host-ip 0.0.0.0 -host-port 2222 -container-ip 172.17.0.2 -container-port 2222 3、containerd dockerd 子进程 4、containerd-shim containerd 子进程 客户端 Docker 原理简述 [Top] 命名空间 - namespace 操作系统中，进程间共享的资源有内核、文件系统、网络、进程号 ( Process ID, PID )、用户号 ( User ID，UID )、进程间通信 ( InterProcess Communication，IPC )等。Linux 命名空间就是为了实现以上的相互隔离，保证了容器之间彼此互补影响 1、进程命名空间 2、IPC 命名空间 IPC - Interprocess Communication - 进程间交互 容器中的进程交互还是采用 Linux 常见 IPC，包括信号量、消息队列、共享内存等方式 3、网络命名空间 4、挂载命名空间 5、UTS 命名空间 UTS - UNIX Time-sharing System 6、用户命名空间 控制组 - Control Groups - CGroups Linux 内核特性，主要用来对共享资源进行隔离、限制、审计等 限制资源配额，比如某个容器只能使用 100M 内存 联合文件系统 - Union File System - UnionFS [参考] DOCKER基础技术：AUFS - 201508 UnionFS 是一种分层、轻量级并且高性能的文件系统，可以把不同物理位置的目录合并 mount 到同一个目录中 UnionFS 的一个最主要的应用是，把一张 CD/DVD 和一个硬盘目录给联合 mount 在一起，然后，你就可以对这个只读的 CD/DVD 上的文件进行修改 Docker 的镜像与容器就是分层存储，可用的存储引擎有 aufs、overlay 等，在 /var/lib/docker 下查看若有 aufs 目录，则使用的是 aufs 文件系统，若是 overlay 则是 overlay 文件系统分层镜像 只读层 - Read Layer - 镜像层 读写层 - Read Write Layer - 容器层 容器就是由存储 image 的只读层和读写层构成 容器需要修改只读层的文件，会先从只读层拷贝一份到读写层，再修改它，实际上修改的是副本。但修改后，只读层对应的文件就“隐藏” 起来了 容器的只读层 ( 镜像 ) 是共享的，也就是当同一镜像创建的多个容器时，其实只是创建了多个读写层，删除容器时，就只是删除容器的读写层。而且读写层也是在容器操作产生数据时才消耗资源，所以创建容器的成本很小！ 镜像作为只读层是共享的，而容器在镜像之上附加了一层可写层 docker engine 是共享宿主机操作系统的，容器又是共享 image 的（只读层共享），所以容器启动成本很小！ Dockerfile - 构建自定义镜像 [Top] Dockerfile 一般分为：基础镜像、镜像元信息、镜像操作指令和容器启动时执行指令 Dockerfile 行注释：# Dockerfile 换行符：\\ Dockerfile 的指令是顺序执行的 指令 说明 FROM [image]:[tag] 基础镜像，省略 tag 则是 latest LABLE [k1]=[v1] [k2]=[v2]... 为镜像添加元数据,多用于声明构建信息，作者、机构、组织等 ENV [k] [v] or ENV [k]=[v] 环境变量，${k} 引用变量 ARG [name]=[value] 构建运行时的变量 WORKDIR [path] 工作目录，其他指令都会在这个目录执行 ADD [src] [dest] 本地文件添加到镜像中 COPY [src] [dest] 同上，但不会自动解压tar和访问网络资源 RUN [command] 构建镜像时执行的命令，shell模式 RUN [\"\", \"\", \"\"] RUN exec执行格式，命令行模式 CMD [\"\", \"\", \"\"] 容器启动时才执行的命令 ENTRYPOINT 可以覆盖 CMD ，下面有详解 EXPOSE [port1] [port2]... 声明镜像内服务监听端口 VOLUME [\"\",\"\"...] 创建镜像内数据卷挂载点 USER [UID]\\ [Username]\\ [GID] 指定运行指令的用户 ONBUILD [INSTRUCTION] 当所构建的镜像被用做其他镜像的基础镜像时被触发 RUN 指令创建的中间镜像会被缓存，并会在下次构建中使用，如果不想使用缓存镜像，可在构建时指定 --no-cache 参数 EXPOSE 只是声明作用，并不会自动完成端口映射，启动容器时候还是需要添加 -P 或 -p VOLUME 和 EXPOSE 类似，不会自动挂载数据卷，需要启动容器时使用 -v ADD 和 COPY CMD 、 ENTRYPOINT 和 docker run ... [command] docker run ... [command] 是指执行 docker run 时跟在最后面的容器启动命令 CMD 、ENTRYPOINT 和 docker run ... [command] 都可以设定容器启动时执行的命令 ENTRYPOINT > docker run ... [command] > CMD 当存在 ENTRYPOINT 时，ENTRYPOINT 会将 docker run ... [command] 和 CMD 中指定的参数传入 当不存在 ENTRYPOINT ，但存在 docker run ... [command] ，会覆盖 CMD 当既不存在 ENTRYPOINT 也不存在 docker run ... [command]，则默认执行 CMD 通常在 Dockerfile 中使用 ENTRYPOINT指定容器启动时的命令同时用 CMD 指定默认命令参数，这样在 docker run 时既可以添加参数，也可以不添加使用 CMD 的默认参数 一个 Dockerfile 最多只能有一个 CMD 和 ENTRYPOINT，如果有多个，只有最后一个生效 CMD 的三种用法： CMD [\"executable\",\"param1\",\"param2\"] (exec form, this is the preferred form，命令行模式 ) CMD [\"param1\",\"param2\"] (as default parameters to ENTRYPOINT) CMD command param1 param2 (shell form，shell 模式 ) ENTRYPOINT 的两种用法： ENTRYPOINT [\"executable\", \"param1\", \"param2\"] (exec form, preferred) ENTRYPOINT command param1 param2 (shell form) Docker Compose - 编排操控容器 [Top] 安装 # Linux $ sudo curl -L https://github.com/docker/compose/releases/download/1.18.0/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose $ sudo chmod +x /usr/local/bin/docker-compose $ docker-compose --version 常用命令 docker-compose [-f ...] [options] [COMMAND] [ARGS...] docker-compose docker-compose -h 1、编写需要重复生成应用 ( app ) 的 Dockerfile 一般一个容器里一个应用，比如 mysql 数据库 2、定义用于编排多个应用以组成服务 ( service ) 的 docker-compose.yml 一个服务一般由多个应用组成，比如 web service 可以由 nignx 负载均衡器、tomcat web 服务器、mysql 数据库服务器等组成 3、docker-compose up docker-compose 本身没有构建镜像的功能，如果容器镜像是直接从 docker registry 拉取，则不需要 Dockerfile ；但如果需要基于基础镜像构建新的镜像，则需要使用 Dockerfile Docker Machine - 创建管理容器宿主机 [Top] 简介 docker-machine 可以在本地、云端服务器快速创建包含 Docker Engine 的虚拟机，但不能在虚拟机中创建（虚拟机中不能再创建虚拟机） docker-machine 可以启动、审查、停止和重新启动托管的宿主机、升级 Docker 客户端和守护程序、并配置 Docker 客户端与你的宿主机通信 也可以使用 Ansible 等 DevOps 工具实现对 Docker 环境的自动化管理 本质上 docker-machine 是一个虚拟机管理工具，它通过创建一个安装好docker 的虚拟机（支持 VirtualBox，DigitalOcean，EC2 等），并设置对应的环境变量（ DOCKER_HOST，DOCKER_MACHINE_NAME 等），使得本地的 docker 工具获得透明远程操作虚拟机的能力。从而使本身不支持 docker 的 Windows 和 Mac 系统能够直接使用 docker 命令 常用命令 docker-machine - 查看常用命令 docker-machine --help - 查看常用命令帮助 安装 https://github.com/docker/machine/releases/ $ curl -L https://github.com/docker/machine/releases/download/v0.16.2/docker-machine-`uname -s`-`uname -m` >/usr/local/bin/docker-machine $ chmod +x /usr/local/bin/docker-machine 常用命令 docker-machine [OPTIONS] COMMAND [arg...] docker-machine - 查看常用命令 docker-machine COMMAND -h - 查看具体某一个命令功能 解决首次运行慢 第一次运行 docker-machine create 会去 https://github.com/boot2docker/boot2docker/releases/ 下载一个最新的 57M 的 boot2docker.iso 镜像，国内下载会很慢 # 1. 下载 boot2docker.iso 最新版本到本地 - https://github.com/boot2docker/boot2docker/releases/ # 2. 移动 boot2docker.iso 到 ~/.docker/machine/cache/ $ mv boot2docker.iso ~/.docker/machine/cache/ # 3. 指定本地的 boot2docker.iso 路径，并跳过网络检查创建新的 docker machine ，命名为 default $ docker-machine create default -d virutalbox --virtualbox-boot2docker-url=/home/`whoami`/.docker/machine/cache/boot2docker.iso # --virtualbox-boot2docker-url 手动指定了boot2docker.iso 位置 配置当前shell docker server $ docker-machine env default export DOCKER_TLS_VERIFY=\"1\" export DOCKER_HOST=\"tcp://192.168.99.100:2376\" export DOCKER_CERT_PATH=\"/home/xcq/.docker/machine/machines/default\" export DOCKER_MACHINE_NAME=\"default\" # Run this command to configure your shell: # eval $(docker-machine env default) $ eval $(docker-machine env default) # 执行上面命令即可切换 docker server 为 default 主机中 docker server Docker Swarm [Top] Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Docker/Docker小知识.html":{"url":"Docker/Docker小知识.html","title":"Docker 小知识","keywords":"","body":"Docker 小知识 目录 连接 docker 容器 更换阿里云镜像 连接 docker 容器 [Top] Docker 原生命令连接容器 docker attach \\[container\\] docker exec -i -t \\[container\\] /bin/bash SSH 登录 使用 nsenter、nsinit 等第三方工具 更换阿里云镜像 https://cr.console.aliyun.com/ **CentOS** sudo mkdir -p /etc/docker sudo tee /etc/docker/daemon.json **Ubuntu** sudo mkdir -p /etc/docker sudo tee /etc/docker/daemon.json Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Docker/Docker必知单词.html":{"url":"Docker/Docker必知单词.html","title":"Docker 学习中的单词","keywords":"","body":"Docker 学习中的单词 isolated - 隔离的 compose - 编排 expose - 开放 reference - 参考 container orchestration - 容器编排 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Git/":{"url":"Git/","title":"Git","keywords":"","body":"Git 资源 GitHub 非官方的代码搜索引擎，支持正则搜索 Git Branching 在线可视化练习 Git 交互式终端 Git入门之形象化理解checkout 分布式世界 1. 版本控制之道 版本库 集中式（CVS、SVN） 分布式（git） 工作目录树 断面视图 工作拷贝 1、初始化（init）.git目录 2、克隆（clone） 代码修改与文件同步 跟踪项目、目录和文件 使用标签跟踪里程碑 使用分支来跟踪并行演进 合并 锁机制 2. 安装与设置 安装 Linux Mac：sudo port install git-core +svn +doc Windows Cygwin MSys 设置 git config 提 交 者：git config --global user.name \"Jamsonwoo\" 邮件地址：git config --global user.email \"Jamsonwoo@126.com\" 查看：git config --global --list 颜色：git config --global color.ui \"auto\" （auto/always/false)(注：MSys建议用always) GUI Tcl/TK：git gui(备注：工作目录树) gitk --all(备注：工作目录树) GitX (Mac) 内置帮助 git help git-doc 3. Hello Git 创建版本库：git int 修改代码 1、添加索引：git add index.html 2、提交记录：git commit -m \"add in hello git HTML\" （备注：提交留言至少应该体现出进行本次修改的原因。先用一句简单的话来概括该提交；然后用几句话全面解释。） 3、查看日志 git log （扩展：SHA-1哈希码） git log --pretty=oneline 视图状态：git status （备注：存放代码） 1、工作目录树 2、索引（暂存区） 3、版本库 分支 1、创建分支：git branch 新分支名称 父分支名称 git branch RB_1.0 master 2、提交修改：git commit -a（-a：提交全部修改过的文件） 3、切换分支：git checkout 分支名称 git checkout RB_1.0 处理发布 1、打标签：git tag 标签名称 打标签的点 git tag 1.0 RB_1.0 2、变基命令：git rebase 分支名称（合并到主分支） git rebase RB_1.0 3、删除分支：git branch -d 分支名称 git branch -d RB_1.0 4、创建归档：git archive --format=输出格式 --prefix=包内容 需要归档的标签名称 | gzip > 压缩结果重定向 git archive --format=tar --prefix=mysite-1.0/ 1.0 | gzip > mysite-1.0.tar.gz git archive --format=zip --prefix=mysite-1.0/ 1.0 > mysite-1.0.zip 克隆远程版本库：git clone 远程版本库的位置 存放该版本库的本地目录 git clone git://github.com/tswicegood/mysit.git mysite-remote Git用法 1. 添加与提交 添加文件到暂存区 1、启动交互命令提示符：git add -i 2、直接进入补丁模式：git add -p 提交修改 1、跟踪空目录：git不单独记录和跟踪目录，解决：在空目录里添加一个句点开头的空文件 2、git commit 的提交留言编辑器 -v 如果输入不带-m参数的git commit命令，Git将启动编辑器来编辑提交留言。为启动编辑器，Git会按照一下顺序查找编辑器的设置： 1、环境变量 GIT_EDITOR 的值。 2、Git 的设置 core.editor 的值。 3、环境变量 VISUAL 的值。 4、环境变量 EDITOR 的值。 5、如果上述值均为空，Git 会尝试启动 vi 编辑器。 提交三法 备注 a、提交暂存后的修改（先暂存后提交） 备注 b、提交工作目录树中的所有修改（把修改直接提交） 备注 c、提交工作目录树中执行的修改（把修改直接提交） 1、添加到暂存区 1、git add 文件 2、git commit -m \"留言\" 2、提交所有修改到版本库：git commit -m \"留言\" -a 3、指定提交文件（列表）：git commit -m \"留言\" 文件 Git别名: git commit 简写为：git ci git config --global alias.ci \"commit\" 查看修改内容 1、查看当前状态：git status Changes to be committed. 待提交变更 Changed but not updated. 未更新到索引的变更 2、查看文件改动：git diff a、git diff 无参 工作目录树 VS 暂存区 b、git diff --cached 暂存区 VS 版本库 b、git diff HEAD 工作目录树（暂存＋未暂存） VS 版本库 管理文件 1、文件重命名与移动：git mv 原文件名称 新文件名称 2、复制文件：无git cp命令，无需复制 3、忽略文件： a、版本级：文件加入.gitignore文件中，支持通配符* b、本地级：.git/info/exclude 2. 分支 什么叫分支 分支重命名：git branch -m 分支原名称 新名称 git branch -m master mymaster 显示本地版本库所有本地分支名称：git branch 创建分支：1、试验性更改 2、增加新功能 3、Bug修复 创建新分支 创建分支：git branch 新分支名称 git branch newBranchName 检出分支：git checkout 分支名称 git checkout newBranchName 创建并检出：git checkout -b 新分支名称 新分支源分支 git checkout -b newBranchName2 master 合并分支 合并(merge)方法 1、直接合并：把两条分支上的历史轨迹合并，交汇到一起 2、压合合并：一条分支上若干提交条目压合成一个提交条目，提交到另一条分支的末梢 3、拣选合并：拣选另一条分支上的某个提交条目的改动带到当前分支上 直接合并 git merge 分支名称 git checkout alternate git add about.html git commit -m \"add about page\" git checkout master git merge alternate 压合合并 git merge --squash 分支名称 git checkout -b contact master git add contact.html git commit -m \"add contact file\" git commit -m \"add contact file 2\" -a git checkout master git merge --squash contact git status git commit -m \"add contact page\" -m \"has primary and secondary email\" 拣选合并 git cherry-pick 提交名称 git checkout contact git commit -m \"add contact 3\" -a [contact 6dbaf82]...... git checkout master git cherry-pick 6dbaf82 / git cherry-pick -n 6dbaf82 冲突处理 git merge git checkout -b about master 编辑about.html git add about.html git commit -m \"add about.html \" git branch about2 about 编辑about.html git commit -m \"add about.html 1\" -a git checkout about2 编辑about.html git commit -m \"add about.html 2\" -a git checkout about git merge about2 git mergetool git commit 处理冲突软件（kdiff3）：git config --global merge.tool kdiff3 git mergetool 删除分支 git branch -d 分支名称 （成功合并到当前分支时） git branch -d about2 git branch -D 分支名称 （强制删除） 分支重命名 git branch -m 原分支名称 新分支名称 （不允许重名） git branch -m contact abc git branch -M 原分支名称 新分支名称 （强制覆盖） git branch -m master contact 3. 查询历史记录 查看日志 git log j 向下浏览；k 向上浏览；q 退出 提交名称、提交人、提交日期、提交留言 git log -p （显示版本之间的代码差异） git log -1（数字表示提交日志条数） git log 7b1558c （指定提交名称缩写[前7位]） 指定查找范围 git log --since/before=\"英文格式日期\" git log --since=\"5 hours\" （最近5小时内） git log --before=\"2012-8.20\" -1 （20120820之前的最后一条） git log 最老版本..最新版本 git log 18f822e..0bb3dfb 注：日志结果不包括最老，包括最新 git log 18f822e..HEAD / git log 18f822e.. git log 标签名称 git log --pretty=format:\"%h %s\" 1.0..HEAD git log --pretty=oneline 1.0..HEAD \\^：回溯一个版本 git log 18f822e^^ 注：1、windows系统下，^需要添加双引号 git log “18f822e^^”。 注：2、当遇到某个节点（通常是版本合并后的节点）有并列的多个父节点时，“^1”代表第一个父节点，“^2”代表第二个，以此类推。而“^”是“^1”的简写。 *~N：回溯N个版本 git log -1 HEAD^^^ / git log -1 HEAD^~2 / git log -1 HEAD~1^ / git log -1 HEAD~3 git log -1 HEAD~10..HEAD 查看版本间差异 git diff 版本名称（与当前工作目录树的差异） git diff 18f822e git diff --stat 1.0（数据统计） 查明提交者 git blame 文件名（特定代码块历史） git blame hello.html 注：1、格式：提交名称 初始文件名（提交人 提交时间 行号） 代码行 注：2、^脱字号开头表示版本库中第一个递交 git blame -L , 文件名（特定代码行历史） git blame -L 12,13 hello.html git blame -L 12,+2 hello.html git blame -L 12,-2 hello.html git blame -L 正则表达式 文件名（特定代码行历史） git blame -L \"//\",+2 hello.html git blame -L \"//\",-2 \"4333289e^\" -- index.html 跟踪内容 检查在同一个文件内移动或复制的代码行：git blame -M 文件名 查看文件之间的复制：git blame -C -C 文件名 查看显示代码的具体变动的历史记录：git log -C -C -1 -p 撤销修改 增补提交：git commit -C HEAD -a --amend --amend：增补提交 -C：复用指定提交的提交留言 -c：打开编辑器，在已有提交留言基础上修改 反转提交：git revert -n 提交名称 参数：--no-edit 复位：git reset 提交名称 提交名称默认值：HEAD 提交名称可用^和~修饰符 参数--soft：暂存所有因复位带来的差异，但不提交它 参数--hard：慎用，从版本库和工作目录树中同时删除提交 重新改写历史记录 重新排序提交：git rebase -i HEAD~3 将多个提交压合成一个提交：git rebase -i 0bb3dfb^ 将一个提交分解成多个提交：git rebase --continue 4. 与远程版本库协作 网络协议 SSH：用户名@服务器名/版本库路径 git@github.com/tswicegood/mysite-chp6.git git：协议://服务器名/版本库路径 （使用9418端口、匿名、无须加密、只读） git://github.com/tswicegood/mysite-chp6.git HTTP/HTTPS：需架设WebDAV服务 最快：git 安全：SSH 不受防火墙限制：HTTP(S) 克隆远程版本库：git clone git://github.com/tswicegood/mysite-chp6.git 版本库同步 取来（fetch）：git fetch 查看远程分支：git branch -r 取来合并：git pull 远程版本库名称 须要拖入的远程分支名 远程分支名前缀origin/表示远程版本库上的分支名称，origin是默认远程版本库别名 推入改动 推入默认版本库origin：git push 查看推入哪些提交：git push --dry-run 推入指定版本库：git push git push origin mybranch:master 添加新的远程版本库 一次拖入：git pull git://ourcompany.com/dev-erin.git 使用别名：git remote add 别名 路径 查看远程版本库详细信息：git remote show 删除别名：git remote rm 5. 管理本地版本库 使用标签标记里程碑 标签只读、标签名不能包含空格 查看已存在标签：git tag 新建标签：git tag 标签名 git tag 标签名 提示名称/分支名称 发布分支的处理 发布分支通常以RB_为前缀并包含版本号，RB_1.3 git branch RB_1.0.1 1.0 标签与分支的有效名称 不能以“/”结尾 不能以“.”开头 不能使用特殊字符：空格~^:?*[控制符删除键 不能出现“..” 记录和跟踪多个项目 多个项目共享一个版本库 多项目多版本库 使用Git子模块跟踪外部版本库 添加新子模块 查看该版本库的子模块：git submodule 添加新子模块：git submodule add 源版本库 存储路径 git submodule add git://github.com/tswicegood/hocus.git hocus 初始化子模块：git submodule init hocus 克隆含子模块的版本库：git submodule update 子模块名 cd work git clone magic new-magic cd new-magic git submodule git submodule init hocus git submodule update hocus 改变子模块的版本 使用子模块时要提防的错误 git add 确保结尾没有“\\” submodule update 先检查提交 添加新内容到本地自模块版本库，要检出正确分支 修改提交，确保改动被送回远程版本库 6. 高级功能 压缩版本库 git gc 整理版本库、优化Git内部存储历史记录 git gc 重新计算增量存储单元 到处版本库 创建版本快照:git archive 格式类型 指定版本 git archive --format= 转换格式 git archive --format=zip --prefix=mysite-release/ HEAD > mysite-release.zip git archive --format=tar --prefix=mysite-release/ HEAD | gzip > mysite-release.tar.gz 分支变基 git rebase --continue/--skip/--abort git rebase --onto master contacts search 重现隐藏的历史：git reflog 二分查找 git bisect start git bisect bad git bisect good 1.0 git bisect reset git bisect visualize git bisect log git bisect replay git bisect run 1 Downloading1 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Git/git-cheatsheet.html":{"url":"Git/git-cheatsheet.html","title":"Git 速查表","keywords":"","body":"Git 速查表 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Git/git学习.html":{"url":"Git/git学习.html","title":"Git 学习笔记","keywords":"","body":"Git 学习笔记 【参考】 常用 Git 命令清单 Git 简明指南 图解Git Github 帮助 Git 官方文档 Git远程操作详解 - 阮一峰 目录 常用命令 Github加速 查看变更内容 - git diff 回退 建立、删除、修改跟踪关系 常用命令 Workspace：工作区 Index / Stage：暂存区 Repository：仓库区（或本地仓库） Remote：远程仓库 工作区 -> git add - > 暂存区 -> git commit -> 本地仓库 -> git push -> 远程仓库 ，后续 git commit就是往 master 上提交 git init - 初始化 git 仓库，git init 时默认创建了一个 master 分支 git init [RepName] - 新建一个目录 RepName，并将其初始化为 git 本地仓库 git ls-files - 查看暂存区文件 git rm [file] - 同时删除工作区和暂存区 file git mv [file1] [file2] - 在工作区和暂存区同时重命名 file1 为 file2 git commit -m - 提交 ( commit ) 暂存区到本地仓库，message 是本次提交说明 git commit -a -m - 会自动暂存 modified、deleted，但不会暂存 untracked 文件，然后 commit git config git config - 修改 ./.git/config 配置文件，当前仓库配置，相同配置会覆盖用户和系统配置 ./.git/config - 在 git 仓库目录下执行该命令，同 git config git config --global - 修改 ~/.gitconfig 配置文件，当前用户配置，会覆盖系统配置 git config --system - 修改 /etc/gitconfig 配置文件，系统配置 git config -l[--list] - 显示 system、global、local 配置 git config --local --list - 显示当前仓库配置 git config --global --list - 显示用户配置 git config --system --list - 显示系统配置 git config [--global] user.name \"[name]\" - 设置提交代码时的用户名 git config [--global] user.email \"[email]\" - 设置提交代码时的用户邮箱 git config [--global] http.https://github.com.proxy socks5://127.0.0.1:1080 - 配置 git github socks5 代理，执行 git 命令时只对 github 代理 git config [--global] https.https://github.com.proxy socks5://127.0.0.1:1080 - 配置 git github socks5 代理 git config [--global] --unset http.https://github.com.proxy - 取消 github git 代理 git add git add - 工作区把 file 添加到暂存区 git add -u - 可以暂存 ( stage ) 工作区 modified、deleted 文件，但不能暂存 untracked 文件 git add --ignore-removal . - 可以暂存工作区 modified、untracked 文件，但不能暂存 deleted 文件 git add . - git 2.0+ 版本中，和 git add -A 功能一样，可以暂存工作区 modified、deleted、untracked 文件 git add -A - 暂存工作区所有文件变化 ( modified、deleted、untracked ) git status git status - 查看工作区和暂存区文件修改状态 git status -s - git status 输出精简版 git log git log - 查看本地仓库 commit 记录 git log --pretty=oneline - 查看本地仓库 commit 记录及对应 commit ID，以单行形式展示 git reflog - 可以查看所有分支对当前仓库的操作记录 ( commit / reset / checkout / merge / etc ) 以及操作的 commit ID ( 方便回退到某个操作时版本状态 ) git reset git reset HEAD - 暂存区撤销 file 修改，把暂存区内关于 file 的修改回退到工作区 git reset --hard HEAD^ - 本地仓库回退到上一次 commit 版本 git reset --hard HEAD~5 - 本地仓库回退到 5 次 commit 前版本 git reset --hard - 本地仓库跳到 commit_ID 对应的 commit 版本 git diff git diff file - 查看 file 工作区和暂存区里的区别 git diff HEAD - 查看工作区与当前分支最新commit之间的差异 git diff HEAD -- file - 查看文件 file 工作区和当前本地仓库之间的差异 git diff --cached - 查看已暂存未提交的内容，及查看暂存区和本地仓库里的区别 git checkout git checkout - 切换到其他分支，并更新工作区 git checkout -b - 创建并切换到 newbranch 分支 git checkout - - 切换到上一分支 git checkout -- - 工作区撤销 file 修改，工作区的 file 回退到最近一次 git commit 或 git add 时的状态 git merge - 合并 branch 分支到当前分支 git cherry-pick - 选择一个 commit，合并到当前分支 git switch git switch -c - 切换到 branch 分支，最新版切换分支方式 git switch master - 切换到本地仓库的 master 主分支 git branch 显示所有分支和用 * 标记当前所在分支 git branch -r - 列出所有远程分支 git branch -a - 列出所有本地分支和远程分支 git branch - 新建一个分支，但依旧停在当前分支 git branch -d - 删除分支 ( 删除不了当前分支，需要先切换到其他分支; 也删除不了未合并的分支 ) git branch -D - 强制删除分支 git branch -vv - 查看本地分支和远程分支的跟踪关系 git branch --set-upstream-to=/ - 为本地分支创建跟踪分支，跟踪远程主机的某个分支 git clone git clone [-o ] [] git clone - 从远程主机克隆一个版本库到本地，且默认生成的本地仓库名就是远程版本库名 - 指定克隆到本地的版本库名字， -o - 克隆并指定远程主机名，默认是 origin git remote 列出所有远程主机名 git remote -v - 参看远程主机的网址 git remote show - 查看远程主机详细信息 git remote add - 添加远程主机 git remote add origin git@github.com:username/reponame.git - 本地 git 仓库关联 github 上的仓库 git remote rm - 删除远程主机 git remote rename - 远程主机重命名 git fetch git fetch - 将某个远程主机的更新，全部取回本地 git fetch - 取回远程主机特定分支的更新，默认取回所有分支的更新 git fetch origin master:temp - 从远程的 origin 仓库的 master 分支下载到本地，并新建一个 temp 分支 git pull 取回远程主机某个分支的更新，再与本地的指定分支合并 git pull : git pull - 远程主机指定分支与本地当前分支合并 git pull - 当前分支设置了跟踪分支 git pull - 当前分支只设置了一个跟踪分支 git pull -p - 在本地删除远程已经删除的分支 git pull --rebase - 合并采用 rebase 模式 git push 将本地分支的更新，推送到远程主机 git push : git push - 省略远程分支名，则表示将本地分支推送与之存在\"追踪关系\"的远程分支（通常两者同名），如果该远程分支不存在，则会被新建 git push : - 省略本地分支名，则表示删除指定的远程分支，因为这等同于推送一个空的本地分支到远程分支 git push - 当前分支与远程分支之间存在追踪关系 git push - 当前分支只有一个追踪分支，那么主机名都可以省略 git push --delete - 删除远程分支，效果同上 git push -u : - 当前分支与多个主机存在追踪关系，则可以使用 -u 选项指定一个默认主机，之后就可以直接用git push git push -u origin master - 第一次推送 master 分支，-u 创建跟踪关系，指定当前分支的 upstream git push origin master - 后续本地推送到远程仓库 `` - Github 加速 GitHub加速最佳实践 Git 目前支持的两种协议 ssh:// 和 https://，其代理配置各不相同：http.proxy用于 https:// 协议，ssh:// 协议的代理需要配置 ssh 的 ProxyCommand 参数 针对HTTPS 协议(https://)配置代理 一、使用 git config # 对所有git服务器设置代理 $ git config --global http.proxy http://127.0.0.1: # 只对github.com设置代理 $ git config --global http.https://github.com.proxy http://127.0.0.1: # 代理需要帐号密码 $ git config --global http.proxy http://:@: #proxyuser= 代理的登录用户名 #proxypwd= 代理的登录密码 #proxy.server.com:1087 = 代理的ip（或域名）以及端口 二、编辑 ~/.gitconfig 文件 # 对所有git服务器设置代理 [http] proxy = http://127.0.0.1:8123 [http] proxy = http://127.0.0.1:8123 # 只对github.com设置代理 [https \"https://github.com\"] proxy = socks5://127.0.0.1:8123 [http \"https://github.com\"] proxy = socks5://127.0.0.1:8123 针对SSH 协议(ssh://)配置代理 查看变更内容 - git diff git diff file - 查看 file 工作区和暂存区里的区别 git diff HEAD -- file - 查看 file 工作区和本地仓库里的区别 git diff --cached - 查看已暂存未提交的内容，及查看暂存区和本地仓库里的区别 git diff t diff --git a/t b/t index f007ede..d09b7e1 100644 --- a/t +++ b/t @@ -1,4 +1,4 @@ 吃了吗 吃了 你吃了吗 -没吃 +我也吃了 diff --git a/t b/t - 对比两个文件，其中 a 改动前，b 是改动后 iindex f007ede..d09b7e1 10064 - 两个版本的 git 哈希值，index 区域（ add 之后）的 f007ede 对象和工作区域的 d09b7e1 对象， 100 表示普通文件，644 表示控制权限 --- a/t - --- 代表源文件 +++ b/t - +++ 代表目标文件 @@ -1,2 +1,5 @ - @@ 表示文件变动描述合并显示的开始和结束，一般在变动前后多显示3行，其中-+表示变动前后，逗号前是起始行位置，逗号后为从起始行往后几行。合起来就是变动前后都是从第4行开始，变动前文件往后数8行对应变动后文件往后数9行 变动内容 ——+表示增加了这一行，-表示删除了这一行，没符号表示此行没有变动。 当git status告诉你有文件被修改过，用git diff可以查看修改内容 回退 HEAD 指向当前版本，HEAD^ 上一个版本，HEAD~100 之前 100 个的版本 版本回退 - git reset # 使用 git log --pretty=oneline 或 git log 可以查看 commit 日志及 commit ID $ git log --pretty=oneline 14ab3268f5bda2287d04cd713e9df978b65bf381 create README b61f11035eff9ca39acd7a8d98356b3060c5997d delete again README.md; 0e41957b5b5be1be7cabcffd09de3bf8ae297e60 modify README.md 6ed84a9599334f9e9632479860b2dfd038f6e2aa create test 9d0e11c192851639ccfba51436af852e6fd5a029 create README.md # 使用 HEAD 回滚一次 $ git reset --hard HEAD^ $ git log --pretty=oneline b61f11035eff9ca39acd7a8d98356b3060c5997d delete again README.md; 0e41957b5b5be1be7cabcffd09de3bf8ae297e60 modify README.md 6ed84a9599334f9e9632479860b2dfd038f6e2aa create test 9d0e11c192851639ccfba51436af852e6fd5a029 create README.md # 使用 HEAD 回滚两次 git reset --hard HEAD~2 重置后撤出暂存区的变更： D README.md $ git log --pretty=oneline 6ed84a9599334f9e9632479860b2dfd038f6e2aa create test 9d0e11c192851639ccfba51436af852e6fd5a029 create README.md # 使用 commid ID 回到“未来”版本 $ git reset --hard 14ab $ git log --pretty=oneline 14ab3268f5bda2287d04cd713e9df978b65bf381 create README b61f11035eff9ca39acd7a8d98356b3060c5997d delete again README.md; 0e41957b5b5be1be7cabcffd09de3bf8ae297e60 modify README.md 6ed84a9599334f9e9632479860b2dfd038f6e2aa create test 9d0e11c192851639ccfba51436af852e6fd5a029 create README.md # 使用 git reflog 查看各个版本的 commit ID 前 7 位，以供返回对应版本（ git reset commitID ） $ git reflog 14ab326 HEAD@{0}: reset: moving to 14ab 6ed84a9 HEAD@{1}: reset: moving to HEAD~2 b61f110 HEAD@{2}: reset: moving to HEAD^ 14ab326 HEAD@{3}: reset: moving to 14ab3 0e41957 HEAD@{4}: reset: moving to HEAD^ b61f110 HEAD@{5}: reset: moving to HEAD^ 14ab326 HEAD@{6}: commit: create README b61f110 HEAD@{7}: commit: delete again README.md; 0e41957 HEAD@{8}: commit: modify README.md 6ed84a9 HEAD@{9}: commit: create test 9d0e11c HEAD@{10}: commit (initial): create README.md 修改回退- git checkout git reset 工作区 file 修改的回退 git checkout -- 工作区 file 修改撤销，工作区的 file 回退到最近一次 git commit 或 git add 时的状态 上次 commit -> 修改 file -> git checkout -- file -> file 回退到上次 commit 上次 commit -> 修改 file -> git add file -> git checkout -- file -> file 回退到上一次 add 后状态 暂存区 file 修改的回退 git reset HEAD 暂存区 file 修改撤销，把暂存区内关于 file 的修改全部回退到工作区 删除回退 git rm file - 同时删除工作区和暂存区 file - 还原：git reset HEAD file + git checkout file rm file - 只删除工作区里的 file - 还原：git checkout file 重命名回退 mv file file1 - 只在工作区里重命名 file 为 file1 - 还原：git checkout file + rm file1 -rf git mv file file1 - 同时重命名工作区和暂存区 file 为 file1 - 还原：git reset HEAD file + git checkout file + rm file1 -rf note: 重命名 file file1 = 删除 file + 新建 file1（ 和 file 内容相同 ） 建立、删除、修改跟踪关系 1、git clone时自动创建master分支追踪origin/master` 分支 $ git clone git@github.com:Xiechengqi/test.git testbook 正克隆到 'testbook'... . . . $ cd testbook $ git branch -vv * master 77418ad [origin/master] Update index.html 案例实操 一、file 在工作区修改并 add 一次，之后又在工作区修改了，此时可以回退到上一次 add 状态，也可以回退到上一次 commit 状态 工作区内操作文件 file 只要没 commit 都能回退到上次 commit 时的版本 1、没有 git add 时，用 git checkout -- file 2、已经 git add 时，先 git reset HEAD 回退到 1，再按 1 操作 $ git status -s $ cat test 你好 你也好 他也好 $ echo 'hello' > test $ git add test $ echo 'hello world!' > test $ git status -s MM test # 此时工作区、暂存区和仓库内的 file 都不相同 # 工作区和暂存区比较 $ git diff test diff --git a/test b/test index ce01362..a042389 100644 --- a/test +++ b/test @@ -1 +1 @@ -hello +hello world! # 工作区和仓库比较 git diff HEAD -- test diff --git a/test b/test index f9132cb..a042389 100644 --- a/test +++ b/test @@ -1,3 +1 @@ -你好 -你也好 -他也好 +hello world! ### 回退还原 # 先回退暂存区与否无所谓，先退回暂存区比先退回工作区少一步操作而已 git reset HEAD test # 回退暂存区 重置后取消暂存的变更： M test $ git status -s M test $ git checkout test # 回退工作区 $ git status -s $ cat test 你好 你也好 他也好 二、更新本地仓库至最新改动 git pull = git fetch + git merge 方法一、git pull # 在本地仓库执行 git pull，便自动更新你的本地仓库至最新改动 $ git pull 方法二、git fetch + git merge 如果远程仓库分支和本地仓库当前分支都修改了同一文件的同一位置（都修改了同一文件是可以的），这就会导致 merge 失败，需要手动修改远程或本地其一 $ git fetch origin master:temp 来自 github.com:Xiechengqi/wiki * [新分支] master -> temp $ git diff temp # 查看当前分支 master 和 temp 分支的不同 diff --git a/index.md b/index.md deleted file mode 100644 index c0cd5ef..0000000 --- a/index.md +++ /dev/null @@ -1,3 +0,0 @@ -# 目录 - -* [hello world](./hello.md) diff --git a/index.rst b/index.rst new file mode 100644 index 0000000..42cee67 --- /dev/null +++ b/index.rst @@ -0,0 +1,20 @@ $ git merge temp # 合并 temp 到当前分支 master 更新 7df7451..36ce930 Fast-forward index.md | 3 +++ index.rst | 20 -------------------- 2 files changed, 3 insertions(+), 20 deletions(-) create mode 100644 index.md delete mode 100644 index.rst $ git brach -d temp # 删除 temp 分支 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Git/git小技巧.html":{"url":"Git/git小技巧.html","title":"Git 小技巧","keywords":"","body":"Git的奇技淫巧 Git常用命令集合，github项目 Git 是一个 “分布式版本管理工具”，简单的理解版本管理工具：大家在写东西的时候都用过 “回撤” 这个功能，但是回撤只能回撤几步，假如想要找回我三天之前的修改，光用 “回撤” 是找不回来的。而 “版本管理工具” 能记录每次的修改，只要提交到版本仓库，你就可以找到之前任何时刻的状态（文本状态）。 下面的内容就是列举了常用的 Git 命令和一些小技巧，可以通过 \"页面内查找\" 的方式进行快速查询：Ctrl/Command+f。 开卷必读 如果之前未使用过 Git，可以学习 Git 小白教程入门 一定要先测试命令的效果后，再用于工作环境中，以防造成不能弥补的后果！到时候别拿着砍刀来找我 所有的命令都在git version 2.7.4 (Apple Git-66)下测试通过 统一概念： 工作区：改动（增删文件和内容） 暂存区：输入命令：git add 改动的文件名，此次改动就放到了 ‘暂存区’ 本地仓库(简称：本地)：输入命令：git commit 此次修改的描述，此次改动就放到了 ’本地仓库’，每个 commit，我叫它为一个 ‘版本’。 远程仓库(简称：远程)：输入命令：git push 远程仓库，此次改动就放到了 ‘远程仓库’（GitHub 等) commit-id：输出命令：git log，最上面那行 commit xxxxxx，后面的字符串就是 commit-id 目录 展示帮助信息 回到远程仓库的状态 重设第一个commit 查看冲突文件列表 展示工作区和暂存区的不同 展示暂存区和最近版本的不同 展示暂存区、工作区和最近版本的不同 快速切换到上一个分支 删除已经合并到 master 的分支 展示本地分支关联远程仓库的情况 关联远程分支 列出所有远程分支 列出本地和远程分支 查看远程分支和本地分支的对应关系 远程删除了分支本地也想删除 创建并切换到本地分支 从远程分支中创建并切换到本地分支 删除本地分支 删除远程分支 重命名本地分支 查看标签 查看标签详细信息 本地创建标签 推送标签到远程仓库 删除本地标签 删除远程标签 切回到某个标签 放弃工作区的修改 恢复删除的文件 以新增一个 commit 的方式还原某一个 commit 的修改 回到某个 commit 的状态，并删除后面的 commit 修改上一个 commit 的描述 查看 commit 历史 显示本地更新过 HEAD 的 git 命令记录 修改作者名 修改远程仓库的 url 增加远程仓库 列出所有远程仓库 查看两个星期内的改动 把 A 分支的某一个 commit，放到 B 分支上 给 git 命令起别名 存储当前的修改，但不用提交 commit 保存当前状态，包括 untracked 的文件 展示所有 stashes 回到某个 stash 的状态 回到最后一个 stash 的状态，并删除这个 stash 删除所有的 stash 从 stash 中拿出某个文件的修改 展示所有 tracked 的文件 展示所有 untracked 的文件 展示所有忽略的文件 强制删除 untracked 的文件 强制删除 untracked 的目录 展示简化的 commit 历史 查看某段代码是谁写的 把某一个分支到导出成一个文件 从包中导入分支 执行 rebase 之前自动 stash 从远程仓库根据 ID，拉下某一状态，到本地分支 详细展示一行中的修改 清除 .gitignore 文件中记录的文件 展示所有 alias 和 configs 展示忽略的文件 commit 历史中显示 Branch1 有的，但是 Branch2 没有 commit 在 commit log 中显示 GPG 签名 删除全局设置 新建并切换到新分支上，同时这个分支没有任何 commit 展示任意分支某一文件的内容 clone 下来指定的单一分支 clone 最新一次提交 忽略某个文件的改动 忽略文件的权限变化 以最后提交的顺序列出所有 Git 分支 在 commit log 中查找相关内容 把暂存区的指定 file 放到工作区中 强制推送 git 配置 http 和 socks 代理 git 配置 ssh 代理 一图详解 优雅的提交Commit信息 展示帮助信息 git help -g The command output as below: The common Git guides are: attributes Defining attributes per path cli Git command-line interface and conventions core-tutorial A Git core tutorial for developers cvs-migration Git for CVS users diffcore Tweaking diff output everyday A useful minimum set of commands for Everyday Git glossary A Git Glossary hooks Hooks used by Git ignore Specifies intentionally untracked files to ignore modules Defining submodule properties namespaces Git namespaces repository-layout Git Repository Layout revisions Specifying revisions and ranges for Git tutorial A tutorial introduction to Git tutorial-2 A tutorial introduction to Git: part two workflows An overview of recommended workflows with Git 'git help -a' and 'git help -g' list available subcommands and some concept guides. See 'git help ' or 'git help ' to read about a specific subcommand or concept. 回到远程仓库的状态 抛弃本地所有的修改，回到远程仓库的状态。 git fetch --all && git reset --hard origin/master 重设第一个 commit 也就是把所有的改动都重新放回工作区，并清空所有的 commit，这样就可以重新提交第一个 commit 了 git update-ref -d HEAD 查看冲突文件列表 展示工作区的冲突文件列表 git diff --name-only --diff-filter=U 展示工作区和暂存区的不同 输出工作区和暂存区的 different (不同)。 git diff 还可以展示本地仓库中任意两个 commit 之间的文件变动： git diff 展示暂存区和最近版本的不同 输出暂存区和本地最近的版本 (commit) 的 different (不同)。 git diff --cached 展示暂存区、工作区和最近版本的不同 输出工作区、暂存区 和本地最近的版本 (commit) 的 different (不同)。 git diff HEAD 快速切换到上一个分支 git checkout - 删除已经合并到 master 的分支 git branch --merged master | grep -v '^\\*\\| master' | xargs -n 1 git branch -d 展示本地分支关联远程仓库的情况 git branch -vv 关联远程分支 关联之后，git branch -vv 就可以展示关联的远程分支名了，同时推送到远程仓库直接：git push，不需要指定远程仓库了。 git branch -u origin/mybranch 或者在 push 时加上 -u 参数 git push origin/mybranch -u 列出所有远程分支 -r 参数相当于：remote git branch -r 列出本地和远程分支 -a 参数相当于：all git branch -a 查看远程分支和本地分支的对应关系 git remote show origin 远程删除了分支本地也想删除 git remote prune origin 创建并切换到本地分支 git checkout -b 从远程分支中创建并切换到本地分支 git checkout -b origin/ 删除本地分支 git branch -d 删除远程分支 git push origin --delete 或者 git push origin : 重命名本地分支 git branch -m 查看标签 git tag 展示当前分支的最近的 tag git describe --tags --abbrev=0 查看标签详细信息 git tag -ln 本地创建标签 git tag 默认 tag 是打在最近的一次 commit 上，如果需要指定 commit 打 tag： $ git tag -a -m \"v1.0 发布(描述)\" 推送标签到远程仓库 首先要保证本地创建好了标签才可以推送标签到远程仓库： git push origin 一次性推送所有标签，同步到远程仓库： git push origin --tags 删除本地标签 git tag -d 删除远程标签 git push origin --delete tag 切回到某个标签 一般上线之前都会打 tag，就是为了防止上线后出现问题，方便快速回退到上一版本。下面的命令是回到某一标签下的状态： git checkout -b branch_name tag_name 放弃工作区的修改 git checkout 放弃所有修改： git checkout . 恢复删除的文件 git rev-list -n 1 HEAD -- #得到 deleting_commit git checkout ^ -- #回到删除文件 deleting_commit 之前的状态 以新增一个 commit 的方式还原某一个 commit 的修改 git revert 回到某个 commit 的状态，并删除后面的 commit 和 revert 的区别：reset 命令会抹去某个 commit id 之后的所有 commit git reset #默认就是-mixed参数。 git reset -- mixed HEAD^ #回退至上个版本，它将重置HEAD到另外一个commit,并且重置暂存区以便和HEAD相匹配，但是也到此为止。工作区不会被更改。 git reset -- soft HEAD~3 #回退至三个版本之前，只回退了commit的信息，暂存区和工作区与回退之前保持一致。如果还要提交，直接commit即可 git reset -- hard #彻底回退到指定commit-id的状态，暂存区和工作区也会变为指定commit-id版本的内容 修改上一个 commit 的描述 如果暂存区有改动，同时也会将暂存区的改动提交到上一个 commit git commit --amend 查看 commit 历史 git log 查看某段代码是谁写的 blame 的意思为‘责怪’，你懂的。 git blame 显示本地更新过 HEAD 的 git 命令记录 每次更新了 HEAD 的 git 命令比如 commint、amend、cherry-pick、reset、revert 等都会被记录下来（不限分支），就像 shell 的 history 一样。 这样你可以 reset 到任何一次更新了 HEAD 的操作之后，而不仅仅是回到当前分支下的某个 commit 之后的状态。 git reflog 修改作者名 git commit --amend --author='Author Name ' 修改远程仓库的 url git remote set-url origin 增加远程仓库 git remote add origin 列出所有远程仓库 git remote 查看两个星期内的改动 git whatchanged --since='2 weeks ago' 把 A 分支的某一个 commit，放到 B 分支上 这个过程需要 cherry-pick 命令，参考 git checkout && git cherry-pick 给 git 命令起别名 简化命令 git config --global alias. 比如：git status 改成 git st，这样可以简化命令 git config --global alias.st status 存储当前的修改，但不用提交 commit 详解可以参考廖雪峰老师的 git 教程 git stash 保存当前状态，包括 untracked 的文件 untracked 文件：新建的文件 git stash -u 展示所有 stashes git stash list 回到某个 stash 的状态 git stash apply 回到最后一个 stash 的状态，并删除这个 stash git stash pop 删除所有的 stash git stash clear 从 stash 中拿出某个文件的修改 git checkout -- 展示所有 tracked 的文件 git ls-files -t 展示所有 untracked 的文件 git ls-files --others 展示所有忽略的文件 git ls-files --others -i --exclude-standard 强制删除 untracked 的文件 可以用来删除新建的文件。如果不指定文件文件名，则清空所有工作的 untracked 文件。clean 命令，注意两点： clean 后，删除的文件无法找回 不会影响 tracked 的文件的改动，只会删除 untracked 的文件 git clean -f 强制删除 untracked 的目录 可以用来删除新建的目录，注意:这个命令也可以用来删除 untracked 的文件。详情见上一条 git clean -df 展示简化的 commit 历史 git log --pretty=oneline --graph --decorate --all 把某一个分支到导出成一个文件 git bundle create 从包中导入分支 新建一个分支，分支内容就是上面 git bundle create 命令导出的内容 git clone repo.bundle -b 执行 rebase 之前自动 stash git rebase --autostash 从远程仓库根据 ID，拉下某一状态，到本地分支 git fetch origin pull//head: 详细展示一行中的修改 git diff --word-diff 清除 gitignore 文件中记录的文件 git clean -X -f 展示所有 alias 和 configs 注意： config 分为：当前目录（local）和全局（golbal）的 config，默认为当前目录的 config git config --local --list (当前目录) git config --global --list (全局) 展示忽略的文件 git status --ignored commit 历史中显示 Branch1 有的，但是 Branch2 没有 commit git log Branch1 ^Branch2 在 commit log 中显示 GPG 签名 git log --show-signature 删除全局设置 git config --global --unset 新建并切换到新分支上，同时这个分支没有任何 commit 相当于保存修改，但是重写 commit 历史 git checkout --orphan 展示任意分支某一文件的内容 git show : clone 下来指定的单一分支 git clone -b --single-branch https://github.com/user/repo.git clone 最新一次提交 只会 clone 最近一次提交，将减少 clone 时间 git clone --depth=1 https://github.com/user/repo.git 忽略某个文件的改动 关闭 track 指定文件的改动，也就是 Git 将不会在记录这个文件的改动 git update-index --assume-unchanged path/to/file 恢复 track 指定文件的改动 git update-index --no-assume-unchanged path/to/file 忽略文件的权限变化 不再将文件的权限变化视作改动 git config core.fileMode false 以最后提交的顺序列出所有 Git 分支 最新的放在最上面 git for-each-ref --sort=-committerdate --format='%(refname:short)' refs/heads/ 在 commit log 中查找相关内容 通过 grep 查找，given-text：所需要查找的字段 git log --all --grep='' 把暂存区的指定 file 放到工作区中 不添加参数，默认是 -mixed git reset 强制推送 git push -f git 配置 http 和 socks 代理 git config --global https.proxy 'http://127.0.0.1:8001' # 适用于 privoxy 将 socks 协议转为 http 协议的 http 端口 git config --global http.proxy 'http://127.0.0.1:8001' git config --global socks.proxy \"127.0.0.1:1080\" git 配置 ssh 代理 $ cat ~/.ssh/config Host gitlab.com ProxyCommand nc -X 5 -x 127.0.0.1:1080 %h %p # 直接使用 shadowsocks 提供的 socks5 代理端口 Host github.com ProxyCommand nc -X 5 -x 127.0.0.1:1080 %h %p 一图详解 优雅的提交Commit信息 使用Angular团队提交规范 主要有以下组成 标题行: 必填, 描述主要修改类型和内容 主题内容: 描述为什么修改, 做了什么样的修改, 以及开发的思路等等 页脚注释: 放 Breaking Changes 或 Closed Issues 常用的修改项 type: commit 的类型 feat: 新特性 fix: 修改问题 refactor: 代码重构 docs: 文档修改 style: 代码格式修改, 注意不是 css 修改 test: 测试用例修改 chore: 其他修改, 比如构建流程, 依赖管理. scope: commit 影响的范围, 比如: route, component, utils, build... subject: commit 的概述 body: commit 具体修改内容, 可以分为多行 footer: 一些备注, 通常是 BREAKING CHANGE 或修复的 bug 的链接. 使用Commitizen代替 git commit 可以使用cz-cli工具代替 git commit 全局安装 npm install -g commitizen cz-conventional-changelog echo '{ \"path\": \"cz-conventional-changelog\" }' > ~/.czrc 全局安装后使用 git cz 代替 git commit就可以了,如下图 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Git/Git入门之形象化理解checkout.html":{"url":"Git/Git入门之形象化理解checkout.html","title":"Git入门之形象化理解checkout","keywords":"","body":"Git入门之形象化理解checkout git checkout 困扰了我很久，今天看到这篇文章可算轻松的明白了 git checkout实际上其实是个平行宇宙时光机，可以带你穿梭到任意一个平行宇宙中，还可以带你穿梭回过去的任意一个时间点。在过去的那个点上，你可以各种观察、修改、删除等，而不对原本时间点产生任何影响。 每一个branch分支，都是一个平行的宇宙，你可以用checkout在两个宇宙之间穿梭。 每一个commit提交，都是现在时间轴上的一个时间点，你可以用checkout回到过去的任何一个时间上。 顺着时光机的思路，你现在身处的时间点，在git里叫HEAD，而当你回到过去时，你的时间点就叫做detached HEAD，因为你已经是\"detached reality\"脱离现实了。 再来让它容易记一点，我们可以叫checkout为一个Jumper！ 它可以跳来跳去，跳到任何地方。你可以用它来跳到别的分支，还可以跳到过去的任何点，总之git里面的它都可以跳过去。所以每次我们用git checkout时，我们可以心里念git 跳到，这样就好理解多了！ 如果是 git checkout 时间点，那么这就是一个回到过去的跳跃； 如果是 git checkout 宇宙名，那么这就是一个平行宇宙的跨越。 其中时间点，就是每次commit的sha值，可以在git log中看到； 宇宙名，指的就是每个branch的名字，可以在git branch中看到。 那么如果我checkout跳到过去，还改变了些东西，会发生什么？ 可以肯定的是，不会发生时空扭曲或祖母悖论。 现在我试一试用git checkout 时间点, git返回了如下信息： 意思就是告知我，现在已经和现实分离，随便玩。“现实”就是HEAD，所以现实分离状态就是detached HEAD。不管怎么样都可以，add, rm, commit等等。 但是，如果做了些实验发现挺好的，想保留，那么就要新建立一个分支来保持这些变动。然后呢，再让这个分支去和主流合并，这之后就是正常merge流程了。 那么回到过去，修修改改后，想保存并建立分支需要用如下命令： git checkout -b 实际上它是把两个单独的命令合到一起，一个是git branch 建立新分支并保存当前的改变，和另一个git checkout 跳转到该分支，这样一步到位还是挺方便的。 返回到现在进行时 当跳跃到过去到某个点时，它是绝对的detached Head状态。 在各种时间跳跃后，简单一句git checkout master就可以跳回到现在进行时了。当然，也可以是git checkout 某分支名跳跃到任何一个平行宇宙的现在进行时。 Git checkout 的妙用：撤销更改 git checkout 某文件名则可以让某个自己不满意的文件，回到最近一个时间点，即最近一个commit提交。 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"GitLab/":{"url":"GitLab/","title":"GitLab","keywords":"","body":"GitLab 学习 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"GitLab/记录一次GitLab迁移.html":{"url":"GitLab/记录一次GitLab迁移.html","title":"记录一次GitLab迁移","keywords":"","body":"GitLab 迁移记录 现有 GitLab 是使用 Docker 安装的 9.3.2 版本，计划迁移到 RPM 安装的 13.3.6 版本 迁移过程 1、逐步升级 GitLab Docker 容器版本 因为 GitLab 不能跨版本升级，比如从 9 大版本是无法直接升级到 11 大版本的，必须先升级到当前大版本的最新版本，然后才能在升级到下一个大版本。 所以，Docker 升级 9.3.2 到 13.3.6 的过程是这样的：9.3.2 -> 9.5.10 -> 10.8.7 -> 11.11.8 -> 12.10.14 -> 13.0.12 -> 13.3.6 (12 升 13 时候有些特殊，必须先升级到 13.0.x，才能升级到最新的 13.3.6) 迁移需要的 GitLab 各个版本容器镜像 tar 包和 rpm 包在 192.168.7.12 上的 /opt/GitLab 中 迁移过程容器命令： $ docker stop gitlab $ docker pull gitlab/gitlab-ce:9.5.10-ce.0 $ docker run -itd --name gitlab-ce-9.5.10 -p 80:80 -p 2222:22 -v /srv/gitlab/config:/etc/gitlab -v /srv/gitlab/logs:/var/log/gitlab -v /srv/gitlab/data:/var/opt/gitlab gitlab/gitlab-ce:9.5.10-ce.0 # 查看容器启动日志，启动成功，浏览器访问，帐号密码登录查看 $ docker logs -f gitlab-ce-9.5.10 $ docker stop gitlab-ce-10.8.7 $ docker run -itd --name gitlab-ce-10.8.7 -p 80:80 -p 2222:22 -v /srv/gitlab/config:/etc/gitlab -v /srv/gitlab/logs:/var/log/gitlab -v /srv/gitlab/data:/var/opt/gitlab gitlab/gitlab-ce:10.8.7-ce.0 # 查看容器启动日志，启动成功，浏览器访问，帐号密码登录查看 $ docker logs -f gitlab-ce-10.8.7 ...... $ docker run -itd --name gitlab-ce-13.3.6 -p 80:80 -p 2222:22 -v /srv/gitlab/config:/etc/gitlab -v /srv/gitlab/logs:/var/log/gitlab -v /srv/gitlab/data:/var/opt/gitlab gitlab/gitlab-ce:13.3.6-ce.0 2、在 13.3.6 版本容器内执行 GitLab 备份命令 $ gitlab-rake gitlab:backup:create 备份目录：/var/opt/gitlab/backups（容器内）、/srv/gitlab/data/backups（容器外） 生成备份数据文件：1600358803_2020_09_17_13.3.6_gitlab_backup.tar 其他迁移需要备份的文件：容器内的 /etc/gitlab/gitlab.rb（宿主机上的/srv/gitlab/config/config/gitlab.rb）和容器内的 /etc/gitlab/gitlab-secrets.json（宿主机上的/srv/gitlab/config/gitlab-secrets.json） 3、将 1600358803_2020_09_17_13.3.6_gitlab_backup.tar、gitlab.rb 和 gitlab-secrets.json 传输到迁移机器 4、在迁移机器上恢复 GitLab 备份数据（迁移机器和源容器内 GitLab 版本必须完全相同） xxx.gitlab_backup.tar 放到 /var/opt/gitlab/backups/ 给 1600358803_2020_09_17_13.3.6_gitlab_backup.tar 增加权限 $ chmod 777 /var/opt/gitlab/backups/1600358803_2020_09_17_13.3.6_gitlab_backup.tar 停止 GitLab 数据交换服务 $ gitlab-ctl stop unicorn ok: down: unicorn: 3188s, normally up $ gitlab-ctl stop puma $ gitlab-ctl stop sidekiq ok: down: sidekiq: 3186s, normally up $ gitlab-ctl status run: alertmanager: (pid 23730) 4249s; run: log: (pid 23210) 4343s run: gitaly: (pid 23585) 4252s; run: log: (pid 22585) 4451s run: gitlab-exporter: (pid 23620) 4251s; run: log: (pid 23064) 4359s run: gitlab-workhorse: (pid 23569) 4253s; run: log: (pid 22926) 4386s run: grafana: (pid 23750) 4248s; run: log: (pid 23407) 4296s run: logrotate: (pid 28170) 780s; run: log: (pid 22977) 4379s run: nginx: (pid 23409) 4295s; run: log: (pid 22937) 4384s run: node-exporter: (pid 23603) 4252s; run: log: (pid 23035) 4367s run: postgres-exporter: (pid 23741) 4249s; run: log: (pid 23245) 4337s run: postgresql: (pid 22682) 4446s; run: log: (pid 22731) 4443s run: prometheus: (pid 23636) 4250s; run: log: (pid 23143) 4349s run: redis: (pid 22520) 4458s; run: log: (pid 22535) 4457s run: redis-exporter: (pid 23623) 4251s; run: log: (pid 23091) 4355s run: registry: (pid 23578) 4252s; run: log: (pid 23018) 4371s down: sidekiq: 3188s, normally up; run: log: (pid 22891) 4390s down: unicorn: 3195s, normally up; run: log: (pid 22877) 4397s 恢复备份，中途需要输入两次 yes $ gitlab-backup restore BACKUP=1600358803_2020_09_17_13.3.6 # 这里去掉备份名字的 _gitlab_backup.tar 将 gitlab.rb 和 gitlab-secrets.json 放到 /etc/gitlab/ 5、重启 GitLab，浏览器访问 $ gitlab-ctl reconfigure $ gitlab-ctl restart $ gitlab-rake gitlab:check SANITIZE=true Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"GitLab/GitLab邮件找回密码.html":{"url":"GitLab/GitLab邮件找回密码.html","title":"GitLab邮件找回密码","keywords":"","body":"GitLab 设置邮件找回密码 一、修改 /etc/gitlab/gitlab.rb 文件 # 在 `/etc/gitlab/gitlab.rb` 中添加如下 gitlab_rails['time_zone'] = 'Asia/Shanghai' ## 配置发信人 gitlab_rails['gitlab_email_enabled'] = true gitlab_rails['gitlab_email_from'] = 'xiecq@paraview.cn' gitlab_rails['gitlab_email_display_name'] = 'Paraview Gitlab' ## 配置 smtp 邮件服务器 gitlab_rails['smtp_enable'] = true gitlab_rails['smtp_address'] = \"smtp.exmail.qq.com\" gitlab_rails['smtp_port'] = 465 gitlab_rails['smtp_user_name'] = \"xiecq@paraview.cn\" gitlab_rails['smtp_password'] = \"Xcq1234567\" gitlab_rails['smtp_domain'] = \"paraview.cn\" gitlab_rails['smtp_authentication'] = \"login\" gitlab_rails['smtp_enable_starttls_auto'] = true gitlab_rails['smtp_tls'] = true 二、重新加载 GitLab 配置 $ gitlab-ctl reconfigure 三、测试发邮件 $ gitlab-rails console ------------------------------------------------------------------------------------- GitLab: 12.0.3 (08a51a9db93) GitLab Shell: 9.3.0 PostgreSQL: 10.7 ------------------------------------------------------------------------------------- Loading production environment (Rails 5.1.7) irb(main):001:0> Notify.test_email('xiechengqiemail@163.com', '测试邮件标题', '测试邮件正文').deliver_now Notify.test_email('xiechengqiemail@163.com','title','content').deliver_now Notify#test_email: processed outbound mail in 3.1ms Sent mail to xiechengqiemail@163.com (1886.5ms) Date: Tue, 29 Sep 2020 07:20:04 +0000 From: Paraview Gitlab Reply-To: Paraview Gitlab To: xiechengqiemail@163.com Message-ID: Subject: title Mime-Version: 1.0 Content-Type: text/html; charset=UTF-8 Content-Transfer-Encoding: 7bit Auto-Submitted: auto-generated X-Auto-Response-Suppress: All content => #, >, >, , >, , , , , , > irb(main):002:0> Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"GitLab/GitLab备份脚本.html":{"url":"GitLab/GitLab备份脚本.html","title":"GitLab备份脚本","keywords":"","body":"GitLab 备份脚本 FreeNAS 挂载到本地 /mnt/backup #!/usr/bin/env bash # ----------------------- # # 每周一到周周日凌晨 3 点备份 # 本地备份路径：/data/backup/gitlab # 远程备份路径：/mnt/backup/gitdev # 本地存放最近 7 天备份 # 远程存放最近 15 天的备份 # # ----------------------- # 今天日期：20200920-121230 - 2020年9月20号，12点12分30秒 today=`date +\"%Y%m%d-%H%M%S\"` # gitlab 备份目录，可以在 /etc/gitlab/gitlab.rb 中查看，默认是 /var/opt/gitlab/backups gitlabBackupLocalPath='/var/opt/gitlab/backups' # 本地磁盘备份路径，只存放最近 7 天的备份 backupLocalPath='/data/backup/gitlab' # 本次备份产生的本地备份文件夹 fileLocalPath=\"$backupLocalPath\"'/'\"$today\" # 本次备份产生的日志文件 logfileLocalPath=\"$fileLocalPath\"'/'\"$today\"'.log' # 远程 freeNAS 备份路径，存放最近 15 天的备份 backupRemotePath='/mnt/backup/gitdev' # 本次备份同步产生的远程备份文件夹 fileRemotePath=\"$backupRemotePath\"'/'\"$today\" # 远程 freeNAS 上的日志目录，永久保存 logsRemotePath=\"$backupRemotePath\"'/logs' # 只保留最近 7 次（即最近一周）的备份 if [ `ls /data/backup/gitlab | egrep '^202.*' | wc -l` -gt 6 ] then cd /data/backup/gitlab deletePath=`ls | egrep '^202.*' | head -1` rm -rf $deletePath fi # 开始备份前删除本地 /var/opt/gitlab/backups 旧的备份 cd $gitlabBackupLocalPath && rm -rf ./* cd - # /etc/gitlab/gitlab.rb、/etc/gitlab/gitlab-secrets.json、xxx.tar 有这三样备份即可随意完整的迁移到任何相同版本的 GitLab mkdir $fileLocalPath gitlab-rake gitlab:backup:create &> \"$logfileLocalPath\" [ $? -ne 0 ] && mv $fileLocalPath \"$fileLocalPath\"'-BackupERROR' && exit 1 tarName=`ls $gitlabBackupLocalPath | egrep '.*13\\.3\\.6_gitlab_backup.tar'` # 备份到本地 /data/backup/gitlab cp /etc/gitlab/gitlab.rb /etc/gitlab/gitlab-secrets.json \"$fileLocalPath\" && mv \"$gitlabBackupLocalPath\"'/'\"$tarName\" \"$fileLocalPath\" [ $? -ne 0 ] && mv $fileLocalPath \"$fileLocalPath\"'-BackupERROR' && exit 1 echo '----------------- BACKUP TO LOCAL SUCCESS --------------' >>\"$logfileLocalPath\" # 同步到远程备份目录 rsync -avztP --delete $fileLocalPath $backupRemotePath [ $? -ne 0 ] && mv $fileLocalPath \"$fileLocalPath\"'-RsyncERROR' && mv $fileRemotePath \"$fileRemotePath\"'-RsyncERROR' && exit 1 echo '----------------- BACKUP TO REMOTE SUCCESS --------------' >>\"$logfileLocalPath\" cp $logfileLocalPath $logsRemotePath Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"frontend/":{"url":"frontend/","title":"前端","keywords":"","body":"前端 前端知识梳理之CSS篇 在线前端编辑调试 在线前端代码展示 在线前端代码展示 W3cplus前端网 Font Awesome 中文网 检测 html、css、javascript 等标签兼容的浏览器版本 JS 前端开发月报 HTML 教程 - 阮一峰 CSS 教程 - 阮一峰 JavaScript 教程 - 阮一峰 ES6 教程 - 阮一峰 Web API 教程 - 阮一峰 Node 教程 - 阮一峰 Git 教程 - 阮一峰 JS前端开发联盟群 - github team 测试网站 SSL 安全性 数字证书认证机构 Let's Encrypt - 免费申请 SSL 证书 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"frontend/小知识.html":{"url":"frontend/小知识.html","title":"小知识","keywords":"","body":"前端小知识 META 定义编码 关键字 描述 定时跳转与刷新 # 这个表示当前页面每5秒钟刷一下，刷一下~ # 这个表示当前页面2秒后跳到首页~ # 页面直接跳转到腾讯网 响应式布局 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"持续集成和部署/":{"url":"持续集成和部署/","title":"持续集成和部署","keywords":"","body":"持续集成、持续交付和持续部署 持续集成是什么？- 阮一峰 Continuous integration - CI - 持续集成 Continuous delivery - CD - 持续交付 continuous deployment - CD - 持续部署 当下持续集成工具不胜枚举，开源的或商业的，可本地安装的或 Sass 的，如： Jenkins Github Action Travis CI Drone Gitlab CI Circle CI CodeShip Bamboo ThoughtWorks GO …… Xiechengqi            最新修订时间： 2020-10-09 10:09:48 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"持续集成和部署/github-action.html":{"url":"持续集成和部署/github-action.html","title":"Github Action","keywords":"","body":"Github Actions 学习 Github 官方文档 Github Actions 入门教程 - 阮一峰 Github awesome actions 项目 Github Actions 通过 SSH 自动备份到代码托管网站 GitHub action for deploying a project to GitHub pages 基础知识 Github Action 其实就是通过编写项目根目录下 .github/workflow/xxx.yml 配置文件，触发 Github 提供的 docker 虚拟机完成 CI 和 CD 定时任务 手动点击 star 触发 CI 使用 ssh 私钥同步部署到 github、gitee、coding 等代码托管平台或远程服务器、对象存储等 QA 1、Github Actions 设置 serects(SSH_PRIVATE_KEY) 时必须完全复制粘贴 ~/.ssh/id_rsa 内容 # 包括 BEGIN 和 END 行 -----BEGIN RSA PRIVATE KEY----- ...... -----END RSA PRIVATE KEY----- Xiechengqi            最新修订时间： 2020-10-09 10:09:48 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Redux/":{"url":"Redux/","title":"Redux","keywords":"","body":"《看漫画，学 Redux》 —— A cartoon intro to Redux 不写一行代码，轻松看懂 Redux 原理。 原文 如果你有任何疑惑，不妨在 Issues 中提出。 Flux 架构已然让人觉得有些迷惑，而比 Flux 更让人摸不着头脑的是 Flux 与 Redux 的区别。Redux 是一个基于 Flux 思想的新架构方式，本文将探讨它们的区别。 如果你还没有看过这篇关于 Flux 的文章（译者注：也可以参考这篇），你应该先阅读一下。 为什么要改变 Flux？ Redux 解决的问题和 Flux 一样，但 Redux 能做的还有更多。 和 Flux 一样，Redux 让应用的状态变化变得更加可预测。如果你想改变应用的状态，就必须 dispatch 一个 action。你没有办法直接改变应用的状态，因为保存这些状态的东西（称为 store）只有 getter 而没有 setter。对于 Flux 和 Redux 来说，这些概念都是相似的。 那么为什么要新设计一种架构呢？Redux 的创造者 Dan Abramov 发现了改进 Flux 架构的可能。他想要一个更好的开发者工具来调试 Flux 应用。他发现如果稍微对 Flux 架构进行一些调整，就可以开发出一款更好用的开发者工具，同时依然能享受 Flux 架构带给你的可预测性。 确切的说，他想要的开发者工具包含了代码热替换（hot reload）和时间旅行（time travel）功能。然而要想在 Flux 架构上实现这些功能，确实有些麻烦。 问题1：store 的代码无法被热替换，除非清空当前的状态 在 Flux 中，store 包含了两样东西： 改变状态的逻辑 当前的状态 在一个 store 中同时保存这两样东西将会导致代码热替换功能出现问题。当你热替换掉 store 的代码想要看看新的状态改变逻辑是否生效时，你就丢失了 store 中保存的当前状态。此外，你还把 store 与 Flux 架构中其它组件产生关系的事件系统搞乱了。 解决方案 将这两样东西分开处理。让一个对象来保存状态，这个对象在热替换代码的时候不会受到影响。让另一个对象包含所有改变状态的逻辑，这个对象可以被热替换因为它不用关心任何保存状态相关的事情。 问题2：每次触发 action 时状态对象都被直接改写了 时间旅行调试法的特性是：你能掌握状态对象的每一次变化，这样的话，你就能轻松的跳回到这个对象之前的某个状态（想象一个撤销功能）。 要实现这样的功能，每次状态改变之后，你都需要把旧的状态保存在一个数组中。但是由于 JavaScript 的对象引用特性，简单的把一个对象放进数组中并不能实现我们需要的功能。这样做不能创建一个快照（snapshot），而只是创建了一个新的指针指向同一个对象。 所以要想实现时间旅行特性，每一个状态改变的版本都需要保存在不同的 JavaScript 对象中，这样你才不会不小心改变了某个历史版本的状态。 解决方案 当一个 action 需要 store 响应时，不要直接修改 store 中的状态，而是将状态拷贝一份并在这份拷贝的状态上做出修改。 问题3：没有合适的位置引入第三方插件 当你在写一些调试性工具时，你希望它们能够更加通用。一个使用该工具的用户应该可以直接引入这个工具而不需要做额外的包装或桥接。 要实现这样的特性，Flux 架构需要一个扩展点。 一个简单的例子就是日志。比如说你希望 console.log() 每一个触发的 action 同时 console.log() 这个 action 被响应完成后的状态。在 Flux 中，你只能订阅（subscribe） dispatcher 的更新和每一个 store 的变动。但是这样就侵入了业务代码，这样的日志功能不是一个第三方插件能够轻易实现的。 解决方案 将这个架构的部分功能包装进其他的对象中将使得我们的需求变得更容易实现。这些「其他对象」在架构原有的功能基础之上添加了自己的功能。你可以把这种扩展点看做是一个增强器（enhancers）或者高阶对象（higher order objects），亦或者中间件（middleware）。 此外，使用一个树形结构来组织所有改变状态的逻辑，这样当状态发生改变的时候 store 只会触发一个事件来通知视图层（view），而这一个事件会被整棵树中的所有逻辑处理（译者注：「处理」不代表一定会改变状态，这些改变状态的逻辑本质上是函数，函数内部会根据 action 的类型等来确定是否对状态进行改变）。 *注意：就上述这些问题和解决方案来说，我主要在关注开发者工具这一使用场景。实际上，对 Flux 做出的这些改变在其他场景中也非常有帮助。在上述三点之外，Flux 和 Redux 还有更多的不同点。比如，相比于 Flux，Redux 精简了整个架构的冗余代码，并且复用 store 的逻辑变得更加简单。这里有一个 Redux 优点的列表可供参考。 那么让我们来看看 Redux 是怎么让这些特性变为现实的。 新的角色 从 Flux 演进到 Redux，整个架构中的角色发生了些许的变化。 Action creators Redux 保留了 Flux 中 action creator 的概念。每当你想要改变应用中的状态时，你就要 dispatch 一个 action，这也是唯一改变状态的方法。 就像我在这篇关于 Flux 的文章中提到的一样，我把 action creator 看做是一个报务员（负责发电报的人，telegraph operator），你找到 action creator 告诉他你大致上想要传达什么信息，action creator 则会把这些信息格式化为一种标准的格式，以便系统中的其他部分能够理解。 与 Flux 不同的是，Redux 中的 action creator 不会直接把 action 发送给 dispatcher，而是返回一个格式化好的 JavaScript 对象。 The store 我把 Flux 中 store 的那一套机制描述为一种控制过度的官僚体系。你不能简单直接的修改状态，而是要求所有的状态改变都必须由 store 亲自产生，还必须要经历 action 分发那种套路。在 Redux 中，store 依然是这么的充满控制欲和官僚主义，但是又有些不一样。 在 Flux 中，你可以拥有多个 store，每一个 store 都有自己的统治权。每个 store 都保存着自己对应的那部分状态，以及所有修改这些状态的逻辑。 而 Redux 中的 store 更喜欢将权力下放，事实上不得不这么做。因为在 Redux 中，你只能有一个 store……所以如果你打算像 Flux 那样让 store 完全独立处理自己的事情，那么在 Redux 中，store 里的工作量将变得非常大。 因此，Redux 中的 store 首先会保存整个应用的所有状态，然后将「判断哪一部分状态需要改变」的任务分配下去。而以根 reducer（root reducer）为首的 reducer 们将会承担这个任务。 你可能发现这里好像没有 dispatcher 什么事。是的，虽然看起来有点儿越权，但 Redux 里的 store 已经完全接管了 dispatcher 相关的工作。 The reducers 当 store 需要知道一个 action 触发后状态需要怎么改变时，他会去询问 reducer。根 reducer 会根据状态对象的键（key）将整个状态树进行拆分，然后将拆分后的每一块子状态传到知道该怎么对这块状态进行响应的子 reducer 那里处理。 我把 reducers 看做是对复印情有独钟的白领们。他们不希望把任何事搞砸，因此他们不会修改任何传递给他们的文件。取而代之的是，他们会对这些文件进行复印，然后在复印件上进行修改。（译者注：当然，当这些修改后的复印件定稿后，他们也不会再去修改这些复印件。） 这是 Redux 的核心思想之一。不直接修改整个应用的状态树，而是将状态树的每一部分进行拷贝并修改拷贝后的部分，然后将这些部分重新组合成一颗新的状态树。 子 reducers 会把他们创建的副本传回给根 reducer，而根 reducer 会把这些副本组合起来形成一颗新的状态树。最后根 reducer 将新的状态树传回给 store，store 再将新的状态树设为最终的状态。 如果你有一个小型应用，你可能只有一个 reducer 对整个状态树进行拷贝并作出修改。又或者你有一个超大的应用，你可能会有若干个 reducers 对整个状态树进行修改。这也是 Flux 和 Redux 的另一处区别。在 Flux 中，store 并不需要与其他 store 产生关联，而且 store 的结构是扁平的。而在 Redux 中，reducers 是有层级结构的。这种层级结构可以有若干层，就像组件的层级结构那样。 The views: 智能组件（smart components）和木偶组件(dumb components) Flux 拥有控制型视图（controller views） 和常规型视图（regular views）。控制型视图就像是一个经理一样，管理着 store 和子视图（child views）之间的通信。 在 Redux 中，也有一个类似的概念：智能组件和木偶组件。（译者注：在最新的 Redux 文档中，它们分别叫做容器型组件 Container component 和展示型组件 Presentational component）智能组件的职责就像经理一样，但是比起 Flux 中的角色，Redux 对经理的职责有了更多的定义： 智能组件负责所有的 action 相关的工作。如果智能组件里包含的一个木偶组件需要触发一个 action，智能组件会通过 props 传一个 function 给木偶组件，而木偶组件可以在需要触发 action 时调用这个 function。 智能组件不定义 CSS 样式。 智能组件几乎不会产生自己的 DOM 节点，他的工作是组织若干的木偶组件，由木偶组件来生成最终的 DOM 节点。 木偶组件不会直接依赖 action（译者注：即不会在木偶组件里 require action 相关的文件），因为所有的 action 都会当做 props 传下来。这意味着木偶组件可以被任何一个逻辑不同的 App 拿去使用。同时木偶组件也需要有一定的样式来让自己变得好看一些（当然你可以让木偶组件接受某些 props 作为设置样式的变量）。 视图层绑定 要把 store 绑定到视图上，Redux 还需要一点帮助。如果你在使用 React，那么你需要使用 react-redux。 视图绑定工作有点像为组件树服务的 IT 部门。IT 部门确保所有的组件都正确的绑定到 store 上，并处理各种技术上的细节，以确保余下层级的组件对绑定相关的操作毫无感知。 视图层绑定引入了三个概念： 组件： 这个组件需要包裹在整个组件树的最外层。这个组件让根组件的所有子孙组件能够轻松的使用 connect() 方法绑定 store。 connect()：这是 react-redux 提供的一个方法。如果一个组件想要响应状态的变化，就把自己作为参数传给 connect() 的结果（译者注：connect() 返回的依然是一个函数），connect() 方法会处理与 store 绑定的细节，并通过 selector 确定该绑定 store 中哪一部分的数据。 selector：这是你自己编写的一个函数。这个函数声明了你的组件需要整个 store 中的哪一部分数据作为自己的 props。 根组件 所有的 React 应用都存在一个根组件（root component）。他其实就是整个组件树最外层的那个组件，但是在 Redux 中，根组件还要承担额外的任务。 根组件承担的角色有点像企业中的高管，他将整个团队整合到一起来完成某项任务。他会创建 store，并告诉 store 使用哪些 reducers，并最终完成视图层的绑定。 当完成整个应用的初始化工作后，根组件的就不再插手整个应用的运行过程了。每一次重新渲染（re-render）都没有根组件什么事，这些活儿都由根组件下面的子组件完成，当然也少不了视图层绑定的功劳。 Redux 完成的运行流程 让我们看看上述各个部分是怎样组合成一个可以运行的应用的。 配置环节 应用中的不同部分需要在配置环节中整合到一起。 (1) 准备好 store。根组件会创建 store，并通过 createStore(reducer) 方法告诉 store 该使用哪个根 reducer。与此同时，根 reducer 也通过 combineReducers() 方法组建了一只向自己汇报的 reducer 团队。 (2) 设置 store 和组件之间的通信。根组件将它所有的子组件包裹在 组件中，并建立了 Provider 与 store 之间的联系。 Provider 本质上创建了一个用于更新视图组件的网络。那些智能组件通过 connect() 方法连入这个网络，以此确保他们能够获取到状态的更新。 (3) 准备好 action callback。为了让木偶组件更好的处理 action，智能组件可以用 bindActionCreators() 方法来创建 action callback。这样做之后，智能组件就能给木偶组件传入一个回调（callback）。对应的 action 会在木偶组件调用这个回调时被自动 dispatch。（译者注：使用 bindActionCreators() 使得木偶组件无需关心 action 的 type 等信息，只用调用 props 中的某个方法传入需要的参数作为 action 的 payload 即可） 数据流 现在我们的应用已经配置完成，用户可以开始操作了。让我们触发一个 action，看看数据是怎样流动的。 (1) 视图发出了一个 action，action creator 将这个 action 格式化并返回。 (2) 这个 action 要么被自动 dispatch（如果我们在配置阶段使用了 bindActionCreators()），要么由视图层手动 dispatch。 (3) store 接受到这个 action 后，将当前的状态树和这个 action 传给根 reducer。 (4) 根 reducer 将整个状态树切分成一个个小块，然后将某一个小块分发给知道怎么处理这部分内容的子 reducer。 (5) 子 reducer 将传入的一小块状态树进行拷贝，然后在副本上进行修改，并最终将修改后的副本返回根 reducer。 (6) 当所有的子 reducer 返回他们修改的副本之后，根 reducer 将这些部分再次组合起来形成一颗新的状态树。然后根 reducer 将这个新的状态树交还给 store，store 再把自己的状态置为这个最新的状态树。 (7) store 告诉视图层绑定：「状态更新啦」 (8) 视图层绑定让 store 把更新的状态传过来 (9) 视图层绑定触发了一个重新渲染的操作（re-render） 这就是我所理解的 Redux，希望对你有所帮助。 更多资源 Redux 官方文档 Redux 官方文档中文版 The Evolution of Flux Frameworks Smart and Dumb Components The upsides of using Redux The downsides of using Redux 如何评价数据流管理架构 Redux? Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Zabbix/":{"url":"Zabbix/","title":"Zabbix","keywords":"","body":"Zabbix 学习 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Zabbix/Docker安装配置Zabbix.html":{"url":"Zabbix/Docker安装配置Zabbix.html","title":"Docker 安装配置 Zabbix","keywords":"","body":"Docker 安装配置 Zabbix 官方安装介绍 直接安装整合好组件的 zabbix docker 镜像 docker run --name zabbix-appliance -t \\ -p 10051:10051 \\ -p 80:80 \\ -d zabbix/zabbix-appliance:latest zabbix 不同组件分别安装对应的 docker 镜像 一、运行 MySQL 数据库支持、基于 Nginx Web 服务器的 Zabbix Web 界面和 Zabbix Java gateway 启动空的 MySQL 服务器实例 docker run --name mysql-server -t \\ -e MYSQL_DATABASE=\"zabbix\" \\ -e MYSQL_USER=\"zabbix\" \\ -e MYSQL_PASSWORD=\"zabbix_pwd\" \\ -e MYSQL_ROOT_PASSWORD=\"root_pwd\" \\ -d mysql:5.7 \\ --character-set-server=utf8 --collation-server=utf8_bin 启动 Zabbix Java gateway 实例 docker run --name zabbix-java-gateway -t \\ -d zabbix/zabbix-java-gateway:latest 启动 Zabbix server 实例，并将其关联到已创建的 MySQL server 实例 docker run --name zabbix-server-mysql -t \\ -e DB_SERVER_HOST=\"mysql-server\" \\ -e MYSQL_DATABASE=\"zabbix\" \\ -e MYSQL_USER=\"zabbix\" \\ -e MYSQL_PASSWORD=\"zabbix_pwd\" \\ -e MYSQL_ROOT_PASSWORD=\"root_pwd\" \\ -e ZBX_JAVAGATEWAY=\"zabbix-java-gateway\" \\ --link mysql-server:mysql \\ --link zabbix-java-gateway:zabbix-java-gateway \\ -p 10051:10051 \\ -d zabbix/zabbix-server-mysql:latest 启动 Zabbix Web 界面，并将其关联到已创建的 MySQL server 和 Zabbix server 实例 docker run --name zabbix-web-nginx-mysql -t \\ -e DB_SERVER_HOST=\"mysql-server\" \\ -e MYSQL_DATABASE=\"zabbix\" \\ -e MYSQL_USER=\"zabbix\" \\ -e MYSQL_PASSWORD=\"zabbix_pwd\" \\ -e MYSQL_ROOT_PASSWORD=\"root_pwd\" \\ --link mysql-server:mysql \\ --link zabbix-server-mysql:zabbix-server \\ -p 80:80 \\ -d zabbix/zabbix-web-nginx-mysql:latest 二、运行 PostgreSQL 数据库支持的 Zabbix server、基于 Nginx Web 服务器的 Zabbix Web 界面和 SNMP trap 功能 启动空的 PostgreSQL server 实例 docker run --name postgres-server -t \\ -e POSTGRES_USER=\"zabbix\" \\ -e POSTGRES_PASSWORD=\"zabbix\" \\ -e POSTGRES_DB=\"zabbix_pwd\" \\ -d postgres:latest 启动 Zabbix snmptraps 实例 docker run --name zabbix-snmptraps -t \\ -v /zbx_instance/snmptraps:/var/lib/zabbix/snmptraps:rw \\ -v /var/lib/zabbix/mibs:/usr/share/snmp/mibs:ro \\ -p 162:162/udp \\ -d zabbix/zabbix-snmptraps:latest 启动 Zabbix server 实例，并将其关联到已创建的 PostgreSQL server 实例 docker run --name zabbix-server-pgsql -t \\ -e DB_SERVER_HOST=\"postgres-server\" \\ -e POSTGRES_USER=\"zabbix\" \\ -e POSTGRES_PASSWORD=\"zabbix\" \\ -e POSTGRES_DB=\"zabbix_pwd\" \\ -e ZBX_ENABLE_SNMP_TRAPS=\"true\" \\ --link postgres-server:postgres \\ -p 10051:10051 \\ --volumes-from zabbix-snmptraps \\ -d zabbix/zabbix-server-pgsql:latest 启动 Zabbix Web 界面，并将其关联到已创建的 PostgreSQL server 和 Zabbix server 实例 docker run --name zabbix-web-nginx-pgsql -t \\ -e DB_SERVER_HOST=\"postgres-server\" \\ -e POSTGRES_USER=\"zabbix\" \\ -e POSTGRES_PASSWORD=\"zabbix\" \\ -e POSTGRES_DB=\"zabbix_pwd\" \\ --link postgres-server:postgres \\ --link zabbix-server-pgsql:zabbix-server \\ -p 443:443 \\ -v /etc/ssl/nginx:/etc/ssl/nginx:ro \\ -d zabbix/zabbix-web-nginx-pgsql:latest Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Zabbix/术语单词.html":{"url":"Zabbix/术语单词.html","title":"Zabbix 中常用单词","keywords":"","body":"Zabbix 中常用单词 inventory - 资产 encryption - 加密 certificate - 证书 items - 监控项 triggers - 触发器 interval - 间隔 flexible - 灵活 scheduling - 调度 event correlation - 事件关联 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Zabbix/重置密码.html":{"url":"Zabbix/重置密码.html","title":"重置 Zabbix 账户密码","keywords":"","body":"重置 Zabbix 账户密码 在 zabbix 服务器上登录 zabbix 连接的数据库，这里是 mysql $ mysql -uroot -p 查看 zabbix 数据库中的 users 数据表 MariaDB [(none)]> use zabbix; Reading table information for completion of table and column names You can turn off this feature to get a quicker startup with -A Database changed MariaDB [zabbix]> show tables; MariaDB [zabbix]> select * from users; MariaDB [zabbix]> select userid,alias,passwd from users; +--------+-------+----------------------------------+ | userid | alias | passwd | +--------+-------+----------------------------------+ | 1 | Admin | 070a5ec75b5f7420cc49440c9994cfdb | | 2 | guest | d41d8cd98f00b204e9800998ecf8427e | +--------+-------+----------------------------------+ 生成一个新密码的 MD5 值 # 新密码设为 admin $ echo -n admin | openssl md5 (stdin)= 21232f297a57a5a743894a0e4a801fc3 然后 update 表数据，userid=1 的这个用户 MariaDB [zabbix]> update users set passwd='21232f297a57a5a743894a0e4a801fc3' where userid = '1'; Query OK, 1 row affected (0.01 sec) Rows matched: 1 Changed: 1 Warnings: 0 刷新重新加载权限表 MariaDB [zabbix]> FLUSH PRIVILEGES; Query OK, 0 rows affected (0.03 sec) Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"KVM/":{"url":"KVM/","title":"KVM","keywords":"","body":"KVM 学习 如何迁移 VMware 上的 Windows 及 Linux 虚拟机到基于 KVM 的虚拟机 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"KVM/常用名词解释.html":{"url":"KVM/常用名词解释.html","title":"常用名词解释","keywords":"","body":"KVM 常用名词解释 hypervisor domain - 域 storage pool - 存储池 storage volumes - 存储卷 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"KVM/安装配置.html":{"url":"KVM/安装配置.html","title":"安装配置","keywords":"","body":"常用命令 virsh list --all - 在宿主上查看虚拟机 virsh start [VM] virsh destroy [VM] 安装过程 检查CPU是否支持虚拟化 # 返回结果为 0，说明 CPU 不支持虚拟化；大于 0，说明 CPU 支持虚拟化 egrep -c '(vmx|svm)' /proc/cpuinfo #如果输出结果中包含vmx，则表示采用Intel虚拟化技术；如果包含svm，则表示采用AMD虚拟化技术；如果没有任何输出，表示当前的CPU不支持KVM虚拟化技术 $ cat /proc/cpuinfo | egrep '(vmx|svm)' # 还可以用 grep -E 'svm|vmx' /proc/cpuinfo 和 egrep --color -i \"svm|vmx\" /proc/cpuinfo 来检查 安装 KVM $ sudo apt update $ sudo apt install qemu-kvm libvirt-bin bridge-utils virt-manager qemu $ sudo apt-get install qemu-kvm libvirt-bin bridge-utils virtinst cpu-checker # bridge-utils - 用户网络桥接 # virt-manager - KVM 虚拟机 GUI 管理工具 验证KVM是否安装成功 # 验证 KVM 模块是否成功加载 $ lsmod | grep kvm kvm_intel 217088 0 kvm 602112 1 kvm_intel irqbypass 16384 1 kvm 启动 libvertd 服务 # 验证 libvirtd 服务是否正常启动 $ sudo systemctl status libvirtd 配置宿主机网络桥接 KVM 桥接和 NAT sudo virt-install -n Sysgeek-Server --description \"Test VM for Sysgeek\" --os-type=Linux --os-variant=rhel7 --ram=1096 --vcpus=1 --disk path=/var/lib/libvirt/images/ sgserver.img,bus=virtio,size=10 --network bridge:br0 --graphics none --location /home/billyfu/rhel-server-7.3-x86_64-dvd.iso --extra-args console=ttyS0 CLI 创建虚拟机 - virt-install -n NAME, --name=NAME 虚拟机的名字 -r MEMORY, --ram=MEMORY 虚拟机内在大小，单位为 MB --vcpus=VCPUS[,maxvcpus=MAX][,sockets=#][,cores=#][,threads=#]：VCPU个数及相关配置 --os-type=DISTRO_TYPE：操作系统类型，如 linux、unix 或 windows 等 bridge=BRIDGE：连接至名为“BRIDEG”的桥设备 --name 指定虚拟机的名称 --memory 指定分配给虚拟机的内存资源大小 maxmemory 指定可调节的最大内存资源大小，因为KVM支持热调整虚拟机的资源 --vcpus 指定分配给虚拟机的CPU核心数量 maxvcpus 指定可调节的最大CPU核心数量 --os-type 指定虚拟机安装的操作系统类型 --os-variant 指定系统的发行版本 --location 指定ISO镜像文件所在的路径，支持使用网络资源路径，也就是说可以使用URL --disk path 指定虚拟硬盘所存放的路径及名称，size 则是指定该硬盘的可用大小，单位是G --bridge 指定使用哪一个桥接网卡，也就是说使用桥接的网络模式 --graphics 指定是否开启图形 --console 定义终端的属性，target_type 则是定义终端的类型 --extra-args 定义终端额外的参数 GUI 创建虚拟机 - virt-manager 登录虚拟机 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"KVM/创建虚拟机和安装操作系统.html":{"url":"KVM/创建虚拟机和安装操作系统.html","title":"创建虚拟机和安装操作系统","keywords":"","body":"KVM 创建虚拟机并安装操作系统 目录 KVM 安装 配置网络 创建存储池和存储卷 创建虚拟机 参考 Windows Guest Virtual Machines on Red Hat Enterprise Linux 7 使用 KVM 安装一个 CentOS 或 Windows Server 等涉及到两个步骤： 使用 virt-install (命令行) 或 virt-manager (图形化) 创建一个虚拟机 ( Creating the guest virtual machine, using either virt-install or virt-manager ) 在虚拟机上使用 virt-viewer 或 VNC 客户端 安装操作系统 ( Installing the Windows operating system on the guest virtual machine, using virt-viewer ) 如果创建 Windows Server ISO 镜像没有内置 virtio 驱动，需要在宿主机提前安装 virtio - yum install -y virtio-win 创建虚拟机 一、图形化安装（virt-manager） 二、命令行安装（virt-install） 使用 virt-install 工具安装虚拟机后，在目录 /etc/libvirt/qemu/ 下生成 xml 配置文件，配置文件命名: 虚拟机名.xml virt-install + 命令行交互式 - 只适用于安装 Linux guest os virt-install + virt-viewer CentOS 7 Minimal virt-install \\ --virt-type=kvm \\ --name centos7 \\ --os-type=linux \\ --os-variant=centos7.0 \\ --ram 1024 \\ --vcpus=1 \\ --cdrom=/data/iso/CentOS-7-x86_64-Minimal-2003.iso \\ --disk path=/data/images/centos7.qcow2,size=10,bus=virtio,format=qcow2 --network bridge=br0,model=virtio \\ --boot cdrom,hd,menu=on \\ --noautoconsole virt-install \\ --virt-type kvm \\ --name windows2016 \\ --os-type=windows \\ --ram=2048 \\ --vcpus=1 \\ --cdrom=/data/iso/xxx.iso \\ --disk /data/images/xxx.qcow2,size=20,bus=virtio,format=qcow2 \\ --network bridge=br0,model=virtio \\ --boot cdrom,hd,menu=on --noautoconsole # --boot: 指定机器的启动顺序，cdrom 是从光驱，hd 从硬盘， menu - bios virt-install + VNC 查看虚拟机的vnc端口号：virsh vncdisplay windows2016 显示虚拟机的xml信息：virsh dumpxml windows2016 xml 虚拟机配置文件目录：/etc/libvirt/qemu 虚拟机的镜像文件位置：/var/lib/libvirt/images/ # 使用 raw 格式磁盘 $ virt-install \\ --name=vm1 \\ --ram=1024 \\ --vcpus=2 \\ --disk path=/opt/kvm/images/vm1.img,size=10 \\ --cdrom /opt/kvm/data/centos7.iso \\ --graphics vnc,port=5910, \\ --network bridge=virbr0,model=virtio \\ --force \\ --autostart # 使用 qcow2 格式磁盘(kvm 推荐使用 qcow2) $ virt-install \\ --name=vm2 \\ --ram=1024 \\ --vcpus=1 \\ --disk path=/opt/kvm/images/vm2.qcow2,format=qcow2,size=7,bus=virtio \\ --cdrom /opt/kvm/data/centos7.iso \\ --graphics vnc,port=5911 \\ --network bridge=virbr0,model=virtio \\ --force \\ --autostart VNC 连接安装系统 VNC 默认监听本地是指只能从宿主机本地登录指定虚拟机如 vncviewer 127.0.0.1:[端口号](如 127.0.0.1:5902)，如果监听所有端口则可以从远程通过宿主机 [ip]:[端口号] 登录虚拟机(如 192.168.122.24:5902) 开启 VNC 远程 $ sed -i 's/#vnc_listen = \"0.0.0.0\"/vnc_listen = \"0.0.0.0\"/g' /etc/libvirt/qemu.conf 安装好后必须重启 $ reboot 三、模板化安装（module） Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"KVM/常用命令行工具详解.html":{"url":"KVM/常用命令行工具详解.html","title":"常用命令行工具详解","keywords":"","body":"KVM 常用命令行工具详解 查看相关工具 使用 ls /usr/bin | grep virt，ls /usr/bin/ | grep qemu，ls /usr/bin/ | grep virsh 可以看到 KVM 所有命令行工具 $ ls /usr/bin | grep virt auvirt systemd-detect-virt virt-alignment-scan virt-builder virt-builder-repository virt-cat virt-clone virt-copy-in virt-copy-out virt-customize virt-df virt-diff virt-edit virt-filesystems virt-format virt-get-kernel virt-host-validate virt-index-validate virt-inspector virt-install virt-log virt-ls virt-make-fs virt-manager virt-pki-validate virt-rescue virt-resize virt-sparsify virt-sysprep virt-tail virt-tar-in virt-tar-out virt-v2v virt-v2v-copy-to-local virt-viewer virt-xml virt-xml-validate $ ls /usr/bin | grep qemu qemu-img qemu-io qemu-kvm qemu-nbd $ ls /usr/bin | grep virsh virsh 这里总结一些常用到的 KVM 命令行工具 virsh The virsh program is the main interface for managing virsh guest domains（域）. The program can be used to create, pause, and shutdown domains. It can also be used to list current domains. Libvirt is a C toolkit（工具包） to interact with the virtualization capabilities of recent versions of Linux (and other OSes). It is free software available under the GNU Lesser General Public License. Virtualization of the Linux Operating System means the ability to run multiple instances（多实例） of Operating Systems concurrently （同时）on a single hardware system where the basic resources are driven by a Linux instance. The library aims at providing a long term stable C API. It currently supports Xen, QEMU, KVM, LXC, OpenVZ, VirtualBox and VMware ESX. 大多 virsh 相关命令都需要 root 权限 virsh 命令是并行执行的，往往虽然回车立马有执行反馈信息，但并不意味这命令的动作已经完全执行完成，所以必须定时轮询命令的动作是否全部执行完成 virsh [OPTION]... [ARG]... 可以是一个数字(domain id)、域名(domain name)或 domain 的 UUID 命令 分类 可以在 man virsh 查找对应内容 generic commands domain commands device commands nodedev commands virtual network commands interface commands storage pool commands volume commands secret commands snapshot commands nwfilter commands hypervisor-specific commands 帮助文档 man virsh - 查看 virsh 相关信息的手册 virsh help - 查看 virsh 所有命令 virsh help pool - 查看 virsh pool 相关命令 virsh help pool-list - 查看 virsh pool-list 详细手册 常用命令 virsh - 进入 virsh 交互式终端，在交互式输入命令省略 virsh **`virsh list --all - 列出所有已安装的虚拟机 virsh dominfo domain - 查看 domain 基本信息 virsh autostart [--disable] domain - 配置 domain 在宿主机开机时自动启动 (--diable 反之) virsh console domain - 连接客户虚拟机 virsh create [FILE] - 从 xml 文件创建虚拟 `` - `` - `` - `` - `` - `` - Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"KVM/磁盘镜像格式.html":{"url":"KVM/磁盘镜像格式.html","title":"磁盘镜像格式","keywords":"","body":"磁盘镜像格式 参考 迁移 VMware 虚拟机到 KVM QEMU 使用的镜像文件：qcow2 与 raw qcow2、raw、vmdk等镜像格式 Converting between image formats row qcow2 vdi vmdk vpc 创建特定格式的磁盘镜像 qemu-img create -f [镜像格式] [镜像名] [磁盘大小，例如: 30G] # 不指定磁盘格式，默认是 raw (原生格式） $ qemu-img create centos.raw 10G # 指定磁盘格式 $ qemu-img create -f qcow2 centos7.qcow2 10G 磁盘镜像格式转换 qemu-img convert 命令可以实现在多种镜像格式之间进行转换，包括 qcow2、qed、raw、vdi、vhd 和 vmdk 使用 qemu-img convert 转换完成后，将新生产一个目标镜像文件，源文件仍保存 qemu-img convert [-f [源镜像格式]] -O [目标镜像格式] [源镜像名] [目标镜像名] -f [源镜像格式] 是可选的，如果忽略，qemu-img 会尝试推断源镜像的格式 vmdk -> qcow2 $ qemu-img convert -f vmdk -O qcow2 centos7.vmd kcentos7.img qcow2 -> raw $ qemu-img convert -f qcow2 -O raw centos7.qcow2 centos7.raw raw -> qcow2 $ qemu-img convert -f raw -O qcow2 centos7.raw centos7.qcow2 vmdk -> raw $ qemu-img convert -f vmdk -O raw centos7.vmdk centos7.raw vdi -> raw 可以使用 VirtualBox 附带的 VBoxManage 工具将 VDI 镜像转换为 raw 格式镜像 $ VBoxManage clonehd ~/VirtualBox\\ VMs/image.vdi image.img --format raw 使用 qemu-img convert 方法 $ qemu-img convert -f vdi -O raw centos7.vdi centos7.raw `` -> `` Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"KVM/虚拟机网络配置.html":{"url":"KVM/虚拟机网络配置.html","title":"虚拟机网络配置","keywords":"","body":"虚拟机网络连接常见的有 3 种方式： NAT 网络：即内部地址转换，相当于从物理网卡外接了一个虚拟的路由，然后所有虚拟机都连接到该“路由器”上，虚拟机可以借助这个路由器访问到外面的网络，但外面的网络却无法访问，因为虚拟机的地址只是路由器上唯一的，出了路由器就不再唯一了。 桥接网络：也叫物理设备共享，相当于虚拟了一个和服务网卡一样的网卡，这个虚拟网卡和物理网卡是平行的关系，并且虚拟机共用物理网卡额资源。这样，虚拟机能够接入外部网络，不受物理机的限制了。 Host-Only 网络：与 NAT 类似，但是比 NAT 更封闭，只有物理机能够访问该虚拟机，其他虚拟机也不能访问。 1.Bridged 桥接模式 虚拟机和主机是处于同等地位的机器，所以网络功能也无异于主机，并且和主机处于同一网段 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"KVM/KVM安装wins2016.html":{"url":"KVM/KVM安装wins2016.html","title":"KVM安装wins2016","keywords":"","body":"KVM 安装 Windows Server 2016 实验环境 CentOS 7 KVM 安装 windows 的 virtio 驱动 查看 virtio 软件包信息 yum info virtio-win 已加载插件：fastestmirror Determining fastest mirrors * base: mirrors.aliyuncs.com * extras: mirrors.aliyuncs.com * updates: mirrors.aliyuncs.com 错误：没有匹配的软件包可以列出 以上说明缺少 virtio-win 的 yum 软件源 1、使用 wget 下载 virtio-win.repo wget https://fedorapeople.org/groups/virt/virtio-win/virtio-win.repo -O /etc/yum.repos.d/virtio-win.repo 2、或手动添加 vim /etc/yum.repos.d/virtio-win.repo 写入一下内容: virtio-win yum repo Details: https://fedoraproject.org/wiki/Windows_Virtio_Drivers [virtio-win-stable] name=virtio-win builds roughly matching what was shipped in latest RHEL baseurl=http://fedorapeople.org/groups/virt/virtio-win/repo/stable enabled=1 skip_if_unavailable=1 gpgcheck=0 [virtio-win-latest] name=Latest virtio-win builds baseurl=http://fedorapeople.org/groups/virt/virtio-win/repo/latest enabled=0 skip_if_unavailable=1 gpgcheck=0 [virtio-win-source] name=virtio-win source RPMs baseurl=http://fedorapeople.org/groups/virt/virtio-win/repo/srpms enabled=0 skip_if_unavailable=1 gpgcheck=0 * 再次执行 ``` shell # yum info virtio-win 已加载插件：fastestmirror Loading mirror speeds from cached hostfile * base: mirrors.aliyuncs.com * extras: mirrors.aliyuncs.com * updates: mirrors.aliyuncs.com base | 3.6 kB 00:00:00 docker-ce-stable | 3.5 kB 00:00:00 epel | 4.7 kB 00:00:00 extras | 2.9 kB 00:00:00 updates | 2.9 kB 00:00:00 virtio-win-stable | 3.0 kB 00:00:00 (1/3): epel/x86_64/updateinfo | 1.0 MB 00:00:00 (2/3): epel/x86_64/primary_db | 6.8 MB 00:00:00 (3/3): virtio-win-stable/primary_db | 2.7 kB 00:00:07 可安装的软件包 名称 ：virtio-win 架构 ：noarch 版本 ：0.1.171 发布 ：1 大小 ：64 M 源 ：virtio-win-stable 简介 ： VirtIO para-virtualized drivers for Windows(R) 网址 ：http://www.redhat.com/ 协议 ： BSD and Apache and GPLv2 描述 ： VirtIO para-virtualized Windows(R) drivers for 32-bit and 64-bit : Windows(R) guests. virt-install --name server2016 --memory 4096 --vcpus sockets=1,cores=2,threads=2 \\ --disk device=cdrom,path=/kvm/iso/cn_windows_server_2016_x64_dvd_9718765.iso \\ --disk device=cdrom,path=/usr/share/virtio-win/virtio-win.iso \\ --disk path=/disk2/kvm/images/server2016.img,size=50,bus=virtio \\ --network bridge=br0,model=virtio \\ --noautoconsole --accelerate --hvm \\ --graphics vnc,listen=0.0.0.0,port=20006 --video vga --input tablet,bus=usb --cpu host-passthrough virt-install --name win2016 --virt-type kvm --hvm --os-type windows --memory 2048 --vcpus 1 \\ --network bridge=br0,model=virtio \\ --cdrom /data/iso/cn_windows_server_2016_x64_dvd_9718765.iso \\ --disk path=/data/kvm/images/win2016.qcow2,bus=ide \\ --graphics vnc root@cagetest-inner1:~# virt-install \\ --name windows2016 \\ --os-type=windows \\ --ram=2048 --vcpus=2 \\ --disk /data/kvm/win2016.qcow2,bus=virtio,size=50 \\ --disk /data/iso/virtio-win-0.1.141_amd64.vfd,device=floppy \\ --cdrom=/data/iso/cn_windows_server_2016_vl_x64_dvd_11636695.iso \\ --network bridge=br0,model=virtio \\ --graphic vnc,listen=0.0.0.0,port=5905 \\ --virt-type kvm 查看虚拟机的vnc端口号：virsh vncdisplay windows2016 显示虚拟机的xml信息：virsh dumpxml windows2016 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"MySQL/":{"url":"MySQL/","title":"MySQL","keywords":"","body":"目录 MySQL Product Archives MySQL Community Server (Archived Versions) Installing and Upgrading MySQL MySQL 8.0 中文参考手册 使用Mysqldump备份和恢复MySQL数据库 mysqldump备份所有数据库，恢复单个库的场景预演 MySQL DataBase 各个发行版本 MySQL Community Server：社区版本，开源免费，但不提供官方技术支持（我们常用的MySQL版本） MySQL Enterprise Edition：企业版本，需付费，可以试用30天 MySQL Cluster：集群版，开源免费。可将几个MySQL Server封装成一个Server MySQL Cluster CGE：高级集群版，需付费 MySQL Workbench (GUI TOOL)：专为MySQL设计的ER/数据库建模工具。MySQL Workbench又分为两个版本，分别是社区版（MySQL Workbench OSS）、商用版（MySQL Workbench SE） MySQL Community Server 各个下载版本 MySQL 官网的 MySQL Community Server (也就是我们常说的 MySQL ) 档案 CentOS / Red Hat 可以看到如下下载选项： rpm package 是某个特定的包，比如 server、client、shared lib 等，也可以单独安装 rpm bundle 是该版本所有包的集合，一般是把服务器端要用的都安装上，其他的不带，尤其是开发包 Compressed TAR Archive 源码，必须用源码方式安装，需要自己编译的，也有编译好，但不是安装包的 mysql-server mysql服务器 mysql-client mysql客户端 mysql-common 包含客户端需要的一些文件，如/etc/mysql/my.cnf mysql-devel 库和包含文件，如果想要做客户端开发，则需要该包 mysql-share 包含某些语言和应用程序需要动态装载的共享库(libmysqlclient.so*) mysql-libs 包含任意mysql客户端程序与接口的共享库 mysql-bench MySQL数据库服务器的基准和性能测试工具 mysql-embedded MySQL是一个多用户、多线程的数据库，这个组件将mysql服务程序集成到客户端应用程序中，而不是占用一个单独的进程 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"MySQL/MySQL学习笔记.html":{"url":"MySQL/MySQL学习笔记.html","title":"MySQL 学习笔记","keywords":"","body":"MySQL 学习笔记 目录 介绍 基本命令 介绍 MySQL 是单进程多线程的 基本命令 # which mysql /usr/bin/mysql # ls /usr/bin | grep mysql mysql mysqladmin mysqlshow mysqldump mysqldumpslow mysqlbinlog mysqlcheck mysql_config_editor mysqld_pre_systemd mysqlimport mysql_install_db mysql_plugin mysqlpump mysql_secure_installation mysqlslap mysql_ssl_rsa_setup mysql_tzinfo_to_sql mysql_upgrade mysql mysql [选项] [参数] [选项] -h：MySQL 服务器的 ip 地址或主机名 -u：连接 MySQL 服务器的用户名 -e：执行 MySQL 内部命令 -p：连接 MySQL 服务器的密码 # mysql 终端登录 $ mysql -h[ip/hostname] -u[用户] -p[密码] -e[sql语句] # 创建数据库 $ mysql -uroot -p\"$password\" -e 'CREATE DATABASE test;' $ mysql -uroot -p\"$password\" mysqladmin MySQL 服务器管理任务的客户端工具，它可以检查 MySQL 服务器的配置和当前工作状态、创建和删除数据库、创建用户和修改用户密码等操作 常用在从 MySQL 执行一次命令获取信息，常见于脚本中使用 mysqladmin [选项] [命令[参数]] [选项] -h：MySQL 服务器的 ip 地址或主机名 -u：连接 MySQL 服务器的用户名 -e：执行 MySQL 内部命令 -p：连接 MySQL 服务器的密码 -c [num]/--sleep=[num]：自动运行次数统计，必须和 -i 一起使用 -i [num]/--count=[num]：间隔多长时间重复执行 -S：--socket=name，指定用于连接数据库 socket file [命令] create DB_Name：创建数据库 drop DB_Name：删除数据库及其所有表 debug：打开调试日志并记录于 error log 中 status：显示数据库简要状态信息 extended-status：显示扩展信息，输出 mysqld 的各状态变量及赋值，相当于执行 mysql> show global status variables：输出 mysqld 的各服务器变量 flush-hosts：清空主机相关的缓存- DNS 解析缓存；此前因为连接错误次数过多而被拒绝访问 mysqld 的主机列表 flush-logs：清空所有日志 refresh：相当于同时使用 flush-hosts 和 flush-logs flush-tables：清空所有表 flush-privileges：重载授权表 reload：同 flush-privileges flush-status：重置状态变量的值 flush-threads：清空线程缓存 kill [id]：杀死 MySQL 指定线程（可以一次杀死多个线程，以逗号分隔，但不能有多余空格） password [新密码]：修改当前用户的密码 ping：检测 mysqld 是否存活 processlist：显示 mysqld 线程列表 shutdown：关掉 mysqld start-slave/stop-slave：启动/关闭从服务器线程 # 修改 MySQL 用户密码 $ mysqladmin -uroot -p\"$password\" password \"$newpassword\" # 显示 MySQL 简要状态 $ mysqladmin -uroot -p\"$password\" status # 检测 MySQL Server(mysqld) 是否可用 mysqladmin -uroot -p ping # 查看 mysqld 版本信息 $ mysqladmin -uroot -p version # 同时执行多个命令 $ mysqladmin -uroot -p process status version mysqlshow 显示 MySQL 服务器中数据库、表和列表信息 mysqldump MySQL 数据库的备份工具，，用于将 MySQL 服务器中的数据库以标准的 sql 语言的方式导出，并保存到文件中 mysqldump 属于单线程，功能是非常强大的，不仅常被用于执行数据备份任务，甚至还可以用于数据迁移 # 导出整个数据库 $ mysqldump -u 用户名 -p 密码 数据库名 > 导出文件名 # 导出一张表 $ mysqldump -u 用户名 -p 密码 数据库名 表名 > 导出文件名 # 导出一个数据库结构 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"MySQL/MySQL多实例.html":{"url":"MySQL/MySQL多实例.html","title":"MySQL 多实例","keywords":"","body":"MySQL 实例 实例、进程、 单实例部署 Linux command / shell docker command / docfile 多实例部署 MySQL数据库运维之多单机多实例搭建 简单的说，MySQL 多实例就是在一台服务器上同时开启多个不同的服务端口（如 3306、 3307），同时运行多个 MySQL 服务进程，这些服务进程通过不同的 socket 监听不同的服务端口来提供服务。这些 MySQL 多实例公用一套 MySQL 安装程序，使用不同的 my.cnf（也可以相同）配置 文件、启动程序（也可以相同）和数据文件，在提供服务时，多实例 mysql 在逻辑上看来是各自独立的，他们根据配置文件的对应设定值，获得服务器相应数量的硬件资源 MySQL 多实例只需要一次部署，但有各自的配置文件（my.cnf）、启动程序、数据目录 实现方法 1、基于多配置文件 分开管理启动脚本、配置文件、端口、basedir、datadir 创建 mysql 用户和组 创建数据目录，通常用端口号作为目录名 创建多实例各自的配置文件( $datadir/xxx.cnf ) 更改实例数据目录的属主和属组权限 通过指定的配置文件( $datadir/xxx.cnf )初始化数据目录（即初始化数据库），数据目录初始化前必须为空 配置 /etc/my.cnf 实现集中管理多实例，这一步视实例各自的配置文件内容而定 通过启动脚本管理多实例( 可以自己编写一个 shell 脚本或注册服务 service ) 优点：逻辑简单，配置简单 缺点：管理起来不方便 2、基于 mysqld_multi mysqld_multi - 管理多个MySQL服务器 基于mysqld_multi实现MySQL 5.7.24多实例多进程配置 对于某些Linux平台，从RPM或Debian软件包安装MySQL包括用于管理MySQL服务器启动和关闭的systemd支持。 在这些平台上， 没有安装 mysqld_multi， 因为它是不必要的 通过官方自带的 mysqld_multi 工具，使用单独配置文件来实现多实例 优点：便于集中管理管理 缺点：不方便针对每个实例配置进行定制 3、基于 systemd Configuring Multiple MySQL Instances Using systemd 4、基于 IM 使用 MySQL 实例管理器（MYSQLMANAGER），这个方法好像比较好不过也有点复杂 优点：便于集中管理 缺点：耦合度高。IM 一挂，实例全挂 不方便针对每个实例配置进行定制 4、docker 容器 5、ansible + mysqltools https://github.com/Neeky/mysqltools 如何一键部署mysql的多实例 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"MySQL/Ubuntu安装Navicat.html":{"url":"MySQL/Ubuntu安装Navicat.html","title":"Ubuntu 安装及配置 Navicat","keywords":"","body":"Ubuntu 安装及配置 Navicat 解决乱码 ubuntu下 navicat 的乱码大致可分为两类，一类是 navicat 软件自身的乱码，另一类是链接到数据库后的乱码，包括编辑器，表格等的乱码 1、navicat 自身的乱码解决 编辑 navicat 的启动脚本 - - start_navicat，修改成export LANG=\"zh_CN.UTF-8\"即可 2、连接数据库后的乱码解决 首先在连接数据库时，在高级选项中，设置编码为UTF-8，连接成功后进入界面。 选择工具-首选项，常规页签下，字体选择Noto Sans Mono CJK TC 编辑器页签下编辑器字体选择Noto Sans CJK SC 记录页签下网格字体选择Noto Sans Mono CJK TC 修改完成后，重启软件后，编码问题即可解决！ Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"MySQL/忘记root密码.html":{"url":"MySQL/忘记root密码.html","title":"如何替换已忘记的 root 密码","keywords":"","body":"如何替换已忘记的 root 密码 环境： 操作系统：Ubuntu 18.04 LTS 软件：Mysql 5.7.27 错误信息： $ mysql -u root -p Enter password: ERROR 1045 (28000): Access denied for user 'root'@'localhost' (using password: YES) 操作 1、关闭 mysql 服务 service mysql stop 2、修改/etc/mysql/my.cnf文件 # 添加 [mysqld] skip-grant-tables 3、启动 mysql ，并登录 $ service mysql start $ mysql -uroot # 此时无需密码即可直接进入 4、操作 user 表 $ mysql -u root Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 4 Server version: 5.7.18 MySQL Community Server (GPL) Copyright (c) 2000, 2017, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. mysql> use mysql; Reading table information for completion of table and column names You can turn off this feature to get a quicker startup with -A Database changed # MySQL 5.7 下，user 表已经没有 Password 字段 mysql> update user set password=PASSWORD('123') where user='root'; ERROR 1054 (42S22): Unknown column 'password' in 'field list' # 加密后的用户密码存储于 authentication_string 字段 mysql> update mysql.user set authentication_string=password('123') where user='root'; Query OK, 1 row affected, 1 warning (0.00 sec) Rows matched: 1 Changed: 1 Warnings: 1 mysql> flush privileges; Query OK, 0 rows affected (0.00 sec) mysql> exit 5、删除 my.cnf 中刚添加的内容，重启 mysql 服务器即可 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Nginx/":{"url":"Nginx/","title":"Nginx","keywords":"","body":"Nginx 学习 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Nginx/Nginx学习笔记.html":{"url":"Nginx/Nginx学习笔记.html","title":"Nginx 学习","keywords":"","body":"Nginx 学习 反向代理 正向代理和反向代理的区别 概念 正向代理是一个位于客户端和目标服务器之间的代理服务器(中间服务器)。为了从原始服务器取得内容，客户端向代理服务器发送一个请求，并且指定目标服务器，之后代理向目标服务器转交并且将获得的内容返回给客户端。正向代理的情况下客户端必须要进行一些特别的设置才能使用 正向代理 VPN 翻墙：客户端 - 海外VPN - Youtube服务器 反向代理正好相反。对于客户端来说，反向代理就好像目标服务器。并且客户端不需要进行任何设置。客户端向反向代理发送请求，接着反向代理判断请求走向何处，并将请求转交给客户端，使得这些内容就好似他自己一样，客户端并不会感知到反向代理后面的服务，也因此不需要客户端做任何设置，只需要把反向代理服务器当成真正的服务器就好了 区别 正向代理需要你主动设置代理服务器ip或者域名进行访问，由设置的服务器ip或者域名去获取访问内容并返回；而反向代理不需要你做任何设置，直接访问服务器真实ip或者域名，但是服务器内部会自动根据访问内容进行跳转及内容返回，你不知道它最终访问的是哪些机器 正向代理是代理客户端，为客户端收发请求，使真实客户端对服务器不可见；而反向代理是代理服务器端，为服务器收发请求，使真实服务器对客户端不可见 负载均衡 动静分离 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Nginx/安装.html":{"url":"Nginx/安装.html","title":"安装","keywords":"","body":"Nginx 安装 目录 yum / apt 手动安装 源码安装 Shell 安装脚本 docker 安装 dockerfile 安装 yum / apt 手动安装 源码安装 Building nginx from Sources - nginx.org Shell 安装脚本 docker 安装 dockerfile 安装 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Nginx/设置https.html":{"url":"Nginx/设置https.html","title":"配置https","keywords":"","body":"Nginx 配置开启 https 证书 Q&A 、配置 http 自动跳转 https 、自建 https 证书在 chrome 浏览器中提示“不安全” 解决： 默认情况下生成的证书一旦选择信任，在 Edge, Firefox 等浏览器都显示为安全，但是Chrome仍然会标记为不安全并警告拦截，这是因为 Chrome 需要证书支持扩展 Subject Alternative Name, 因此生成时需要特别指定 SAN 扩展并添加相关参数 、`` 、`` 1、网页中存在不带 https 的资源，比如 http 协议的 js 、 css 或图片，那么访问这个 https 页面，某些浏览器（比如IE）就会发出警告，提示页面中存在不安全的内容，并且不会加载这些 http 协议的资源，导致页面错乱等问题 解决： 将 http 资源链接全部更换成相对地址。比如 http://xiechengqi.top/img/logo.png 修改成 /img/logo.png 将全部 http 换成 https Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"NoClass/":{"url":"NoClass/","title":"闲知","keywords":"","body":"目录 计算机小知识 待学习、整理知识 Markdown奇淫技巧 华为国产手机芯片产的是 SoC 不是 CPU 浏览器架构简析 图片格式详解及对比 诗词歌赋 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"NoClass/容易读错的IT术语.html":{"url":"NoClass/容易读错的IT术语.html","title":"容易读错的IT术语","keywords":"","body":"中国程序员容易发音错误的单词 Github 项目地址 单词 正确发音 错误发音 access 🔊 ✅ ['ækses] ❌ [ək'ses] Adobe 🔊 ✅ [ə'dəʊbi] ❌ [əˈdub] admin 🔊 ✅ ['ædmɪn] ❌ [ɜ:d'mɪn] agile 🔊 ✅ ['ædʒaɪl] ❌ [ə'dʒaɪl] amazon 🔊 ✅ ['æməzən] ❌ ['əmeizən; ə'meizən] analogy 🔊 ✅ [əˈnælədʒi] ❌ [ænə'lɒdʒi] Angular 🔊 ✅ ['æŋgjʊlə] ❌ ['æŋɡələ; 'æŋdʒʌlə] AJAX 🔊 ✅ ['eidʒæks] ❌ [ə'dʒʌks] alias 🔊 ✅ [ˈeɪliəs] ❌ [ə'lais] Apache 🔊 ✅ [ə'pætʃɪ] ❌ [ʌpʌtʃ] app 🔊 ✅ [æp] ❌ [eipi'pi] archive 🔊 ✅ ['ɑːkaɪv] ❌ ['ətʃɪv] array 🔊 ✅ [ə'rei] ❌ [æ'rei] ASCII 🔊 ✅ ['æski] ❌ [ɑːsk] aspect 🔊 ✅ ['æspekt] ❌ [ə'spekt] avatar 🔊 ✅ ['ævətɑː] ❌ [ə'vʌtɑ] Azure 🔊 ✅ ['æʒə] ❌ [ˈæzʊʒə] bind 🔊 ✅ [baɪnd] ❌ [bɪnd] cache 🔊 ✅ [kæʃ] ❌ [kætʃ] clang 🔊 ✅ [klæŋ] ❌ [sɪlæŋ] Daemon 🔊 ✅ ['diːmən] ❌ [[dæmən]] deny 🔊 ✅ [dɪ'naɪ] ❌ ['dæni] deque 🔊 ✅ ['dek] ❌ [di'kju] digest 🔊 ✅ n. ['dɑɪdʒɛst] v. [dɑɪ'dʒɛst] ❌ ['dɪgɛst] Dijkstra 🔊 ✅ Dutch:[ˈdɛikstra] English:[ˈdaɪkstrə] Django 🔊 ✅ [ˈdʒæŋɡoʊ] ❌ [diˈdʒæŋɡoʊ] doc 🔊 ✅ [dɒk] ❌ [daʊk] event 🔊 ✅ [ɪ'vent] ❌ ['ɪvənt] facade 🔊 ✅ [fə'sɑːd] ❌ ['feikeid] fedora 🔊 ✅ [fɪ'dɔːrə] ❌ ['fedərə] format 🔊 ✅ ['fɔːmæt] ❌ [fɔ'mæt] Git 🔊 ✅ [ɡɪt] ❌ [dʒɪt] GNU 🔊 ✅ [gnu:] GUI 🔊 ✅ [ˈɡu:i] Haskell 🔊 ✅ [ˈhæskəl] ❌ [hæˈskəl] height 🔊 ✅ [haɪt] ❌ [heɪt] hidden 🔊 ✅ ['hɪdn] ❌ ['haɪdn] image 🔊 ✅ ['ɪmɪdʒ] ❌ [ɪ'meɪdʒ] implement 🔊 ✅ ['ɪmplɪm(ə)nt] ❌ [ɪm'plem(ə)nt] integer 🔊 ✅ ['ɪntɪdʒə] ❌ [ˈɪntaɪgə] issue 🔊 ✅ ['ɪʃuː] ❌ [ˈaɪʃuː] Java 🔊 ✅ ['dʒɑːvə] ❌ ['dʒɑːvɑː] jpg(jpeg) 🔊 ✅ ['dʒeɪpeɡ] ❌ [ˈdʒeɪˈpi:ˈdʒiː] key 🔊 ✅ [kiː] ❌ [kei] lambda 🔊 ✅ [ˈlæmdə] ❌ [ˈlɒŋmdɑ] linear 🔊 ✅ ['lɪnɪə] ❌ ['laɪə] Linux 🔊 ✅ ['lɪnəks] ❌ [ˈlɪnʌks; ˈlɪnjuːks] locale 🔊 ✅ [ləʊ'kɑːl] ❌ [ˈloʊk(ə)l] main 🔊 ✅ [meɪn] ❌ [mɪn] margin 🔊 ✅ ['mɑːdʒɪn] ❌ ['mʌgɪn] matrix 🔊 ✅ [ˈmeɪtrɪks] ❌ [ˈmɑ:trɪks] maven 🔊 ✅ ['meɪvn] ❌ ['maːvn] Microsoft 🔊 ✅ ['maikrəusɔft] ❌ ['mikrəusɔft] module 🔊 ✅ ['mɒdjuːl] ❌ ['məʊdl] nginx ✅ Engine X null 🔊 ✅ [nʌl] ❌ [naʊ] OS X ✅ OS ten phantom 🔊 ✅ ['fæntəm] ❌ ['pæntəm] parameter 🔊 ✅ [pə'ræmɪtə] ❌ ['pærəmɪtə] privilege 🔊 ✅ ['prɪvəlɪdʒ] ❌ ['prɪvɪlɪdʒ] putty 🔊 ✅ [ˈpʌti] ❌ [ˈpuːti] query 🔊 ✅ ['kwɪəri] ❌ ['kwaɪri] Qt 🔊 ✅ [kjuːt] Realm 🔊 ✅ [relm] ❌ [riəlm] resume 🔊 ✅ [rɪ'zju:m] ❌ [rɪ'sju:m] resolved 🔊 ✅ [rɪ'zɒlvd] ❌ [rɪ'səʊvd] resort 🔊 ✅ [rɪˈzɔ:t] ❌ [rɪˈsɔ:t] retina 🔊 ✅ ['retɪnə] ❌ [ri'tina] san jose 🔊 ✅ [sænhəu'zei] ❌ [sæn'ju:s] safari 🔊 ✅ [sə'fɑːrɪ] ❌ [sæfərɪ] scheme 🔊 ✅ [skiːm] ❌ [s'kæmə] segue 🔊 ✅ ['sɛɡwe] ❌ [se'dʒ] SQL ✅ [ˈsiːkwəl]/[ˈesˈkjuːˈel] sudo ✅ ['suːduː] suite 🔊 ✅ [swiːt] ❌ [sjuːt] typical 🔊 ✅ ['tɪpɪkl] ❌ ['taɪpɪkəl] Ubuntu 🔊 ✅ [ʊ'bʊntʊ] ❌ [juː'bʊntʊ] variable 🔊 ✅ ['veəriəbl] ❌ [və'raiəbl] vue 🔊 ✅ [v'ju:] ❌ [v'ju:i] width 🔊 ✅ [wɪdθ] ❌ [waɪdθ] YouTube 🔊 ✅ ['juː'tjuːb] ❌ ['juː'tʊbɪ] Lucene 🔊 ✅ [lu'siːn] ❌ ['lu:sən] debt 🔊 ✅ [det] ❌ [de'bit] Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"NoClass/Navicat持续激活.html":{"url":"NoClass/Navicat持续激活.html","title":"Linux 持续激活 Navicat","keywords":"","body":"Linux 下 Navicat 持续激活 Navicat 默认是有一个月的使用时间，到了一个月后，删除 ~/.navicat64/system.reg 则会重新计时 如果重新安装 Navicat，必须先手动删除 ~/.navicat64 文件夹，否则安装会加载这个文件夹，导致使用出错 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"NoClass/内网穿透.html":{"url":"NoClass/内网穿透.html","title":"内网穿透","keywords":"","body":"内网穿透 Natapp Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"NoClass/Linux-electron-tutorial.html":{"url":"NoClass/Linux-electron-tutorial.html","title":"Linux electron 学习记录","keywords":"","body":"Linux electron 学习记录 electron Electron（ 原名为 Atom Shell ）是 GitHub 开发的一个开源库，可以通过使用 HTML、CSS、JavaScript 创建跨平台的桌面应用 它允许使用 Node.js（作为后端）和 Chromium（作为前端）完成桌面 GUI 应用程序的开发 一个基础的 Electron 包含三个文件：package.json（元数据）、main.js（代码）和 index.html（图形用户界面） Electron 对应不同平台可执行文件：Windows 中为 electron.exe、macOS 中为 electron.app、Linux 中为 electron 开发者可以自行添加标志、自定义图标、重命名或编辑 Electron 可执行文件 Electron 现已被多个开源 Web 应用程序用于前端与后端的开发，著名项目包括 GitHub 的 Atom、GitHub 客户端、WhatsApp Windows 及 Mac 客户端和微软的 Visual Studio Code Electron 使用 web 页面作为它的 GUI，所以你能把它看作成一个被 JavaScript 控制的，精简版的 Chromium 浏览器 由于 Electron 本身就是基于 Chromium 的，所以它的基础大小就已经很大了，应该 50M 左右 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"NoClass/MarkdownSkills.html":{"url":"NoClass/MarkdownSkills.html","title":"记录 Markdown 的各种小技巧","keywords":"","body":"记录 Markdown 的各种小技巧 代码块为markdown源码，紧接着展示效果 Simply press command + F to search for a keyword Simply press command + F to search for a keyword ` ## [Badidu](www.baidu.com)公司 Badidu公司 图片居中显示 图片设置链接 [![百度](https://www.baidu.com/img/bd_logo1.png?where=super)](https://www.baidu.com) 未设置图片链接 设置图片点击跳转到　https://www.baidu.com 设置图片缩放、大小 在图片下加标注 标注内容 百度 | 一个普通标题 | 一个普通标题 | 一个普通标题 | | ------ | ------ | ------ | | 短文本 | 中等文本 | 稍微长一点的文本 | | 稍微长一点的文本 | 短文本 | 中等文本 | 一个普通标题 一个普通标题 一个普通标题 短文本 中等文本 稍微长一点的文本 稍微长一点的文本 短文本 中等文本 | 左对齐标题 | 右对齐标题 | 居中对齐标题 | | :------| ------: | :------: | | 短文本 | 中等文本 | 稍微长一点的文本 | | 稍微长一点的文本 | 短文本 | 中等文本 | 左对齐标题 右对齐标题 居中对齐标题 短文本 中等文本 稍微长一点的文本 稍微长一点的文本 短文本 中等文本 | 命令 | 解释 | | --- | --- | | ps -aux &#124; grep mysql | 表格中竖线显示 | | ps -aux &#124; grep mysql | 表格代码中竖线显示 | | &lt;code&gt; | 表格中左、右尖括号显示 | | &amp; | 表格中 And 符号显示 | | 第一行 第二行 | 表格中换行 | | -&ensp;- | 半角空格 | | -&emsp;- | 全角空格 | 示例 解释 ps -aux | grep mysql 表格中竖线显示 ps -aux | grep mysql 表格代码中竖线显示 表格中左、右尖括号显示 & 表格中 And 符号显示 第一行 第二行 表格中换行 - - 半角空格 - - 全角空格 |、-、:之间的多余空格会被忽略，不影响布局 默认标题栏居中对齐，内容居左对齐 -:表示内容和标题栏居右对齐，:-表示内容和标题栏居左对齐，:-:表示内容和标题栏居中对齐 内容和|之间的多余空格会被忽略，每行第一个|和最后一个|可以省略，-的数量至少有一个 ├── coding │ ├── baidutranslate.ipynb │ ├── Python datetime.ipynb │ ├── Python hashlib.ipynb │ ├── Python urllib.ipynb │ ├── Python 多进程和多线程.ipynb │ ├── Python 模版.ipynb │ ├── test1.py │ ├── test.py │ └── 未命名.ipynb ├── learning.py └── src 制表符 ┌ └ ┐ ┘ ─ │ ├ ┤ ┬ ┴ ┼ 就是制作表格用的符号。 可以用输入法自带的特殊符号输入，也可以从现成的表格中撷取粘贴 | 单词 | 正确发音 | 错误发音 | | ---- | ------- | ------- | | access [🔊](http://dict.youdao.com/dictvoice?audio=access&type=1) | ✅ ['ækses] | ❌ [ək'ses] | | Adobe [🔊](http://dict.youdao.com/dictvoice?audio=Adobe&type=2) | ✅ [ə'dəʊbi]| ❌ [əˈdub] | 单词 正确发音 错误发音 access 🔊 ✅ ['ækses] ❌ [ək'ses] Adobe 🔊 ✅ [ə'dəʊbi] ❌ [əˈdub] 图片九公格 | [![Mega-Bundle-HUGO](https://gethugothemes.com/wp-content/uploads/edd/2019/09/Mega-Bundle-HUGO.png)](https://themefisher.com/products/hugo-mega-bundle/) | [![Phantop](https://gethugothemes.com/wp-content/uploads/edd/2019/06/Phantom.jpg)](https://gethugothemes.com/products/phantom-hugo-theme/) | [![redlab](https://gethugothemes.com/wp-content/uploads/edd/2019/09/redlab-hugo-thumbnail.jpg)](https://gethugothemes.com/products/redlab-hugo/) | |:---:|:---:|:---:| | **Hugo Mega Bundle** | **Phantom** | **Red Lab** | | [![northendlab](https://gethugothemes.com/wp-content/uploads/2019/11/Blogplate-Blog-Template.png)](https://gethugothemes.com/products/northendlab/) | [![Influencer](https://gethugothemes.com/wp-content/uploads/2019/11/Influencer.png)](https://gethugothemes.com/products/influencer-hugo/) | [![Kross](https://gethugothemes.com/wp-content/uploads/edd/2019/07/kross-portfolio-template.jpg)](https://gethugothemes.com/products/kross-hugo-theme/) | | **Northendlab** | **Influencer** | **Kross** | | [![Timer](https://gethugothemes.com/wp-content/uploads/edd/2019/07/Timer.jpg)](https://gethugothemes.com/products/timer-hugo-theme/) | [![Parsa](https://gethugothemes.com/wp-content/uploads/edd/2019/07/parsa-768x576.jpg)](https://gethugothemes.com/products/parsa-hugo-theme/) | [![all](https://gethugothemes.com/wp-content/uploads/2019/12/get-more-hugo-themes.png)](https://gethugothemes.com/shop/) | | **Timer** | **Parsa** | **More Hugo Themes** | Hugo Mega Bundle Phantom Red Lab Northendlab Influencer Kross Timer Parsa More Hugo Themes Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"NoClass/RaspeberryPi.html":{"url":"NoClass/RaspeberryPi.html","title":"使用树莓派 3B 遇到的问题","keywords":"","body":"使用树莓派 3B 遇到的问题 树莓派挂载硬盘 # 查看系统上的文件系统的磁盘使用情况统计 df -h // 树莓派源的配置 修改/etc/apt/sources.list 命令sudo apt update就是在这个文件里找软件源镜像站进行缓存更新 pi@raspberrypi:/etc/apt $ cat sources.list # Uncomment line below then 'apt-get update' to enable 'apt-get source' # 注释掉原来的软件源 #deb-src http://archive.raspbian.org/raspbian/ stretch main contrib non-free rpi # 添加替换的软件源 deb http://mirrors.aliyun.com/raspbian/raspbian/ stretch main contrib non-free rpi 修改好文件后执行命令：sudo apt update即完成软件源的替换了 常用软件源中科大 deb http://mirrors.ustc.edu.cn/raspbian/raspbian/ jessie main contrib non-free rpi 清华 deb https://mirrors.tuna.tsinghua.edu.cn/raspbian/raspbian/ jessie main contrib non-free rpi 大连东软 deb http://mirrors.neusoft.edu.cn/raspbian/raspbian/ jessie main contrib non-free rpi 重庆大学 deb http://mirrors.cqu.edu.cn/raspbian/raspbian/ jessie main contrib non-free rpi 浙江大学 deb http://mirrors.zju.edu.cn/raspbian/raspbian/ jessie main contrib non-free rpi 阿里云 deb http://mirrors.aliyun.com/raspbian/raspbian/ jessie main contrib non-free rpi 搜狐 deb http://mirrors.sohu.com/raspbian/raspbian/ jessie main contrib non-free rpi 元智大学（中国台湾） deb http://ftp.cse.yzu.edu.tw/Linux/raspbian/raspbian/ jessie main contrib non-free rpi 新加坡国立大学 deb http://mirror.nus.edu.sg/raspbian/raspbian/ jessie main contrib non-free rpi 北陆先端科学技术大学院大学（日本知名镜像站，日常出口带宽2g） deb http://ftp.jaist.ac.jp/raspbian/ jessie main contrib non-free rpi 牛津大学 deb http://mirror.ox.ac.uk/sites/archive.raspbian.org/archive/raspbian/ jessie main contrib non-free rpi 美国Berkely大学 deb http://mirrors.ocf.berkeley.edu/raspbian/raspbian/ jessie main contrib non-free rpi 美国俄克拉荷马大学 deb http://reflection.oss.ou.edu/raspbian/raspbian/ jessie main contrib non-free rpi 南非知名软件源 deb http://mirror.liquidtelecom.com/raspbian/raspbian/ jessie main contrib non-free rpi 默认源（带重定向by mirrorbrain） deb http://mirrordirector.raspbian.org/raspbian/ jessie main contrib non-free rpi 官方源 deb https://archive.raspbian.org/raspbian/ jessie main contrib non-free rpi ssh 登录，开启后台运行命 screen - 希望断开 ssh 即关闭 screen 内执行任务，当再次登录还能从上次任务结束出开始，不必重新执行 安装 screen :sudo apt install screen 开启一个后台：screen -dmS xxx( 后台名字 ) 暂时退出当前 screen :CTRL + a + d 显示已开启的后台：screen -ls 返回某一个后台“xxx” :screen -r xxx nohup - 即使断开 ssh 连接，使用 nohup 执行的任务仍然会在后台运行，非常适用于远程使用服务器下载 如果你正在运行一个进程，而且你觉得在退出帐户时该进程还不会结束，那么可以使用 nohup 命令。该命令可以在你退出帐户/关闭终端之后继续运行相应的进程。nohup 就是不挂起的意思( no hang up) nohup [命令] [参数] [&] # 最后加上 & ，这样即使退出当前终端，命令仍然会在后台运行 安装中文字库 由于树莓派默认是采用英文字库的，而且系统里没有预装中文字库，所以即使你在locale中改成中文，也不会显示中文，只会显示一堆方块。因此需要我们手动来安装中文字体，好在有一个中文字体是免费开源使用 # 安装 sudo apt-get install ttf-wqy-zenhei # 刷新字库缓存 sudo fc-cache 在命令状态下输入一下代码，打开配置界面 # 进入配置界面 sudo raspi-config # 当想直接进入字体配置可用 sudo dpkg-reconfigure locales 树莓派命令行打开的配置界面 树莓派命令行打开的字体配置界面 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"NoClass/华为国产手机芯片SoC.html":{"url":"NoClass/华为国产手机芯片SoC.html","title":"华为国产手机芯片SoC","keywords":"","body":"首先，什么是CPU?就是中央处理单元，它负责把数据读入计算并输出。所以，无论什么时候谈到CPU，一定是数据的处理和计算部分，这是必须要满足的基本要求。 之所以你们会发生混淆，是因为你们不知道，除了数据处理，还有什么其他部分。简单来说，CPU除了内部的Cache和指令存储器和一些缓冲，就没有什么可供存储数据和指令的了。所以，对于程序来说，运行时候需要的代码数据都是在内存里面的，CPU从内存里面把数据和代码取出来放到Cache里面，再从Cache里取出需要的数据。 同样，内存容量是有限的，如果找不到数据，就要从硬盘里面或者nandflash进行数据读取，或者直接读取，或者拷贝到DDR里面再进行读取，这取决于这些硬件的结构了。但是，每种架构CPU的指令是固定的，指令不会区分什么具体的DDR或者nand的架构，所以，我们需要内存控制器、硬盘控制器、nand控制器，也就是所谓的外围IP，通常，如果Cache不命中，如果需要从内存读取数据，这条访问指令就会被内存控制器获取，它进行分析后会把相应的数据从内存颗粒里面读出来发回给CPU。如果是nand的，它有自己的寄存器，可以通过对寄存器操作来实现数据的读取，这些数据仍然由控制器送给CPU。类似还有网络控制器之类的，CPU的命令都是要由这些控制器去具体实施的。 一个CPU的外部端口都会有地址总线和数据总线，我们选择一种总线，把CPU和这些外围IP连起来，让CPU可以和这些IP进行通讯，完成数据的计算和输入输出，这样就变成了一个具有实际意义的系统了。 在这一点上，不同的厂商做法不同。 对于Intel而言，他是有晶圆的老大，也就是说，它的CPU由他自己设计好后入场流片，生产好之后就诞生一个正方形的下面有很多针脚的东西，就是你们口中的CPU了。它的内存控制器在主板上的北桥里面，而硬盘控制器网络控制器啥的都在主板上的南桥。从这里可以看出，它的CPU和各类控制器都是分开的，因而面积大，功耗高，性能强。 ARM就不一样，首先ARM属于无晶圆。什么意思？就是ARM自己不会去流片，想用ARM的CPU怎么办？直接购买授权，而后ARM就直接把它的CPU的源代码发给你了。我们实验室就有ARM7和ARM11的源代码，这些代码我也读过不少。从这点来说，ARM的确胆子很大。 ARM的功耗较低面积较小，所以各大厂商通常会把它的CPU和各类外围IP都放到一起，然后自己拿着图纸去流片，生产出来的也是一个正方形，下面有很多引脚，这个东西不仅包含了CPU，还包含了其他的控制器，这个东西就叫做SOC(system on chip)。从英文来看，所谓的四核SOC什么的，本意就不是单指CPU，而是四核系统。 因特尔绝对不会给你看它的RTL代码，只会给你他芯片的spec。 所以目前各大厂商所做的事情，就是买来ARM的授权，得到ARM处理器的源代码，而后自己搞一些外围IP(或者买或者自己设计)，组成一个SOC后，去流片。不同的SOC，架构不同(就是CPU如何和IP联系起来，有的以总线为核心，有的以DDR为核心)，所以，海思是拥有自主产权的SOC架构。可是，无论任何厂商，再怎么折腾，都没有怎么动过CPU，ARM核心就好好的呆在那里，那是中央处理器。你要说成是自己的CPU，对不起，ARM首先就不会同意，因为你侵犯了它的知识产权。 当然，厂商会对SOC里面的ARM核做一些小的修改，例如我们就给ARM7加过Cache。高通也做过修改，但是，都只是在边角料上做一些小小的改动，根本谈不上自己产权的CPU！ 其实，有一个方法，就可以很好的验证所谓海思是不是自主产权的CPU了。对于IP产权法来说，如果这东西是你自主产权，那么你就有一个权力，就是你可以把这个东西授权给其它公司。如果海思真像各位所说，CPU是有自主产权的，那么华为完全可以把其中的核心卖给其他厂商。可我告诉你，世界上任何厂商都没有这个权利，只有ARM自己有。这就是你们自己打自己的脸了 　　所以，说了这么多，所谓自主产权的CPU，什么国产CPU，纯粹是不着边的事情。 原文链接 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"NoClass/图片格式详解及其对比.html":{"url":"NoClass/图片格式详解及其对比.html","title":"图片格式详解及其对比","keywords":"","body":"图片格式详解及其对比 图像的基本数据结构 要讲图片格式还先得从图像的基本数据结构说起，在计算机中, 图像是由一个个像素点组成，像素点就是颜色点，而颜色最简单的方式就是用RGB或RGBA表示，如图所示 常见的图片格式有 bmp、jpg(jpeg)、png、gif、webp 等 如果有 A 通道就表明这个图像可以有透明效果 R、G、B 每个分量一般是用一个字节( 8 位 )来表示，所以图 ( 1 ) 中每个像素大小就是 3 × 8 = 24 位图, 而图( 2 )中每个像素大小是 4 × 8 = 32 位 三点补充介绍 图像 y 方向正立或倒立 图像是二维数据，数据在内存中只能一维存储，二维转一维有不同的对应方式。比较常见的只有两种方式: 按像素 “行排列” 从上往下或者从下往上 如图所示的图像有 9 个像素点，如果从上往下排列成一维数据是( 123456789 )， 如果是从下往上排列则为( 789456123 ) 只所以会有这种区别是因为，前一种是以计算机图形学的屏幕坐标系为参考( 右上为原点，y 轴向下 )，而另后一种是以标准的数学坐标系为参考( 右下为原点，y 轴向上 )。这两个坐标系只是 y 值不一样，互相转换的公式为: y2 = height-1-y1 y1、y2 分别为像素在两个坐标系中的 y 坐标，height 为图像的高度 不过好像只有 bmp 图片格式以及 windows 下的 GDI，GDI+ 是从下往上排列，其它比如 DirectX、OpenGL、Cocoa( NSImage、UIImage )，OpenCV 等都是从上往下排列 RGB排列顺序 不同图形库中每个像素点中RGBA的排序顺序可能不一样。上面说过像素一般会有RGB,或RGBA四个分量，那么在内存中RGB的排列就有6种情况，如下: RGB RBG GRB GBR BGR BRG RGBA的排列有24种情况，这里就不全部列出来了 不过一般只会有RGB,BGR, RGBA, RGBA, BGRA这几种排列据。 绝大多数图形库或环境是BGR/BGRA排列，cocoa中的NSImage或UIImage是RGBA排列 像素32位对齐 如果是 RGB 24 位图，会存在一个 32 位对齐的问题： 在 x86 体系下，cpu 一次处理 32 整数倍的数据会更快，图像处理中经常会按行为单位来处理像素。24 位图，宽度不是 4 的倍数时，其行字节数将不是 32 整数倍。这时可以采取在行尾添加冗余数据的方式，使其行字节数为 32 的倍数 比如，如果图像宽为 5 像素，不做 32 位对齐的话，其行位数为 24 × 5 = 120，120不是32的倍数。是 32 整数倍并且刚好比 120 大的数是 128，也就只需要在其行尾添加 1 字节( 8 位 )的冗余数据即可。(一个以空间换时间的例子) 有个公式可以轻松计算出 32 位对齐后每行应该占的字节数 byteNum = ((width × 24 + 31) & ~31)>>3 注意结果是字节数，如果想知道位数，还得 x8 图片格式的必要性 如果将图像原始格式直接存储到文件中将会非常大，比如一个 5000 × 5000 24 位图，所占文件大小 为5000 × 5000 × 3 字节 = 71.5MB，其大小非常可观 如果用 zip 或 rar 之类的通用算法来压缩像素数据，得到的压缩比例通常不会太高，因为这些压缩算法没有针对图像数据结构进行特殊处理 于是就有了 jpeg、png 等格式，同样是图像压缩算法 jpeg 和 png 也有不同的适用场景 所以可以总结如下: jpeg、png 文件之于图像，就相当于 zip、rar 格式之于普通文件(用 zip、rar 格式对普通文件进行压缩) 常见图片压缩格式比较 图片格式分类 无压缩 - 无压缩的图片格式不对图片数据进行压缩处理，能准确地呈现原图片（例如 BMP 格式） 无损压缩 - 压缩算法对图片的所有的数据进行编码压缩，能在保证图片的质量的同时降低图片的尺寸（例如 png 格式） 有损压缩 - 压缩算法不会对图片所有的数据进行编码压缩，而是在压缩的时候，去除了人眼无法识别的图片细节。因此有损压缩可以在同等图片质量的情况下大幅降低图片的尺寸（例如 jpg 格式） PNG 格式 png 是一种无损压缩格式， 压缩大概是用行程编码算法 png 可以有透明效果 png 比较适合适量图、几何图 png 可能有 24 位图和 32 位图之分。32位图就是带有alpha通道的图片 jpeg 比较适合存储色彩 “杂乱” 的拍摄图片，png 比较适合存储几何特征强的图形类图片 JPEG 格式 jpeg 是有损压缩格式，将像素信息用 jpeg 保存成文件再读取出来，其中某些像素值会有少许变化。在保存时有个质量参数可在 [ 0, 100 ] 之间选择，参数越大图片就越保真，但图片的体积也就越大。一般情况下选择 70 或 80 就足够了 jpeg 没有透明信息 jpeg 比较适合用来存储相机拍出来的照片，这类图像用 jpeg 压缩后的体积比较小。其使用的具体算法核心是离散余弦变换、Huffman 编码、算术编码等技术 jpeg格式支持不完全读取整张图片，即可以选择读取原图、1/2、1/4、1/8大小的图片 比如50005000的一张大图，可以只读取将其缩小成1/8后即625625大小的图片。 这样比先完全读取50005000的图像，再用算法缩小成625625大小不知快多少倍。 如果应用需求只需要一张小图时，这种读取方式就可以大显身手了 JPG 格式 jpg 是一种有损的基于直接色的图片格式 jpg 由于采用直接色，jpg可使用的颜色有 1600w 之多（2^24），而人眼识别的颜色数量大约只有 1w 多种，因此 jpg 非常适合色彩丰富图片、渐变色 jpg 有损压缩移除肉眼无法识别的图片细节后，可以将图片的尺寸大幅度地减小 jpg 不适合 icon、logo，因为相比 gif / png-8，它在文件大小上丝毫没有优势 GIF 格式 gif 采用 LZW 压缩算法进行编码，是一种无损的基于索引色的图片格式 gif 由于采用了无损压缩，相比古老的bmp格式，尺寸较小，而且支持透明和动画 缺点是由于 gif 只存储 8 位索引（也就是最多能表达 2^8=256 种颜色），色彩复杂、细节丰富的图片不适合保存为 gif 格式，色彩简单的 logo、icon、线框图适合采用 gif 格式 WEBG 格式 WebP 图片是一种新的图像格式，由 Google 开发 webp 与 png、jpg 相比，相同的视觉体验下，WebP 图像的尺寸缩小了大约 30％ WebP 图像格式还支持有损压缩、无损压缩、透明和动画，理论上完全可以替代 png、jpg、gif 等图片格式，当然目前 webp 的还没有得到全面的支持 BMP 格式 bmp 格式没有压缩像素格式，存储在文件中时先有文件头、再图像头、后面就都是像素数据了，上下颠倒存储 用 windows 自带的 mspaint 工具保存 bmp 格式时，可以发现有四种 bmp 可供选择： 单色: 一个像素只占一位，要么是 0，要么是 1，所以只能存储黑白信息 16 色位图: 一个像素 4 位，有 16 种颜色可选 256 色位图: 一个像素 8 位，有 256 种颜色可选 24 位位图: 就是图( 1 )所示的位图，颜色可有 2^24 种可选，对于人眼来说完全足够了 图片格式　 优点　 缺点 适应场景 GIF 文件小，支持动画、透明，无兼容性问题 只支持256种颜色 色彩简单的logo、icon、动图 JPG 色彩丰富，文件小 有损压缩，反复保存图片质量下降明显 色彩丰富的图片/渐变图像 PNG 无损压缩，支持透明，简单图片尺寸小 不支持动画，色彩丰富的图片尺寸大 logo/icon/透明图 WEBG 文件小，支持有损和无损压缩，支持动画、透明 浏览器兼容性不好 支持webp格式的app和webview Google　关于图片格式的选择指南 参考链接 常见图片格式详解 聊一聊几种常用web图片格式：gif、jpg、png、webp Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"NoClass/计算机小知识.html":{"url":"NoClass/计算机小知识.html","title":"记录一些计算机的小知识","keywords":"","body":"记录一些计算机的小知识 目录 集成电路上的晶体管的摩尔定律 CPU 集成度 CPU、MPU、MCU、SoC详解 常会用到的２的ｎ次幂的值 计算机中的编码格式 静态链接库和动态链接库 TCP/IP 协议端口详解 集成电路上的晶体管的摩尔定律 - Moore's law [Top] 由英特尔（Intel）创始人之一戈登·摩尔提出来的，其内容为：当价格不变时，集成电路上可容纳的元器件的数目，约每隔 18-24 个月便会增加一倍，性能也将提升一倍 目前，摩尔定律也快到尽头了，根据量子力学，2nm 是理论极限值，线宽不能再细了，低于 2nm，隧穿效应就会产生干扰。intel i9 的制程工艺已经到了 14nm CPU 集成度 [Top] 集成度，是指图形中最小线条宽度，集成电路的集成度是指单块芯片上所容纳的元件数目，集成度越高，所容纳的元件数目越多，为此对传统的光刻方法进行了很多改进以满足分辨率的要求，增加集成电路的集成度 集成电路的线宽通常可理解为所加工的电路图形中最小线条宽度，但在 MOS 电路中，人们也常用栅极长度来定义线宽。集成度与线宽有对应关系，即集成度越高，线宽越小，所以，线宽也常用来表示集成电路制造技术水平的高低。 CPU、MPU、MCU、SoC 详解 [Top] CPU - Central Processing Unit - 中央处理单元 CPU 是指单一的中央处理器，是一块超大规模的集成电路，是一台计算机的运算核心和控制核心。CPU 由运算器、控制器和寄存器及实现它们之间联系的数据、控制及状态的总线构成。差不多所有的CPU的运作原理可分为四个阶段：提取(Fetch)、解码(Decode)、执行(Execute)和写回(Writeback)。CPU 从存储器或高速缓冲存储器中取出指令，放入指令寄存器，并对指令译码，并执行指令。所谓的计算机的可编程性主要是指对 CPU 的编程 MPU - Micro Processor Unit - 微处理器 MPU (不是微控制器)，通常代表一个功能强大的 CPU (暂且理解为增强版的CPU吧)，但不是为任何已有的特定计算目的而设计的芯片。这种芯片往往是个人计算机和高端工作站的核心 CPU。Intel X86，ARM　的一些 Cortex-A 芯片如飞思卡尔 i.MX6、全志 A20、TI AM335X 等都属于 MPU。 MCU - Microcontroller Unit - 微控制单元【又称微控制器、单片微型计算机(Single Chip Microcomputer )或者单片机】 MCU 是把 CPU 的频率与规格做适当缩减，并将内存(memory)、计数器(Timer)、USB、A/D转换、UART、PLC、DMA 等周边接口，甚至 LCD 驱动电路都整合在单一芯片上，形成芯片级的计算机，为不同的应用场合做不同组合控制。诸如手机、PC 外围、遥控器，至汽车电子、工业上的步进马达、机器手臂的控制等，都可见到 MCU 的身影。 是指随着大规模集成电路的出现及其发展，是把中央处理器、存储器、定时/计数器（timer/counter）、各种输入输出接口等都集成在一块集成电路芯片上的微型计算机，比如 51，AVR、Cortex-M 这些芯片，内部除了 CPU 外还有 RAM、ROM，可以直接加简单的外围器件(电阻，电容)就可以运行代码了。而如 x86、ARM 这些 MPU 就不能直接放代码了，它只不过是增强版的 CPU，所以得添加 RAM，ROM。 MCU 只是集成了一些更多的功能模块，它本质上仍是一个完整的单片机，有处理器，有各种接口，所有的开发都是基于已经存在的系统架构，应用者要做的就是开发软件程序和加外部设备 SoC - System on Chip - 系统芯片 从狭义角度讲，SoC 是信息系统核心的芯片集成，是将系统关键部件集成在一块芯片上；从广义角度讲，SoC 是一个微小型系统，如果说中央处理器(CPU)是大脑，那么 SoC 就是包括大脑、心脏、眼睛和手的系统 系统芯片是采用低于 0.6um 工艺尺寸的电路，包含一个或者多个微处理器（CPU），并且有相当容量的存储器（用来记忆），在一块芯片上实现多种电路，能够自主地工作，这里的多种电路就是对信号进行操作的各种电路，就像我们的手、脚，各有各的功能 SoC 指的是片上系统，SOC 是系统级的芯片，它既 MCU(51，avr) 那样有内置 RAM、ROM 同时又像 MPU 那样强大，不单单是放简单的代码，可以放系统级的代码，也就是说可以运行操作系统（可以认为是将 MCU 集成化优点与 MPU 强处理力优点合二为一）。 SoC 是一个有专用目标的集成电路，其中包含完整系统并有嵌入软件的全部内容。目前 SoC 大多集成处理器 (包括　CPU、GPU、DSP)、存储器、基带、各种接口控制模块、各种互联总线等，其典型代表为手机芯片。 可以理解为SoC里包涵CPU 比如 ARM 公司生产的就是 CPU，他将自己的所生产的 CPU 设计卖给其他公司，而其他公司就根据 ARM 提供的 CPU 自己添加上自己所需要的各种外设控制器，这就产生了各自手机厂商的手机芯片（SoC） CPU = 运算器 + 控制器，现在几乎没有纯粹的 CPU 了，都是 SoC，常说的 CPU 其实就是 SoC，就像内存有 NandFlash 和普通内存 常会用到的２的ｎ次幂的值 [Top] n 的数值 8 10 16 24 32 ２的ｎ次幂的值 256 1024 65536 16777216 4294967296 三原色光模式（RGB color model），又称RGB颜色模型，以每像素24位（比特s per pixel，bpp）编码RGB值：使用三个8位无符号整数（0到255）表示红色、绿色和蓝色的强度，所以可以显示 16777216 种颜色组合 计算机中的编码格式 [Top] 编码和解码 编码格式发展概述 编码格式　 ASCII 码　 ANSI编码 Unicode 编码 UTF-8编码 由来 计算机起源于美国，ASCII 码利用 8 位二进制数（一个字节）表示字母及常用的符号 随着计算机发展传播，各个地区都需要能显示自己语言的计算机，就要扩展或重建编码格式（大多是基于 ASCII 码扩展，即向下兼容） 收集所有已知的符号并统一编码，二或四字节定长编码方式 是 Unicode 编码的衍生，一种变长的编码方式 例子 ASCII 码 中国制定了 GB2312 编码，用来把中文编进去另外，日本把日文编到 Shift_JIS 里，韩国把韩文编到 Euc-kr 里，各国有各国的标准 经历了定长为 2 字节和定长为 4 字节编码 UTF-8，UTF-32等等 缺点 计算机只能显示英文及一些 ASCII 码中规定的符号 不同语言之间的 ANSI 码之间不能互相转换，这就会导致在多语言混合的文本中会有乱码 浪费存储空间 节约了存储文件所需的硬盘空间，但由于是变长，不利于查找每个符号，所以在内存中编码使用 Unicode 编码 ASCII 码 (发音：/ˈæski/) - American Standard Code for Information Interchange - 美国信息交换标准代码 ASCII 码表 在计算机内存中，统一使用 Unicode 编码，当需要保存到硬盘或者需要传输的时候，就转换为 UTF-8 编码，很多编辑器也可以选择转换为其他格式进行保存。 用记事本编辑的时候，从文件读取的 UTF-8 字符被转换为 Unicode 字符到内存里，编辑完成后，保存的时候再把 Unicode 转换为 UTF-8 保存到文件 浏览网页的时候，服务器一般情况下会是先读取静态的 UTF-8 网页到内存中成为 Unicode 编码，然后将动态修改后的 Unicode 内容转换为 UTF-8 传输到浏览器，因为传输的文本包含大量英文字符，用 UTF-8 编码就能节省空间 C、C++、Python2 内部字符串都是使用当前系统默认编码，而 Python3、Java 内部字符串用 Unicode 保存 不怕浪费空间的，就用 UTF-32；不怕浪费处理时间的，就用完整的 UTF-16，或者索性用 UTF-8。 因为一些历史原因，Windows 记事本的 “Unicode” 这个名号其实相当有误导性。这个编码实际上是 UTF-16 LE LE 是 “小端” 的缩写。因为只要是多字节的数据，就有端序问题，也就是高位字节在先还是低位字节在先的问题。windows 平台默认小端，即低位字节在先 Windows 身上的“历史原因”，在于 Unicode 标准初生的时，字符码其实是 16 位，那时的 UTF-16 就能直接保存 Unicode 字符码，于是 Windows 就直接将自己使用的 UTF-16 LE 编码命名为 “Unicode\"。但是后来发现如果把中文里的罕用字，各种小语种的文字都收进去的话，16 位 65536 个码位仍然是不够用的，Unicode 升级成了 32 位，出现了字符码突破 16 位的字符，UTF-16 从定长码变成了不定长码。字符码在 16 位以内的字符，在新的 UTF-16 编码仍然保持不变 Unicode 字符码是定长 32 位，因为其太浪费空间，很少在计算机中直接用在存储和表达文本上。平常使用的字符里，99% 以上的字符都不会突破2个字节，这就诞生了 UTF-8，UTF-16，UTF-32 等编码标准 UTF-32 是定长编码，UTF-8 和 UTF-16 都是不定长的编码。可以理解为按照编码规则，将一个 Unicode 字符的字符码，编码成 N 个 8 位或者 N 个 16 位，至于 N 是多少，要看具体的字符来定。UTF-32 例外的原因是，它已经足够直接保存 Unicode 的所有字符码了 UTF-8 编码综合了 ASCII 和 Unicode ,会自动根据不同数据类型弹性分配编码字节大小,比如英文字母被编码成 1 个字节,而中文单词则被编码成 3 个字节, 只有很生僻的字符才会被编码成 4 - 6 个字节, 但这就造成了查询数据时会更慢, 是一种用时间换空间的方法 在操作字符串时，我们经常遇到 str 和 bytes 的互相转换。为了避免乱码问题，应当始终坚持使用 UTF-8 编码对 str 和 bytes 进行转换 用记事本编辑的时候，从文件读取的 UTF-8 字符被转换为 Unicode 字符到内存里，编辑完成后，保存的时候再把 Unicode 转换为 UTF-8 保存到文件 浏览网页的时候，服务器会把动态生成的 Unicode 内容转换为 UTF-8 再传输到浏览器 静态链接库和动态链接库 [Top] 库是写好的现有的，成熟的，可以复用的代码。现实中每个程序都要依赖很多基础的底层库 静态/动态链接库都是库函数 本质上来说库是一种可执行代码的二进制形式，可以被操作系统载入内存执行 库有两种：静态库和动态库，Windows 上对应的是 .lib 和 .dll 文件，Linux 对应的是 .a 和 .so 文件 静态链接库 - Static Link Libaray 静态链接库是在编译过程中的链接（ Link ）阶段，链接器把中间代码与相关的静态链接库和应用程序的其他模块组合起来创建最终的可执行文件（例如 .EXE 文件）。在运行时，程序与函数库再无瓜葛，因为所有需要的函数已经拷贝进来了下 若一个程序的依赖只涉及静态链接库，当需要运行可执行文件时，不需要再载入静态库。如果执行时有多个程序调用静态库里的内容，那么在内存中就会存在多个拷贝 代码的装载速度快，执行速度也比较快，因为编译时它只会把你需要的那部分链接进去 应用程序相对比较大，如果多个应用程序使用的话，会被装载多次，浪费内存 如果静态函数库改变了，那么你的程序必须重新编译 如果你的系统上有多个应用程序都使用该库的话，建议把它编译成动态库，这样虽然刚启动的时候加载比较慢，但是多任务的时候会比较节省内存；如果你的系统上只有一到两个应用使用该库，并且使用的 API 比较少的话，就编译成静态库吧，一般的静态库还可以进行裁剪编译，这样应用程序可能会比较大，但是启动的速度会大大提高 Linux 中，通常文件名为“ lib静态库名.a ”，Windows 通常扩展名为 .lib 动态链接库 - Dynamic Link Library 动态链接库是在程序运行的时期（ runtime ）再链接载入（编译过程的链接阶段不链接动态链接库到可执行文件 就是说在程序运行过程中，使用到动态库里函数时我再调用这些函数，而不是一开始就将动态库里所有函数都加载进程序，如果有多个程序调用同一个动态链接库里内容，系统内存中只会有一份数据 共享：多个应用程序可以使用同一个动态库，启动多个应用程序的时候，只需要将动态库加载到内存一次即可 开发模块好：要求设计者对功能划分的比较好 动态函数库的改变并不影响你的程序，所以动态函数库的升级比较方便 Linux中，通常文件名为“lib动态库名.so”，Windows 通常扩展名为 .dll 因此目前实际情况是许多应用程序并不是一个完整的可执行文件，它们被分割成一些相对独立的动态链接库，即 .dll 文件，放置于系统中。当程序真正运行的时候，相应的 .dll 文件才会被调用。一个应用程序可有多个 .dll 文件，同时一个 .dll 文件也可能被几个应用程序所共用，这样的 .dll 文件被称为共享 dll 文件 dll 也是一个被编译过的二进制程序，可以被其他程序调用，但与 exe 不同，dll 不能独立运行，必须由其他程序调用载入内存。dll 中封装了很多函数，只要知道函数的入口地址，就可以被其他程序调用。 通过使用 dll，程序可以实现模块化，程序可以由相对独立的模块组件组成。因为模块是彼此独立的，程序在启动时不用加载所有的模块，因以程序的加载速度更快，而且模块只在相应的功能被请求时才加载 比较静态链接库和动态链接库 简单的说，静态库和应用程序编译在一起，在任何情况下都能运行，而动态库是动态链接，顾名思义就是在应用程序启动的时候才会链接，所以，当用户的系统上没有该动态库时，应用程序就会运行失败。 如果程序是在编译时加载库文件的，就是使用了静态库。如果是在运行时加载目标代码，就成为动态库。换句话说，如果是使用静态库，则静态库代码在编译时就拷贝到了程序的代码段，程序的体积会膨胀。如果使用动态库，则程序中只保留库文件的名字和函数名，在运行时去查找库文件和函数体，程序的体积基本变化不大。 静态库的原则是“以空间换时间”，增加程序体积，减少运行时间; 动态库则是“以时间换空间”，增加了运行时间，但减少了程序本身的体积。 TCP/IP 协议端口详解 [Top] 物理意义上的端口，比如 ADSL Modem、集线器、交换机、路由器用于连接其他网络设备的接口，如 RJ-45 端口、SC 端口等等 逻辑意义上的端口，一般是指 TCP/IP 协议中的端口，端口号的范围从 0 到 65535，比如用于浏览网页服务的 80 端口，用于 FTP 服务的 21 端口等等 引入背景 在 Internet上，各主机间通过 TCP/TP 协议发送和接收数据报，各个数据报根据其目的主机的 ip 地址来进行互联网络中的路由选择，进而把数据报传送到目的主机，但我们知道大多数操作系统都支持多程序（进程）同时运行，那么目的主机应该把接收到的数据报传送给众多同时运行的进程中的哪一个呢？显然这个问题有待解决，端口机制便由此被引入进来 链路层层标识 MAC 网络层标识 IP 传输层标识 PORT 端口分类 按端口号分布划分 知名端口（ Well-Known Ports ） 知名端口即众所周知的端口号，范围从 0 到 1023，这些端口号一般固定分配给一些服务。比如 21 端口分配给 FTP 服务，25 端口分配给 SMTP（简单邮件传输协议）服务，80 端口分配给 HTTP 服务，135 端口分配给 RPC（远程过程调用）服务等等 动态端口（ Dynamic Ports ） 动态端口的范围从 1024 到 65535，这些端口号一般不固定分配给某个服务，也就是说许多服务都可以使用这些端口。只要运行的程序向系统提出访问网络的申请，那么操作系统就可以从这些端口号中分配一个供该程序使用。比如 1024 端口就是分配给第一个向系统发出申请的程序。在关闭程序进程后，就会释放所占用的端口号 不过，动态端口也常常被病毒木马程序所利用，如冰河默认连接端口是7626、WAY 2.4是8011、Netspy 3.0是7306、YAI病毒是1024等等 按协议类型划分 按协议类型划分，可以分为 TCP、UDP、IP 和 ICMP（ Internet 控制消息协议）等端口。下面主要介绍 TCP 和 UDP 端口 TCP 端口 TCP 端口，即传输控制协议端口，需要在客户端和服务器之间建立连接，这样可以提供可靠的数据传输。常见的包括 FTP 服务的 21 端口，Telnet 服务的 23 端口，SMTP 服务的 25 端口，以及 HTTP 服务的 80 端口等等 UDP 端口 UDP 端口，即用户数据包协议端口，无需在客户端和服务器之间建立连接，安全性得不到保障。常见的有 DNS 服务的 53 端口，SNMP（简单网络管理协议）服务的 161 端口，QQ 使用的 8000 和 4000 端口等等 TCP/UDP端口列表 Linux 下关于端口操控 查看进程占用端口和端口占用进程命令 通过端口入侵计算机 入侵者通常会用扫描器对目标主机的端口进行扫描，以确定哪些端口是开放的，从开放的端口，入侵者可以知道目标主机大致提供了哪些服务，进而猜测可能存在的漏洞，因此对端口的扫描可以帮助我们更好的了解目标主机，而对于管理员，扫描本机的开放端口也是做好安全防范的第一步 内存中的堆栈详解 [Top] Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"NoClass/诗词.html":{"url":"NoClass/诗词.html","title":"诗词","keywords":"","body":" 蝶恋花·春景 苏轼 花褪残红青杏。 燕子飞时，绿水人家绕。 枝上柳绵吹又少，天涯何处无芳！ 墙里秋千墙外道。 墙外行人，墙里佳人笑。 笑渐不闻声渐，多情却被无情恼! Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"OS/":{"url":"OS/","title":"OS","keywords":"","body":"目录 OS 笔记 OS 专业词语 SoC 与 CPU区别 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"OS/学习笔记.html":{"url":"OS/学习笔记.html","title":"操作系统学习笔记","keywords":"","body":"操作系统学习笔记 计算机组成架构图 计算机组成架构图 计算机架构 - Computer Architecture 定义：计算机架构是描述计算机系统功能，组织和实现的一组规则和方法。而这组规则和方法是通过 ISA(指令集架构) 和 Microarchitecture(微架构) 实现的 指令集架构与微架构（一套用于执行指令集的微处理器设计方法）不同。使用同一个指令集架构可以有不同的微架构，例如，Intel 的 Pentium 和 AMD 的 AMD Athlon，两者几乎采用相同版本的 x86 指令集体系，但是两者在内部设计（即微架构）上有本质的区别 人们通常所说的 X86 ARM 架构分别采用的是复杂指令集和精简指令集，桌面及服务器端通常是 X86 架构，移动端通常是 ARM 架构。例如苹果、ThinkPad 等等电脑都是 X86，苹果、三星等手机都是 ARM 架构。所以理论上苹果电脑可以安装 windows 系列系统，原来安装的是 windows 系统可以安装 MacOS，（但由于苹果不希望 windows 系统用户可以随意安装 MacOS 导致安装十分困难，但理论上完全可行，实际也可以实现，只是即使实现了也难以像苹果电脑使用起来舒服），手机也是同理 计算机架构图 CPU 的指令集架构（又称指令集或指令集体系） - ISA - Instruction Set Architecture 指令集架构是规定程序设计如何使用指令的规范，指令集架构为汇编语言的设计师和编译器所见 计算机是由硬件和软件组成的，而它们之间的桥梁是 ISA，换句话说，硬件的功能通过ISA提供出来，而软件通过 ISA 规定的指令使用硬件。 机器语言（即二进制机器指令）是由声明和指令所组成的，不同的指令集规定的指令也不相同，即机器语言也会由于指令集架构不同而有不同形式，针对同一指令集架构编写的软件可以运行在采用该指令集架构而微架构不同的机器上 定义：是计算机体系结构中与程序设计有关的部分，包含了基本数据类型，指令集，寄存器，寻址模式，存储体系，中断，异常处理以及外部 I/O。指令集架构包含一系列的 opcode 即操作码（机器语言），以及由特定处理器执行的基本命令 指令集架构的种类： 复杂指令集 - CISC - Complex Instruction Set Computing 精简指令集 - RISC - Reduced Instruction Set Computing 显式并发指令集 - EPIC - Explicitly Parallel Instruction Computing 超长指令字指令集 - VLIW CPU 的微架构（又称处理器架构、CPU架构） - Microarchitecture 微架构是 ISA 在处理器的实现，描述处理器是怎样实现功能的，其本质就是一系列硬件实现以满足各种指令集 CPU 执行指令集架构的方法叫做微架构，各品牌为了使 CPU 更高效化，在设计上花费了不少功夫，所以即使是拥有同一指令集架构的 CPU，其性能和负荷方面的特点也是有所不同的。 Microarchitecture 是 ISA 的具体实现，而且对于同一个ISA，可以使用不同技术的微架构 ，比如单周期、多周期以及流水线。比如说 x86 ISA 有 286，386，486，Pretium，Pretium Pro 等实现。目前，微架构涉及以下部分：流水线、并行、存储系统分层结构 微架构包含处理器内部的构成以及这些构成起来的部分如何运行指令集架构，微架构通常被表示成流程图，以描述机器内部组件的连接情况，从一个闸或是寄存器，到算术逻辑单元（ALU），图上分布着数据路径（可以显示数据在微架构的位置）以及控制路径（显示数据该被什么指令所处理） 现代操作系统模块化图 现代操作系统模块化图 操作系统内核 内核，是一个操作系统的核心。是基于硬件的第一层软件扩充，提供操作系统的最基本的功能，是操作系统工作的基础，它负责管理系统的进程、内存、设备驱动程序、文件和网络系统，决定着系统的性能和稳定性 内核并不是计算机系统中必要的组成部分 操作系统内核按照体系结构分为两类 : 微内核　(microkernel)　与宏内核　(macrokernel) 微内核 只是将 OS 中最核心的功能加入内核，包括IPC通信、地址空间分配和基本的调度，这些东西处在内核态运行,自身仅仅是一个消息中转战,用于各种功能间的通讯 其他功能如设备驱动、文件系统、存储管理、网络等作为一个个处于用户态的进程而向外提供某种服务来实现，而且这些处于用户态的进程可以针对某些特定的应用和环境需求进行定制。有时，也称这些进程为服务器。 功能被划分成独立的进程，进程间通过 IPC 进行通信，且模块化程度高，一个服务失效不会影响另外一个服务 微内核小而精炼，运行在内核态（ 管态、系统态 )，开机后常驻内存 微内核的系统有 WindowNT, Minix, Mach, etc. 操作系统微内核 IPC - InterProcess Communication - 进程间通信 宏内核（或单内核） 将 OS 的全部功能都做进内核中，包括调度、文件系统、网络、设备驱动器、存储管理,比如设备驱动管理、资源分配、进程间通信、进程间切换管理、文件系统、存储管理、网络等,这一切都运行在内核态，内核模块间的通讯是通过直接调用其他模块中的函数实现的（只针对于内核态的进程，内核态进程与用户态进程通信需要消息传递），无需消息传递 在一大块代码中实际包含了所有操作系统功能，并作为一个单一进程运行，具有唯一地址空间 宏内核的系统有 Unix, Linux, etc. Linux 是一个宏内核结构，同时又吸收了微内核的优点：模块化设计，支持动态装载内核模块，避免一次性装入所有内核造成内存浪费。但也正因为 Linux 采用宏内核，造成 Linux 系统移植到其他架构平台较难实现（传统 Linux 系统是 X86 架构的） 微内核是一个信息中转站，自身完成很少功能，主要是传递一个模块对另一个模块的功能请求，而宏内核则是一个大主管，把内存管理，文件管理等等一股脑全部接管。 从理论上来看，微内核的思想更好些，微内核把系统分为各个小的功能块，降低了设计难度，系统的维护与修改也容易，但通信带来的效率损失是个问题。宏内核的功能块之间的耦合度太高，造成修改与维护的代价太高，不过在目前的 Linux 里面还不算大问题，因为 Linux 目前还不算太复杂，宏内核因为是直接调用，所以效率是比较高的。 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"OS/术语单词.html":{"url":"OS/术语单词.html","title":"OS 专业词语解析","keywords":"","body":"OS 专业词语解析 CPU - Central Processing Unit - 中央处理单元 GPU - Graphics Processing Unit - 图像处理单元 RAM - Random Access Memory - 随机存取存储器 ISA - Instruction Set Architecture - 指令集架构 RISC - reduced instruction set computing - 精简指令集 CISC - Complex Instruction Set Computing - 复杂指令集 ARM - Advanced RISC Machine - 高级 RISC 机 IPC - Inter-Process Communication - 进程间通信 SoC - System on a Chip - 系统芯片 regiser - 寄存器 CPU Cache - CPU 缓存 Computer memory - storage - 计算机存储器 microkernel - 微内核 macrokernel　- 宏内核 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"OS/SoCCPU.html":{"url":"OS/SoCCPU.html","title":"SoC 与 CPU","keywords":"","body":"首先，什么是CPU?就是中央处理单元，它负责把数据读入计算并输出。所以，无论什么时候谈到CPU，一定是数据的处理和计算部分，这是必须要满足的基本要求。 之所以你们会发生混淆，是因为你们不知道，除了数据处理，还有什么其他部分。简单来说，CPU除了内部的Cache和指令存储器和一些缓冲，就没有什么可供存储数据和指令的了。所以，对于程序来说，运行时候需要的代码数据都是在内存里面的，CPU从内存里面把数据和代码取出来放到Cache里面，再从Cache里取出需要的数据。 同样，内存容量是有限的，如果找不到数据，就要从硬盘里面或者nandflash进行数据读取，或者直接读取，或者拷贝到DDR里面再进行读取，这取决于这些硬件的结构了。但是，每种架构CPU的指令是固定的，指令不会区分什么具体的DDR或者nand的架构，所以，我们需要内存控制器、硬盘控制器、nand控制器，也就是所谓的外围IP，通常，如果Cache不命中，如果需要从内存读取数据，这条访问指令就会被内存控制器获取，它进行分析后会把相应的数据从内存颗粒里面读出来发回给CPU。如果是nand的，它有自己的寄存器，可以通过对寄存器操作来实现数据的读取，这些数据仍然由控制器送给CPU。类似还有网络控制器之类的，CPU的命令都是要由这些控制器去具体实施的。 一个CPU的外部端口都会有地址总线和数据总线，我们选择一种总线，把CPU和这些外围IP连起来，让CPU可以和这些IP进行通讯，完成数据的计算和输入输出，这样就变成了一个具有实际意义的系统了。 在这一点上，不同的厂商做法不同。 对于Intel而言，他是有晶圆的老大，也就是说，它的CPU由他自己设计好后入场流片，生产好之后就诞生一个正方形的下面有很多针脚的东西，就是你们口中的CPU了。它的内存控制器在主板上的北桥里面，而硬盘控制器网络控制器啥的都在主板上的南桥。从这里可以看出，它的CPU和各类控制器都是分开的，因而面积大，功耗高，性能强。 ARM就不一样，首先ARM属于无晶圆。什么意思？就是ARM自己不会去流片，想用ARM的CPU怎么办？直接购买授权，而后ARM就直接把它的CPU的源代码发给你了。我们实验室就有ARM7和ARM11的源代码，这些代码我也读过不少。从这点来说，ARM的确胆子很大。 ARM的功耗较低面积较小，所以各大厂商通常会把它的CPU和各类外围IP都放到一起，然后自己拿着图纸去流片，生产出来的也是一个正方形，下面有很多引脚，这个东西不仅包含了CPU，还包含了其他的控制器，这个东西就叫做SOC(system on chip)。从英文来看，所谓的四核SOC什么的，本意就不是单指CPU，而是四核系统。 因特尔绝对不会给你看它的RTL代码，只会给你他芯片的spec。 所以目前各大厂商所做的事情，就是买来ARM的授权，得到ARM处理器的源代码，而后自己搞一些外围IP(或者买或者自己设计)，组成一个SOC后，去流片。不同的SOC，架构不同(就是CPU如何和IP联系起来，有的以总线为核心，有的以DDR为核心)，所以，海思是拥有自主产权的SOC架构。可是，无论任何厂商，再怎么折腾，都没有怎么动过CPU，ARM核心就好好的呆在那里，那是中央处理器。你要说成是自己的CPU，对不起，ARM首先就不会同意，因为你侵犯了它的知识产权。 当然，厂商会对SOC里面的ARM核做一些小的修改，例如我们就给ARM7加过Cache。高通也做过修改，但是，都只是在边角料上做一些小小的改动，根本谈不上自己产权的CPU！ 其实，有一个方法，就可以很好的验证所谓海思是不是自主产权的CPU了。对于IP产权法来说，如果这东西是你自主产权，那么你就有一个权力，就是你可以把这个东西授权给其它公司。如果海思真像各位所说，CPU是有自主产权的，那么华为完全可以把其中的核心卖给其他厂商。可我告诉你，世界上任何厂商都没有这个权利，只有ARM自己有。这就是你们自己打自己的脸了 　　所以，说了这么多，所谓自主产权的CPU，什么国产CPU，纯粹是不着边的事情。 原文链接 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Tomcat/":{"url":"Tomcat/","title":"Tomcat","keywords":"","body":"Tomcat 学习 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Tomcat/Tomcat学习.html":{"url":"Tomcat/Tomcat学习.html","title":"Tomcat 学习","keywords":"","body":"Tomcat 学习 目录 Tomcat 安装及配置 Tomcat 安装及配置 [Top] 环境 Ubuntu 18.04 Tomcat 7、8、9 JDK-12.0.1 1. 安装 Java $ echo $JAVA_HOME /usr/lib/jvm/jdk-12.0.1 2. 到官网或其他软件镜像站，比如清华镜像站，下载二进制编码包 ( Binary Distributions 或 bin ) 下载后一定要使用非 root 用户解压，然后再将解压后文件转移到/opt/tomcat（可选其他） Tomcat 解压后目录 3. 修改权限 sudo chgrp -R xcq（非root用户） /opt/tomcat sudo chmod -R g+r conf sudo chmod g+x conf sudo chown -R xcq webapps/ work/ temp/ logs/ 4. 修改 systemctl 服务文件 $ sudo vim /etc/systemd/system/tomcat.service [Unit] Description=Apache Tomcat Web Application Container After=network.target [Service] Type=forking Environment=JAVA_HOME= # #需要修改行 (Java home 路径，使用 echo $JAVA_HOME 查看） Environment=CATALINA_PID=/opt/tomcat/temp/tomcat.pid Environment=CATALINA_HOME=/opt/tomcat/apache-tomcat-9.0.27 #需要修改行 Environment=CATALINA_BASE=/opt/tomcat/apache-tomcat-9.0.27 #需要修改行 Environment='CATALINA_OPTS=-Xms512M -Xmx1024M -server -XX:+UseParallelGC' Environment='JAVA_OPTS=-Djava.awt.headless=true -Djava.security.egd=file:/dev/./urandom' ExecStart=/opt/tomcat/apache-tomcat-9.0.27/bin/startup.sh #需要修改行 ExecStop=/opt/tomcat/apache-tomcat-9.0.27/bin/shutdown.sh #需要修改行 User=tomcat Group=tomcat UMask=0007 RestartSec=10 Restart=always [Install] WantedBy=multi-user.target 5. 重新加载 systemd 守护程序，以便它知道我们的服务文件 $ sudo systemctl daemon-reload 6. 调整防火墙 # Tomcat 使用端口 8080 接受传统请求。 输入以下内容允许到该端口的流量： sudo ufw allow 8080 7. 启动 tomcat sudo systemctl start tomcat sudo systemctl status tomcat Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"VPS/":{"url":"VPS/","title":"VPS","keywords":"","body":"目录 AWS [Top] AWS LightSail 创建和基本配置 GCP [Top] VM 实例创建和基本配置.md Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"VPS/AWS_lightsail.html":{"url":"VPS/AWS_lightsail.html","title":"AWS LightSail","keywords":"","body":"AWS LightSail 创建和基本配置 本地使用 ssh 命令行登录 步骤讲解 1、首次登录命令: ssh -i xxx.pem username@host_ip 使用密钥直接登录无需密码 2、xxx.pem 可以在 aws lightsail 服务器控制台下载 ( Lightsail 在您创建实例的每个 AWS 区域中创建一个默认密钥对 ) 每个地区都有自己的默认密钥 3、首次登录用户需要在实例的 \"管理\" 中的 \"连接\" 页面查看 4、登录后切换成 root 用户, 设置 root 密码 sudo su passwd root 5、修改 /etc/ssh/sshd_config 文件 # 被注释去掉注释, 是 no 的改为 yes PermitRootLogin yes PasswordAuthentication yes 6、最后修改 /root/.ssh/authorized_keys , 删除 /root/.ssh/authorized_keys 中 ssh-rsa 前面内容 ( 没有则不修改 ) 7、重启 ssh: sudo service sshd restart 8、再次登录时即可使用 ssh root@host_ip,之后输入密码即可登入 若想使用普通用户登录, 需要切换到 root 下修改普通用户登录密码, 并且需要如上面一样修改 /home/用户名/.ssh/authorized_keys,重启 ssh 后退出再次登录即可使用普通用户 实操截屏 下载私钥到本地 本地切换到私钥目录 本地修改私钥权限为 600 登入远程服务器, sudo su 切换到 root 用户并修改 root 密码 PermitRootLogin yes PasswordAuthentication yes 修改 /root/.ssh/authorized_keys 重启 sshd 服务 ssh root@ip 登录 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"VPS/GCP_VM实例创建和基本配置.html":{"url":"VPS/GCP_VM实例创建和基本配置.html","title":"GCP VM","keywords":"","body":"配置 root passwd登录 首先使用 Google Cloud SSH 连接上去 切换到 root：sudo -i 编辑 ssh 配置文件：vim /etc/ssh/sshd_config 修改以下内容即可PermitRootLogin yes PasswordAuthentication yes 重启 ssh：service sshd restart Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"VPS/ECS和VPS等等.html":{"url":"VPS/ECS和VPS等等.html","title":"ECS和VPS","keywords":"","body":"虚拟主机 一台服务器只安一个操作系统，但利用 Web 服务器（ 比如 Apache、IIS ）识别 Http 请求带的域名，路由到不同的操作系统目录，实现单台服务器单个 Ip 支持多个域名网站的功能。然后再给不同客户配个 FTP 权限，让他们把网页文件传达自己那个目录空间。中国大部分的网站现在还是这个技术模式。所谓云虚拟主机只不过把以前的物理服务器换成云服务器而已 虚拟主机的局限性就是隔离性差，一个用户出问题，其他人也受影响 云虚拟主机 不能直接远程，只能通过 ftp 操作文件 云服务器 & 云主机 利用了 X86 虚拟化技术，把物理服务器一分多，变成配置较小的虚拟机。从而实现多个操作系统同时运行，不同客户可以有自己独立管理员的权限，划分的每个小块都需要一个公网 IP ECS - Elastic Compute Service - 弹性计算服务 VPS vps 是物理机上分割的可以独立 root 的服务器 VPS 利用了 X86 虚拟化技术，把物理服务器一分多，变成配置较小的虚拟机。从而实现多个操作系统同时运行，不同客户可以有自己独立管理员的权限 每个 VPS 需要一个独立的公网 IP 地址 AWS EC2 ( EC2 = ECC = Elastic Compute Cloud ) - 弹性计算云 AWS Lightsail Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"ComputerComposition/":{"url":"ComputerComposition/","title":"ComputerComposition","keywords":"","body":"计算机组成原理学习笔记目录 学习笔记 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"ComputerComposition/学习笔记.html":{"url":"ComputerComposition/学习笔记.html","title":"计算机组成原理学习笔记","keywords":"","body":"计算机组成原理学习笔记 存储层次结构 Intel Core i7存储层次结构 CPU很少会直接访问内存，相反，当CPU请求内存中的数据时，L1 Cache会接管该访问。如果请求的数据在缓存中，那么L1 Cache 就将数据提供给CPU，并结束这次内存访问；如果请求的数据不在L1 Cache中，那么L1 Cache就将请求传递给L2 Cache。 如果L2 Cache有需要的数据，它就将数据返回给L1 Cache，L1 Cache再将数据返回给CPU。后续短时间内对这些数据的访问请求将由L1 Cache而不是L2 Cache满足，因为当Cache缺失时，大多数Cache系统会读取主存中连续的一些字节(这块数据被称为Cache Line，例如80x86 CPU在一次高速缓存缺失时读取16到64个字节)，现在L1 Cache已经有这些数据的副本了。 如果L1 Cache与L2 Cache都不包含需要的数据，那么请求被发送到主存。如果在主存中发现了请求的数据，那么主存子系统就将数据传递给L2 Cache，再由L2 Cache传递给L1 Cache，最后由L1 Cache传递给CPU。同样，数据现在已经在L1 Cache中了，因此，短时间内对这些数据的访问请求将由L1 Cache满足。 如果数据不在主存中，而在虚存中，在某个存储设备上，那么操作系统会接管这次访问操作，从磁盘或其他设备(例如网络存储服务器)读取数据，并将数据传送到主存子系统。主存再通过Cache将数据传送给CPU，过程如前所述。 总线 计算机总线详解图 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"ComputerNetwork/":{"url":"ComputerNetwork/","title":"ComputerNetwork","keywords":"","body":"目录 学习笔记 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"ComputerNetwork/ProWords.html":{"url":"ComputerNetwork/ProWords.html","title":"术语单词","keywords":"","body":" Multiplexing - 多路复用 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"ComputerNetwork/学习笔记.html":{"url":"ComputerNetwork/学习笔记.html","title":"计算机网络学习笔记","keywords":"","body":"计算机网络学习笔记 OSI 模型 - Open System Interconnection Reference Model - 开放式系统互联通信参考模型 OSI 七层结构 OSI 模型在数据传输过程中的应用 两主机通信，从发送者到接收者的过程：在发送者端从第七层（应用层）到第一层（物理层）封装，然后传输到远端接受者，再从第一层（物理层）到第七层（应用层）解封装 应用层（ Application Layer ） 就是应用软件使用的协议，如邮箱使用的 POP3，SMTP、远程登录使用的 Telnet、获取 IP 地址的 DHCP、域名解析的 DNS、网页浏览的 http 协议等；这部分协议主要是规定应用软件如何去进行通信的，为用户的应用程序提供网络服务 表示层（ Presentation Layer ） 决定数据的展现（编码）形式，如同一部电影可以采样、量化、编码为 RMVB、AVI，一张图片能够是 JPEG、BMP、PNG 等 会话层（ Session Layer ） 负责在网络中的两节点之间建立、维持和终止通信。功能包括：建立通信链接，保持会话过程通信链接的畅通，同步两个节点之间的对话，决定通信是否被中断以及通信中断时决定从何处重新发送 传输层（ Transport Layer ） 将一个数据/文件斩件分成很多小段，标记顺序以被对端接收后可以按顺序重组数据，另外标记该应用程序使用的端口号及提供 QOS。（不同的应用程序使用不同计算机的端口号，同样的应用程序需要使用一样的端口号才能正常通信） 定义了一些传输数据的协议和端口号（ WWW 端口 80 等），如：TCP（传输控制协议，传输效率低，可靠性强，用于传输可靠性要求高，数据量大的数据），UDP（用户数据报协议，与 TCP 特性恰恰相反，用于传输可靠性要求不高，数据量小的数据，如 QQ 聊天数据就是通过这种方式传输的）， 主要是将从下层接收的数据进行分段和传输，到达目的地址后再进行重组，常常把这一层数据叫做段 网络层（ Network Layer ） 路由选路，选择本次通信使用的协议（http、ftp等），指定路由策略及访问控制策略。（ IP 地址在这一层） 网络层负责在源机器和目标机器之间建立它们所使用的路由，路由器在该层。协议有：IP、ICMP（互联网控制报文协议）、ARP（地址转换协议）、RARP（反向地址转换协议） 数据链路层（ Datalink Layer ） 根据端口与 MAC 地址，做分组（VLAN）隔离、端口安全、访问控制（ MAC 地址在这一层） 定义了如何让格式化数据以进行传输，以及如何让控制对物理介质的访问，这一层通常还提供错误检测和纠正，以确保数据的可靠传输（交换机、网桥设备在这一层） 物理层（ Physical Layer ） 主要定义物理设备标准，如网线的接口类型、光纤的接口类型、各种传输介质的传输速率等。它的主要作用是传输比特流（就是由 1、0 转化为电流强弱来进行传输，到达目的地后在转化为 1、0，也就是我们常说的数模转换与模数转换），这一层的数据叫做比特，单位是 bit 比特。 OSI 七层模型是一种框架性的设计方法，建立七层模型的主要目的是为解决异种网络互连时所遇到的兼容性问题，其最主要的功能就是帮助不同类型的主机实现数据传输。它的最大优点是将服务、接口和协议这三个概念明确地区分开来，通过七个层次化的结构模型使不同的系统不同的网络之间实现可靠的通讯 OSI 模型所分的七层，在实际应用中，往往有一些层被整合，或者功能分散到其他层去，比如 TCP/IP 模型实际上是 OSI 模型的一个浓缩版本 用户数据经过以上七层后，一串 0、1 组成的二进制流诞生了，然后根据物理层是光纤、电缆、还是空气，二进制流转化为光信号、电信号、电磁波信号在物理介质（物理层）里传输，经过若干个中继交换机（链路层）的交换、经过若干个中继路由器（网络层）的转发，最终到达数据的终点 经以上层最终产生了二进制流，除了物理层之外，每层都会在原始数据前添加一串属于自己的协议头 TCP/IP 模型 TCP/IP 结构图 TCP/IP 与 OSI 对比图 HTTP 响应码 HTTP 响应状态代码指示特定 HTTP 请求是否已成功完成 响应分为五类：信息响应(100–199)，成功响应(200–299)，重定向(300–399)，客户端错误(400–499)和服务器错误 (500–599) Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"ComputerNetwork/小知识.html":{"url":"ComputerNetwork/小知识.html","title":"学习计算机网络中的小知识","keywords":"","body":"学习计算机网络中的小知识 目录 OSI 七层和 TCP/IP 五层 OSI TCP / IP 功能 协议 传输数据 应用层 Application Layer 应用层 文件传输、电子邮件、文件服务、虚拟终端 HTTP、FTP、DHCP、SNMP、SMTP、DNS、Telnet、TFTP、etc 表示层 Presentation Layer 应用层 数据格式转化、数据加密 无 会话层 Session Layer 应用层 接触或建立与别的节点的链接 无 传输层Transport Layer 传输层 提供端对端的接口 TCP、UDP TCP Segment 或 UPD Datagram 网络层Network Layer 网络层 为数据包选择路由 IP、ICMP、IGMP、RIP、OSPF、etc IP Datagram 数据链路层 Data Link Layer 数据链路层 传输有地址的帧以及错误检测功能 PPP、ARP、RARP、MTU、etc Ethernet Frame 物理层 Physical Layer 物理层 以二进制数据形式在物理媒体上传输数据 ISO2110、IEEE802、IEEE802.2、etc Bits 数据从应用层发下来，会在每一层都会加上头部信息，进行封装，然后再发送到数据接收端，即每个数据都会经过数据的封装和解封装的过程 我们可以用一个公式来表示每一层协议的构成：Packet = Protocol Header + Payload Payload 指传入这一层的数据内容 比如：TCP Segment = TCP header + HTTP data 所以对于每一层协议的学习，最后就落实到每一层 header 的学习上了，学习 TCP 就是研究 TCP header 的构成，header 里的每一个 bit 位都有特别的用处，来实现协议层对于网络传输的控制。学习网络协议其实就是学习网络协议的 header Segment、Datagram、Frame、Packet、Fragment、SDU、PDU 《TCP/IP 详解》中的描述： Segment: If the transport protocol is TCP, the unit of data sent from TCP to network layer is called Segment. Datagram: This is used in 2 layers. If the network protocol is IP, the unit of data is called Datagram. At transport layer, if protocol is UDP, we use datagram there as well. Hence, we differentiate them as UDP Datagram, IP Datagram. Frame: Physical layer representation. Packet: It is a more generic term used either transport layer or network layer. TCP Packet, UDP Packet, IP Packet etc. I have not seen it to represent Physical layer data units. Fragment: My guess here is that when a unit of data is chopped up by a protocol to fit the MTU size, the resultant unit of data is called Fragments. But I am guessing. SDU & PDU SDU - Service Data Unit PDU - Protocol Data Unit 封装过程中，对于 OSI 模型中第 N 层而言，从 N+1 层接受到的数据即是此层的 SDU，然后会将接受的数据（即第 N 层的 SDU）加上根据本层协议生成的头（ header ）或尾 （ footer ），然后向下转发；解封过程中，也是一样，从 N-1 层接收到的是发送方 N 层的 PDU，掐头去尾得到本层的 SDU，让后向上转发 所以每一层都有自己的 SDU 和 PDU。简言之就是，向下转发数据时，某一层接受到的数据就是本层的 SDU，而转发出去的就是本层的 PDU，即上一层的 PDU 是本层的 SDU；向上转发数据时，某一层接受到的数据就是本层的 PDU，转发出去的就是本层的 SDU，即上一层的 SDU 是本层的 PDU TCP Header 详解 一个 TCP Header 一般有 20 个字节，如果启用了 options，header 的长度可以达到 60 个 bytes。上图中每一行是 4 个 bytes ( 32 bits ) 计算机中，通常会以 bit，byte，word（ 4 个 byte ）等不同粒度来描述信息，header 的学习一般是以 4 个字节为一个单位来展示的 Source port 和 Destination port 这两个字段分别表示 TCP 连接中的，发送方端口号和接收方的端口号，2 个字节对应端口范围即是 0 ~ 65535 Sequence number 表示发送方的序列号。用来标识从 TCP 发送端向 TCP 接收端发送的数据字节流，它表示在这个报文段中的的第一个数据字节在数据流中的序号；主要用来解决网络包乱序的问题 Acknowledge number 表示接收方 ack 的序列号。接收方收到发送方一个的 TCP 包之后，取出其中的 sequence number，在下一个接收方自己要发送的包中，设置 ack 比特位为 1，同时设置 acknowledge number 为 sequence number + 1。所以接收方的 acknowledge number 表示的是，接收方期待接收的下一个包起始字节的标号，大家可以仔细理解下这一句话。所以 acknowledge number 和 sequence number 是配对使用的 Offset 给出首部中32 bit字的数目，需要这个值是因为任选字段的长度是可变的。这个字段占4bit（最多能表示15个32bit的的字，即 4*15=60个字节的首部长度），因此TCP最多有60字节的首部。然而，没有任选字段，正常的长度是20字节 Tcp Flag TCP 首部中有 6 个标志比特，它们中的多个可同时被设置为 1，主要是用于操控 TCP 的状态机的，依次为 URG、ACK、PSH、RST、SYN、FIN。每个标志位的意思如下： URG - 此标志表示 TCP 包的紧急指针域有效，用来保证 TCP 连接不被中断，并且督促中间层设备要尽快处理这些数据 ACK - 此标志表示应答域有效，就是说前面所说的 TCP 应答号将会包含在 TCP 数据包中；有两个取值：0 和 1，为 1 的时候表示应答域有效，反之为 0。TCP 协议规定，只有 ACK=1 时有效，也规定连接建立后所有发送的报文的 ACK 必须为 1 PSH - 这个标志位表示 Push 操作。所谓 Push 操作就是指在数据包到达接收端以后，立即传送给应用程序，而不是在缓冲区中排队； RST - 这个标志表示连接复位请求。用来复位那些产生错误的连接，也被用来拒绝错误和非法的数据包 SYN - 表示同步序号，用来建立连接。SYN 标志位和 ACK 标志位搭配使用，当连接请求的时候，SYN=1，ACK=0；连接被响应的时候，SYN=1，ACK=1；这个标志的数据包经常被用来进行端口扫描。扫描者发送一个只有 SYN 的数据包，如果对方主机响应了一个数据包回来 ，就表明这台主机存在这个端口；但是由于这种扫描方式只是进行 TCP 三次握手的第一次握手，因此这种扫描的成功表示被扫描的机器不很安全，一台安全的主机将会强制要求一个连接严格的进行 TCP 的三次握手 FIN - 表示发送端已经达到数据末尾，也就是说双方的数据传送完成，没有数据可以传送了，发送 FIN 标志位的 TCP 数据包后，连接将被断开。这个标志的数据包也经常被用于进行端口扫描 Window 窗口大小，也就是有名的滑动窗口，用来进行流量控制 Checksum checksum 是个通用的计算机概念，做完整性校验之用，在很多协议（ IP，UDP，ICMP ）中都有应用，这个值由包的发送方去计算，之后由包的接收方取出来校验 Urgent pointer Urgent pointer 为两个字节的偏移量，加上当前包的 sequence number，用来标记某一个范围内的 bytes 为特殊用途数据 SYN(SYNchronization) - 在连接建立时用来同步序号。当SYN=1而ACK=0时，表明这是一个连接请求报文。对方若同意建立连接，则应在响应报文中使SYN=1和ACK=1. 因此, SYN置1就表示这是一个连接请求或连接接受报文 FIN （finish）即终结的意思， 用来释放一个连接。当 FIN = 1 时，表明此报文段的发送方的数据已经发送完毕，并要求释放连接 TCP 3 次握手和 4 次分手 三次握手 第一次握手：建立连接。客户端发送连接请求报文段，将 SYN 设置为1，假设 Sequence Number 为 x；然后，客户端进入 SYN_SEND 状态，等待服务器的确认 第二次握手：服务器收到 SYN 报文段。服务器收到客户端的 SYN 报文段，需要对这个 SYN 报文段进行确认，设置 Acknowledgment Number 为 x+1( Sequence Number+1 )；同时，自己自己还要发送 SYN 请求信息，将 SYN 位置为1，假设 Sequence Number 为 y；服务器端将上述所有信息放到一个报文段（即 SYN+ACK 报文段）中，一并发送给客户端，此时服务器进入 SYN_RECV 状态 第三次握手：客户端收到服务器的 SYN+ACK 报文段。然后将 Acknowledgment Number 设置为 y+1，向服务器发送 ACK 报文段，这个报文段发送完毕以后，客户端和服务器端都进入 ESTABLISHED 状态，完成 TCP 三次握手 四次分手 第一次分手：主机 1（可以使客户端，也可以是服务器端），设置 Sequence Number 和 Acknowledgment Number，向主机 2 发送一个 FIN 报文段；此时，主机 1 进入FIN_WAIT_1 状态；这表示主机 1 没有数据要发送给主机 2 了 第二次分手：主机 2 收到了主机 1 发送的 FIN 报文段，向主机 1 回一个 ACK 报文段，Acknowledgment Number 为 Sequence Number 加 1；主机 1 进入 FIN_WAIT_2 状态；主机 2 告诉主机 1，我已经知道你没有数据要发送了 第三次分手：主机 2 向主机 1 发送 FIN 报文段，请求关闭连接，同时主机 2 进入 CLOSE_WAIT 状态 第四次分手：主机 1 收到主机 2 发送的 FIN 报文段，向主机 2 发送 ACK 报文段，然后主机 1 进入 TIME_WAIT 状态；主机 2 收到主机 1 的 ACK 报文段以后，就关闭连接；此时，主机 1 等待 2MSL ( 最大报文段生存时间 ) 后依然没有收到回复，则证明 Server 端已正常关闭，那好，主机 1 也可以关闭连接了 为什么要三次握手 在谢希仁著《计算机网络》第四版中讲“三次握手”的目的是“为了防止已失效的连接请求报文段突然又传送到了服务端，因而产生错误”。在另一部经典的《计算机网络》一书中讲“三次握手”的目的是为了解决“网络中存在延迟的重复分组”的问题。 在谢希仁著《计算机网络》书中同时举了一个例子，如下： “已失效的连接请求报文段”的产生在这样一种情况下：client发出的第一个连接请求报文段并没有丢失，而是在某个网络结点长时间的滞留了，以致延误到连接释放以后的某个时间才到达server。本来这是一个早已失效的报文段。但server收到此失效的连接请求报文段后，就误认为是client再次发出的一个新的连接请求。于是就向client发出确认报文段，同意建立连接。假设不采用“三次握手”，那么只要server发出确认，新的连接就建立了。由于现在client并没有发出建立连接的请求，因此不会理睬server的确认，也不会向server发送数据。但server却以为新的运输连接已经建立，并一直等待client发来数据。这样，server的很多资源就白白浪费掉了。采用“三次握手”的办法可以防止上述现象发生。例如刚才那种情况，client不会向server的确认发出确认。server由于收不到确认，就知道client并没有要求建立连接。” 这就很明白了，防止了服务器端的一直等待而浪费资源 白话三次握手 A -> B：吃了吗？ - 第 1 次握手，A 向 B 发出建立沟通请求 B -> A：吃了 - 第 2 次握手，B 听到 A 的话还没回应时，就明白了 A 可以说话，并且 A 的话我能听懂 ( 即 B 确认了 A 的发送能力 )， 回应 A 是为了让 A 知道 B 能听懂他的话并且让 A 判断自己说的话 A 能否听懂，即让 A 确认 B 具有接收能力和判断 B 是否有发送能力 A -> B：知道了 - 第 3 次握手，A 在听到 B 的话还没回应时，就明白了 B 可以听懂我的话并能做出相应的回答，并且自己可以听懂 B 的话 ( 即 A 确认 B 的发送能力和接收能力 ) ，之后 A 回应 B ，是为了让 B 知道自己也能听懂他的话，即让 B 确认 A 具有接收能力，B 收到 A 的回应时，即明白了 A 也能听懂我说的话 ( 即 B 确认了 A 的接收能力 )， 然后就可以愉快沟通了 为什么是三次握手 TCP 需要建立全双工的通道，所以通信双方都要确认对方具有发送和接收信息的能力 第一次 client 发出请求，server 收到了消息，此时 server 就能确认 client 具有发送能力 ，然后回复 “我能收到你的请求，我向你发一个请求”，这一步是为了让 client 确认 server 具有接受的能力和发送能力，client 收到 server 发来的回应，此时 client 就能确认 server 具有接收和发送能力，并做出应答 “我可以收到你的回应”，这一步是为了让 server 确认 client 具有接收能力，server 接收到 client 的应答，此时 server 就能确认 client 具有接收的能力。所以，三次握手就是为了确认 client 和 server 都有收发信息的能力 为什么不是四次握手 通过三次握手就已经达到了互相确认对方收发的能力，所以三次握手是最小成本完成建立全双工信道的方式 为什么不是两次握手 从上面可以知道，两次握手只能完成 client 确认了 server 具有接收和发送能力，以及 server 确认了 client 具有发送能力，但由于缺少了 client 回复 server “我可以收到你的回应”，所以 server 并不能确认 client 是否具有接收能力 可能存在这样情况，client 发出建立连接请求后一段时间的没有收到 server 回应，所以默认丢失，又发送了一遍建立连接请求，这次成功通过两次握手建立连接，通信结束断开连接后，此时之前那个以为丢失的建立连接请求又来了，原来是因为在路上阻塞了，然后 server 收到后以为 client 又需要建立连接，然后分配资源回复 client，并苦苦等着 client 发来请求资源的连接，由于是两次握手，所以连接就这么建立了，但 client 此时并没有建立连接请求呀！所以，server 就一直会等待 client 请求，这样会浪费 server 资源 简述DNS进行域名解析的过程？ 用户要访问www.baidu.com，会先找本机的host文件，再找本地设置的DNS服务器，如果也没有的话，就去网络中找根服务器，根服务器反馈结果，说只能提供一级域名服务器.cn，就去找一级域名服务器，一级域名服务器说只能提供二级域名服务器.com.cn,就去找二级域名服务器，二级域服务器只能提供三级域名服务器.baidu.com.cn，就去找三级域名服务器，三级域名服务器正好有这个网站www.baidu.com，然后发给请求的服务器，保存一份之后，再发给客户端 什么叫CDN？ 即内容分发网络 其目的是通过在现有的Internet中增加一层新的网络架构，将网站的内容发布到 最接近用户的网络边缘，使用户可就近取得所需的内容，提高用户访问网站的速度 什么叫网站灰度发布？ 灰度发布是指在黑与白之间，能够平滑过渡的一种发布方式 AB test就是一种灰度发布方式，让一部用户继续用A，一部分用户开始用B 如果用户对B没有什么反对意见，那么逐步扩大范围，把所有用户都迁移到B上面 来 灰度发布可以保证整体系统的稳定，在初始灰度的时候就可以发现、调整问题，以保证其影响度 Xiechengqi            最新修订时间： 2020-10-09 10:09:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"}}